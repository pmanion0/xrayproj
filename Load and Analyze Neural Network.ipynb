{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Level Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# General Python Packages\n",
    "import os, time, numbers, math\n",
    "\n",
    "# Torch Packages\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim import lr_scheduler, SGD\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import Module\n",
    "\n",
    "# General Analytics Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization / Image Packages\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Randomization Functions\n",
    "from random import random as randuni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TotalSumMeter:\n",
    "    def __init__(self):\n",
    "        self.obs_counter = 0.0\n",
    "        self.total_pred = Variable(torch.FloatTensor(torch.zeros(14)), volatile=True)\n",
    "        self.total_act = Variable(torch.FloatTensor(torch.zeros(14)), volatile=True)\n",
    "        \n",
    "    def update(self, preds, actuals):\n",
    "        self.total_act += actuals.sum(0).cpu()\n",
    "        self.total_pred += preds.sum(0).cpu()\n",
    "        self.obs_counter += len(actuals)\n",
    "        \n",
    "    def get_results(self):\n",
    "        return {\n",
    "            'pred': self.total_pred / self.obs_counter,\n",
    "            'act': self.total_act / self.obs_counter\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassAUCMeter:\n",
    "    \"\"\" Wrapper on the normal AUCMeter to handle multi-class predictions \"\"\"\n",
    "    def __init__(self, num_class):\n",
    "        self.num_class = num_class\n",
    "        self.meters = []\n",
    "        for i in range(self.num_class):\n",
    "            self.meters.append(AUCMeter())\n",
    "\n",
    "    def add(self, output, target):\n",
    "        for i in range(self.num_class):\n",
    "            self.meters[i].add(output[:,i], target[:,i])\n",
    "        \n",
    "    def value(self):\n",
    "        output = []\n",
    "        for i in range(self.num_class):\n",
    "            output.append(self.meters[i].value())\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCMeter:\n",
    "    \"\"\"\n",
    "    SOURCE: https://github.com/pytorch/tnt/blob/master/torchnet/meter/aucmeter.py\n",
    "    \n",
    "    The AUCMeter measures the area under the receiver-operating characteristic\n",
    "    (ROC) curve for binary classification problems. The area under the curve (AUC)\n",
    "    can be interpreted as the probability that, given a randomly selected positive\n",
    "    example and a randomly selected negative example, the positive example is\n",
    "    assigned a higher score by the classification model than the negative example.\n",
    "    The AUCMeter is designed to operate on one-dimensional Tensors `output`\n",
    "    and `target`, where (1) the `output` contains model output scores that ought to\n",
    "    be higher when the model is more convinced that the example should be positively\n",
    "    labeled, and smaller when the model believes the example should be negatively\n",
    "    labeled (for instance, the output of a signoid function); and (2) the `target`\n",
    "    contains only values 0 (for negative examples) and 1 (for positive examples).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(AUCMeter, self).__init__()\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.scores = torch.DoubleTensor(torch.DoubleStorage()).numpy()\n",
    "        self.targets = torch.LongTensor(torch.LongStorage()).numpy()\n",
    "\n",
    "    def add(self, output, target):\n",
    "        if torch.is_tensor(output):\n",
    "            output = output.cpu().squeeze().numpy()\n",
    "        if torch.is_tensor(target):\n",
    "            target = target.cpu().squeeze().numpy()\n",
    "        elif isinstance(target, numbers.Number):\n",
    "            target = np.asarray([target])\n",
    "        assert np.ndim(output) == 1, \\\n",
    "            'wrong output size (1D expected)'\n",
    "        assert np.ndim(target) == 1, \\\n",
    "            'wrong target size (1D expected)'\n",
    "        assert output.shape[0] == target.shape[0], \\\n",
    "            'number of outputs and targets does not match'\n",
    "        assert np.all(np.add(np.equal(target, 1), np.equal(target, 0))), \\\n",
    "            'targets should be binary (0, 1)'\n",
    "\n",
    "        self.scores = np.append(self.scores, output)\n",
    "        self.targets = np.append(self.targets, target)\n",
    "\n",
    "    def value(self):\n",
    "        # case when number of elements added are 0\n",
    "        if self.scores.shape[0] == 0:\n",
    "            return 0.5\n",
    "\n",
    "        # sorting the arrays\n",
    "        scores, sortind = torch.sort(torch.from_numpy(self.scores), dim=0, descending=True)\n",
    "        scores = scores.numpy()\n",
    "        sortind = sortind.numpy()\n",
    "\n",
    "        # creating the roc curve\n",
    "        tpr = np.zeros(shape=(scores.size + 1), dtype=np.float64)\n",
    "        fpr = np.zeros(shape=(scores.size + 1), dtype=np.float64)\n",
    "\n",
    "        for i in range(1, scores.size + 1):\n",
    "            if self.targets[sortind[i - 1]] == 1:\n",
    "                tpr[i] = tpr[i - 1] + 1\n",
    "                fpr[i] = fpr[i - 1]\n",
    "            else:\n",
    "                tpr[i] = tpr[i - 1]\n",
    "                fpr[i] = fpr[i - 1] + 1\n",
    "\n",
    "        tpr /= (self.targets.sum() * 1.0)\n",
    "        fpr /= ((self.targets - 1.0).sum() * -1.0)\n",
    "\n",
    "        # calculating area under curve using trapezoidal rule\n",
    "        n = tpr.shape[0]\n",
    "        h = fpr[1:n] - fpr[0:n - 1]\n",
    "        sum_h = np.zeros(fpr.shape)\n",
    "        sum_h[0:n - 1] = h\n",
    "        sum_h[1:n] += h\n",
    "        area = (sum_h * tpr).sum() / 2.0\n",
    "\n",
    "        return (area, tpr, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, dataset, num_classes = 14):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.num_classes = num_classes\n",
    "        self.is_run = False\n",
    "        \n",
    "    def score_obs(self, data_row):\n",
    "        inputs, actuals = data_row\n",
    "\n",
    "        inputs = Variable(inputs.cuda(), volatile=True)\n",
    "        actuals = Variable(actuals.cuda(), volatile=True)\n",
    "\n",
    "        outputs = self.model(inputs)\n",
    "        preds = outputs.sigmoid()\n",
    "        \n",
    "        return preds, actuals\n",
    "    \n",
    "    def run(self, force_rerun = False):\n",
    "        if self.is_run and not force_rerun:\n",
    "            print(\"Already evaluated this...\")\n",
    "            return None\n",
    "        \n",
    "        self.model.train(False)\n",
    "    \n",
    "        self.m_total_sums = TotalSumMeter()\n",
    "        self.m_auc = MultiClassAUCMeter(self.num_classes)\n",
    "\n",
    "        for data in self.dataset:\n",
    "            preds, actuals = self.score_obs(data)\n",
    "\n",
    "            self.m_total_sums.update(preds, actuals)\n",
    "            self.m_auc.add(preds.data, actuals.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions for Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc_bar(in_evaluator):\n",
    "    auc_out = in_evaluator.m_auc.value()\n",
    "    plt.bar(range(14), [v for v, _, _ in auc_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc_curves(in_evaluator):\n",
    "    index_to_label = {idx: val for val, idx in img_data_train.label_to_index.items()}\n",
    "    auc_out = in_evaluator.m_auc.value()\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "\n",
    "    for idx, (auc, tpr, fpr) in enumerate(auc_out):\n",
    "        disease = index_to_label[idx]\n",
    "        plt.plot(fpr, tpr, label=\"{0} (AUC: {1:0.3f})\".format(disease, auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve by Disease')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_sums(in_evaluator, bar_width = 0.4):\n",
    "    sums_out = in_evaluator.m_total_sums.get_results()\n",
    "    \n",
    "    act = sums_out['act'].data.numpy()\n",
    "    pred = sums_out['pred'].data.numpy()\n",
    "    \n",
    "    indx1 = range(14)\n",
    "    indx2 = [i+bar_width for i in indx1]\n",
    "\n",
    "    plt.bar(indx1, act,  width=bar_width, label=\"Actual\")\n",
    "    plt.bar(indx2, pred, width=bar_width, label=\"Predicted\")\n",
    "    \n",
    "    plt.xticks(indx1, img_data_train.labels, rotation=90)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(fname):\n",
    "    \"\"\"Checks if a file is an image.\n",
    "    Args:\n",
    "        fname (string): path to a file\n",
    "    Returns:\n",
    "        bool: True if the filename ends with a known image extension\n",
    "    \"\"\"\n",
    "    return fname.lower().endswith('.png')\n",
    "\n",
    "def create_label_maps(details_df):\n",
    "    \"\"\" Take a descriptive dataframe and extract the unique labels and map to index values\n",
    "    Args:\n",
    "        details_df: Dataframe with the image details\n",
    "    Returns:\n",
    "        label_list: list of unique labels in the dataframe\n",
    "        label_to_index: map from labels to indices\n",
    "    \"\"\"\n",
    "    \"\"\" TODO: Research paper also excludes these labels but need to figure out how to handle\n",
    "              cases that have these as positive findings (completely exclude?)\n",
    "    excluded_labels = ['Edema','Hernia','Emphysema','Fibrosis','No Finding'\n",
    "                      'Pleural_Thickening','Consolidation']\n",
    "    \"\"\"\n",
    "    excluded_labels = ['No Finding']\n",
    "    \n",
    "    label_groups = details_df['Finding Labels'].unique()\n",
    "    unique_labels = set([label for sublist in label_groups.tolist() for label in sublist.split('|')])\n",
    "    \n",
    "    # Drop some label that we do not want to include\n",
    "    unique_labels = [l for l in unique_labels if l not in excluded_labels]\n",
    "\n",
    "    index_to_label = {idx: val for idx, val in enumerate(unique_labels)}\n",
    "    label_to_index = {val: idx for idx, val in index_to_label.items()}\n",
    "\n",
    "    label_list = list(label_to_index.keys())\n",
    "\n",
    "    return label_list, label_to_index\n",
    "\n",
    "def create_image_list(dir):\n",
    "    \"\"\" Create a full list of images available \n",
    "    Args:\n",
    "        dir (string): root directory of images with subdirectories underneath\n",
    "                      that have the .png images within them\n",
    "    Returns:\n",
    "        image_list: list of tuples with (image_name, full_image_path)\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    dir = os.path.expanduser(dir)\n",
    "    for subfolder in sorted(os.listdir(dir)):\n",
    "        d = os.path.join(dir, subfolder)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        for subfolder_path, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if is_image_file(fname):\n",
    "                    path = os.path.join(subfolder_path, fname)\n",
    "                    image_list.append((fname, path))\n",
    "    return image_list\n",
    "\n",
    "def pil_loader(path):\n",
    "    \"\"\" Opens path as file with Pillow (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    Args:\n",
    "        path (string): File path to the image\n",
    "    Returns:\n",
    "        img: Image in RGB format\n",
    "    \"\"\"\n",
    "    f = open(path, 'rb')\n",
    "    return Image.open(f)\n",
    "    #with open(path, 'rb') as f:\n",
    "    #    return Image.open(f)\n",
    "        #with Image.open(f) as img:\n",
    "        #    return img.load()\n",
    "        \n",
    "def imshow(inp, title=None):\n",
    "    \"\"\" Convert tensor array to an image (only use post-dataset transform) \"\"\"\n",
    "    inp = inp[0]\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayImageSet(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image_root (string): root directory of the images in form image/subfolder/*.png\n",
    "        csv_file (string): path to the CSV data file\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an image given its path.\n",
    "     Attributes:\n",
    "        labels (list): list of the possible label names.\n",
    "        label_to_index (dict): look from label name to a label index\n",
    "        imgs (list): List of (filename, image path) tuples\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_root, csv_file, transform=None, target_transform=None, loader = pil_loader):\n",
    "        \"\"\" Create an instance of the Xray Dataset \"\"\"\n",
    "        img_details = pd.read_csv(csv_file)\n",
    "        \n",
    "        labels, label_to_index = create_label_maps(img_details)\n",
    "        imgs = create_image_list(image_root)\n",
    "\n",
    "        self.imgs = imgs\n",
    "        self.image_details = img_details\n",
    "        self.image_root = image_root\n",
    "        self.labels = labels\n",
    "        self.label_to_index = label_to_index\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.max_label_index = max(label_to_index.values())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get image,labels pair by index\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        fname, path = self.imgs[index]\n",
    "        target = self.get_one_hot_labels(fname)\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Calculate length of the dataset (number of images) \"\"\"\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def get_labels(self, fname):\n",
    "        \"\"\" Return the label string for the file \"\"\"\n",
    "        return self.image_details[self.image_details['Image Index'] == fname]['Finding Labels'].values[0]\n",
    "    \n",
    "    def one_hot_labels(self, labels):\n",
    "        \"\"\" Convert the labels string (with each label separated by |) into 1-hot encoding \"\"\"\n",
    "        if labels == None:\n",
    "            return None\n",
    "        \n",
    "        split_label_indices = [self.label_to_index.get(label)\n",
    "                               for label in labels.split('|')\n",
    "                               if label != 'No Finding']\n",
    "        \n",
    "        out = [1 if idx in split_label_indices else 0 for idx in range(self.max_label_index+1)]\n",
    "        # This code UNHOTs the labels:\n",
    "        # out = '|'.join([index_to_label.get(idx) for idx, val in enumerate(one_hot_tuple) if val == 1])\n",
    "        return out\n",
    "\n",
    "    def get_one_hot_labels(self, fname):\n",
    "        \"\"\" Get the 1-hot encoded label array for the provided file \"\"\"\n",
    "        labels = self.get_labels(fname)\n",
    "        one_hot_labels = self.one_hot_labels(labels)\n",
    "        return torch.FloatTensor(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetBase(base_size = 18, only_update_fc = True, pretrain = True):\n",
    "    \"\"\" ResNet 18 with only final FC layer updatable \"\"\"\n",
    "    m = None\n",
    "    if base_size == 18:\n",
    "        m = models.resnet18(pretrained=pretrain)\n",
    "    elif base_size == 34:\n",
    "        m = models.resnet34(pretrained=pretrain)\n",
    "    elif base_size == 50:\n",
    "        m = models.resnet50(pretrained=pretrain)\n",
    "    elif base_size == 101:\n",
    "        m = models.resnet101(pretrained=pretrain)\n",
    "    elif base_size == 152:\n",
    "        m = models.resnet152(pretrained=pretrain)\n",
    "    \n",
    "    if only_update_fc:\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    m.fc = nn.Linear(m.fc.in_features, len(img_data_train.labels))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_name):\n",
    "    path = '/user/s3_models/' + model_name\n",
    "    params = [18, True, True]\n",
    "    \n",
    "    if model_name == 'resnet18_onlyfc':\n",
    "        path += '/model_10.tar'\n",
    "        params = [18, True, True]\n",
    "    elif model_name == 'resnet18_all_layers':\n",
    "        path += '/model_10.tar'\n",
    "        params = [18, False, True]\n",
    "    elif model_name == 'resnet18_all_layers_imgflip':\n",
    "        path += '/model_10.tar'\n",
    "        params = [18, False, True]\n",
    "    elif model_name == 'resnet18_notpretrained':\n",
    "        path += '/model_20.tar'\n",
    "        params = [18, False, False]\n",
    "    elif model_name == 'resnet18_onlyfc':\n",
    "        path += '/model_10.tar'\n",
    "        params = [18, True, True]\n",
    "    elif model_name == 'resnet34_all_layers_imgflip':\n",
    "        path += '/model_10.tar'\n",
    "        params = [34, True, True]\n",
    "    elif model_name == 'resnet50_all_layers_imgflip':\n",
    "        path += '/model_10.tar'\n",
    "        params = [50, False, True]\n",
    "    \n",
    "    tmp_state = torch.load(path)['state']\n",
    "    model = ResNetBase(base_size = params[0], only_update_fc = params[1], pretrain = params[2])\n",
    "    \n",
    "    model_ft = DataParallel(model).cuda()\n",
    "    model_ft.load_state_dict(tmp_state)\n",
    "    \n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU: 1\n"
     ]
    }
   ],
   "source": [
    "nn_input_size = 224 #1024\n",
    "batch_size = 64\n",
    "pin_mem_setting = True\n",
    "num_gpus = torch.cuda.device_count()\n",
    "num_workers = 10\n",
    "\n",
    "print(\"Number of GPU: {}\".format(num_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms_train = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms_nontrain = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_train = XrayImageSet(image_root = '/user/images_processed/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms_train,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_train.imgs = [img for i, img in enumerate(img_data_train.imgs) if i % 10 >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_val   = XrayImageSet(image_root = '/user/images_processed/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms_nontrain,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_val.imgs = [img for i, img in enumerate(img_data_val.imgs) if i % 10 in (1,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_test  = XrayImageSet(image_root = '/user/images_processed/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms_nontrain,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_test.imgs = [img for i, img in enumerate(img_data_test.imgs) if i % 10 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = set(img_data_train.imgs)\n",
    "val_set = set(img_data_val.imgs)\n",
    "test_set = set(img_data_test.imgs)\n",
    "assert len(train_set.intersection(val_set)) == 0\n",
    "assert len(train_set.intersection(test_set)) == 0\n",
    "assert len(val_set.intersection(test_set)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 78484\n",
      "Validation Set Size: 22424\n",
      "Test Set Size: 11212\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Size: {}\".format(len(img_data_train)))\n",
    "print(\"Validation Set Size: {}\".format(len(img_data_val)))\n",
    "print(\"Test Set Size: {}\".format(len(img_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_loader_train = DataLoader(img_data_train,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = num_workers,\n",
    "                              pin_memory = pin_mem_setting)\n",
    "\n",
    "img_loader_val   = DataLoader(img_data_val,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = num_workers,\n",
    "                              pin_memory = pin_mem_setting)\n",
    "\n",
    "img_loader_test  = DataLoader(img_data_test,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = num_workers,\n",
    "                              pin_memory = pin_mem_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': img_loader_train,\n",
    "    'val': img_loader_val,\n",
    "    'test': img_loader_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading & Analysis of Model Results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mkdir /user/s3_models\n",
    "mkdir /user/s3_models/resnet18_all_layers/\n",
    "mkdir /user/s3_models/resnet18_all_layers_imgflip/\n",
    "mkdir /user/s3_models/resnet18_notpretrained/\n",
    "mkdir /user/s3_models/resnet18_onlyfc/\n",
    "mkdir /user/s3_models/resnet34_all_layers_imgflip/\n",
    "mkdir /user/s3_models/resnet50_all_layers_imgflip/\n",
    "\n",
    "cd /user/s3_models/resnet18_all_layers/\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet18_all_layers/print.txt .\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet18_all_layers/model_10.tar .\n",
    "\n",
    "cd /user/s3_models/resnet18_all_layers_imgflip/\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet18_all_layers_imgflip/print.txt .\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet18_all_layers_imgflip/model_10.tar .\n",
    "\n",
    "cd /user/s3_models/resnet18_notpretrained/\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet18_notpretrained/print.txt .\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet18_notpretrained/model_20.tar .\n",
    "\n",
    "cd /user/s3_models/resnet18_onlyfc/\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet18_onlyfc/print.txt .\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet18_onlyfc/model_10.tar .\n",
    "\n",
    "cd /user/s3_models/resnet34_all_layers_imgflip/\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet34_all_layers_imgflip/print.txt .\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet34_all_layers_imgflip/model_10.tar .\n",
    "\n",
    "cd /user/s3_models/resnet50_all_layers_imgflip/\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet50_all_layers_imgflip/print.txt .\n",
    "aws s3 cp s3://bdh-xrayproj-modelparameters/resnet50_all_layers_imgflip/model_10.tar ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_c.load_state_dict(load_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_load = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = learning_scheduler.last_epoch\n",
    "\n",
    "epoch_evals[epoch] = {}\n",
    "\n",
    "epoch_evals[epoch]['val'] = ModelEvaluator(model_ft, dataloaders['val'])\n",
    "epoch_evals[epoch]['train'] = ModelEvaluator(model_ft, dataloaders['train'])\n",
    "\n",
    "epoch_evals[epoch]['val'].run()\n",
    "#epoch_evals[epoch]['train'].run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_auc_curves(epoch_evals[epoch]['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Training Sums\")\n",
    "#plot_compare_sums(epoch_evals[epoch]['train'])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Validation Sums\")\n",
    "plot_compare_sums(epoch_evals[epoch]['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_opt = test_load['optimizer']\n",
    "load_sched = test_load['scheduler']\n",
    "load_state = test_load['state']\n",
    "# Not used: 'epoch', 'val_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.resnet18(pretrained=True)\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace FC layer\n",
    "model2.fc = nn.Linear(model2.fc.in_features, len(img_data_train.labels))\n",
    "\n",
    "model2_c = DataParallel(model2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_c.forward(Variable(img_data_train[0][0].unsqueeze(0).cuda())).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model_run(model, dataset):\n",
    "    dataset\n",
    "    for data in self.dataset:\n",
    "        inputs, actuals = data\n",
    "\n",
    "        inputs = Variable(inputs.cuda(), volatile=True)\n",
    "        actuals = Variable(actuals.cuda(), volatile=True)\n",
    "\n",
    "        outputs = self.model(inputs)\n",
    "        preds = outputs.sigmoid()\n",
    "\n",
    "        self.m_total_sums.update(preds, actuals)\n",
    "        self.m_auc.add(preds, actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = Variable(torch.FloatTensor(9, 14))\n",
    "for i in range(9):\n",
    "    comparison[0] = conf_a[1] / obs_counter\n",
    "print(comparison.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_model_30.train(mode=False)\n",
    "\n",
    "obs_counter = 0\n",
    "total_pred = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "total_act = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "\n",
    "conf_a = {}\n",
    "conf_b = {}\n",
    "conf_c = {}\n",
    "conf_d = {}\n",
    "for i in range(1,10):\n",
    "    conf_a[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_b[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_c[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_d[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "\n",
    "for data in dataloaders['val']:\n",
    "    print(\"STARTING ITERATION...\")\n",
    "    inputs, labels = data\n",
    "    print(\"PROCESSING FIRST {} OBSERVATIONS\".format(len(inputs)))\n",
    "\n",
    "    inputs = Variable(inputs.cuda())\n",
    "    labels = Variable(labels.cuda())\n",
    "\n",
    "    outputs = out_model_30(inputs).sigmoid()\n",
    "    \n",
    "    total_act += labels.sum(0).cpu()\n",
    "    total_pred += outputs.sum(0).cpu()\n",
    "\n",
    "    # Store statistics (convert from autograd.Variable to float/int)\n",
    "    for i in range(1,10):\n",
    "        t = i/10\n",
    "        conf_a[i] += ((outputs.sigmoid()>t) == (labels>0.5)).sum(0).cpu().float()\n",
    "        conf_b[i] += ((outputs.sigmoid()<t) == (labels>0.5)).sum(0).cpu().float()\n",
    "        conf_c[i] += ((outputs.sigmoid()>t) == (labels<0.5)).sum(0).cpu().float()\n",
    "        conf_d[i] += ((outputs.sigmoid()<t) == (labels<0.5)).sum(0).cpu().float()\n",
    "\n",
    "    obs_counter += len(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

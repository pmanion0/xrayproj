{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ddb34fde-926f-42f6-8bfc-b1b19cb4881d"
    }
   },
   "source": [
    "# High-Level Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "80e3fe37-bc30-43b7-91c3-474b94a16db6"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:279: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "# General Python Packages\n",
    "import os, time, numbers, math\n",
    "\n",
    "# Torch Packages\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim import lr_scheduler, SGD\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import Module\n",
    "\n",
    "# General Analytics Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization / Image Packages\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Randomization Functions\n",
    "from random import random as randuni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "9b582614-ccd7-4f48-8b66-a49ebe66807f"
    }
   },
   "outputs": [],
   "source": [
    "# Put MatPlotLib in interactive mode\n",
    "plt.ion()\n",
    "\n",
    "# Plot graphics inline in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classes and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6fed3f3e-b14a-457d-95d2-c3726ce0fb3e"
    }
   },
   "source": [
    "### Image Data Utility Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "f962c744-4459-4ca1-851c-a19fe8457118"
    }
   },
   "outputs": [],
   "source": [
    "def is_image_file(fname):\n",
    "    \"\"\"Checks if a file is an image.\n",
    "    Args:\n",
    "        fname (string): path to a file\n",
    "    Returns:\n",
    "        bool: True if the filename ends with a known image extension\n",
    "    \"\"\"\n",
    "    return fname.lower().endswith('.png')\n",
    "\n",
    "def create_label_maps(details_df):\n",
    "    \"\"\" Take a descriptive dataframe and extract the unique labels and map to index values\n",
    "    Args:\n",
    "        details_df: Dataframe with the image details\n",
    "    Returns:\n",
    "        label_list: list of unique labels in the dataframe\n",
    "        label_to_index: map from labels to indices\n",
    "    \"\"\"\n",
    "    \"\"\" TODO: Research paper also excludes these labels but need to figure out how to handle\n",
    "              cases that have these as positive findings (completely exclude?)\n",
    "    excluded_labels = ['Edema','Hernia','Emphysema','Fibrosis','No Finding'\n",
    "                      'Pleural_Thickening','Consolidation']\n",
    "    \"\"\"\n",
    "    excluded_labels = ['No Finding']\n",
    "    \n",
    "    label_groups = details_df['Finding Labels'].unique()\n",
    "    unique_labels = set([label for sublist in label_groups.tolist() for label in sublist.split('|')])\n",
    "    \n",
    "    # Drop some label that we do not want to include\n",
    "    unique_labels = [l for l in unique_labels if l not in excluded_labels]\n",
    "\n",
    "    index_to_label = {idx: val for idx, val in enumerate(unique_labels)}\n",
    "    label_to_index = {val: idx for idx, val in index_to_label.items()}\n",
    "\n",
    "    label_list = list(label_to_index.keys())\n",
    "\n",
    "    return label_list, label_to_index\n",
    "\n",
    "def create_image_list(dir):\n",
    "    \"\"\" Create a full list of images available \n",
    "    Args:\n",
    "        dir (string): root directory of images with subdirectories underneath\n",
    "                      that have the .png images within them\n",
    "    Returns:\n",
    "        image_list: list of tuples with (image_name, full_image_path)\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    dir = os.path.expanduser(dir)\n",
    "    for subfolder in sorted(os.listdir(dir)):\n",
    "        d = os.path.join(dir, subfolder)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        for subfolder_path, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if is_image_file(fname):\n",
    "                    path = os.path.join(subfolder_path, fname)\n",
    "                    image_list.append((fname, path))\n",
    "    return image_list\n",
    "\n",
    "def pil_loader(path):\n",
    "    \"\"\" Opens path as file with Pillow (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    Args:\n",
    "        path (string): File path to the image\n",
    "    Returns:\n",
    "        img: Image in RGB format\n",
    "    \"\"\"\n",
    "    f = open(path, 'rb')\n",
    "    return Image.open(f)\n",
    "    #with open(path, 'rb') as f:\n",
    "    #    return Image.open(f)\n",
    "        #with Image.open(f) as img:\n",
    "        #    return img.load()\n",
    "        \n",
    "def imshow(inp, title=None):\n",
    "    \"\"\" Convert tensor array to an image (only use post-dataset transform) \"\"\"\n",
    "    inp = inp[0]\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d5d91972-9d4b-4022-842b-22c823f98fff"
    }
   },
   "source": [
    "### Torch Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "5bf4e82b-13ca-4ac2-bbb6-3081e820ab4e"
    }
   },
   "outputs": [],
   "source": [
    "class XrayImageSet(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image_root (string): root directory of the images in form image/subfolder/*.png\n",
    "        csv_file (string): path to the CSV data file\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an image given its path.\n",
    "     Attributes:\n",
    "        labels (list): list of the possible label names.\n",
    "        label_to_index (dict): look from label name to a label index\n",
    "        imgs (list): List of (filename, image path) tuples\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_root, csv_file, transform=None, target_transform=None, loader = pil_loader):\n",
    "        \"\"\" Create an instance of the Xray Dataset \"\"\"\n",
    "        img_details = pd.read_csv(csv_file)\n",
    "        \n",
    "        labels, label_to_index = create_label_maps(img_details)\n",
    "        imgs = create_image_list(image_root)\n",
    "\n",
    "        self.imgs = imgs\n",
    "        self.image_details = img_details\n",
    "        self.image_root = image_root\n",
    "        self.labels = labels\n",
    "        self.label_to_index = label_to_index\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.max_label_index = max(label_to_index.values())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get image,labels pair by index\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        fname, path = self.imgs[index]\n",
    "        target = self.get_one_hot_labels(fname)\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Calculate length of the dataset (number of images) \"\"\"\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def get_labels(self, fname):\n",
    "        \"\"\" Return the label string for the file \"\"\"\n",
    "        return self.image_details[self.image_details['Image Index'] == fname]['Finding Labels'].values[0]\n",
    "    \n",
    "    def one_hot_labels(self, labels):\n",
    "        \"\"\" Convert the labels string (with each label separated by |) into 1-hot encoding \"\"\"\n",
    "        if labels == None:\n",
    "            return None\n",
    "        \n",
    "        split_label_indices = [self.label_to_index.get(label)\n",
    "                               for label in labels.split('|')\n",
    "                               if label != 'No Finding']\n",
    "        \n",
    "        out = [1 if idx in split_label_indices else 0 for idx in range(self.max_label_index+1)]\n",
    "        # This code UNHOTs the labels:\n",
    "        # out = '|'.join([index_to_label.get(idx) for idx, val in enumerate(one_hot_tuple) if val == 1])\n",
    "        return out\n",
    "\n",
    "    def get_one_hot_labels(self, fname):\n",
    "        \"\"\" Get the 1-hot encoded label array for the provided file \"\"\"\n",
    "        labels = self.get_labels(fname)\n",
    "        one_hot_labels = self.one_hot_labels(labels)\n",
    "        return torch.FloatTensor(one_hot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Output Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "166ce9d1-ff17-4047-b9ae-b4903393ad15"
    }
   },
   "outputs": [],
   "source": [
    "class printer_writer:\n",
    "    def __init__(self, output_folder_path):\n",
    "        self.start_time = time.strftime('%Y%m%d-%Hh%Mm%Ss')\n",
    "        \n",
    "        self.outprefix = output_folder_path + '/' + self.start_time\n",
    "        \n",
    "        # Print Output File\n",
    "        self.print_out_path = self.outprefix + '_print.txt'\n",
    "        self.print_out_file = open(self.print_out_path, 'w', 1)\n",
    "        \n",
    "    def printw(self, string):\n",
    "        print(string)\n",
    "        try:\n",
    "            self.print_out_file.write(string + \"\\n\")\n",
    "        except: # Ignore errors\n",
    "            pass\n",
    "        \n",
    "    def save_checkpoint(self, epoch, model, optimizer, scheduler, val_error):\n",
    "        model_out_path = self.outprefix + '_model_' + str(epoch+1) + '.tar'\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'state': model.state_dict(),\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "            'val_error': val_error\n",
    "        }, model_out_path)\n",
    "        \n",
    "    def close(self):\n",
    "        self.print_out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "eb99e6e4-00db-494a-ad27-70005761f49e"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, outfolder = '/user/xrayproj/output/'):\n",
    "    since = time.time()\n",
    "    scribe = printer_writer(outfolder)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        scribe.printw('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        scribe.printw('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            obs_counter = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Store statistics (convert from autograd.Variable to float/int)\n",
    "                loss_val = loss.data[0]\n",
    "                correct_val = torch.sum( ((outputs.sigmoid()>0.5) == (labels>0.5)).long() ).data[0]\n",
    "                \n",
    "                running_loss += loss_val\n",
    "                running_corrects += correct_val\n",
    "                \n",
    "                obs_counter += len(inputs)\n",
    "                \n",
    "                batch_loss = 1.0 * loss_val / len(inputs)\n",
    "                batch_acc = 1.0 * correct_val / len(inputs)\n",
    "                status = ' |~~ {}@{}  Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    phase, obs_counter, batch_loss, batch_acc)\n",
    "                scribe.printw(status)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            scribe.printw('{}  Loss: {:.6f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Store the model on disk\n",
    "            if phase == 'val':\n",
    "                scheduler.step(epoch_loss)\n",
    "                if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    scribe.save_checkpoint(epoch, model, optimizer, None, epoch_loss)\n",
    "                else:\n",
    "                    scribe.save_checkpoint(epoch, model, optimizer, scheduler, epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    scribe.printw('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    scribe.close()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5e6eebab-809d-4550-b771-135dbf2b893d"
    }
   },
   "source": [
    "### Customized Binary Cross Entropy Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "f66b439c-1f87-4d08-939d-f64d085b846b"
    }
   },
   "outputs": [],
   "source": [
    "class BCEWithLogitsImbalanceWeightedLoss(Module):\n",
    "    def __init__(self, class_weight=None, size_average=True):\n",
    "        super(BCEWithLogitsImbalanceWeightedLoss, self).__init__()\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return self.imbalance_weighted_bce_with_logit(input, target, size_average=self.size_average)\n",
    "    \n",
    "    def imbalance_weighted_bce_with_logit(self, input, target, size_average=True):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        # Determine |P| and |N|\n",
    "        positive_labels = target.sum()\n",
    "        negative_labels = (1-target).sum()\n",
    "\n",
    "        # Upweight the less common class (very often the 1s)\n",
    "        beta_p = (positive_labels + negative_labels) / positive_labels\n",
    "        beta_n = (positive_labels + negative_labels) / negative_labels\n",
    "\n",
    "        # Adjust the losses accordingly\n",
    "        loss_weight = target * beta_p + (1-target) * beta_n\n",
    "\n",
    "        loss = loss * loss_weight\n",
    "\n",
    "        if size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetBase(base_size = 18, only_update_fc = True):\n",
    "    \"\"\" ResNet 18 with only final FC layer updatable \"\"\"\n",
    "    m = None\n",
    "    if base_size == 18:\n",
    "        m = models.resnet18(pretrained=True)\n",
    "    elif base_size == 34:\n",
    "        m = models.resnet34(pretrained=True)\n",
    "    elif base_size == 50:\n",
    "        m = models.resnet50(pretrained=True)\n",
    "    elif base_size == 101:\n",
    "        m = models.resnet101(pretrained=True)\n",
    "    elif base_size == 152:\n",
    "        m = models.resnet152(pretrained=True)\n",
    "    \n",
    "    if only_update_fc:\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    m.fc = nn.Linear(m.fc.in_features, len(img_data_train.labels))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean ± std. dev. of 7 runs, 10000000 loops each\n",
    "\n",
    "#### Time for __get_item__\n",
    "```\n",
    "%timeit img_data_train[3] # 30.8 ms ± 544 µs per loop\n",
    "```\n",
    "\n",
    "#### Breakdown for __get_item__\n",
    "```\n",
    "%timeit img_data_train.imgs[8] # 63 ns ± 0.0057 ns per loop\n",
    "%timeit img_data_train.get_one_hot_labels('00011558_012.png') # 8.72 ms ± 9.44 µs per loop\n",
    "%timeit img_data_train.loader('/user/images/images_006/00011558_012.png') # 14.1 ms ± 3.41 µs per loop\n",
    "%timeit img_data_train.transform(img) # 3.17 ms ± 1.32 µs per loop\n",
    "```\n",
    "\n",
    "#### Breakdown for loader() from __get_item__\n",
    "```\n",
    "%timeit open('/user/images/images_006/00011558_012.png', 'rb') # 7.72 µs ± 13.4 ns per loop\n",
    "%timeit Image.open(f) # 37.5 µs ± 2.25 µs per loop\n",
    "%timeit img.convert('RGB') # 498 µs ± 149 ns per loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Begin Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b6f705b5-c4e4-4fbd-a517-f0c3b58c4305"
    }
   },
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU: 1\n"
     ]
    }
   ],
   "source": [
    "nn_input_size = 224 #1024\n",
    "batch_size = 64\n",
    "pin_mem_setting = True\n",
    "num_gpus = torch.cuda.device_count()\n",
    "num_workers = 10\n",
    "\n",
    "print(\"Number of GPU: {}\".format(num_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbpresent": {
     "id": "6716d746-b7b1-4aff-aec0-2bd91632bf28"
    }
   },
   "outputs": [],
   "source": [
    "img_transforms_train = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms_nontrain = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbpresent": {
     "id": "62d30308-7ecb-40f4-a831-dd0a9274618a"
    }
   },
   "outputs": [],
   "source": [
    "img_data_train = XrayImageSet(image_root = '/user/images_processed/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms_train,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_train.imgs = [img for i, img in enumerate(img_data_train.imgs) if i % 10 >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbpresent": {
     "id": "13f86c44-50f2-4809-8ee1-afb0d8ec0b7a"
    }
   },
   "outputs": [],
   "source": [
    "img_data_val   = XrayImageSet(image_root = '/user/images_processed/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms_nontrain,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_val.imgs = [img for i, img in enumerate(img_data_val.imgs) if i % 10 in (1,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_test  = XrayImageSet(image_root = '/user/images_processed/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms_nontrain,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_test.imgs = [img for i, img in enumerate(img_data_test.imgs) if i % 10 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = set(img_data_train.imgs)\n",
    "val_set = set(img_data_val.imgs)\n",
    "test_set = set(img_data_test.imgs)\n",
    "assert len(train_set.intersection(val_set)) == 0\n",
    "assert len(train_set.intersection(test_set)) == 0\n",
    "assert len(val_set.intersection(test_set)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbpresent": {
     "id": "09ab4157-ad5b-4602-8b93-85c86bd5a620"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 78484\n",
      "Validation Set Size: 22424\n",
      "Test Set Size: 11212\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Size: {}\".format(len(img_data_train)))\n",
    "print(\"Validation Set Size: {}\".format(len(img_data_val)))\n",
    "print(\"Test Set Size: {}\".format(len(img_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "nbpresent": {
     "id": "1001fa5d-b820-4da6-9d18-0ee7f4462b90"
    }
   },
   "outputs": [],
   "source": [
    "img_loader_train = DataLoader(img_data_train,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = num_workers,\n",
    "                              pin_memory = pin_mem_setting)\n",
    "\n",
    "img_loader_val   = DataLoader(img_data_val,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = num_workers,\n",
    "                              pin_memory = pin_mem_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "nbpresent": {
     "id": "0e1d2cb0-4d0f-4ab1-a1cf-cd66a3e298a2"
    }
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': img_loader_train,\n",
    "    'val': img_loader_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "nbpresent": {
     "id": "91946119-bf67-4871-92af-649559fa9bfd"
    }
   },
   "outputs": [],
   "source": [
    "model_base = ResNetBase(base_size = 34, only_update_fc = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "nbpresent": {
     "id": "0a904f1f-73ac-418b-86cf-cdafdf0f67b1"
    }
   },
   "outputs": [],
   "source": [
    "model_ft = DataParallel(model_base).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e6851de2-8645-4547-9f00-414ad8a3811a"
    }
   },
   "source": [
    "### Setup learning rates and procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "nbpresent": {
     "id": "1d61f077-84ec-4d2c-bdb0-82b28f8c4ed9"
    }
   },
   "outputs": [],
   "source": [
    "#criterion = BCEWithLogitsImbalanceWeightedLoss()\n",
    "criterion_base = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#optimizer_ft = SGD(model_ft.module.fc.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_ft = SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "learning_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = criterion_base.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future code for allowing optimization of the base layer with a lower learning rate\n",
    "\n",
    "```\n",
    "ignored_params = list(map(id, model.fc.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model.parameters())\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "            {'params': base_params},\n",
    "            {'params': model.fc.parameters(), 'lr': opt.lr}\n",
    "        ], lr=opt.lr*0.1, momentum=0.9)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2f9596b5-a2fc-4e0c-984b-4e13b68dcd6d"
    }
   },
   "source": [
    "# Begin Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "nbpresent": {
     "id": "f1672c30-c299-4265-934b-6af391d9de8c"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.012500 Acc: 6.4062\n",
      " |~~ train@128  Loss: 0.011301 Acc: 7.4844\n",
      " |~~ train@192  Loss: 0.009418 Acc: 9.9219\n",
      " |~~ train@256  Loss: 0.007308 Acc: 12.2188\n",
      " |~~ train@320  Loss: 0.005580 Acc: 13.1094\n",
      " |~~ train@384  Loss: 0.004395 Acc: 13.2188\n",
      " |~~ train@448  Loss: 0.003584 Acc: 13.2344\n",
      " |~~ train@512  Loss: 0.002905 Acc: 13.3906\n",
      " |~~ train@576  Loss: 0.003035 Acc: 13.2500\n",
      " |~~ train@640  Loss: 0.002534 Acc: 13.3906\n",
      " |~~ train@704  Loss: 0.003214 Acc: 13.2188\n",
      " |~~ train@768  Loss: 0.002709 Acc: 13.3750\n",
      " |~~ train@832  Loss: 0.002899 Acc: 13.3594\n",
      " |~~ train@896  Loss: 0.002006 Acc: 13.5312\n",
      " |~~ train@960  Loss: 0.003835 Acc: 13.1719\n",
      " |~~ train@1024  Loss: 0.002904 Acc: 13.4062\n",
      " |~~ train@1088  Loss: 0.001903 Acc: 13.5938\n",
      " |~~ train@1152  Loss: 0.003015 Acc: 13.3438\n",
      " |~~ train@1216  Loss: 0.003071 Acc: 13.2969\n",
      " |~~ train@1280  Loss: 0.004000 Acc: 13.1562\n",
      " |~~ train@1344  Loss: 0.003153 Acc: 13.3281\n",
      " |~~ train@1408  Loss: 0.002817 Acc: 13.3594\n",
      " |~~ train@1472  Loss: 0.003028 Acc: 13.3125\n",
      " |~~ train@1536  Loss: 0.002962 Acc: 13.3438\n",
      " |~~ train@1600  Loss: 0.004074 Acc: 13.1406\n",
      " |~~ train@1664  Loss: 0.003662 Acc: 13.2188\n",
      " |~~ train@1728  Loss: 0.003813 Acc: 13.2344\n",
      " |~~ train@1792  Loss: 0.003573 Acc: 13.1875\n",
      " |~~ train@1856  Loss: 0.003617 Acc: 13.2812\n",
      " |~~ train@1920  Loss: 0.003820 Acc: 13.1875\n",
      " |~~ train@1984  Loss: 0.003134 Acc: 13.2969\n",
      " |~~ train@2048  Loss: 0.003096 Acc: 13.3750\n",
      " |~~ train@2112  Loss: 0.002969 Acc: 13.3594\n",
      " |~~ train@2176  Loss: 0.003662 Acc: 13.3125\n",
      " |~~ train@2240  Loss: 0.003357 Acc: 13.2031\n",
      " |~~ train@2304  Loss: 0.002403 Acc: 13.5156\n",
      " |~~ train@2368  Loss: 0.003014 Acc: 13.3281\n",
      " |~~ train@2432  Loss: 0.002233 Acc: 13.5000\n",
      " |~~ train@2496  Loss: 0.002522 Acc: 13.4531\n",
      " |~~ train@2560  Loss: 0.003427 Acc: 13.2344\n",
      " |~~ train@2624  Loss: 0.003454 Acc: 13.2188\n",
      " |~~ train@2688  Loss: 0.003434 Acc: 13.2344\n",
      " |~~ train@2752  Loss: 0.003281 Acc: 13.2812\n",
      " |~~ train@2816  Loss: 0.002425 Acc: 13.3438\n",
      " |~~ train@2880  Loss: 0.003123 Acc: 13.2969\n",
      " |~~ train@2944  Loss: 0.003763 Acc: 13.1562\n",
      " |~~ train@3008  Loss: 0.003251 Acc: 13.2344\n",
      " |~~ train@3072  Loss: 0.002981 Acc: 13.3594\n",
      " |~~ train@3136  Loss: 0.003320 Acc: 13.2500\n",
      " |~~ train@3200  Loss: 0.002490 Acc: 13.3594\n",
      " |~~ train@3264  Loss: 0.002706 Acc: 13.4531\n",
      " |~~ train@3328  Loss: 0.002393 Acc: 13.4062\n",
      " |~~ train@3392  Loss: 0.002612 Acc: 13.3125\n",
      " |~~ train@3456  Loss: 0.003642 Acc: 13.0000\n",
      " |~~ train@3520  Loss: 0.003485 Acc: 13.1406\n",
      " |~~ train@3584  Loss: 0.003126 Acc: 13.2031\n",
      " |~~ train@3648  Loss: 0.003558 Acc: 13.0781\n",
      " |~~ train@3712  Loss: 0.002584 Acc: 13.3594\n",
      " |~~ train@3776  Loss: 0.002429 Acc: 13.3125\n",
      " |~~ train@3840  Loss: 0.002942 Acc: 13.1875\n",
      " |~~ train@3904  Loss: 0.002598 Acc: 13.3594\n",
      " |~~ train@3968  Loss: 0.002553 Acc: 13.2969\n",
      " |~~ train@4032  Loss: 0.003521 Acc: 13.1094\n",
      " |~~ train@4096  Loss: 0.003297 Acc: 13.1875\n",
      " |~~ train@4160  Loss: 0.002833 Acc: 13.2344\n",
      " |~~ train@4224  Loss: 0.002715 Acc: 13.2812\n",
      " |~~ train@4288  Loss: 0.002917 Acc: 13.2812\n",
      " |~~ train@4352  Loss: 0.002808 Acc: 13.2656\n",
      " |~~ train@4416  Loss: 0.002382 Acc: 13.4219\n",
      " |~~ train@4480  Loss: 0.003008 Acc: 13.1719\n",
      " |~~ train@4544  Loss: 0.003471 Acc: 13.0156\n",
      " |~~ train@4608  Loss: 0.002874 Acc: 13.1875\n",
      " |~~ train@4672  Loss: 0.003102 Acc: 13.1719\n",
      " |~~ train@4736  Loss: 0.002762 Acc: 13.2656\n",
      " |~~ train@4800  Loss: 0.002373 Acc: 13.4688\n",
      " |~~ train@4864  Loss: 0.002271 Acc: 13.4219\n",
      " |~~ train@4928  Loss: 0.002926 Acc: 13.2031\n",
      " |~~ train@4992  Loss: 0.002911 Acc: 13.2344\n",
      " |~~ train@5056  Loss: 0.002901 Acc: 13.2188\n",
      " |~~ train@5120  Loss: 0.003495 Acc: 13.0625\n",
      " |~~ train@5184  Loss: 0.002243 Acc: 13.4219\n",
      " |~~ train@5248  Loss: 0.003682 Acc: 13.0469\n",
      " |~~ train@5312  Loss: 0.002828 Acc: 13.1250\n",
      " |~~ train@5376  Loss: 0.002798 Acc: 13.3125\n",
      " |~~ train@5440  Loss: 0.003194 Acc: 13.0781\n",
      " |~~ train@5504  Loss: 0.002672 Acc: 13.2969\n",
      " |~~ train@5568  Loss: 0.002494 Acc: 13.3125\n",
      " |~~ train@5632  Loss: 0.002887 Acc: 13.2344\n",
      " |~~ train@5696  Loss: 0.002875 Acc: 13.2812\n",
      " |~~ train@5760  Loss: 0.002178 Acc: 13.4844\n",
      " |~~ train@5824  Loss: 0.002485 Acc: 13.2969\n",
      " |~~ train@5888  Loss: 0.002514 Acc: 13.3438\n",
      " |~~ train@5952  Loss: 0.003086 Acc: 13.1406\n",
      " |~~ train@6016  Loss: 0.002548 Acc: 13.4219\n",
      " |~~ train@6080  Loss: 0.002293 Acc: 13.3906\n",
      " |~~ train@6144  Loss: 0.002363 Acc: 13.4062\n",
      " |~~ train@6208  Loss: 0.001862 Acc: 13.5781\n",
      " |~~ train@6272  Loss: 0.002341 Acc: 13.4062\n",
      " |~~ train@6336  Loss: 0.002567 Acc: 13.3125\n",
      " |~~ train@6400  Loss: 0.002805 Acc: 13.2812\n",
      " |~~ train@6464  Loss: 0.002234 Acc: 13.4062\n",
      " |~~ train@6528  Loss: 0.002938 Acc: 13.2031\n",
      " |~~ train@6592  Loss: 0.002794 Acc: 13.2500\n",
      " |~~ train@6656  Loss: 0.002654 Acc: 13.2656\n",
      " |~~ train@6720  Loss: 0.002694 Acc: 13.2812\n",
      " |~~ train@6784  Loss: 0.003207 Acc: 13.1406\n",
      " |~~ train@6848  Loss: 0.002445 Acc: 13.3438\n",
      " |~~ train@6912  Loss: 0.003260 Acc: 13.1094\n",
      " |~~ train@6976  Loss: 0.002479 Acc: 13.2656\n",
      " |~~ train@7040  Loss: 0.002536 Acc: 13.2969\n",
      " |~~ train@7104  Loss: 0.002432 Acc: 13.3281\n",
      " |~~ train@7168  Loss: 0.002646 Acc: 13.2812\n",
      " |~~ train@7232  Loss: 0.003239 Acc: 13.0938\n",
      " |~~ train@7296  Loss: 0.003192 Acc: 13.1875\n",
      " |~~ train@7360  Loss: 0.002403 Acc: 13.3281\n",
      " |~~ train@7424  Loss: 0.002486 Acc: 13.3750\n",
      " |~~ train@7488  Loss: 0.002503 Acc: 13.3281\n",
      " |~~ train@7552  Loss: 0.003226 Acc: 13.0469\n",
      " |~~ train@7616  Loss: 0.003095 Acc: 13.1250\n",
      " |~~ train@7680  Loss: 0.002613 Acc: 13.2969\n",
      " |~~ train@7744  Loss: 0.002760 Acc: 13.2188\n",
      " |~~ train@7808  Loss: 0.002762 Acc: 13.2188\n",
      " |~~ train@7872  Loss: 0.002730 Acc: 13.2500\n",
      " |~~ train@7936  Loss: 0.002579 Acc: 13.3750\n",
      " |~~ train@8000  Loss: 0.002803 Acc: 13.2969\n",
      " |~~ train@8064  Loss: 0.002363 Acc: 13.4844\n",
      " |~~ train@8128  Loss: 0.002669 Acc: 13.2656\n",
      " |~~ train@8192  Loss: 0.003230 Acc: 13.0625\n",
      " |~~ train@8256  Loss: 0.002759 Acc: 13.1875\n",
      " |~~ train@8320  Loss: 0.002555 Acc: 13.3438\n",
      " |~~ train@8384  Loss: 0.002551 Acc: 13.3281\n",
      " |~~ train@8448  Loss: 0.003079 Acc: 13.1406\n",
      " |~~ train@8512  Loss: 0.002572 Acc: 13.3594\n",
      " |~~ train@8576  Loss: 0.002878 Acc: 13.2344\n",
      " |~~ train@8640  Loss: 0.002713 Acc: 13.2656\n",
      " |~~ train@8704  Loss: 0.002482 Acc: 13.2500\n",
      " |~~ train@8768  Loss: 0.002861 Acc: 13.2188\n",
      " |~~ train@8832  Loss: 0.002607 Acc: 13.2969\n",
      " |~~ train@8896  Loss: 0.002428 Acc: 13.4062\n",
      " |~~ train@8960  Loss: 0.002271 Acc: 13.3594\n",
      " |~~ train@9024  Loss: 0.002399 Acc: 13.4375\n",
      " |~~ train@9088  Loss: 0.002869 Acc: 13.2656\n",
      " |~~ train@9152  Loss: 0.002889 Acc: 13.1250\n",
      " |~~ train@9216  Loss: 0.002795 Acc: 13.2031\n",
      " |~~ train@9280  Loss: 0.002696 Acc: 13.3125\n",
      " |~~ train@9344  Loss: 0.002153 Acc: 13.5469\n",
      " |~~ train@9408  Loss: 0.002557 Acc: 13.2188\n",
      " |~~ train@9472  Loss: 0.002598 Acc: 13.2344\n",
      " |~~ train@9536  Loss: 0.002490 Acc: 13.3281\n",
      " |~~ train@9600  Loss: 0.001888 Acc: 13.5625\n",
      " |~~ train@9664  Loss: 0.002586 Acc: 13.2969\n",
      " |~~ train@9728  Loss: 0.003260 Acc: 13.1562\n",
      " |~~ train@9792  Loss: 0.002737 Acc: 13.2969\n",
      " |~~ train@9856  Loss: 0.003138 Acc: 13.1250\n",
      " |~~ train@9920  Loss: 0.001976 Acc: 13.5000\n",
      " |~~ train@9984  Loss: 0.002976 Acc: 13.0938\n",
      " |~~ train@10048  Loss: 0.002916 Acc: 13.1562\n",
      " |~~ train@10112  Loss: 0.002722 Acc: 13.2812\n",
      " |~~ train@10176  Loss: 0.002690 Acc: 13.2500\n",
      " |~~ train@10240  Loss: 0.002687 Acc: 13.2812\n",
      " |~~ train@10304  Loss: 0.003093 Acc: 13.1406\n",
      " |~~ train@10368  Loss: 0.002561 Acc: 13.3594\n",
      " |~~ train@10432  Loss: 0.002923 Acc: 13.2500\n",
      " |~~ train@10496  Loss: 0.002789 Acc: 13.2969\n",
      " |~~ train@10560  Loss: 0.003247 Acc: 13.0312\n",
      " |~~ train@10624  Loss: 0.002687 Acc: 13.2500\n",
      " |~~ train@10688  Loss: 0.002701 Acc: 13.2812\n",
      " |~~ train@10752  Loss: 0.003028 Acc: 13.1562\n",
      " |~~ train@10816  Loss: 0.002893 Acc: 13.1719\n",
      " |~~ train@10880  Loss: 0.002365 Acc: 13.3594\n",
      " |~~ train@10944  Loss: 0.002576 Acc: 13.2500\n",
      " |~~ train@11008  Loss: 0.002663 Acc: 13.2969\n",
      " |~~ train@11072  Loss: 0.003093 Acc: 13.1719\n",
      " |~~ train@11136  Loss: 0.002514 Acc: 13.3438\n",
      " |~~ train@11200  Loss: 0.002706 Acc: 13.2031\n",
      " |~~ train@11264  Loss: 0.003133 Acc: 13.1406\n",
      " |~~ train@11328  Loss: 0.002540 Acc: 13.2344\n",
      " |~~ train@11392  Loss: 0.002374 Acc: 13.4062\n",
      " |~~ train@11456  Loss: 0.002729 Acc: 13.2812\n",
      " |~~ train@11520  Loss: 0.003168 Acc: 13.1094\n",
      " |~~ train@11584  Loss: 0.003356 Acc: 13.0781\n",
      " |~~ train@11648  Loss: 0.002532 Acc: 13.3125\n",
      " |~~ train@11712  Loss: 0.002611 Acc: 13.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@11776  Loss: 0.002366 Acc: 13.3906\n",
      " |~~ train@11840  Loss: 0.002305 Acc: 13.2500\n",
      " |~~ train@11904  Loss: 0.002531 Acc: 13.2812\n",
      " |~~ train@11968  Loss: 0.003422 Acc: 13.0000\n",
      " |~~ train@12032  Loss: 0.003083 Acc: 13.1562\n",
      " |~~ train@12096  Loss: 0.002993 Acc: 13.1875\n",
      " |~~ train@12160  Loss: 0.002162 Acc: 13.4688\n",
      " |~~ train@12224  Loss: 0.003319 Acc: 13.0469\n",
      " |~~ train@12288  Loss: 0.003406 Acc: 12.9844\n",
      " |~~ train@12352  Loss: 0.002405 Acc: 13.3125\n",
      " |~~ train@12416  Loss: 0.002202 Acc: 13.4531\n",
      " |~~ train@12480  Loss: 0.002793 Acc: 13.2812\n",
      " |~~ train@12544  Loss: 0.002623 Acc: 13.3281\n",
      " |~~ train@12608  Loss: 0.002859 Acc: 13.2031\n",
      " |~~ train@12672  Loss: 0.002656 Acc: 13.3125\n",
      " |~~ train@12736  Loss: 0.002650 Acc: 13.2500\n",
      " |~~ train@12800  Loss: 0.001760 Acc: 13.6562\n",
      " |~~ train@12864  Loss: 0.002950 Acc: 13.1562\n",
      " |~~ train@12928  Loss: 0.003395 Acc: 13.0000\n",
      " |~~ train@12992  Loss: 0.002395 Acc: 13.3594\n",
      " |~~ train@13056  Loss: 0.003023 Acc: 13.1406\n",
      " |~~ train@13120  Loss: 0.002936 Acc: 13.1250\n",
      " |~~ train@13184  Loss: 0.002942 Acc: 13.2188\n",
      " |~~ train@13248  Loss: 0.003076 Acc: 13.1875\n",
      " |~~ train@13312  Loss: 0.003001 Acc: 13.1875\n",
      " |~~ train@13376  Loss: 0.002262 Acc: 13.5312\n",
      " |~~ train@13440  Loss: 0.002279 Acc: 13.4375\n",
      " |~~ train@13504  Loss: 0.002418 Acc: 13.3594\n",
      " |~~ train@13568  Loss: 0.003263 Acc: 13.0781\n",
      " |~~ train@13632  Loss: 0.002854 Acc: 13.2031\n",
      " |~~ train@13696  Loss: 0.002721 Acc: 13.1719\n",
      " |~~ train@13760  Loss: 0.002856 Acc: 13.2031\n",
      " |~~ train@13824  Loss: 0.002729 Acc: 13.3281\n",
      " |~~ train@13888  Loss: 0.002735 Acc: 13.1875\n",
      " |~~ train@13952  Loss: 0.002456 Acc: 13.2969\n",
      " |~~ train@14016  Loss: 0.002387 Acc: 13.3438\n",
      " |~~ train@14080  Loss: 0.003149 Acc: 13.1094\n",
      " |~~ train@14144  Loss: 0.002357 Acc: 13.3906\n",
      " |~~ train@14208  Loss: 0.002497 Acc: 13.3281\n",
      " |~~ train@14272  Loss: 0.002579 Acc: 13.3594\n",
      " |~~ train@14336  Loss: 0.002439 Acc: 13.3125\n",
      " |~~ train@14400  Loss: 0.002926 Acc: 13.2031\n",
      " |~~ train@14464  Loss: 0.002299 Acc: 13.3594\n",
      " |~~ train@14528  Loss: 0.002485 Acc: 13.2656\n",
      " |~~ train@14592  Loss: 0.002717 Acc: 13.3281\n",
      " |~~ train@14656  Loss: 0.002974 Acc: 13.0781\n",
      " |~~ train@14720  Loss: 0.002253 Acc: 13.4375\n",
      " |~~ train@14784  Loss: 0.002538 Acc: 13.3594\n",
      " |~~ train@14848  Loss: 0.002460 Acc: 13.3125\n",
      " |~~ train@14912  Loss: 0.002116 Acc: 13.4531\n",
      " |~~ train@14976  Loss: 0.002922 Acc: 13.2031\n",
      " |~~ train@15040  Loss: 0.003532 Acc: 13.0781\n",
      " |~~ train@15104  Loss: 0.003242 Acc: 13.1562\n",
      " |~~ train@15168  Loss: 0.002872 Acc: 13.1719\n",
      " |~~ train@15232  Loss: 0.002535 Acc: 13.3281\n",
      " |~~ train@15296  Loss: 0.002245 Acc: 13.4375\n",
      " |~~ train@15360  Loss: 0.002771 Acc: 13.1875\n",
      " |~~ train@15424  Loss: 0.003206 Acc: 13.1250\n",
      " |~~ train@15488  Loss: 0.003140 Acc: 13.1094\n",
      " |~~ train@15552  Loss: 0.002993 Acc: 13.1875\n",
      " |~~ train@15616  Loss: 0.003006 Acc: 13.1562\n",
      " |~~ train@15680  Loss: 0.002307 Acc: 13.4219\n",
      " |~~ train@15744  Loss: 0.002931 Acc: 13.1562\n",
      " |~~ train@15808  Loss: 0.002662 Acc: 13.2500\n",
      " |~~ train@15872  Loss: 0.002688 Acc: 13.2500\n",
      " |~~ train@15936  Loss: 0.002642 Acc: 13.3594\n",
      " |~~ train@16000  Loss: 0.002569 Acc: 13.3750\n",
      " |~~ train@16064  Loss: 0.002525 Acc: 13.3125\n",
      " |~~ train@16128  Loss: 0.003406 Acc: 13.0000\n",
      " |~~ train@16192  Loss: 0.003485 Acc: 13.0156\n",
      " |~~ train@16256  Loss: 0.003143 Acc: 13.1094\n",
      " |~~ train@16320  Loss: 0.002406 Acc: 13.4219\n",
      " |~~ train@16384  Loss: 0.002296 Acc: 13.4531\n",
      " |~~ train@16448  Loss: 0.002543 Acc: 13.3281\n",
      " |~~ train@16512  Loss: 0.003038 Acc: 13.1406\n",
      " |~~ train@16576  Loss: 0.002303 Acc: 13.3750\n",
      " |~~ train@16640  Loss: 0.002429 Acc: 13.4062\n",
      " |~~ train@16704  Loss: 0.003013 Acc: 13.1719\n",
      " |~~ train@16768  Loss: 0.003343 Acc: 13.0469\n",
      " |~~ train@16832  Loss: 0.002402 Acc: 13.3594\n",
      " |~~ train@16896  Loss: 0.002809 Acc: 13.2812\n",
      " |~~ train@16960  Loss: 0.002684 Acc: 13.2344\n",
      " |~~ train@17024  Loss: 0.002920 Acc: 13.1094\n",
      " |~~ train@17088  Loss: 0.002879 Acc: 13.1562\n",
      " |~~ train@17152  Loss: 0.002860 Acc: 13.2344\n",
      " |~~ train@17216  Loss: 0.002443 Acc: 13.3438\n",
      " |~~ train@17280  Loss: 0.002724 Acc: 13.1875\n",
      " |~~ train@17344  Loss: 0.002362 Acc: 13.3906\n",
      " |~~ train@17408  Loss: 0.002664 Acc: 13.2344\n",
      " |~~ train@17472  Loss: 0.002811 Acc: 13.2969\n",
      " |~~ train@17536  Loss: 0.002124 Acc: 13.4844\n",
      " |~~ train@17600  Loss: 0.002805 Acc: 13.2969\n",
      " |~~ train@17664  Loss: 0.002848 Acc: 13.2031\n",
      " |~~ train@17728  Loss: 0.003067 Acc: 13.0781\n",
      " |~~ train@17792  Loss: 0.002179 Acc: 13.4688\n",
      " |~~ train@17856  Loss: 0.002443 Acc: 13.2656\n",
      " |~~ train@17920  Loss: 0.002621 Acc: 13.2656\n",
      " |~~ train@17984  Loss: 0.002494 Acc: 13.2969\n",
      " |~~ train@18048  Loss: 0.002913 Acc: 13.1250\n",
      " |~~ train@18112  Loss: 0.002200 Acc: 13.4688\n",
      " |~~ train@18176  Loss: 0.002254 Acc: 13.4531\n",
      " |~~ train@18240  Loss: 0.003082 Acc: 13.1250\n",
      " |~~ train@18304  Loss: 0.002399 Acc: 13.4219\n",
      " |~~ train@18368  Loss: 0.003044 Acc: 13.1094\n",
      " |~~ train@18432  Loss: 0.002461 Acc: 13.3281\n",
      " |~~ train@18496  Loss: 0.002711 Acc: 13.2500\n",
      " |~~ train@18560  Loss: 0.002958 Acc: 13.2031\n",
      " |~~ train@18624  Loss: 0.002527 Acc: 13.2031\n",
      " |~~ train@18688  Loss: 0.002253 Acc: 13.3750\n",
      " |~~ train@18752  Loss: 0.002550 Acc: 13.3906\n",
      " |~~ train@18816  Loss: 0.002560 Acc: 13.2656\n",
      " |~~ train@18880  Loss: 0.002693 Acc: 13.3125\n",
      " |~~ train@18944  Loss: 0.002313 Acc: 13.3438\n",
      " |~~ train@19008  Loss: 0.002922 Acc: 13.1875\n",
      " |~~ train@19072  Loss: 0.002528 Acc: 13.3281\n",
      " |~~ train@19136  Loss: 0.002216 Acc: 13.3906\n",
      " |~~ train@19200  Loss: 0.003002 Acc: 13.1250\n",
      " |~~ train@19264  Loss: 0.002794 Acc: 13.2188\n",
      " |~~ train@19328  Loss: 0.002254 Acc: 13.3594\n",
      " |~~ train@19392  Loss: 0.002024 Acc: 13.4688\n",
      " |~~ train@19456  Loss: 0.002289 Acc: 13.4531\n",
      " |~~ train@19520  Loss: 0.002518 Acc: 13.3438\n",
      " |~~ train@19584  Loss: 0.002991 Acc: 13.2031\n",
      " |~~ train@19648  Loss: 0.002498 Acc: 13.2812\n",
      " |~~ train@19712  Loss: 0.002291 Acc: 13.3281\n",
      " |~~ train@19776  Loss: 0.002545 Acc: 13.3750\n",
      " |~~ train@19840  Loss: 0.002961 Acc: 13.2344\n",
      " |~~ train@19904  Loss: 0.002490 Acc: 13.3594\n",
      " |~~ train@19968  Loss: 0.002718 Acc: 13.2344\n",
      " |~~ train@20032  Loss: 0.002602 Acc: 13.3281\n",
      " |~~ train@20096  Loss: 0.002241 Acc: 13.3281\n",
      " |~~ train@20160  Loss: 0.002133 Acc: 13.4844\n",
      " |~~ train@20224  Loss: 0.003043 Acc: 13.1719\n",
      " |~~ train@20288  Loss: 0.002846 Acc: 13.1250\n",
      " |~~ train@20352  Loss: 0.003050 Acc: 13.1250\n",
      " |~~ train@20416  Loss: 0.001940 Acc: 13.4844\n",
      " |~~ train@20480  Loss: 0.002753 Acc: 13.2500\n",
      " |~~ train@20544  Loss: 0.002478 Acc: 13.2812\n",
      " |~~ train@20608  Loss: 0.002621 Acc: 13.2656\n",
      " |~~ train@20672  Loss: 0.003112 Acc: 13.0938\n",
      " |~~ train@20736  Loss: 0.002216 Acc: 13.3906\n",
      " |~~ train@20800  Loss: 0.003249 Acc: 13.1250\n",
      " |~~ train@20864  Loss: 0.002751 Acc: 13.2500\n",
      " |~~ train@20928  Loss: 0.002672 Acc: 13.2188\n",
      " |~~ train@20992  Loss: 0.002658 Acc: 13.2500\n",
      " |~~ train@21056  Loss: 0.002034 Acc: 13.4219\n",
      " |~~ train@21120  Loss: 0.002485 Acc: 13.3125\n",
      " |~~ train@21184  Loss: 0.002628 Acc: 13.1875\n",
      " |~~ train@21248  Loss: 0.002765 Acc: 13.2500\n",
      " |~~ train@21312  Loss: 0.002666 Acc: 13.3125\n",
      " |~~ train@21376  Loss: 0.002189 Acc: 13.4375\n",
      " |~~ train@21440  Loss: 0.002854 Acc: 13.1406\n",
      " |~~ train@21504  Loss: 0.002597 Acc: 13.2812\n",
      " |~~ train@21568  Loss: 0.002272 Acc: 13.3750\n",
      " |~~ train@21632  Loss: 0.002264 Acc: 13.3594\n",
      " |~~ train@21696  Loss: 0.002998 Acc: 13.1562\n",
      " |~~ train@21760  Loss: 0.003000 Acc: 13.1719\n",
      " |~~ train@21824  Loss: 0.001937 Acc: 13.4844\n",
      " |~~ train@21888  Loss: 0.002836 Acc: 13.1719\n",
      " |~~ train@21952  Loss: 0.003345 Acc: 13.0156\n",
      " |~~ train@22016  Loss: 0.002897 Acc: 13.1875\n",
      " |~~ train@22080  Loss: 0.002514 Acc: 13.2500\n",
      " |~~ train@22144  Loss: 0.002790 Acc: 13.2031\n",
      " |~~ train@22208  Loss: 0.002341 Acc: 13.3281\n",
      " |~~ train@22272  Loss: 0.002308 Acc: 13.2812\n",
      " |~~ train@22336  Loss: 0.002458 Acc: 13.2812\n",
      " |~~ train@22400  Loss: 0.002304 Acc: 13.4375\n",
      " |~~ train@22464  Loss: 0.002358 Acc: 13.3281\n",
      " |~~ train@22528  Loss: 0.002213 Acc: 13.3750\n",
      " |~~ train@22592  Loss: 0.002525 Acc: 13.3125\n",
      " |~~ train@22656  Loss: 0.002758 Acc: 13.2188\n",
      " |~~ train@22720  Loss: 0.002594 Acc: 13.3125\n",
      " |~~ train@22784  Loss: 0.002342 Acc: 13.3438\n",
      " |~~ train@22848  Loss: 0.002404 Acc: 13.4375\n",
      " |~~ train@22912  Loss: 0.002906 Acc: 13.2500\n",
      " |~~ train@22976  Loss: 0.002466 Acc: 13.2969\n",
      " |~~ train@23040  Loss: 0.002807 Acc: 13.2031\n",
      " |~~ train@23104  Loss: 0.003149 Acc: 13.1562\n",
      " |~~ train@23168  Loss: 0.002135 Acc: 13.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@23232  Loss: 0.002233 Acc: 13.4531\n",
      " |~~ train@23296  Loss: 0.002517 Acc: 13.2812\n",
      " |~~ train@23360  Loss: 0.001959 Acc: 13.5000\n",
      " |~~ train@23424  Loss: 0.002684 Acc: 13.2812\n",
      " |~~ train@23488  Loss: 0.003483 Acc: 13.0156\n",
      " |~~ train@23552  Loss: 0.002936 Acc: 13.2500\n",
      " |~~ train@23616  Loss: 0.003802 Acc: 12.7656\n",
      " |~~ train@23680  Loss: 0.002594 Acc: 13.2344\n",
      " |~~ train@23744  Loss: 0.001918 Acc: 13.4844\n",
      " |~~ train@23808  Loss: 0.002961 Acc: 13.1562\n",
      " |~~ train@23872  Loss: 0.003169 Acc: 13.1406\n",
      " |~~ train@23936  Loss: 0.002149 Acc: 13.4375\n",
      " |~~ train@24000  Loss: 0.002479 Acc: 13.2969\n",
      " |~~ train@24064  Loss: 0.002629 Acc: 13.2188\n",
      " |~~ train@24128  Loss: 0.002631 Acc: 13.3281\n",
      " |~~ train@24192  Loss: 0.002528 Acc: 13.3438\n",
      " |~~ train@24256  Loss: 0.002435 Acc: 13.3906\n",
      " |~~ train@24320  Loss: 0.002462 Acc: 13.2812\n",
      " |~~ train@24384  Loss: 0.002478 Acc: 13.2812\n",
      " |~~ train@24448  Loss: 0.003148 Acc: 13.0938\n",
      " |~~ train@24512  Loss: 0.002348 Acc: 13.2969\n",
      " |~~ train@24576  Loss: 0.002458 Acc: 13.3125\n",
      " |~~ train@24640  Loss: 0.002593 Acc: 13.2656\n",
      " |~~ train@24704  Loss: 0.003331 Acc: 13.0938\n",
      " |~~ train@24768  Loss: 0.003033 Acc: 13.1562\n",
      " |~~ train@24832  Loss: 0.002518 Acc: 13.3438\n",
      " |~~ train@24896  Loss: 0.002534 Acc: 13.2812\n",
      " |~~ train@24960  Loss: 0.002872 Acc: 13.1094\n",
      " |~~ train@25024  Loss: 0.002157 Acc: 13.4062\n",
      " |~~ train@25088  Loss: 0.002520 Acc: 13.2969\n",
      " |~~ train@25152  Loss: 0.002940 Acc: 13.1875\n",
      " |~~ train@25216  Loss: 0.001737 Acc: 13.5781\n",
      " |~~ train@25280  Loss: 0.003015 Acc: 13.2188\n",
      " |~~ train@25344  Loss: 0.002028 Acc: 13.4688\n",
      " |~~ train@25408  Loss: 0.002309 Acc: 13.3906\n",
      " |~~ train@25472  Loss: 0.002497 Acc: 13.2656\n",
      " |~~ train@25536  Loss: 0.002636 Acc: 13.2812\n",
      " |~~ train@25600  Loss: 0.003062 Acc: 13.1094\n",
      " |~~ train@25664  Loss: 0.002698 Acc: 13.2656\n",
      " |~~ train@25728  Loss: 0.002128 Acc: 13.3906\n",
      " |~~ train@25792  Loss: 0.002310 Acc: 13.4062\n",
      " |~~ train@25856  Loss: 0.002725 Acc: 13.2344\n",
      " |~~ train@25920  Loss: 0.002218 Acc: 13.3750\n",
      " |~~ train@25984  Loss: 0.003129 Acc: 13.0469\n",
      " |~~ train@26048  Loss: 0.002768 Acc: 13.2188\n",
      " |~~ train@26112  Loss: 0.002345 Acc: 13.2656\n",
      " |~~ train@26176  Loss: 0.003134 Acc: 13.0312\n",
      " |~~ train@26240  Loss: 0.002852 Acc: 13.2500\n",
      " |~~ train@26304  Loss: 0.002431 Acc: 13.3281\n",
      " |~~ train@26368  Loss: 0.002720 Acc: 13.1406\n",
      " |~~ train@26432  Loss: 0.002471 Acc: 13.3750\n",
      " |~~ train@26496  Loss: 0.002863 Acc: 13.1406\n",
      " |~~ train@26560  Loss: 0.002407 Acc: 13.4062\n",
      " |~~ train@26624  Loss: 0.002320 Acc: 13.3281\n",
      " |~~ train@26688  Loss: 0.002430 Acc: 13.4062\n",
      " |~~ train@26752  Loss: 0.002715 Acc: 13.2344\n",
      " |~~ train@26816  Loss: 0.003629 Acc: 12.9531\n",
      " |~~ train@26880  Loss: 0.003155 Acc: 13.0781\n",
      " |~~ train@26944  Loss: 0.002505 Acc: 13.2031\n",
      " |~~ train@27008  Loss: 0.002446 Acc: 13.3281\n",
      " |~~ train@27072  Loss: 0.002246 Acc: 13.4531\n",
      " |~~ train@27136  Loss: 0.003366 Acc: 13.0781\n",
      " |~~ train@27200  Loss: 0.003050 Acc: 13.0938\n",
      " |~~ train@27264  Loss: 0.002834 Acc: 13.1875\n",
      " |~~ train@27328  Loss: 0.002428 Acc: 13.3594\n",
      " |~~ train@27392  Loss: 0.002446 Acc: 13.3438\n",
      " |~~ train@27456  Loss: 0.002435 Acc: 13.2969\n",
      " |~~ train@27520  Loss: 0.002402 Acc: 13.3750\n",
      " |~~ train@27584  Loss: 0.002841 Acc: 13.1250\n",
      " |~~ train@27648  Loss: 0.002816 Acc: 13.1562\n",
      " |~~ train@27712  Loss: 0.002694 Acc: 13.2344\n",
      " |~~ train@27776  Loss: 0.002560 Acc: 13.2969\n",
      " |~~ train@27840  Loss: 0.002045 Acc: 13.4219\n",
      " |~~ train@27904  Loss: 0.002583 Acc: 13.2500\n",
      " |~~ train@27968  Loss: 0.002423 Acc: 13.3281\n",
      " |~~ train@28032  Loss: 0.002437 Acc: 13.2656\n",
      " |~~ train@28096  Loss: 0.002133 Acc: 13.4531\n",
      " |~~ train@28160  Loss: 0.002647 Acc: 13.3438\n",
      " |~~ train@28224  Loss: 0.002534 Acc: 13.2344\n",
      " |~~ train@28288  Loss: 0.002344 Acc: 13.2656\n",
      " |~~ train@28352  Loss: 0.002806 Acc: 13.2031\n",
      " |~~ train@28416  Loss: 0.002430 Acc: 13.3125\n",
      " |~~ train@28480  Loss: 0.002760 Acc: 13.2500\n",
      " |~~ train@28544  Loss: 0.002979 Acc: 13.1719\n",
      " |~~ train@28608  Loss: 0.002313 Acc: 13.4062\n",
      " |~~ train@28672  Loss: 0.002450 Acc: 13.2812\n",
      " |~~ train@28736  Loss: 0.002679 Acc: 13.2188\n",
      " |~~ train@28800  Loss: 0.002040 Acc: 13.5469\n",
      " |~~ train@28864  Loss: 0.002625 Acc: 13.3281\n",
      " |~~ train@28928  Loss: 0.003205 Acc: 13.1094\n",
      " |~~ train@28992  Loss: 0.002472 Acc: 13.2969\n",
      " |~~ train@29056  Loss: 0.003346 Acc: 13.0000\n",
      " |~~ train@29120  Loss: 0.001935 Acc: 13.4062\n",
      " |~~ train@29184  Loss: 0.002631 Acc: 13.2812\n",
      " |~~ train@29248  Loss: 0.002347 Acc: 13.3125\n",
      " |~~ train@29312  Loss: 0.002436 Acc: 13.3750\n",
      " |~~ train@29376  Loss: 0.003110 Acc: 13.0625\n",
      " |~~ train@29440  Loss: 0.002482 Acc: 13.2812\n",
      " |~~ train@29504  Loss: 0.001812 Acc: 13.5625\n",
      " |~~ train@29568  Loss: 0.002399 Acc: 13.2969\n",
      " |~~ train@29632  Loss: 0.002464 Acc: 13.3438\n",
      " |~~ train@29696  Loss: 0.002785 Acc: 13.1562\n",
      " |~~ train@29760  Loss: 0.002872 Acc: 13.1875\n",
      " |~~ train@29824  Loss: 0.002303 Acc: 13.3594\n",
      " |~~ train@29888  Loss: 0.002551 Acc: 13.2812\n",
      " |~~ train@29952  Loss: 0.002484 Acc: 13.2500\n",
      " |~~ train@30016  Loss: 0.002405 Acc: 13.3281\n",
      " |~~ train@30080  Loss: 0.002303 Acc: 13.3750\n",
      " |~~ train@30144  Loss: 0.002384 Acc: 13.3438\n",
      " |~~ train@30208  Loss: 0.002514 Acc: 13.2812\n",
      " |~~ train@30272  Loss: 0.002718 Acc: 13.2656\n",
      " |~~ train@30336  Loss: 0.002388 Acc: 13.3750\n",
      " |~~ train@30400  Loss: 0.002177 Acc: 13.4062\n",
      " |~~ train@30464  Loss: 0.002664 Acc: 13.2812\n",
      " |~~ train@30528  Loss: 0.002630 Acc: 13.2031\n",
      " |~~ train@30592  Loss: 0.002135 Acc: 13.4531\n",
      " |~~ train@30656  Loss: 0.002454 Acc: 13.2656\n",
      " |~~ train@30720  Loss: 0.002349 Acc: 13.4531\n",
      " |~~ train@30784  Loss: 0.002065 Acc: 13.4688\n",
      " |~~ train@30848  Loss: 0.002808 Acc: 13.3438\n",
      " |~~ train@30912  Loss: 0.002519 Acc: 13.3750\n",
      " |~~ train@30976  Loss: 0.002839 Acc: 13.2500\n",
      " |~~ train@31040  Loss: 0.003103 Acc: 13.2188\n",
      " |~~ train@31104  Loss: 0.002637 Acc: 13.2656\n",
      " |~~ train@31168  Loss: 0.002433 Acc: 13.2656\n",
      " |~~ train@31232  Loss: 0.002634 Acc: 13.2188\n",
      " |~~ train@31296  Loss: 0.002861 Acc: 13.2188\n",
      " |~~ train@31360  Loss: 0.002610 Acc: 13.3281\n",
      " |~~ train@31424  Loss: 0.002067 Acc: 13.4062\n",
      " |~~ train@31488  Loss: 0.002811 Acc: 13.2031\n",
      " |~~ train@31552  Loss: 0.002281 Acc: 13.3906\n",
      " |~~ train@31616  Loss: 0.002725 Acc: 13.2969\n",
      " |~~ train@31680  Loss: 0.002015 Acc: 13.3906\n",
      " |~~ train@31744  Loss: 0.002433 Acc: 13.2500\n",
      " |~~ train@31808  Loss: 0.002466 Acc: 13.3438\n",
      " |~~ train@31872  Loss: 0.002225 Acc: 13.4219\n",
      " |~~ train@31936  Loss: 0.002358 Acc: 13.3438\n",
      " |~~ train@32000  Loss: 0.002505 Acc: 13.3281\n",
      " |~~ train@32064  Loss: 0.002388 Acc: 13.2812\n",
      " |~~ train@32128  Loss: 0.002150 Acc: 13.3906\n",
      " |~~ train@32192  Loss: 0.002850 Acc: 13.1875\n",
      " |~~ train@32256  Loss: 0.002050 Acc: 13.4219\n",
      " |~~ train@32320  Loss: 0.002082 Acc: 13.4531\n",
      " |~~ train@32384  Loss: 0.001988 Acc: 13.4844\n",
      " |~~ train@32448  Loss: 0.002210 Acc: 13.3750\n",
      " |~~ train@32512  Loss: 0.002431 Acc: 13.3125\n",
      " |~~ train@32576  Loss: 0.003053 Acc: 13.1250\n",
      " |~~ train@32640  Loss: 0.002351 Acc: 13.3594\n",
      " |~~ train@32704  Loss: 0.002434 Acc: 13.3281\n",
      " |~~ train@32768  Loss: 0.002456 Acc: 13.2812\n",
      " |~~ train@32832  Loss: 0.002451 Acc: 13.3125\n",
      " |~~ train@32896  Loss: 0.002884 Acc: 13.1875\n",
      " |~~ train@32960  Loss: 0.003086 Acc: 13.1406\n",
      " |~~ train@33024  Loss: 0.003057 Acc: 13.1875\n",
      " |~~ train@33088  Loss: 0.002857 Acc: 13.2188\n",
      " |~~ train@33152  Loss: 0.002876 Acc: 13.1406\n",
      " |~~ train@33216  Loss: 0.002407 Acc: 13.2812\n",
      " |~~ train@33280  Loss: 0.003137 Acc: 13.1094\n",
      " |~~ train@33344  Loss: 0.002257 Acc: 13.4219\n",
      " |~~ train@33408  Loss: 0.002260 Acc: 13.3750\n",
      " |~~ train@33472  Loss: 0.002277 Acc: 13.2812\n",
      " |~~ train@33536  Loss: 0.002378 Acc: 13.2969\n",
      " |~~ train@33600  Loss: 0.002578 Acc: 13.1875\n",
      " |~~ train@33664  Loss: 0.003127 Acc: 13.1719\n",
      " |~~ train@33728  Loss: 0.002620 Acc: 13.1875\n",
      " |~~ train@33792  Loss: 0.002610 Acc: 13.2188\n",
      " |~~ train@33856  Loss: 0.002653 Acc: 13.2812\n",
      " |~~ train@33920  Loss: 0.002545 Acc: 13.2812\n",
      " |~~ train@33984  Loss: 0.002758 Acc: 13.2031\n",
      " |~~ train@34048  Loss: 0.002697 Acc: 13.2344\n",
      " |~~ train@34112  Loss: 0.002037 Acc: 13.4219\n",
      " |~~ train@34176  Loss: 0.002430 Acc: 13.2344\n",
      " |~~ train@34240  Loss: 0.002560 Acc: 13.3125\n",
      " |~~ train@34304  Loss: 0.002634 Acc: 13.2812\n",
      " |~~ train@34368  Loss: 0.003070 Acc: 13.0625\n",
      " |~~ train@34432  Loss: 0.002902 Acc: 13.1562\n",
      " |~~ train@34496  Loss: 0.002643 Acc: 13.1562\n",
      " |~~ train@34560  Loss: 0.002614 Acc: 13.2500\n",
      " |~~ train@34624  Loss: 0.003107 Acc: 13.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@34688  Loss: 0.002369 Acc: 13.3281\n",
      " |~~ train@34752  Loss: 0.002574 Acc: 13.2812\n",
      " |~~ train@34816  Loss: 0.002701 Acc: 13.1875\n",
      " |~~ train@34880  Loss: 0.002324 Acc: 13.3594\n",
      " |~~ train@34944  Loss: 0.002856 Acc: 13.1250\n",
      " |~~ train@35008  Loss: 0.002399 Acc: 13.3906\n",
      " |~~ train@35072  Loss: 0.002602 Acc: 13.2969\n",
      " |~~ train@35136  Loss: 0.002651 Acc: 13.2812\n",
      " |~~ train@35200  Loss: 0.002657 Acc: 13.2656\n",
      " |~~ train@35264  Loss: 0.002666 Acc: 13.2656\n",
      " |~~ train@35328  Loss: 0.002557 Acc: 13.2812\n",
      " |~~ train@35392  Loss: 0.002883 Acc: 13.2344\n",
      " |~~ train@35456  Loss: 0.002771 Acc: 13.2031\n",
      " |~~ train@35520  Loss: 0.002469 Acc: 13.2344\n",
      " |~~ train@35584  Loss: 0.002459 Acc: 13.3750\n",
      " |~~ train@35648  Loss: 0.002335 Acc: 13.2812\n",
      " |~~ train@35712  Loss: 0.001982 Acc: 13.3906\n",
      " |~~ train@35776  Loss: 0.002846 Acc: 13.1875\n",
      " |~~ train@35840  Loss: 0.002294 Acc: 13.3125\n",
      " |~~ train@35904  Loss: 0.002725 Acc: 13.1719\n",
      " |~~ train@35968  Loss: 0.003124 Acc: 13.0781\n",
      " |~~ train@36032  Loss: 0.002752 Acc: 13.2812\n",
      " |~~ train@36096  Loss: 0.003002 Acc: 13.1875\n",
      " |~~ train@36160  Loss: 0.002545 Acc: 13.2188\n",
      " |~~ train@36224  Loss: 0.002579 Acc: 13.3125\n",
      " |~~ train@36288  Loss: 0.002247 Acc: 13.4375\n",
      " |~~ train@36352  Loss: 0.002769 Acc: 13.2656\n",
      " |~~ train@36416  Loss: 0.002344 Acc: 13.3281\n",
      " |~~ train@36480  Loss: 0.002445 Acc: 13.3281\n",
      " |~~ train@36544  Loss: 0.002122 Acc: 13.4219\n",
      " |~~ train@36608  Loss: 0.002742 Acc: 13.1719\n",
      " |~~ train@36672  Loss: 0.002894 Acc: 13.1094\n",
      " |~~ train@36736  Loss: 0.002979 Acc: 13.1406\n",
      " |~~ train@36800  Loss: 0.002461 Acc: 13.3750\n",
      " |~~ train@36864  Loss: 0.003086 Acc: 13.0312\n",
      " |~~ train@36928  Loss: 0.002655 Acc: 13.2500\n",
      " |~~ train@36992  Loss: 0.002855 Acc: 13.1250\n",
      " |~~ train@37056  Loss: 0.002931 Acc: 13.2188\n",
      " |~~ train@37120  Loss: 0.002409 Acc: 13.3438\n",
      " |~~ train@37184  Loss: 0.002182 Acc: 13.3750\n",
      " |~~ train@37248  Loss: 0.002041 Acc: 13.4062\n",
      " |~~ train@37312  Loss: 0.002919 Acc: 13.1406\n",
      " |~~ train@37376  Loss: 0.002699 Acc: 13.2344\n",
      " |~~ train@37440  Loss: 0.002262 Acc: 13.3906\n",
      " |~~ train@37504  Loss: 0.002709 Acc: 13.2344\n",
      " |~~ train@37568  Loss: 0.002133 Acc: 13.3906\n",
      " |~~ train@37632  Loss: 0.002642 Acc: 13.2188\n",
      " |~~ train@37696  Loss: 0.002459 Acc: 13.3750\n",
      " |~~ train@37760  Loss: 0.003027 Acc: 13.2500\n",
      " |~~ train@37824  Loss: 0.002606 Acc: 13.2500\n",
      " |~~ train@37888  Loss: 0.002321 Acc: 13.3594\n",
      " |~~ train@37952  Loss: 0.002517 Acc: 13.3281\n",
      " |~~ train@38016  Loss: 0.002314 Acc: 13.3594\n",
      " |~~ train@38080  Loss: 0.002006 Acc: 13.4531\n",
      " |~~ train@38144  Loss: 0.002207 Acc: 13.3906\n",
      " |~~ train@38208  Loss: 0.002790 Acc: 13.1719\n",
      " |~~ train@38272  Loss: 0.002490 Acc: 13.2969\n",
      " |~~ train@38336  Loss: 0.002739 Acc: 13.2344\n",
      " |~~ train@38400  Loss: 0.001749 Acc: 13.5938\n",
      " |~~ train@38464  Loss: 0.002494 Acc: 13.2344\n",
      " |~~ train@38528  Loss: 0.002375 Acc: 13.2969\n",
      " |~~ train@38592  Loss: 0.003360 Acc: 13.0156\n",
      " |~~ train@38656  Loss: 0.002240 Acc: 13.3906\n",
      " |~~ train@38720  Loss: 0.002877 Acc: 13.1094\n",
      " |~~ train@38784  Loss: 0.002161 Acc: 13.4375\n",
      " |~~ train@38848  Loss: 0.002549 Acc: 13.2656\n",
      " |~~ train@38912  Loss: 0.002710 Acc: 13.2188\n",
      " |~~ train@38976  Loss: 0.002840 Acc: 13.2031\n",
      " |~~ train@39040  Loss: 0.002725 Acc: 13.1875\n",
      " |~~ train@39104  Loss: 0.002253 Acc: 13.3906\n",
      " |~~ train@39168  Loss: 0.002954 Acc: 13.2031\n",
      " |~~ train@39232  Loss: 0.002234 Acc: 13.3125\n",
      " |~~ train@39296  Loss: 0.002576 Acc: 13.2969\n",
      " |~~ train@39360  Loss: 0.002142 Acc: 13.3750\n",
      " |~~ train@39424  Loss: 0.002303 Acc: 13.3750\n",
      " |~~ train@39488  Loss: 0.002210 Acc: 13.3281\n",
      " |~~ train@39552  Loss: 0.002579 Acc: 13.2656\n",
      " |~~ train@39616  Loss: 0.003600 Acc: 12.9219\n",
      " |~~ train@39680  Loss: 0.002624 Acc: 13.1562\n",
      " |~~ train@39744  Loss: 0.002234 Acc: 13.3125\n",
      " |~~ train@39808  Loss: 0.002226 Acc: 13.4062\n",
      " |~~ train@39872  Loss: 0.002272 Acc: 13.4062\n",
      " |~~ train@39936  Loss: 0.002473 Acc: 13.2812\n",
      " |~~ train@40000  Loss: 0.003328 Acc: 13.0000\n",
      " |~~ train@40064  Loss: 0.002474 Acc: 13.3281\n",
      " |~~ train@40128  Loss: 0.002683 Acc: 13.3125\n",
      " |~~ train@40192  Loss: 0.002513 Acc: 13.2812\n",
      " |~~ train@40256  Loss: 0.002488 Acc: 13.2500\n",
      " |~~ train@40320  Loss: 0.002295 Acc: 13.3594\n",
      " |~~ train@40384  Loss: 0.002106 Acc: 13.4219\n",
      " |~~ train@40448  Loss: 0.002378 Acc: 13.3438\n",
      " |~~ train@40512  Loss: 0.002919 Acc: 13.1875\n",
      " |~~ train@40576  Loss: 0.002139 Acc: 13.4375\n",
      " |~~ train@40640  Loss: 0.002532 Acc: 13.2969\n",
      " |~~ train@40704  Loss: 0.002312 Acc: 13.3125\n",
      " |~~ train@40768  Loss: 0.002309 Acc: 13.4219\n",
      " |~~ train@40832  Loss: 0.002333 Acc: 13.3594\n",
      " |~~ train@40896  Loss: 0.002108 Acc: 13.4219\n",
      " |~~ train@40960  Loss: 0.003578 Acc: 13.0000\n",
      " |~~ train@41024  Loss: 0.003191 Acc: 13.1250\n",
      " |~~ train@41088  Loss: 0.002614 Acc: 13.2344\n",
      " |~~ train@41152  Loss: 0.002081 Acc: 13.4531\n",
      " |~~ train@41216  Loss: 0.002988 Acc: 13.2031\n",
      " |~~ train@41280  Loss: 0.002334 Acc: 13.3125\n",
      " |~~ train@41344  Loss: 0.002372 Acc: 13.3438\n",
      " |~~ train@41408  Loss: 0.002347 Acc: 13.3594\n",
      " |~~ train@41472  Loss: 0.003032 Acc: 13.0938\n",
      " |~~ train@41536  Loss: 0.002267 Acc: 13.4062\n",
      " |~~ train@41600  Loss: 0.002525 Acc: 13.3438\n",
      " |~~ train@41664  Loss: 0.002538 Acc: 13.2500\n",
      " |~~ train@41728  Loss: 0.002280 Acc: 13.3750\n",
      " |~~ train@41792  Loss: 0.002882 Acc: 13.2188\n",
      " |~~ train@41856  Loss: 0.002100 Acc: 13.3750\n",
      " |~~ train@41920  Loss: 0.002276 Acc: 13.3594\n",
      " |~~ train@41984  Loss: 0.002898 Acc: 13.1562\n",
      " |~~ train@42048  Loss: 0.002087 Acc: 13.4375\n",
      " |~~ train@42112  Loss: 0.002603 Acc: 13.2500\n",
      " |~~ train@42176  Loss: 0.002790 Acc: 13.2500\n",
      " |~~ train@42240  Loss: 0.002320 Acc: 13.3750\n",
      " |~~ train@42304  Loss: 0.002656 Acc: 13.2344\n",
      " |~~ train@42368  Loss: 0.002770 Acc: 13.1562\n",
      " |~~ train@42432  Loss: 0.002651 Acc: 13.3281\n",
      " |~~ train@42496  Loss: 0.002507 Acc: 13.2812\n",
      " |~~ train@42560  Loss: 0.002864 Acc: 13.1406\n",
      " |~~ train@42624  Loss: 0.002017 Acc: 13.4531\n",
      " |~~ train@42688  Loss: 0.002220 Acc: 13.4062\n",
      " |~~ train@42752  Loss: 0.002750 Acc: 13.2500\n",
      " |~~ train@42816  Loss: 0.002895 Acc: 13.1719\n",
      " |~~ train@42880  Loss: 0.002332 Acc: 13.3594\n",
      " |~~ train@42944  Loss: 0.002682 Acc: 13.3125\n",
      " |~~ train@43008  Loss: 0.002441 Acc: 13.2969\n",
      " |~~ train@43072  Loss: 0.002306 Acc: 13.4219\n",
      " |~~ train@43136  Loss: 0.002542 Acc: 13.2812\n",
      " |~~ train@43200  Loss: 0.002573 Acc: 13.2969\n",
      " |~~ train@43264  Loss: 0.002460 Acc: 13.3750\n",
      " |~~ train@43328  Loss: 0.002805 Acc: 13.2188\n",
      " |~~ train@43392  Loss: 0.002724 Acc: 13.2344\n",
      " |~~ train@43456  Loss: 0.002479 Acc: 13.2656\n",
      " |~~ train@43520  Loss: 0.002603 Acc: 13.2500\n",
      " |~~ train@43584  Loss: 0.002719 Acc: 13.2031\n",
      " |~~ train@43648  Loss: 0.002786 Acc: 13.1875\n",
      " |~~ train@43712  Loss: 0.002214 Acc: 13.3438\n",
      " |~~ train@43776  Loss: 0.002463 Acc: 13.3906\n",
      " |~~ train@43840  Loss: 0.002534 Acc: 13.2500\n",
      " |~~ train@43904  Loss: 0.002181 Acc: 13.3438\n",
      " |~~ train@43968  Loss: 0.002106 Acc: 13.3438\n",
      " |~~ train@44032  Loss: 0.002334 Acc: 13.3906\n",
      " |~~ train@44096  Loss: 0.002965 Acc: 13.2500\n",
      " |~~ train@44160  Loss: 0.002900 Acc: 13.1250\n",
      " |~~ train@44224  Loss: 0.002429 Acc: 13.2969\n",
      " |~~ train@44288  Loss: 0.002218 Acc: 13.4219\n",
      " |~~ train@44352  Loss: 0.002512 Acc: 13.3594\n",
      " |~~ train@44416  Loss: 0.002366 Acc: 13.3438\n",
      " |~~ train@44480  Loss: 0.002824 Acc: 13.2031\n",
      " |~~ train@44544  Loss: 0.002616 Acc: 13.2656\n",
      " |~~ train@44608  Loss: 0.002473 Acc: 13.3125\n",
      " |~~ train@44672  Loss: 0.002406 Acc: 13.2344\n",
      " |~~ train@44736  Loss: 0.002564 Acc: 13.2812\n",
      " |~~ train@44800  Loss: 0.002392 Acc: 13.2969\n",
      " |~~ train@44864  Loss: 0.002606 Acc: 13.2969\n",
      " |~~ train@44928  Loss: 0.002504 Acc: 13.4219\n",
      " |~~ train@44992  Loss: 0.002885 Acc: 13.0938\n",
      " |~~ train@45056  Loss: 0.002339 Acc: 13.2812\n",
      " |~~ train@45120  Loss: 0.003273 Acc: 13.0625\n",
      " |~~ train@45184  Loss: 0.002773 Acc: 13.2344\n",
      " |~~ train@45248  Loss: 0.003153 Acc: 13.0625\n",
      " |~~ train@45312  Loss: 0.002692 Acc: 13.1562\n",
      " |~~ train@45376  Loss: 0.002619 Acc: 13.2031\n",
      " |~~ train@45440  Loss: 0.002467 Acc: 13.2969\n",
      " |~~ train@45504  Loss: 0.002650 Acc: 13.1250\n",
      " |~~ train@45568  Loss: 0.002218 Acc: 13.4375\n",
      " |~~ train@45632  Loss: 0.002290 Acc: 13.4375\n",
      " |~~ train@45696  Loss: 0.001974 Acc: 13.4531\n",
      " |~~ train@45760  Loss: 0.002030 Acc: 13.4375\n",
      " |~~ train@45824  Loss: 0.002685 Acc: 13.2344\n",
      " |~~ train@45888  Loss: 0.002401 Acc: 13.3438\n",
      " |~~ train@45952  Loss: 0.002902 Acc: 13.0625\n",
      " |~~ train@46016  Loss: 0.003006 Acc: 13.1875\n",
      " |~~ train@46080  Loss: 0.002954 Acc: 13.1719\n",
      " |~~ train@46144  Loss: 0.002233 Acc: 13.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@46208  Loss: 0.002520 Acc: 13.3281\n",
      " |~~ train@46272  Loss: 0.002704 Acc: 13.1094\n",
      " |~~ train@46336  Loss: 0.002372 Acc: 13.2812\n",
      " |~~ train@46400  Loss: 0.002469 Acc: 13.2969\n",
      " |~~ train@46464  Loss: 0.003057 Acc: 13.1094\n",
      " |~~ train@46528  Loss: 0.002065 Acc: 13.4375\n",
      " |~~ train@46592  Loss: 0.002648 Acc: 13.2969\n",
      " |~~ train@46656  Loss: 0.002448 Acc: 13.3281\n",
      " |~~ train@46720  Loss: 0.002462 Acc: 13.2188\n",
      " |~~ train@46784  Loss: 0.002487 Acc: 13.3438\n",
      " |~~ train@46848  Loss: 0.002594 Acc: 13.2500\n",
      " |~~ train@46912  Loss: 0.002623 Acc: 13.2188\n",
      " |~~ train@46976  Loss: 0.002129 Acc: 13.4531\n",
      " |~~ train@47040  Loss: 0.003079 Acc: 13.0781\n",
      " |~~ train@47104  Loss: 0.002511 Acc: 13.2969\n",
      " |~~ train@47168  Loss: 0.002421 Acc: 13.2812\n",
      " |~~ train@47232  Loss: 0.002642 Acc: 13.2812\n",
      " |~~ train@47296  Loss: 0.002366 Acc: 13.3125\n",
      " |~~ train@47360  Loss: 0.002702 Acc: 13.2812\n",
      " |~~ train@47424  Loss: 0.002449 Acc: 13.3281\n",
      " |~~ train@47488  Loss: 0.001884 Acc: 13.5156\n",
      " |~~ train@47552  Loss: 0.002431 Acc: 13.3281\n",
      " |~~ train@47616  Loss: 0.002257 Acc: 13.3438\n",
      " |~~ train@47680  Loss: 0.002378 Acc: 13.4219\n",
      " |~~ train@47744  Loss: 0.002149 Acc: 13.3750\n",
      " |~~ train@47808  Loss: 0.002121 Acc: 13.3906\n",
      " |~~ train@47872  Loss: 0.002575 Acc: 13.2031\n",
      " |~~ train@47936  Loss: 0.002603 Acc: 13.2812\n",
      " |~~ train@48000  Loss: 0.002949 Acc: 13.0781\n",
      " |~~ train@48064  Loss: 0.002820 Acc: 13.1875\n",
      " |~~ train@48128  Loss: 0.002544 Acc: 13.2500\n",
      " |~~ train@48192  Loss: 0.002061 Acc: 13.3906\n",
      " |~~ train@48256  Loss: 0.002433 Acc: 13.2812\n",
      " |~~ train@48320  Loss: 0.002629 Acc: 13.2656\n",
      " |~~ train@48384  Loss: 0.002315 Acc: 13.3906\n",
      " |~~ train@48448  Loss: 0.002284 Acc: 13.3750\n",
      " |~~ train@48512  Loss: 0.002823 Acc: 13.1875\n",
      " |~~ train@48576  Loss: 0.002376 Acc: 13.3594\n",
      " |~~ train@48640  Loss: 0.003048 Acc: 13.0938\n",
      " |~~ train@48704  Loss: 0.002915 Acc: 13.2188\n",
      " |~~ train@48768  Loss: 0.002543 Acc: 13.2500\n",
      " |~~ train@48832  Loss: 0.002202 Acc: 13.4219\n",
      " |~~ train@48896  Loss: 0.003111 Acc: 13.1250\n",
      " |~~ train@48960  Loss: 0.002885 Acc: 13.2188\n",
      " |~~ train@49024  Loss: 0.002164 Acc: 13.3906\n",
      " |~~ train@49088  Loss: 0.002774 Acc: 13.2500\n",
      " |~~ train@49152  Loss: 0.002416 Acc: 13.3125\n",
      " |~~ train@49216  Loss: 0.002420 Acc: 13.3438\n",
      " |~~ train@49280  Loss: 0.002369 Acc: 13.2969\n",
      " |~~ train@49344  Loss: 0.002857 Acc: 13.1719\n",
      " |~~ train@49408  Loss: 0.002256 Acc: 13.3750\n",
      " |~~ train@49472  Loss: 0.002770 Acc: 13.2188\n",
      " |~~ train@49536  Loss: 0.002801 Acc: 13.2500\n",
      " |~~ train@49600  Loss: 0.003029 Acc: 13.0938\n",
      " |~~ train@49664  Loss: 0.001947 Acc: 13.5312\n",
      " |~~ train@49728  Loss: 0.002572 Acc: 13.2656\n",
      " |~~ train@49792  Loss: 0.002291 Acc: 13.3750\n",
      " |~~ train@49856  Loss: 0.002772 Acc: 13.2500\n",
      " |~~ train@49920  Loss: 0.003132 Acc: 12.9688\n",
      " |~~ train@49984  Loss: 0.003134 Acc: 13.0781\n",
      " |~~ train@50048  Loss: 0.002899 Acc: 13.1094\n",
      " |~~ train@50112  Loss: 0.002665 Acc: 13.2969\n",
      " |~~ train@50176  Loss: 0.002146 Acc: 13.3750\n",
      " |~~ train@50240  Loss: 0.003155 Acc: 13.0781\n",
      " |~~ train@50304  Loss: 0.002401 Acc: 13.2344\n",
      " |~~ train@50368  Loss: 0.002844 Acc: 13.1562\n",
      " |~~ train@50432  Loss: 0.001839 Acc: 13.5156\n",
      " |~~ train@50496  Loss: 0.002574 Acc: 13.2500\n",
      " |~~ train@50560  Loss: 0.002436 Acc: 13.2969\n",
      " |~~ train@50624  Loss: 0.002598 Acc: 13.2969\n",
      " |~~ train@50688  Loss: 0.001783 Acc: 13.6094\n",
      " |~~ train@50752  Loss: 0.002577 Acc: 13.3281\n",
      " |~~ train@50816  Loss: 0.002685 Acc: 13.1875\n",
      " |~~ train@50880  Loss: 0.002287 Acc: 13.3125\n",
      " |~~ train@50944  Loss: 0.002568 Acc: 13.2500\n",
      " |~~ train@51008  Loss: 0.002600 Acc: 13.2344\n",
      " |~~ train@51072  Loss: 0.002819 Acc: 13.1406\n",
      " |~~ train@51136  Loss: 0.002378 Acc: 13.3750\n",
      " |~~ train@51200  Loss: 0.002430 Acc: 13.2656\n",
      " |~~ train@51264  Loss: 0.002938 Acc: 13.1406\n",
      " |~~ train@51328  Loss: 0.002282 Acc: 13.3750\n",
      " |~~ train@51392  Loss: 0.002310 Acc: 13.2969\n",
      " |~~ train@51456  Loss: 0.002710 Acc: 13.2188\n",
      " |~~ train@51520  Loss: 0.002475 Acc: 13.2969\n",
      " |~~ train@51584  Loss: 0.002761 Acc: 13.2188\n",
      " |~~ train@51648  Loss: 0.001910 Acc: 13.4531\n",
      " |~~ train@51712  Loss: 0.002704 Acc: 13.3438\n",
      " |~~ train@51776  Loss: 0.002334 Acc: 13.2969\n",
      " |~~ train@51840  Loss: 0.002771 Acc: 13.1562\n",
      " |~~ train@51904  Loss: 0.002253 Acc: 13.4375\n",
      " |~~ train@51968  Loss: 0.002738 Acc: 13.2031\n",
      " |~~ train@52032  Loss: 0.002718 Acc: 13.3281\n",
      " |~~ train@52096  Loss: 0.002302 Acc: 13.3281\n",
      " |~~ train@52160  Loss: 0.002776 Acc: 13.2188\n",
      " |~~ train@52224  Loss: 0.002681 Acc: 13.2344\n",
      " |~~ train@52288  Loss: 0.002671 Acc: 13.1562\n",
      " |~~ train@52352  Loss: 0.002799 Acc: 13.0938\n",
      " |~~ train@52416  Loss: 0.003107 Acc: 13.2031\n",
      " |~~ train@52480  Loss: 0.002064 Acc: 13.4219\n",
      " |~~ train@52544  Loss: 0.002278 Acc: 13.2812\n",
      " |~~ train@52608  Loss: 0.002804 Acc: 13.2031\n",
      " |~~ train@52672  Loss: 0.002127 Acc: 13.3906\n",
      " |~~ train@52736  Loss: 0.002738 Acc: 13.1875\n",
      " |~~ train@52800  Loss: 0.002258 Acc: 13.3750\n",
      " |~~ train@52864  Loss: 0.002308 Acc: 13.3125\n",
      " |~~ train@52928  Loss: 0.002454 Acc: 13.3281\n",
      " |~~ train@52992  Loss: 0.002564 Acc: 13.2344\n",
      " |~~ train@53056  Loss: 0.002260 Acc: 13.3594\n",
      " |~~ train@53120  Loss: 0.002739 Acc: 13.2188\n",
      " |~~ train@53184  Loss: 0.002436 Acc: 13.3281\n",
      " |~~ train@53248  Loss: 0.002854 Acc: 13.1562\n",
      " |~~ train@53312  Loss: 0.002786 Acc: 13.1250\n",
      " |~~ train@53376  Loss: 0.002711 Acc: 13.1719\n",
      " |~~ train@53440  Loss: 0.002220 Acc: 13.3750\n",
      " |~~ train@53504  Loss: 0.002659 Acc: 13.2812\n",
      " |~~ train@53568  Loss: 0.002297 Acc: 13.2500\n",
      " |~~ train@53632  Loss: 0.002371 Acc: 13.3594\n",
      " |~~ train@53696  Loss: 0.002844 Acc: 13.1875\n",
      " |~~ train@53760  Loss: 0.003264 Acc: 13.0312\n",
      " |~~ train@53824  Loss: 0.002661 Acc: 13.2812\n",
      " |~~ train@53888  Loss: 0.001937 Acc: 13.5469\n",
      " |~~ train@53952  Loss: 0.002659 Acc: 13.2656\n",
      " |~~ train@54016  Loss: 0.002491 Acc: 13.2656\n",
      " |~~ train@54080  Loss: 0.002056 Acc: 13.3594\n",
      " |~~ train@54144  Loss: 0.002468 Acc: 13.3125\n",
      " |~~ train@54208  Loss: 0.002354 Acc: 13.3125\n",
      " |~~ train@54272  Loss: 0.002518 Acc: 13.2656\n",
      " |~~ train@54336  Loss: 0.002586 Acc: 13.2656\n",
      " |~~ train@54400  Loss: 0.002697 Acc: 13.2188\n",
      " |~~ train@54464  Loss: 0.002475 Acc: 13.2500\n",
      " |~~ train@54528  Loss: 0.002417 Acc: 13.3750\n",
      " |~~ train@54592  Loss: 0.002176 Acc: 13.4531\n",
      " |~~ train@54656  Loss: 0.002253 Acc: 13.3438\n",
      " |~~ train@54720  Loss: 0.002293 Acc: 13.3125\n",
      " |~~ train@54784  Loss: 0.002464 Acc: 13.2656\n",
      " |~~ train@54848  Loss: 0.002752 Acc: 13.2188\n",
      " |~~ train@54912  Loss: 0.002121 Acc: 13.4219\n",
      " |~~ train@54976  Loss: 0.002824 Acc: 13.1875\n",
      " |~~ train@55040  Loss: 0.002448 Acc: 13.2969\n",
      " |~~ train@55104  Loss: 0.002010 Acc: 13.4688\n",
      " |~~ train@55168  Loss: 0.002669 Acc: 13.1875\n",
      " |~~ train@55232  Loss: 0.002900 Acc: 13.0625\n",
      " |~~ train@55296  Loss: 0.002510 Acc: 13.3438\n",
      " |~~ train@55360  Loss: 0.002556 Acc: 13.2188\n",
      " |~~ train@55424  Loss: 0.002422 Acc: 13.3125\n",
      " |~~ train@55488  Loss: 0.002598 Acc: 13.1719\n",
      " |~~ train@55552  Loss: 0.002642 Acc: 13.1875\n",
      " |~~ train@55616  Loss: 0.002662 Acc: 13.1875\n",
      " |~~ train@55680  Loss: 0.002419 Acc: 13.3438\n",
      " |~~ train@55744  Loss: 0.002759 Acc: 13.1562\n",
      " |~~ train@55808  Loss: 0.002822 Acc: 13.2500\n",
      " |~~ train@55872  Loss: 0.002756 Acc: 13.1719\n",
      " |~~ train@55936  Loss: 0.002141 Acc: 13.4531\n",
      " |~~ train@56000  Loss: 0.002421 Acc: 13.2969\n",
      " |~~ train@56064  Loss: 0.002252 Acc: 13.3594\n",
      " |~~ train@56128  Loss: 0.002084 Acc: 13.2969\n",
      " |~~ train@56192  Loss: 0.002228 Acc: 13.2656\n",
      " |~~ train@56256  Loss: 0.002161 Acc: 13.3750\n",
      " |~~ train@56320  Loss: 0.002408 Acc: 13.2656\n",
      " |~~ train@56384  Loss: 0.002597 Acc: 13.1719\n",
      " |~~ train@56448  Loss: 0.002363 Acc: 13.3281\n",
      " |~~ train@56512  Loss: 0.002682 Acc: 13.2344\n",
      " |~~ train@56576  Loss: 0.002038 Acc: 13.4688\n",
      " |~~ train@56640  Loss: 0.002426 Acc: 13.2656\n",
      " |~~ train@56704  Loss: 0.002192 Acc: 13.3594\n",
      " |~~ train@56768  Loss: 0.002855 Acc: 13.1406\n",
      " |~~ train@56832  Loss: 0.002795 Acc: 13.1250\n",
      " |~~ train@56896  Loss: 0.002030 Acc: 13.4688\n",
      " |~~ train@56960  Loss: 0.001935 Acc: 13.5312\n",
      " |~~ train@57024  Loss: 0.002183 Acc: 13.4062\n",
      " |~~ train@57088  Loss: 0.002420 Acc: 13.2812\n",
      " |~~ train@57152  Loss: 0.002210 Acc: 13.3438\n",
      " |~~ train@57216  Loss: 0.002521 Acc: 13.2344\n",
      " |~~ train@57280  Loss: 0.002234 Acc: 13.3125\n",
      " |~~ train@57344  Loss: 0.002516 Acc: 13.2656\n",
      " |~~ train@57408  Loss: 0.002114 Acc: 13.3594\n",
      " |~~ train@57472  Loss: 0.001832 Acc: 13.5156\n",
      " |~~ train@57536  Loss: 0.002804 Acc: 13.1406\n",
      " |~~ train@57600  Loss: 0.002366 Acc: 13.3594\n",
      " |~~ train@57664  Loss: 0.002560 Acc: 13.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@57728  Loss: 0.002547 Acc: 13.2344\n",
      " |~~ train@57792  Loss: 0.002902 Acc: 13.1094\n",
      " |~~ train@57856  Loss: 0.002665 Acc: 13.3438\n",
      " |~~ train@57920  Loss: 0.002653 Acc: 13.2500\n",
      " |~~ train@57984  Loss: 0.002413 Acc: 13.3281\n",
      " |~~ train@58048  Loss: 0.002503 Acc: 13.2656\n",
      " |~~ train@58112  Loss: 0.002447 Acc: 13.2500\n",
      " |~~ train@58176  Loss: 0.002140 Acc: 13.4688\n",
      " |~~ train@58240  Loss: 0.002063 Acc: 13.4062\n",
      " |~~ train@58304  Loss: 0.002775 Acc: 13.2656\n",
      " |~~ train@58368  Loss: 0.002160 Acc: 13.4375\n",
      " |~~ train@58432  Loss: 0.002098 Acc: 13.5156\n",
      " |~~ train@58496  Loss: 0.001874 Acc: 13.5000\n",
      " |~~ train@58560  Loss: 0.002598 Acc: 13.3125\n",
      " |~~ train@58624  Loss: 0.002553 Acc: 13.2500\n",
      " |~~ train@58688  Loss: 0.002354 Acc: 13.3125\n",
      " |~~ train@58752  Loss: 0.002059 Acc: 13.3750\n",
      " |~~ train@58816  Loss: 0.002089 Acc: 13.4219\n",
      " |~~ train@58880  Loss: 0.002860 Acc: 13.1562\n",
      " |~~ train@58944  Loss: 0.002063 Acc: 13.4375\n",
      " |~~ train@59008  Loss: 0.002765 Acc: 13.1250\n",
      " |~~ train@59072  Loss: 0.002082 Acc: 13.5000\n",
      " |~~ train@59136  Loss: 0.002391 Acc: 13.3594\n",
      " |~~ train@59200  Loss: 0.002793 Acc: 13.1719\n",
      " |~~ train@59264  Loss: 0.002038 Acc: 13.4531\n",
      " |~~ train@59328  Loss: 0.002205 Acc: 13.4062\n",
      " |~~ train@59392  Loss: 0.002634 Acc: 13.1719\n",
      " |~~ train@59456  Loss: 0.002621 Acc: 13.2656\n",
      " |~~ train@59520  Loss: 0.002445 Acc: 13.2344\n",
      " |~~ train@59584  Loss: 0.002441 Acc: 13.2500\n",
      " |~~ train@59648  Loss: 0.002663 Acc: 13.1562\n",
      " |~~ train@59712  Loss: 0.002114 Acc: 13.4062\n",
      " |~~ train@59776  Loss: 0.002458 Acc: 13.3281\n",
      " |~~ train@59840  Loss: 0.002463 Acc: 13.3125\n",
      " |~~ train@59904  Loss: 0.002042 Acc: 13.5156\n",
      " |~~ train@59968  Loss: 0.002304 Acc: 13.3281\n",
      " |~~ train@60032  Loss: 0.002475 Acc: 13.2656\n",
      " |~~ train@60096  Loss: 0.002302 Acc: 13.3594\n",
      " |~~ train@60160  Loss: 0.002679 Acc: 13.3281\n",
      " |~~ train@60224  Loss: 0.002031 Acc: 13.3906\n",
      " |~~ train@60288  Loss: 0.001853 Acc: 13.5156\n",
      " |~~ train@60352  Loss: 0.002574 Acc: 13.3125\n",
      " |~~ train@60416  Loss: 0.002596 Acc: 13.1562\n",
      " |~~ train@60480  Loss: 0.002674 Acc: 13.1875\n",
      " |~~ train@60544  Loss: 0.002331 Acc: 13.3125\n",
      " |~~ train@60608  Loss: 0.002373 Acc: 13.3125\n",
      " |~~ train@60672  Loss: 0.002931 Acc: 13.1562\n",
      " |~~ train@60736  Loss: 0.002612 Acc: 13.2812\n",
      " |~~ train@60800  Loss: 0.002614 Acc: 13.2969\n",
      " |~~ train@60864  Loss: 0.002410 Acc: 13.2500\n",
      " |~~ train@60928  Loss: 0.002450 Acc: 13.3125\n",
      " |~~ train@60992  Loss: 0.002608 Acc: 13.1719\n",
      " |~~ train@61056  Loss: 0.002778 Acc: 13.2188\n",
      " |~~ train@61120  Loss: 0.002562 Acc: 13.3438\n",
      " |~~ train@61184  Loss: 0.002323 Acc: 13.3438\n",
      " |~~ train@61248  Loss: 0.002297 Acc: 13.3438\n",
      " |~~ train@61312  Loss: 0.002464 Acc: 13.3438\n",
      " |~~ train@61376  Loss: 0.002225 Acc: 13.3438\n",
      " |~~ train@61440  Loss: 0.002159 Acc: 13.4062\n",
      " |~~ train@61504  Loss: 0.002478 Acc: 13.2812\n",
      " |~~ train@61568  Loss: 0.002185 Acc: 13.3750\n",
      " |~~ train@61632  Loss: 0.001961 Acc: 13.4688\n",
      " |~~ train@61696  Loss: 0.002296 Acc: 13.3594\n",
      " |~~ train@61760  Loss: 0.002538 Acc: 13.2656\n",
      " |~~ train@61824  Loss: 0.002127 Acc: 13.4062\n",
      " |~~ train@61888  Loss: 0.002523 Acc: 13.2969\n",
      " |~~ train@61952  Loss: 0.002862 Acc: 13.1094\n",
      " |~~ train@62016  Loss: 0.002619 Acc: 13.2500\n",
      " |~~ train@62080  Loss: 0.002025 Acc: 13.4375\n",
      " |~~ train@62144  Loss: 0.002168 Acc: 13.3281\n",
      " |~~ train@62208  Loss: 0.002115 Acc: 13.4375\n",
      " |~~ train@62272  Loss: 0.002190 Acc: 13.4062\n",
      " |~~ train@62336  Loss: 0.002391 Acc: 13.3281\n",
      " |~~ train@62400  Loss: 0.002912 Acc: 13.1562\n",
      " |~~ train@62464  Loss: 0.002765 Acc: 13.1250\n",
      " |~~ train@62528  Loss: 0.001854 Acc: 13.4062\n",
      " |~~ train@62592  Loss: 0.002096 Acc: 13.4375\n",
      " |~~ train@62656  Loss: 0.002636 Acc: 13.1406\n",
      " |~~ train@62720  Loss: 0.002469 Acc: 13.3438\n",
      " |~~ train@62784  Loss: 0.002270 Acc: 13.3594\n",
      " |~~ train@62848  Loss: 0.002462 Acc: 13.3438\n",
      " |~~ train@62912  Loss: 0.001923 Acc: 13.4688\n",
      " |~~ train@62976  Loss: 0.001994 Acc: 13.5000\n",
      " |~~ train@63040  Loss: 0.002231 Acc: 13.3906\n",
      " |~~ train@63104  Loss: 0.002164 Acc: 13.4062\n",
      " |~~ train@63168  Loss: 0.002346 Acc: 13.3438\n",
      " |~~ train@63232  Loss: 0.002676 Acc: 13.2656\n",
      " |~~ train@63296  Loss: 0.002260 Acc: 13.3281\n",
      " |~~ train@63360  Loss: 0.002904 Acc: 13.1719\n",
      " |~~ train@63424  Loss: 0.003039 Acc: 13.0938\n",
      " |~~ train@63488  Loss: 0.003101 Acc: 13.0469\n",
      " |~~ train@63552  Loss: 0.002701 Acc: 13.2188\n",
      " |~~ train@63616  Loss: 0.002716 Acc: 13.2656\n",
      " |~~ train@63680  Loss: 0.002095 Acc: 13.4375\n",
      " |~~ train@63744  Loss: 0.001917 Acc: 13.4219\n",
      " |~~ train@63808  Loss: 0.002631 Acc: 13.2031\n",
      " |~~ train@63872  Loss: 0.002317 Acc: 13.3281\n",
      " |~~ train@63936  Loss: 0.001882 Acc: 13.5312\n",
      " |~~ train@64000  Loss: 0.002412 Acc: 13.2812\n",
      " |~~ train@64064  Loss: 0.002245 Acc: 13.2969\n",
      " |~~ train@64128  Loss: 0.002788 Acc: 13.2500\n",
      " |~~ train@64192  Loss: 0.001939 Acc: 13.4688\n",
      " |~~ train@64256  Loss: 0.002548 Acc: 13.2188\n",
      " |~~ train@64320  Loss: 0.002410 Acc: 13.3281\n",
      " |~~ train@64384  Loss: 0.002545 Acc: 13.1875\n",
      " |~~ train@64448  Loss: 0.003014 Acc: 13.2031\n",
      " |~~ train@64512  Loss: 0.001852 Acc: 13.5312\n",
      " |~~ train@64576  Loss: 0.002816 Acc: 13.2031\n",
      " |~~ train@64640  Loss: 0.002420 Acc: 13.2969\n",
      " |~~ train@64704  Loss: 0.002516 Acc: 13.2969\n",
      " |~~ train@64768  Loss: 0.001911 Acc: 13.5156\n",
      " |~~ train@64832  Loss: 0.002416 Acc: 13.2812\n",
      " |~~ train@64896  Loss: 0.002524 Acc: 13.2344\n",
      " |~~ train@64960  Loss: 0.002637 Acc: 13.2031\n",
      " |~~ train@65024  Loss: 0.003169 Acc: 13.0469\n",
      " |~~ train@65088  Loss: 0.002556 Acc: 13.2656\n",
      " |~~ train@65152  Loss: 0.002705 Acc: 13.2500\n",
      " |~~ train@65216  Loss: 0.001898 Acc: 13.5000\n",
      " |~~ train@65280  Loss: 0.001932 Acc: 13.4688\n",
      " |~~ train@65344  Loss: 0.002409 Acc: 13.3438\n",
      " |~~ train@65408  Loss: 0.002889 Acc: 13.2188\n",
      " |~~ train@65472  Loss: 0.002579 Acc: 13.2031\n",
      " |~~ train@65536  Loss: 0.003166 Acc: 13.0938\n",
      " |~~ train@65600  Loss: 0.002034 Acc: 13.3125\n",
      " |~~ train@65664  Loss: 0.003065 Acc: 13.0312\n",
      " |~~ train@65728  Loss: 0.002707 Acc: 13.1719\n",
      " |~~ train@65792  Loss: 0.002648 Acc: 13.0938\n",
      " |~~ train@65856  Loss: 0.002387 Acc: 13.3906\n",
      " |~~ train@65920  Loss: 0.002462 Acc: 13.2188\n",
      " |~~ train@65984  Loss: 0.002352 Acc: 13.3594\n",
      " |~~ train@66048  Loss: 0.002536 Acc: 13.3125\n",
      " |~~ train@66112  Loss: 0.003172 Acc: 13.1875\n",
      " |~~ train@66176  Loss: 0.002141 Acc: 13.4531\n",
      " |~~ train@66240  Loss: 0.002374 Acc: 13.2812\n",
      " |~~ train@66304  Loss: 0.002201 Acc: 13.3281\n",
      " |~~ train@66368  Loss: 0.002577 Acc: 13.2812\n",
      " |~~ train@66432  Loss: 0.002916 Acc: 13.0781\n",
      " |~~ train@66496  Loss: 0.002615 Acc: 13.2344\n",
      " |~~ train@66560  Loss: 0.001925 Acc: 13.5781\n",
      " |~~ train@66624  Loss: 0.002417 Acc: 13.2500\n",
      " |~~ train@66688  Loss: 0.002721 Acc: 13.2656\n",
      " |~~ train@66752  Loss: 0.002167 Acc: 13.4375\n",
      " |~~ train@66816  Loss: 0.002177 Acc: 13.4219\n",
      " |~~ train@66880  Loss: 0.002179 Acc: 13.3281\n",
      " |~~ train@66944  Loss: 0.002295 Acc: 13.3438\n",
      " |~~ train@67008  Loss: 0.002492 Acc: 13.2969\n",
      " |~~ train@67072  Loss: 0.003025 Acc: 13.1094\n",
      " |~~ train@67136  Loss: 0.002242 Acc: 13.3750\n",
      " |~~ train@67200  Loss: 0.002289 Acc: 13.4844\n",
      " |~~ train@67264  Loss: 0.001966 Acc: 13.4219\n",
      " |~~ train@67328  Loss: 0.002733 Acc: 13.2344\n",
      " |~~ train@67392  Loss: 0.002455 Acc: 13.2656\n",
      " |~~ train@67456  Loss: 0.002515 Acc: 13.2344\n",
      " |~~ train@67520  Loss: 0.002480 Acc: 13.2188\n",
      " |~~ train@67584  Loss: 0.002162 Acc: 13.3906\n",
      " |~~ train@67648  Loss: 0.002668 Acc: 13.1250\n",
      " |~~ train@67712  Loss: 0.003048 Acc: 13.2031\n",
      " |~~ train@67776  Loss: 0.002951 Acc: 13.2188\n",
      " |~~ train@67840  Loss: 0.002378 Acc: 13.3125\n",
      " |~~ train@67904  Loss: 0.002558 Acc: 13.2188\n",
      " |~~ train@67968  Loss: 0.002199 Acc: 13.3281\n",
      " |~~ train@68032  Loss: 0.002071 Acc: 13.3906\n",
      " |~~ train@68096  Loss: 0.002980 Acc: 13.2031\n",
      " |~~ train@68160  Loss: 0.002581 Acc: 13.2500\n",
      " |~~ train@68224  Loss: 0.002537 Acc: 13.2500\n",
      " |~~ train@68288  Loss: 0.002659 Acc: 13.2500\n",
      " |~~ train@68352  Loss: 0.003011 Acc: 12.9844\n",
      " |~~ train@68416  Loss: 0.002552 Acc: 13.2031\n",
      " |~~ train@68480  Loss: 0.002261 Acc: 13.2812\n",
      " |~~ train@68544  Loss: 0.002117 Acc: 13.3438\n",
      " |~~ train@68608  Loss: 0.002330 Acc: 13.3750\n",
      " |~~ train@68672  Loss: 0.002576 Acc: 13.3594\n",
      " |~~ train@68736  Loss: 0.002208 Acc: 13.3750\n",
      " |~~ train@68800  Loss: 0.002650 Acc: 13.2344\n",
      " |~~ train@68864  Loss: 0.002563 Acc: 13.1562\n",
      " |~~ train@68928  Loss: 0.002240 Acc: 13.3906\n",
      " |~~ train@68992  Loss: 0.002483 Acc: 13.2656\n",
      " |~~ train@69056  Loss: 0.002634 Acc: 13.2031\n",
      " |~~ train@69120  Loss: 0.002234 Acc: 13.4844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@69184  Loss: 0.002233 Acc: 13.2812\n",
      " |~~ train@69248  Loss: 0.003461 Acc: 13.0156\n",
      " |~~ train@69312  Loss: 0.002221 Acc: 13.3594\n",
      " |~~ train@69376  Loss: 0.002934 Acc: 13.2188\n",
      " |~~ train@69440  Loss: 0.002310 Acc: 13.3438\n",
      " |~~ train@69504  Loss: 0.002836 Acc: 13.0938\n",
      " |~~ train@69568  Loss: 0.002488 Acc: 13.2969\n",
      " |~~ train@69632  Loss: 0.002211 Acc: 13.4219\n",
      " |~~ train@69696  Loss: 0.002217 Acc: 13.3594\n",
      " |~~ train@69760  Loss: 0.001996 Acc: 13.4062\n",
      " |~~ train@69824  Loss: 0.002013 Acc: 13.3750\n",
      " |~~ train@69888  Loss: 0.002091 Acc: 13.4375\n",
      " |~~ train@69952  Loss: 0.002335 Acc: 13.3281\n",
      " |~~ train@70016  Loss: 0.002389 Acc: 13.2656\n",
      " |~~ train@70080  Loss: 0.002547 Acc: 13.2500\n",
      " |~~ train@70144  Loss: 0.002486 Acc: 13.3281\n",
      " |~~ train@70208  Loss: 0.002153 Acc: 13.4688\n",
      " |~~ train@70272  Loss: 0.002635 Acc: 13.2812\n",
      " |~~ train@70336  Loss: 0.002888 Acc: 13.1250\n",
      " |~~ train@70400  Loss: 0.002108 Acc: 13.4219\n",
      " |~~ train@70464  Loss: 0.002061 Acc: 13.4219\n",
      " |~~ train@70528  Loss: 0.002287 Acc: 13.2656\n",
      " |~~ train@70592  Loss: 0.002310 Acc: 13.3281\n",
      " |~~ train@70656  Loss: 0.002775 Acc: 13.1719\n",
      " |~~ train@70720  Loss: 0.002648 Acc: 13.2500\n",
      " |~~ train@70784  Loss: 0.002090 Acc: 13.4219\n",
      " |~~ train@70848  Loss: 0.002433 Acc: 13.3281\n",
      " |~~ train@70912  Loss: 0.003037 Acc: 13.1094\n",
      " |~~ train@70976  Loss: 0.002484 Acc: 13.1406\n",
      " |~~ train@71040  Loss: 0.002723 Acc: 13.2188\n",
      " |~~ train@71104  Loss: 0.001704 Acc: 13.5312\n",
      " |~~ train@71168  Loss: 0.002576 Acc: 13.2188\n",
      " |~~ train@71232  Loss: 0.002274 Acc: 13.3125\n",
      " |~~ train@71296  Loss: 0.002899 Acc: 13.1875\n",
      " |~~ train@71360  Loss: 0.002281 Acc: 13.3125\n",
      " |~~ train@71424  Loss: 0.002640 Acc: 13.2812\n",
      " |~~ train@71488  Loss: 0.002915 Acc: 13.0625\n",
      " |~~ train@71552  Loss: 0.002913 Acc: 13.0938\n",
      " |~~ train@71616  Loss: 0.002089 Acc: 13.4219\n",
      " |~~ train@71680  Loss: 0.001922 Acc: 13.4844\n",
      " |~~ train@71744  Loss: 0.002412 Acc: 13.2969\n",
      " |~~ train@71808  Loss: 0.002608 Acc: 13.1562\n",
      " |~~ train@71872  Loss: 0.002819 Acc: 13.2344\n",
      " |~~ train@71936  Loss: 0.003004 Acc: 13.0781\n",
      " |~~ train@72000  Loss: 0.002571 Acc: 13.2188\n",
      " |~~ train@72064  Loss: 0.003377 Acc: 12.9375\n",
      " |~~ train@72128  Loss: 0.002606 Acc: 13.2656\n",
      " |~~ train@72192  Loss: 0.002872 Acc: 13.1094\n",
      " |~~ train@72256  Loss: 0.002481 Acc: 13.3281\n",
      " |~~ train@72320  Loss: 0.002416 Acc: 13.4062\n",
      " |~~ train@72384  Loss: 0.002830 Acc: 13.2031\n",
      " |~~ train@72448  Loss: 0.002653 Acc: 13.2344\n",
      " |~~ train@72512  Loss: 0.002498 Acc: 13.2969\n",
      " |~~ train@72576  Loss: 0.002662 Acc: 13.1562\n",
      " |~~ train@72640  Loss: 0.002137 Acc: 13.4062\n",
      " |~~ train@72704  Loss: 0.002324 Acc: 13.3438\n",
      " |~~ train@72768  Loss: 0.003168 Acc: 13.0469\n",
      " |~~ train@72832  Loss: 0.003034 Acc: 13.0000\n",
      " |~~ train@72896  Loss: 0.002060 Acc: 13.4844\n",
      " |~~ train@72960  Loss: 0.002471 Acc: 13.3125\n",
      " |~~ train@73024  Loss: 0.002825 Acc: 13.1250\n",
      " |~~ train@73088  Loss: 0.002311 Acc: 13.3125\n",
      " |~~ train@73152  Loss: 0.002827 Acc: 13.2031\n",
      " |~~ train@73216  Loss: 0.001843 Acc: 13.5000\n",
      " |~~ train@73280  Loss: 0.002415 Acc: 13.2656\n",
      " |~~ train@73344  Loss: 0.002300 Acc: 13.4219\n",
      " |~~ train@73408  Loss: 0.002306 Acc: 13.3438\n",
      " |~~ train@73472  Loss: 0.002125 Acc: 13.4219\n",
      " |~~ train@73536  Loss: 0.002602 Acc: 13.1875\n",
      " |~~ train@73600  Loss: 0.002521 Acc: 13.3125\n",
      " |~~ train@73664  Loss: 0.002357 Acc: 13.3594\n",
      " |~~ train@73728  Loss: 0.002362 Acc: 13.2812\n",
      " |~~ train@73792  Loss: 0.002729 Acc: 13.1562\n",
      " |~~ train@73856  Loss: 0.002537 Acc: 13.2188\n",
      " |~~ train@73920  Loss: 0.002976 Acc: 13.1250\n",
      " |~~ train@73984  Loss: 0.002290 Acc: 13.2812\n",
      " |~~ train@74048  Loss: 0.002645 Acc: 13.1562\n",
      " |~~ train@74112  Loss: 0.003197 Acc: 12.9219\n",
      " |~~ train@74176  Loss: 0.002078 Acc: 13.3750\n",
      " |~~ train@74240  Loss: 0.002262 Acc: 13.3906\n",
      " |~~ train@74304  Loss: 0.002427 Acc: 13.2812\n",
      " |~~ train@74368  Loss: 0.002964 Acc: 13.0938\n",
      " |~~ train@74432  Loss: 0.002751 Acc: 13.1719\n",
      " |~~ train@74496  Loss: 0.002842 Acc: 13.2344\n",
      " |~~ train@74560  Loss: 0.002103 Acc: 13.3906\n",
      " |~~ train@74624  Loss: 0.002535 Acc: 13.1406\n",
      " |~~ train@74688  Loss: 0.002456 Acc: 13.2812\n",
      " |~~ train@74752  Loss: 0.001982 Acc: 13.4219\n",
      " |~~ train@74816  Loss: 0.002287 Acc: 13.3594\n",
      " |~~ train@74880  Loss: 0.002378 Acc: 13.2969\n",
      " |~~ train@74944  Loss: 0.002976 Acc: 13.1250\n",
      " |~~ train@75008  Loss: 0.002208 Acc: 13.3594\n",
      " |~~ train@75072  Loss: 0.002483 Acc: 13.2812\n",
      " |~~ train@75136  Loss: 0.001796 Acc: 13.5781\n",
      " |~~ train@75200  Loss: 0.002613 Acc: 13.2500\n",
      " |~~ train@75264  Loss: 0.002276 Acc: 13.3281\n",
      " |~~ train@75328  Loss: 0.002474 Acc: 13.2344\n",
      " |~~ train@75392  Loss: 0.002748 Acc: 13.2969\n",
      " |~~ train@75456  Loss: 0.002328 Acc: 13.3125\n",
      " |~~ train@75520  Loss: 0.002296 Acc: 13.2344\n",
      " |~~ train@75584  Loss: 0.002118 Acc: 13.3594\n",
      " |~~ train@75648  Loss: 0.001858 Acc: 13.5000\n",
      " |~~ train@75712  Loss: 0.002130 Acc: 13.3594\n",
      " |~~ train@75776  Loss: 0.002402 Acc: 13.3594\n",
      " |~~ train@75840  Loss: 0.002727 Acc: 13.2656\n",
      " |~~ train@75904  Loss: 0.002037 Acc: 13.4219\n",
      " |~~ train@75968  Loss: 0.002100 Acc: 13.3125\n",
      " |~~ train@76032  Loss: 0.002065 Acc: 13.4062\n",
      " |~~ train@76096  Loss: 0.003159 Acc: 13.1406\n",
      " |~~ train@76160  Loss: 0.002339 Acc: 13.3125\n",
      " |~~ train@76224  Loss: 0.002161 Acc: 13.3438\n",
      " |~~ train@76288  Loss: 0.002015 Acc: 13.4531\n",
      " |~~ train@76352  Loss: 0.002309 Acc: 13.3594\n",
      " |~~ train@76416  Loss: 0.002389 Acc: 13.3125\n",
      " |~~ train@76480  Loss: 0.002389 Acc: 13.3750\n",
      " |~~ train@76544  Loss: 0.002865 Acc: 13.2500\n",
      " |~~ train@76608  Loss: 0.002131 Acc: 13.3750\n",
      " |~~ train@76672  Loss: 0.002809 Acc: 13.1406\n",
      " |~~ train@76736  Loss: 0.002340 Acc: 13.2656\n",
      " |~~ train@76800  Loss: 0.002252 Acc: 13.3906\n",
      " |~~ train@76864  Loss: 0.003272 Acc: 13.0000\n",
      " |~~ train@76928  Loss: 0.002718 Acc: 13.2031\n",
      " |~~ train@76992  Loss: 0.002923 Acc: 13.0000\n",
      " |~~ train@77056  Loss: 0.002284 Acc: 13.3594\n",
      " |~~ train@77120  Loss: 0.002355 Acc: 13.2656\n",
      " |~~ train@77184  Loss: 0.002109 Acc: 13.3906\n",
      " |~~ train@77248  Loss: 0.002537 Acc: 13.2656\n",
      " |~~ train@77312  Loss: 0.002504 Acc: 13.1875\n",
      " |~~ train@77376  Loss: 0.002955 Acc: 13.1406\n",
      " |~~ train@77440  Loss: 0.002264 Acc: 13.2812\n",
      " |~~ train@77504  Loss: 0.002104 Acc: 13.3281\n",
      " |~~ train@77568  Loss: 0.002754 Acc: 13.1719\n",
      " |~~ train@77632  Loss: 0.002070 Acc: 13.3906\n",
      " |~~ train@77696  Loss: 0.002277 Acc: 13.3594\n",
      " |~~ train@77760  Loss: 0.002345 Acc: 13.2188\n",
      " |~~ train@77824  Loss: 0.002489 Acc: 13.2969\n",
      " |~~ train@77888  Loss: 0.002303 Acc: 13.3750\n",
      " |~~ train@77952  Loss: 0.002256 Acc: 13.3438\n",
      " |~~ train@78016  Loss: 0.002834 Acc: 13.1250\n",
      " |~~ train@78080  Loss: 0.002253 Acc: 13.4062\n",
      " |~~ train@78144  Loss: 0.002343 Acc: 13.3438\n",
      " |~~ train@78208  Loss: 0.002485 Acc: 13.1562\n",
      " |~~ train@78272  Loss: 0.002199 Acc: 13.4062\n",
      " |~~ train@78336  Loss: 0.002802 Acc: 13.0938\n",
      " |~~ train@78400  Loss: 0.002306 Acc: 13.3906\n",
      " |~~ train@78464  Loss: 0.002355 Acc: 13.3438\n",
      " |~~ train@78484  Loss: 0.007511 Acc: 13.4000\n",
      "train  Loss: 0.002609 Acc: 13.2668\n",
      " |~~ val@64  Loss: 0.002257 Acc: 13.3125\n",
      " |~~ val@128  Loss: 0.002684 Acc: 13.2188\n",
      " |~~ val@192  Loss: 0.002693 Acc: 13.1562\n",
      " |~~ val@256  Loss: 0.002735 Acc: 13.1250\n",
      " |~~ val@320  Loss: 0.002219 Acc: 13.3438\n",
      " |~~ val@384  Loss: 0.002621 Acc: 13.2969\n",
      " |~~ val@448  Loss: 0.002591 Acc: 13.2344\n",
      " |~~ val@512  Loss: 0.003046 Acc: 13.1094\n",
      " |~~ val@576  Loss: 0.001840 Acc: 13.5000\n",
      " |~~ val@640  Loss: 0.002323 Acc: 13.3438\n",
      " |~~ val@704  Loss: 0.002673 Acc: 13.1562\n",
      " |~~ val@768  Loss: 0.001917 Acc: 13.5000\n",
      " |~~ val@832  Loss: 0.002089 Acc: 13.3750\n",
      " |~~ val@896  Loss: 0.002285 Acc: 13.3438\n",
      " |~~ val@960  Loss: 0.002466 Acc: 13.2656\n",
      " |~~ val@1024  Loss: 0.002214 Acc: 13.3438\n",
      " |~~ val@1088  Loss: 0.002018 Acc: 13.4688\n",
      " |~~ val@1152  Loss: 0.002058 Acc: 13.4531\n",
      " |~~ val@1216  Loss: 0.002688 Acc: 13.1406\n",
      " |~~ val@1280  Loss: 0.002485 Acc: 13.2656\n",
      " |~~ val@1344  Loss: 0.002098 Acc: 13.4531\n",
      " |~~ val@1408  Loss: 0.003185 Acc: 13.0625\n",
      " |~~ val@1472  Loss: 0.002391 Acc: 13.3906\n",
      " |~~ val@1536  Loss: 0.002201 Acc: 13.3750\n",
      " |~~ val@1600  Loss: 0.002465 Acc: 13.3906\n",
      " |~~ val@1664  Loss: 0.002892 Acc: 13.1562\n",
      " |~~ val@1728  Loss: 0.002942 Acc: 13.0938\n",
      " |~~ val@1792  Loss: 0.002432 Acc: 13.3125\n",
      " |~~ val@1856  Loss: 0.002187 Acc: 13.3125\n",
      " |~~ val@1920  Loss: 0.002634 Acc: 13.1875\n",
      " |~~ val@1984  Loss: 0.002977 Acc: 13.1094\n",
      " |~~ val@2048  Loss: 0.001865 Acc: 13.4688\n",
      " |~~ val@2112  Loss: 0.002108 Acc: 13.3594\n",
      " |~~ val@2176  Loss: 0.002698 Acc: 13.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@2240  Loss: 0.002770 Acc: 13.1250\n",
      " |~~ val@2304  Loss: 0.002638 Acc: 13.3125\n",
      " |~~ val@2368  Loss: 0.002038 Acc: 13.4531\n",
      " |~~ val@2432  Loss: 0.002300 Acc: 13.4219\n",
      " |~~ val@2496  Loss: 0.002766 Acc: 13.2656\n",
      " |~~ val@2560  Loss: 0.002336 Acc: 13.3281\n",
      " |~~ val@2624  Loss: 0.002601 Acc: 13.2500\n",
      " |~~ val@2688  Loss: 0.002464 Acc: 13.2188\n",
      " |~~ val@2752  Loss: 0.002430 Acc: 13.3125\n",
      " |~~ val@2816  Loss: 0.002387 Acc: 13.3438\n",
      " |~~ val@2880  Loss: 0.002924 Acc: 13.1875\n",
      " |~~ val@2944  Loss: 0.002829 Acc: 13.1875\n",
      " |~~ val@3008  Loss: 0.002721 Acc: 13.1875\n",
      " |~~ val@3072  Loss: 0.002202 Acc: 13.4062\n",
      " |~~ val@3136  Loss: 0.002663 Acc: 13.1875\n",
      " |~~ val@3200  Loss: 0.002341 Acc: 13.2031\n",
      " |~~ val@3264  Loss: 0.002917 Acc: 13.0625\n",
      " |~~ val@3328  Loss: 0.002773 Acc: 13.0938\n",
      " |~~ val@3392  Loss: 0.002767 Acc: 13.1094\n",
      " |~~ val@3456  Loss: 0.002932 Acc: 13.0938\n",
      " |~~ val@3520  Loss: 0.002206 Acc: 13.4531\n",
      " |~~ val@3584  Loss: 0.002651 Acc: 13.2500\n",
      " |~~ val@3648  Loss: 0.002056 Acc: 13.4375\n",
      " |~~ val@3712  Loss: 0.002458 Acc: 13.1094\n",
      " |~~ val@3776  Loss: 0.002157 Acc: 13.3438\n",
      " |~~ val@3840  Loss: 0.002253 Acc: 13.3281\n",
      " |~~ val@3904  Loss: 0.002088 Acc: 13.3906\n",
      " |~~ val@3968  Loss: 0.002513 Acc: 13.3750\n",
      " |~~ val@4032  Loss: 0.002328 Acc: 13.3125\n",
      " |~~ val@4096  Loss: 0.002233 Acc: 13.2969\n",
      " |~~ val@4160  Loss: 0.002259 Acc: 13.3125\n",
      " |~~ val@4224  Loss: 0.002389 Acc: 13.3281\n",
      " |~~ val@4288  Loss: 0.002202 Acc: 13.3438\n",
      " |~~ val@4352  Loss: 0.002483 Acc: 13.3125\n",
      " |~~ val@4416  Loss: 0.002277 Acc: 13.4219\n",
      " |~~ val@4480  Loss: 0.002250 Acc: 13.4219\n",
      " |~~ val@4544  Loss: 0.002760 Acc: 13.1875\n",
      " |~~ val@4608  Loss: 0.002188 Acc: 13.4219\n",
      " |~~ val@4672  Loss: 0.002402 Acc: 13.2812\n",
      " |~~ val@4736  Loss: 0.002536 Acc: 13.2812\n",
      " |~~ val@4800  Loss: 0.001980 Acc: 13.4688\n",
      " |~~ val@4864  Loss: 0.002947 Acc: 13.0938\n",
      " |~~ val@4928  Loss: 0.002309 Acc: 13.2812\n",
      " |~~ val@4992  Loss: 0.002832 Acc: 13.1875\n",
      " |~~ val@5056  Loss: 0.002505 Acc: 13.2969\n",
      " |~~ val@5120  Loss: 0.002458 Acc: 13.2969\n",
      " |~~ val@5184  Loss: 0.002640 Acc: 13.2344\n",
      " |~~ val@5248  Loss: 0.002197 Acc: 13.3594\n",
      " |~~ val@5312  Loss: 0.002232 Acc: 13.4219\n",
      " |~~ val@5376  Loss: 0.002231 Acc: 13.3281\n",
      " |~~ val@5440  Loss: 0.002634 Acc: 13.1875\n",
      " |~~ val@5504  Loss: 0.002695 Acc: 13.1719\n",
      " |~~ val@5568  Loss: 0.002362 Acc: 13.3750\n",
      " |~~ val@5632  Loss: 0.002749 Acc: 13.1875\n",
      " |~~ val@5696  Loss: 0.002535 Acc: 13.2969\n",
      " |~~ val@5760  Loss: 0.002399 Acc: 13.2969\n",
      " |~~ val@5824  Loss: 0.002755 Acc: 13.1406\n",
      " |~~ val@5888  Loss: 0.002499 Acc: 13.2344\n",
      " |~~ val@5952  Loss: 0.002245 Acc: 13.2969\n",
      " |~~ val@6016  Loss: 0.002204 Acc: 13.3750\n",
      " |~~ val@6080  Loss: 0.002687 Acc: 13.2188\n",
      " |~~ val@6144  Loss: 0.002792 Acc: 13.1406\n",
      " |~~ val@6208  Loss: 0.002452 Acc: 13.2188\n",
      " |~~ val@6272  Loss: 0.001673 Acc: 13.5312\n",
      " |~~ val@6336  Loss: 0.002134 Acc: 13.3281\n",
      " |~~ val@6400  Loss: 0.002331 Acc: 13.3281\n",
      " |~~ val@6464  Loss: 0.002508 Acc: 13.2188\n",
      " |~~ val@6528  Loss: 0.002516 Acc: 13.2812\n",
      " |~~ val@6592  Loss: 0.002307 Acc: 13.2500\n",
      " |~~ val@6656  Loss: 0.002122 Acc: 13.3594\n",
      " |~~ val@6720  Loss: 0.002785 Acc: 13.2188\n",
      " |~~ val@6784  Loss: 0.003421 Acc: 12.8750\n",
      " |~~ val@6848  Loss: 0.002518 Acc: 13.3281\n",
      " |~~ val@6912  Loss: 0.003174 Acc: 13.0469\n",
      " |~~ val@6976  Loss: 0.002432 Acc: 13.3125\n",
      " |~~ val@7040  Loss: 0.002594 Acc: 13.1875\n",
      " |~~ val@7104  Loss: 0.003000 Acc: 13.1406\n",
      " |~~ val@7168  Loss: 0.002462 Acc: 13.3281\n",
      " |~~ val@7232  Loss: 0.002440 Acc: 13.3125\n",
      " |~~ val@7296  Loss: 0.002281 Acc: 13.3125\n",
      " |~~ val@7360  Loss: 0.002775 Acc: 13.1562\n",
      " |~~ val@7424  Loss: 0.002052 Acc: 13.4219\n",
      " |~~ val@7488  Loss: 0.002665 Acc: 13.2969\n",
      " |~~ val@7552  Loss: 0.002243 Acc: 13.3438\n",
      " |~~ val@7616  Loss: 0.002556 Acc: 13.2656\n",
      " |~~ val@7680  Loss: 0.002354 Acc: 13.3594\n",
      " |~~ val@7744  Loss: 0.002273 Acc: 13.2656\n",
      " |~~ val@7808  Loss: 0.002220 Acc: 13.3594\n",
      " |~~ val@7872  Loss: 0.002751 Acc: 13.1719\n",
      " |~~ val@7936  Loss: 0.002968 Acc: 13.2188\n",
      " |~~ val@8000  Loss: 0.002715 Acc: 13.2188\n",
      " |~~ val@8064  Loss: 0.002517 Acc: 13.2969\n",
      " |~~ val@8128  Loss: 0.002275 Acc: 13.3438\n",
      " |~~ val@8192  Loss: 0.002705 Acc: 13.2500\n",
      " |~~ val@8256  Loss: 0.002754 Acc: 13.2656\n",
      " |~~ val@8320  Loss: 0.002777 Acc: 13.2656\n",
      " |~~ val@8384  Loss: 0.003283 Acc: 13.0156\n",
      " |~~ val@8448  Loss: 0.002785 Acc: 13.1875\n",
      " |~~ val@8512  Loss: 0.002534 Acc: 13.2969\n",
      " |~~ val@8576  Loss: 0.003020 Acc: 13.0781\n",
      " |~~ val@8640  Loss: 0.002346 Acc: 13.3906\n",
      " |~~ val@8704  Loss: 0.002464 Acc: 13.3281\n",
      " |~~ val@8768  Loss: 0.002262 Acc: 13.3906\n",
      " |~~ val@8832  Loss: 0.002531 Acc: 13.2656\n",
      " |~~ val@8896  Loss: 0.002635 Acc: 13.1719\n",
      " |~~ val@8960  Loss: 0.002079 Acc: 13.3750\n",
      " |~~ val@9024  Loss: 0.002663 Acc: 13.2656\n",
      " |~~ val@9088  Loss: 0.002344 Acc: 13.3438\n",
      " |~~ val@9152  Loss: 0.002733 Acc: 13.3281\n",
      " |~~ val@9216  Loss: 0.002227 Acc: 13.4219\n",
      " |~~ val@9280  Loss: 0.002405 Acc: 13.2969\n",
      " |~~ val@9344  Loss: 0.003081 Acc: 13.1562\n",
      " |~~ val@9408  Loss: 0.002070 Acc: 13.4375\n",
      " |~~ val@9472  Loss: 0.002745 Acc: 13.2344\n",
      " |~~ val@9536  Loss: 0.002498 Acc: 13.2188\n",
      " |~~ val@9600  Loss: 0.002759 Acc: 13.1250\n",
      " |~~ val@9664  Loss: 0.002771 Acc: 13.1719\n",
      " |~~ val@9728  Loss: 0.002568 Acc: 13.3281\n",
      " |~~ val@9792  Loss: 0.002862 Acc: 13.2188\n",
      " |~~ val@9856  Loss: 0.002239 Acc: 13.4531\n",
      " |~~ val@9920  Loss: 0.002200 Acc: 13.3281\n",
      " |~~ val@9984  Loss: 0.002355 Acc: 13.3438\n",
      " |~~ val@10048  Loss: 0.002637 Acc: 13.2031\n",
      " |~~ val@10112  Loss: 0.002542 Acc: 13.2656\n",
      " |~~ val@10176  Loss: 0.002175 Acc: 13.3594\n",
      " |~~ val@10240  Loss: 0.001747 Acc: 13.5000\n",
      " |~~ val@10304  Loss: 0.001972 Acc: 13.4375\n",
      " |~~ val@10368  Loss: 0.002078 Acc: 13.3750\n",
      " |~~ val@10432  Loss: 0.002384 Acc: 13.2812\n",
      " |~~ val@10496  Loss: 0.002693 Acc: 13.2969\n",
      " |~~ val@10560  Loss: 0.002504 Acc: 13.2188\n",
      " |~~ val@10624  Loss: 0.002134 Acc: 13.3906\n",
      " |~~ val@10688  Loss: 0.002400 Acc: 13.3906\n",
      " |~~ val@10752  Loss: 0.002549 Acc: 13.2031\n",
      " |~~ val@10816  Loss: 0.002170 Acc: 13.5000\n",
      " |~~ val@10880  Loss: 0.002278 Acc: 13.3594\n",
      " |~~ val@10944  Loss: 0.002307 Acc: 13.3594\n",
      " |~~ val@11008  Loss: 0.002795 Acc: 13.2344\n",
      " |~~ val@11072  Loss: 0.002779 Acc: 13.1250\n",
      " |~~ val@11136  Loss: 0.002921 Acc: 13.1875\n",
      " |~~ val@11200  Loss: 0.002865 Acc: 13.1250\n",
      " |~~ val@11264  Loss: 0.002284 Acc: 13.3906\n",
      " |~~ val@11328  Loss: 0.002162 Acc: 13.3750\n",
      " |~~ val@11392  Loss: 0.002068 Acc: 13.3906\n",
      " |~~ val@11456  Loss: 0.002497 Acc: 13.1562\n",
      " |~~ val@11520  Loss: 0.002071 Acc: 13.3906\n",
      " |~~ val@11584  Loss: 0.002825 Acc: 13.1094\n",
      " |~~ val@11648  Loss: 0.002176 Acc: 13.3438\n",
      " |~~ val@11712  Loss: 0.002466 Acc: 13.2188\n",
      " |~~ val@11776  Loss: 0.002929 Acc: 13.2031\n",
      " |~~ val@11840  Loss: 0.002350 Acc: 13.2344\n",
      " |~~ val@11904  Loss: 0.002128 Acc: 13.3594\n",
      " |~~ val@11968  Loss: 0.001840 Acc: 13.5000\n",
      " |~~ val@12032  Loss: 0.002140 Acc: 13.4219\n",
      " |~~ val@12096  Loss: 0.002933 Acc: 13.1094\n",
      " |~~ val@12160  Loss: 0.002790 Acc: 13.2188\n",
      " |~~ val@12224  Loss: 0.002722 Acc: 13.2656\n",
      " |~~ val@12288  Loss: 0.002666 Acc: 13.0938\n",
      " |~~ val@12352  Loss: 0.003207 Acc: 13.0469\n",
      " |~~ val@12416  Loss: 0.002842 Acc: 13.2188\n",
      " |~~ val@12480  Loss: 0.002121 Acc: 13.3438\n",
      " |~~ val@12544  Loss: 0.002771 Acc: 13.1875\n",
      " |~~ val@12608  Loss: 0.001974 Acc: 13.5000\n",
      " |~~ val@12672  Loss: 0.002392 Acc: 13.2969\n",
      " |~~ val@12736  Loss: 0.002234 Acc: 13.3438\n",
      " |~~ val@12800  Loss: 0.002735 Acc: 13.2188\n",
      " |~~ val@12864  Loss: 0.002466 Acc: 13.2656\n",
      " |~~ val@12928  Loss: 0.002650 Acc: 13.2344\n",
      " |~~ val@12992  Loss: 0.002394 Acc: 13.2812\n",
      " |~~ val@13056  Loss: 0.002800 Acc: 13.2344\n",
      " |~~ val@13120  Loss: 0.002336 Acc: 13.2969\n",
      " |~~ val@13184  Loss: 0.002201 Acc: 13.3594\n",
      " |~~ val@13248  Loss: 0.002355 Acc: 13.3125\n",
      " |~~ val@13312  Loss: 0.002182 Acc: 13.4531\n",
      " |~~ val@13376  Loss: 0.002594 Acc: 13.1719\n",
      " |~~ val@13440  Loss: 0.002173 Acc: 13.4062\n",
      " |~~ val@13504  Loss: 0.002474 Acc: 13.2812\n",
      " |~~ val@13568  Loss: 0.002677 Acc: 13.2500\n",
      " |~~ val@13632  Loss: 0.002519 Acc: 13.2188\n",
      " |~~ val@13696  Loss: 0.002650 Acc: 13.3125\n",
      " |~~ val@13760  Loss: 0.002696 Acc: 13.1406\n",
      " |~~ val@13824  Loss: 0.002261 Acc: 13.3438\n",
      " |~~ val@13888  Loss: 0.001927 Acc: 13.4375\n",
      " |~~ val@13952  Loss: 0.002803 Acc: 13.2500\n",
      " |~~ val@14016  Loss: 0.002914 Acc: 13.1406\n",
      " |~~ val@14080  Loss: 0.002183 Acc: 13.3906\n",
      " |~~ val@14144  Loss: 0.002282 Acc: 13.3906\n",
      " |~~ val@14208  Loss: 0.001814 Acc: 13.5625\n",
      " |~~ val@14272  Loss: 0.002915 Acc: 13.0938\n",
      " |~~ val@14336  Loss: 0.002562 Acc: 13.3438\n",
      " |~~ val@14400  Loss: 0.002475 Acc: 13.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@14464  Loss: 0.002515 Acc: 13.2031\n",
      " |~~ val@14528  Loss: 0.002038 Acc: 13.4219\n",
      " |~~ val@14592  Loss: 0.002346 Acc: 13.3125\n",
      " |~~ val@14656  Loss: 0.002635 Acc: 13.2344\n",
      " |~~ val@14720  Loss: 0.002523 Acc: 13.2969\n",
      " |~~ val@14784  Loss: 0.002507 Acc: 13.2656\n",
      " |~~ val@14848  Loss: 0.002278 Acc: 13.3125\n",
      " |~~ val@14912  Loss: 0.002716 Acc: 13.2188\n",
      " |~~ val@14976  Loss: 0.003562 Acc: 12.9531\n",
      " |~~ val@15040  Loss: 0.002818 Acc: 13.0938\n",
      " |~~ val@15104  Loss: 0.002483 Acc: 13.2500\n",
      " |~~ val@15168  Loss: 0.002581 Acc: 13.2656\n",
      " |~~ val@15232  Loss: 0.002182 Acc: 13.4219\n",
      " |~~ val@15296  Loss: 0.002128 Acc: 13.3438\n",
      " |~~ val@15360  Loss: 0.002463 Acc: 13.2500\n",
      " |~~ val@15424  Loss: 0.002547 Acc: 13.2969\n",
      " |~~ val@15488  Loss: 0.002205 Acc: 13.3281\n",
      " |~~ val@15552  Loss: 0.002074 Acc: 13.3594\n",
      " |~~ val@15616  Loss: 0.002753 Acc: 13.1875\n",
      " |~~ val@15680  Loss: 0.002831 Acc: 13.1875\n",
      " |~~ val@15744  Loss: 0.002391 Acc: 13.2031\n",
      " |~~ val@15808  Loss: 0.002780 Acc: 13.1562\n",
      " |~~ val@15872  Loss: 0.002094 Acc: 13.4531\n",
      " |~~ val@15936  Loss: 0.003123 Acc: 13.1719\n",
      " |~~ val@16000  Loss: 0.003187 Acc: 13.0469\n",
      " |~~ val@16064  Loss: 0.002143 Acc: 13.3906\n",
      " |~~ val@16128  Loss: 0.002277 Acc: 13.3281\n",
      " |~~ val@16192  Loss: 0.002985 Acc: 13.0938\n",
      " |~~ val@16256  Loss: 0.002199 Acc: 13.3438\n",
      " |~~ val@16320  Loss: 0.002720 Acc: 13.1875\n",
      " |~~ val@16384  Loss: 0.002797 Acc: 13.1562\n",
      " |~~ val@16448  Loss: 0.002772 Acc: 13.2656\n",
      " |~~ val@16512  Loss: 0.002181 Acc: 13.3594\n",
      " |~~ val@16576  Loss: 0.003237 Acc: 12.9531\n",
      " |~~ val@16640  Loss: 0.002206 Acc: 13.4375\n",
      " |~~ val@16704  Loss: 0.002719 Acc: 13.2500\n",
      " |~~ val@16768  Loss: 0.001940 Acc: 13.5625\n",
      " |~~ val@16832  Loss: 0.002196 Acc: 13.4375\n",
      " |~~ val@16896  Loss: 0.002758 Acc: 13.1562\n",
      " |~~ val@16960  Loss: 0.002800 Acc: 13.1562\n",
      " |~~ val@17024  Loss: 0.002406 Acc: 13.2500\n",
      " |~~ val@17088  Loss: 0.001786 Acc: 13.4844\n",
      " |~~ val@17152  Loss: 0.002137 Acc: 13.3594\n",
      " |~~ val@17216  Loss: 0.002656 Acc: 13.2188\n",
      " |~~ val@17280  Loss: 0.002910 Acc: 13.1719\n",
      " |~~ val@17344  Loss: 0.002046 Acc: 13.4375\n",
      " |~~ val@17408  Loss: 0.002232 Acc: 13.3594\n",
      " |~~ val@17472  Loss: 0.002365 Acc: 13.2812\n",
      " |~~ val@17536  Loss: 0.002276 Acc: 13.3281\n",
      " |~~ val@17600  Loss: 0.002676 Acc: 13.1719\n",
      " |~~ val@17664  Loss: 0.002367 Acc: 13.2812\n",
      " |~~ val@17728  Loss: 0.002440 Acc: 13.3281\n",
      " |~~ val@17792  Loss: 0.002294 Acc: 13.3906\n",
      " |~~ val@17856  Loss: 0.002224 Acc: 13.3125\n",
      " |~~ val@17920  Loss: 0.002344 Acc: 13.3281\n",
      " |~~ val@17984  Loss: 0.002886 Acc: 13.1562\n",
      " |~~ val@18048  Loss: 0.002642 Acc: 13.1875\n",
      " |~~ val@18112  Loss: 0.002208 Acc: 13.4531\n",
      " |~~ val@18176  Loss: 0.002658 Acc: 13.2031\n",
      " |~~ val@18240  Loss: 0.002456 Acc: 13.3125\n",
      " |~~ val@18304  Loss: 0.002312 Acc: 13.2812\n",
      " |~~ val@18368  Loss: 0.002305 Acc: 13.4062\n",
      " |~~ val@18432  Loss: 0.002724 Acc: 13.1719\n",
      " |~~ val@18496  Loss: 0.002534 Acc: 13.3281\n",
      " |~~ val@18560  Loss: 0.002949 Acc: 13.0469\n",
      " |~~ val@18624  Loss: 0.002318 Acc: 13.3906\n",
      " |~~ val@18688  Loss: 0.003009 Acc: 13.1406\n",
      " |~~ val@18752  Loss: 0.002022 Acc: 13.4375\n",
      " |~~ val@18816  Loss: 0.002276 Acc: 13.3125\n",
      " |~~ val@18880  Loss: 0.002491 Acc: 13.2500\n",
      " |~~ val@18944  Loss: 0.002449 Acc: 13.3125\n",
      " |~~ val@19008  Loss: 0.002298 Acc: 13.3594\n",
      " |~~ val@19072  Loss: 0.002447 Acc: 13.2969\n",
      " |~~ val@19136  Loss: 0.002722 Acc: 13.1406\n",
      " |~~ val@19200  Loss: 0.002348 Acc: 13.3438\n",
      " |~~ val@19264  Loss: 0.002083 Acc: 13.4375\n",
      " |~~ val@19328  Loss: 0.002628 Acc: 13.2344\n",
      " |~~ val@19392  Loss: 0.002497 Acc: 13.2812\n",
      " |~~ val@19456  Loss: 0.002442 Acc: 13.3281\n",
      " |~~ val@19520  Loss: 0.002264 Acc: 13.3438\n",
      " |~~ val@19584  Loss: 0.002391 Acc: 13.3438\n",
      " |~~ val@19648  Loss: 0.002372 Acc: 13.2656\n",
      " |~~ val@19712  Loss: 0.002155 Acc: 13.4062\n",
      " |~~ val@19776  Loss: 0.002793 Acc: 13.1250\n",
      " |~~ val@19840  Loss: 0.002576 Acc: 13.2500\n",
      " |~~ val@19904  Loss: 0.002864 Acc: 13.0938\n",
      " |~~ val@19968  Loss: 0.002158 Acc: 13.3750\n",
      " |~~ val@20032  Loss: 0.002473 Acc: 13.2344\n",
      " |~~ val@20096  Loss: 0.002579 Acc: 13.3750\n",
      " |~~ val@20160  Loss: 0.002634 Acc: 13.2344\n",
      " |~~ val@20224  Loss: 0.003068 Acc: 13.1250\n",
      " |~~ val@20288  Loss: 0.002582 Acc: 13.2188\n",
      " |~~ val@20352  Loss: 0.002307 Acc: 13.3750\n",
      " |~~ val@20416  Loss: 0.003245 Acc: 13.1094\n",
      " |~~ val@20480  Loss: 0.002729 Acc: 13.1719\n",
      " |~~ val@20544  Loss: 0.001995 Acc: 13.3750\n",
      " |~~ val@20608  Loss: 0.002931 Acc: 13.1406\n",
      " |~~ val@20672  Loss: 0.002372 Acc: 13.3594\n",
      " |~~ val@20736  Loss: 0.002827 Acc: 13.1094\n",
      " |~~ val@20800  Loss: 0.002470 Acc: 13.3125\n",
      " |~~ val@20864  Loss: 0.002418 Acc: 13.3750\n",
      " |~~ val@20928  Loss: 0.002433 Acc: 13.2656\n",
      " |~~ val@20992  Loss: 0.002375 Acc: 13.3125\n",
      " |~~ val@21056  Loss: 0.002205 Acc: 13.4062\n",
      " |~~ val@21120  Loss: 0.002692 Acc: 13.2344\n",
      " |~~ val@21184  Loss: 0.002537 Acc: 13.2656\n",
      " |~~ val@21248  Loss: 0.002787 Acc: 13.1406\n",
      " |~~ val@21312  Loss: 0.002124 Acc: 13.3750\n",
      " |~~ val@21376  Loss: 0.001943 Acc: 13.5156\n",
      " |~~ val@21440  Loss: 0.002198 Acc: 13.3438\n",
      " |~~ val@21504  Loss: 0.002107 Acc: 13.4688\n",
      " |~~ val@21568  Loss: 0.002500 Acc: 13.2969\n",
      " |~~ val@21632  Loss: 0.002343 Acc: 13.3750\n",
      " |~~ val@21696  Loss: 0.002228 Acc: 13.3125\n",
      " |~~ val@21760  Loss: 0.002420 Acc: 13.2812\n",
      " |~~ val@21824  Loss: 0.002643 Acc: 13.2031\n",
      " |~~ val@21888  Loss: 0.002891 Acc: 13.1719\n",
      " |~~ val@21952  Loss: 0.002849 Acc: 13.1250\n",
      " |~~ val@22016  Loss: 0.002673 Acc: 13.2500\n",
      " |~~ val@22080  Loss: 0.002693 Acc: 13.2188\n",
      " |~~ val@22144  Loss: 0.002138 Acc: 13.3594\n",
      " |~~ val@22208  Loss: 0.002071 Acc: 13.4219\n",
      " |~~ val@22272  Loss: 0.002068 Acc: 13.4375\n",
      " |~~ val@22336  Loss: 0.002398 Acc: 13.4062\n",
      " |~~ val@22400  Loss: 0.002366 Acc: 13.3594\n",
      " |~~ val@22424  Loss: 0.005680 Acc: 13.4167\n",
      "val  Loss: 0.002482 Acc: 13.2818\n",
      "Epoch 1/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.002703 Acc: 13.2031\n",
      " |~~ train@128  Loss: 0.002378 Acc: 13.2812\n",
      " |~~ train@192  Loss: 0.002667 Acc: 13.1406\n",
      " |~~ train@256  Loss: 0.002474 Acc: 13.2812\n",
      " |~~ train@320  Loss: 0.002017 Acc: 13.3750\n",
      " |~~ train@384  Loss: 0.002233 Acc: 13.3906\n",
      " |~~ train@448  Loss: 0.002987 Acc: 13.1562\n",
      " |~~ train@512  Loss: 0.002283 Acc: 13.2969\n",
      " |~~ train@576  Loss: 0.002517 Acc: 13.2500\n",
      " |~~ train@640  Loss: 0.001910 Acc: 13.5156\n",
      " |~~ train@704  Loss: 0.001937 Acc: 13.3438\n",
      " |~~ train@768  Loss: 0.002273 Acc: 13.3281\n",
      " |~~ train@832  Loss: 0.002468 Acc: 13.2344\n",
      " |~~ train@896  Loss: 0.002500 Acc: 13.2969\n",
      " |~~ train@960  Loss: 0.002336 Acc: 13.2969\n",
      " |~~ train@1024  Loss: 0.002609 Acc: 13.1719\n",
      " |~~ train@1088  Loss: 0.002689 Acc: 13.0781\n",
      " |~~ train@1152  Loss: 0.002605 Acc: 13.1875\n",
      " |~~ train@1216  Loss: 0.002507 Acc: 13.1250\n",
      " |~~ train@1280  Loss: 0.002800 Acc: 13.1875\n",
      " |~~ train@1344  Loss: 0.002209 Acc: 13.4375\n",
      " |~~ train@1408  Loss: 0.002379 Acc: 13.2969\n",
      " |~~ train@1472  Loss: 0.001937 Acc: 13.4844\n",
      " |~~ train@1536  Loss: 0.002570 Acc: 13.2500\n",
      " |~~ train@1600  Loss: 0.002075 Acc: 13.4219\n",
      " |~~ train@1664  Loss: 0.002536 Acc: 13.2500\n",
      " |~~ train@1728  Loss: 0.002004 Acc: 13.4531\n",
      " |~~ train@1792  Loss: 0.002588 Acc: 13.3750\n",
      " |~~ train@1856  Loss: 0.002017 Acc: 13.3594\n",
      " |~~ train@1920  Loss: 0.002245 Acc: 13.4531\n",
      " |~~ train@1984  Loss: 0.002439 Acc: 13.2344\n",
      " |~~ train@2048  Loss: 0.002384 Acc: 13.2812\n",
      " |~~ train@2112  Loss: 0.002177 Acc: 13.4062\n",
      " |~~ train@2176  Loss: 0.001986 Acc: 13.5469\n",
      " |~~ train@2240  Loss: 0.002412 Acc: 13.2656\n",
      " |~~ train@2304  Loss: 0.002471 Acc: 13.2969\n",
      " |~~ train@2368  Loss: 0.002818 Acc: 13.0781\n",
      " |~~ train@2432  Loss: 0.002171 Acc: 13.4375\n",
      " |~~ train@2496  Loss: 0.002357 Acc: 13.2500\n",
      " |~~ train@2560  Loss: 0.002243 Acc: 13.3281\n",
      " |~~ train@2624  Loss: 0.002088 Acc: 13.4531\n",
      " |~~ train@2688  Loss: 0.001911 Acc: 13.5000\n",
      " |~~ train@2752  Loss: 0.002174 Acc: 13.3281\n",
      " |~~ train@2816  Loss: 0.003241 Acc: 13.0938\n",
      " |~~ train@2880  Loss: 0.002254 Acc: 13.3750\n",
      " |~~ train@2944  Loss: 0.002777 Acc: 13.1250\n",
      " |~~ train@3008  Loss: 0.002425 Acc: 13.2500\n",
      " |~~ train@3072  Loss: 0.002621 Acc: 13.1875\n",
      " |~~ train@3136  Loss: 0.002313 Acc: 13.2656\n",
      " |~~ train@3200  Loss: 0.002328 Acc: 13.3281\n",
      " |~~ train@3264  Loss: 0.001603 Acc: 13.6406\n",
      " |~~ train@3328  Loss: 0.001754 Acc: 13.4688\n",
      " |~~ train@3392  Loss: 0.002409 Acc: 13.3438\n",
      " |~~ train@3456  Loss: 0.002016 Acc: 13.4688\n",
      " |~~ train@3520  Loss: 0.002365 Acc: 13.3594\n",
      " |~~ train@3584  Loss: 0.002286 Acc: 13.2656\n",
      " |~~ train@3648  Loss: 0.002356 Acc: 13.2188\n",
      " |~~ train@3712  Loss: 0.002189 Acc: 13.3750\n",
      " |~~ train@3776  Loss: 0.002873 Acc: 13.0469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@3840  Loss: 0.002353 Acc: 13.3281\n",
      " |~~ train@3904  Loss: 0.001720 Acc: 13.4844\n",
      " |~~ train@3968  Loss: 0.002181 Acc: 13.4688\n",
      " |~~ train@4032  Loss: 0.003369 Acc: 13.0625\n",
      " |~~ train@4096  Loss: 0.002168 Acc: 13.3438\n",
      " |~~ train@4160  Loss: 0.002218 Acc: 13.3281\n",
      " |~~ train@4224  Loss: 0.001974 Acc: 13.4219\n",
      " |~~ train@4288  Loss: 0.002493 Acc: 13.2188\n",
      " |~~ train@4352  Loss: 0.002557 Acc: 13.2031\n",
      " |~~ train@4416  Loss: 0.002454 Acc: 13.2344\n",
      " |~~ train@4480  Loss: 0.002629 Acc: 13.2344\n",
      " |~~ train@4544  Loss: 0.002427 Acc: 13.2812\n",
      " |~~ train@4608  Loss: 0.002415 Acc: 13.2188\n",
      " |~~ train@4672  Loss: 0.002356 Acc: 13.3281\n",
      " |~~ train@4736  Loss: 0.002080 Acc: 13.4531\n",
      " |~~ train@4800  Loss: 0.002132 Acc: 13.4531\n",
      " |~~ train@4864  Loss: 0.002449 Acc: 13.2969\n",
      " |~~ train@4928  Loss: 0.002562 Acc: 13.1875\n",
      " |~~ train@4992  Loss: 0.002728 Acc: 13.0938\n",
      " |~~ train@5056  Loss: 0.002178 Acc: 13.2969\n",
      " |~~ train@5120  Loss: 0.002219 Acc: 13.3750\n",
      " |~~ train@5184  Loss: 0.002257 Acc: 13.3906\n",
      " |~~ train@5248  Loss: 0.002367 Acc: 13.2812\n",
      " |~~ train@5312  Loss: 0.002468 Acc: 13.2656\n",
      " |~~ train@5376  Loss: 0.002094 Acc: 13.3750\n",
      " |~~ train@5440  Loss: 0.002386 Acc: 13.3438\n",
      " |~~ train@5504  Loss: 0.002439 Acc: 13.2969\n",
      " |~~ train@5568  Loss: 0.002299 Acc: 13.3281\n",
      " |~~ train@5632  Loss: 0.001757 Acc: 13.5312\n",
      " |~~ train@5696  Loss: 0.002295 Acc: 13.3281\n",
      " |~~ train@5760  Loss: 0.002461 Acc: 13.3906\n",
      " |~~ train@5824  Loss: 0.002715 Acc: 13.1562\n",
      " |~~ train@5888  Loss: 0.002286 Acc: 13.3281\n",
      " |~~ train@5952  Loss: 0.002620 Acc: 13.1875\n",
      " |~~ train@6016  Loss: 0.002379 Acc: 13.2969\n",
      " |~~ train@6080  Loss: 0.001948 Acc: 13.4844\n",
      " |~~ train@6144  Loss: 0.001862 Acc: 13.5000\n",
      " |~~ train@6208  Loss: 0.002331 Acc: 13.2969\n",
      " |~~ train@6272  Loss: 0.002137 Acc: 13.4531\n",
      " |~~ train@6336  Loss: 0.002321 Acc: 13.3281\n",
      " |~~ train@6400  Loss: 0.002825 Acc: 13.2188\n",
      " |~~ train@6464  Loss: 0.001589 Acc: 13.5312\n",
      " |~~ train@6528  Loss: 0.001771 Acc: 13.5000\n",
      " |~~ train@6592  Loss: 0.002517 Acc: 13.2188\n",
      " |~~ train@6656  Loss: 0.002576 Acc: 13.2031\n",
      " |~~ train@6720  Loss: 0.002008 Acc: 13.3750\n",
      " |~~ train@6784  Loss: 0.003010 Acc: 13.0781\n",
      " |~~ train@6848  Loss: 0.002889 Acc: 13.1875\n",
      " |~~ train@6912  Loss: 0.002385 Acc: 13.2500\n",
      " |~~ train@6976  Loss: 0.002679 Acc: 13.2188\n",
      " |~~ train@7040  Loss: 0.002084 Acc: 13.3750\n",
      " |~~ train@7104  Loss: 0.001995 Acc: 13.4219\n",
      " |~~ train@7168  Loss: 0.002099 Acc: 13.3594\n",
      " |~~ train@7232  Loss: 0.001995 Acc: 13.4219\n",
      " |~~ train@7296  Loss: 0.002279 Acc: 13.3594\n",
      " |~~ train@7360  Loss: 0.002049 Acc: 13.3750\n",
      " |~~ train@7424  Loss: 0.003148 Acc: 13.0156\n",
      " |~~ train@7488  Loss: 0.002581 Acc: 13.2969\n",
      " |~~ train@7552  Loss: 0.002448 Acc: 13.2969\n",
      " |~~ train@7616  Loss: 0.002468 Acc: 13.2969\n",
      " |~~ train@7680  Loss: 0.002052 Acc: 13.3906\n",
      " |~~ train@7744  Loss: 0.002535 Acc: 13.2344\n",
      " |~~ train@7808  Loss: 0.002370 Acc: 13.2656\n",
      " |~~ train@7872  Loss: 0.002231 Acc: 13.3438\n",
      " |~~ train@7936  Loss: 0.002715 Acc: 13.1406\n",
      " |~~ train@8000  Loss: 0.002960 Acc: 13.1250\n",
      " |~~ train@8064  Loss: 0.002268 Acc: 13.3281\n",
      " |~~ train@8128  Loss: 0.002096 Acc: 13.3906\n",
      " |~~ train@8192  Loss: 0.002016 Acc: 13.4062\n",
      " |~~ train@8256  Loss: 0.001997 Acc: 13.4062\n",
      " |~~ train@8320  Loss: 0.002273 Acc: 13.3906\n",
      " |~~ train@8384  Loss: 0.002083 Acc: 13.4531\n",
      " |~~ train@8448  Loss: 0.002603 Acc: 13.1875\n",
      " |~~ train@8512  Loss: 0.002737 Acc: 13.0312\n",
      " |~~ train@8576  Loss: 0.002052 Acc: 13.4375\n",
      " |~~ train@8640  Loss: 0.002282 Acc: 13.2969\n",
      " |~~ train@8704  Loss: 0.003154 Acc: 13.0938\n",
      " |~~ train@8768  Loss: 0.002205 Acc: 13.3125\n",
      " |~~ train@8832  Loss: 0.002489 Acc: 13.3125\n",
      " |~~ train@8896  Loss: 0.002594 Acc: 13.2188\n",
      " |~~ train@8960  Loss: 0.002518 Acc: 13.2500\n",
      " |~~ train@9024  Loss: 0.002371 Acc: 13.3438\n",
      " |~~ train@9088  Loss: 0.002706 Acc: 13.1875\n",
      " |~~ train@9152  Loss: 0.002273 Acc: 13.2656\n",
      " |~~ train@9216  Loss: 0.002305 Acc: 13.3750\n",
      " |~~ train@9280  Loss: 0.002100 Acc: 13.3438\n",
      " |~~ train@9344  Loss: 0.002347 Acc: 13.3594\n",
      " |~~ train@9408  Loss: 0.002751 Acc: 13.1250\n",
      " |~~ train@9472  Loss: 0.002998 Acc: 13.1094\n",
      " |~~ train@9536  Loss: 0.002373 Acc: 13.3125\n",
      " |~~ train@9600  Loss: 0.003453 Acc: 12.9844\n",
      " |~~ train@9664  Loss: 0.002659 Acc: 13.1719\n",
      " |~~ train@9728  Loss: 0.001746 Acc: 13.4844\n",
      " |~~ train@9792  Loss: 0.002404 Acc: 13.3125\n",
      " |~~ train@9856  Loss: 0.001962 Acc: 13.4531\n",
      " |~~ train@9920  Loss: 0.002599 Acc: 13.2500\n",
      " |~~ train@9984  Loss: 0.002624 Acc: 13.2656\n",
      " |~~ train@10048  Loss: 0.003152 Acc: 13.0000\n",
      " |~~ train@10112  Loss: 0.002290 Acc: 13.3281\n",
      " |~~ train@10176  Loss: 0.002623 Acc: 13.3281\n",
      " |~~ train@10240  Loss: 0.002146 Acc: 13.3750\n",
      " |~~ train@10304  Loss: 0.002267 Acc: 13.2812\n",
      " |~~ train@10368  Loss: 0.002194 Acc: 13.3438\n",
      " |~~ train@10432  Loss: 0.001775 Acc: 13.5156\n",
      " |~~ train@10496  Loss: 0.002310 Acc: 13.2344\n",
      " |~~ train@10560  Loss: 0.002294 Acc: 13.2188\n",
      " |~~ train@10624  Loss: 0.002073 Acc: 13.3750\n",
      " |~~ train@10688  Loss: 0.002195 Acc: 13.3906\n",
      " |~~ train@10752  Loss: 0.002405 Acc: 13.2969\n",
      " |~~ train@10816  Loss: 0.002604 Acc: 13.2031\n",
      " |~~ train@10880  Loss: 0.001950 Acc: 13.4375\n",
      " |~~ train@10944  Loss: 0.002526 Acc: 13.3281\n",
      " |~~ train@11008  Loss: 0.001980 Acc: 13.5000\n",
      " |~~ train@11072  Loss: 0.001858 Acc: 13.4531\n",
      " |~~ train@11136  Loss: 0.002414 Acc: 13.3125\n",
      " |~~ train@11200  Loss: 0.002415 Acc: 13.2188\n",
      " |~~ train@11264  Loss: 0.002247 Acc: 13.2656\n",
      " |~~ train@11328  Loss: 0.002031 Acc: 13.4531\n",
      " |~~ train@11392  Loss: 0.002266 Acc: 13.2812\n",
      " |~~ train@11456  Loss: 0.002329 Acc: 13.3438\n",
      " |~~ train@11520  Loss: 0.002496 Acc: 13.2188\n",
      " |~~ train@11584  Loss: 0.002053 Acc: 13.4531\n",
      " |~~ train@11648  Loss: 0.002172 Acc: 13.3281\n",
      " |~~ train@11712  Loss: 0.001965 Acc: 13.4688\n",
      " |~~ train@11776  Loss: 0.002294 Acc: 13.4375\n",
      " |~~ train@11840  Loss: 0.002010 Acc: 13.4219\n",
      " |~~ train@11904  Loss: 0.002631 Acc: 13.2500\n",
      " |~~ train@11968  Loss: 0.002259 Acc: 13.3750\n",
      " |~~ train@12032  Loss: 0.002507 Acc: 13.2812\n",
      " |~~ train@12096  Loss: 0.002048 Acc: 13.3906\n",
      " |~~ train@12160  Loss: 0.001990 Acc: 13.4375\n",
      " |~~ train@12224  Loss: 0.002325 Acc: 13.3125\n",
      " |~~ train@12288  Loss: 0.002030 Acc: 13.3750\n",
      " |~~ train@12352  Loss: 0.002130 Acc: 13.3750\n",
      " |~~ train@12416  Loss: 0.001780 Acc: 13.5781\n",
      " |~~ train@12480  Loss: 0.001923 Acc: 13.4844\n",
      " |~~ train@12544  Loss: 0.003062 Acc: 13.0156\n",
      " |~~ train@12608  Loss: 0.002101 Acc: 13.3750\n",
      " |~~ train@12672  Loss: 0.003355 Acc: 13.0156\n",
      " |~~ train@12736  Loss: 0.002764 Acc: 13.1875\n",
      " |~~ train@12800  Loss: 0.002289 Acc: 13.3281\n",
      " |~~ train@12864  Loss: 0.002256 Acc: 13.3438\n",
      " |~~ train@12928  Loss: 0.002640 Acc: 13.1094\n",
      " |~~ train@12992  Loss: 0.002494 Acc: 13.2656\n",
      " |~~ train@13056  Loss: 0.002010 Acc: 13.3438\n",
      " |~~ train@13120  Loss: 0.002441 Acc: 13.2969\n",
      " |~~ train@13184  Loss: 0.002197 Acc: 13.3594\n",
      " |~~ train@13248  Loss: 0.002499 Acc: 13.3438\n",
      " |~~ train@13312  Loss: 0.001988 Acc: 13.3906\n",
      " |~~ train@13376  Loss: 0.003211 Acc: 13.1094\n",
      " |~~ train@13440  Loss: 0.002308 Acc: 13.2812\n",
      " |~~ train@13504  Loss: 0.002805 Acc: 13.1094\n",
      " |~~ train@13568  Loss: 0.002247 Acc: 13.4062\n",
      " |~~ train@13632  Loss: 0.002100 Acc: 13.3281\n",
      " |~~ train@13696  Loss: 0.003537 Acc: 12.8750\n",
      " |~~ train@13760  Loss: 0.002296 Acc: 13.3594\n",
      " |~~ train@13824  Loss: 0.002512 Acc: 13.2656\n",
      " |~~ train@13888  Loss: 0.002315 Acc: 13.2812\n",
      " |~~ train@13952  Loss: 0.002271 Acc: 13.3906\n",
      " |~~ train@14016  Loss: 0.002396 Acc: 13.3438\n",
      " |~~ train@14080  Loss: 0.002509 Acc: 13.1719\n",
      " |~~ train@14144  Loss: 0.002369 Acc: 13.3438\n",
      " |~~ train@14208  Loss: 0.002478 Acc: 13.2656\n",
      " |~~ train@14272  Loss: 0.002232 Acc: 13.3750\n",
      " |~~ train@14336  Loss: 0.002813 Acc: 13.1094\n",
      " |~~ train@14400  Loss: 0.001921 Acc: 13.4688\n",
      " |~~ train@14464  Loss: 0.002438 Acc: 13.2656\n",
      " |~~ train@14528  Loss: 0.002480 Acc: 13.2969\n",
      " |~~ train@14592  Loss: 0.002994 Acc: 13.1250\n",
      " |~~ train@14656  Loss: 0.003014 Acc: 13.1406\n",
      " |~~ train@14720  Loss: 0.002416 Acc: 13.2344\n",
      " |~~ train@14784  Loss: 0.001630 Acc: 13.5312\n",
      " |~~ train@14848  Loss: 0.001960 Acc: 13.5781\n",
      " |~~ train@14912  Loss: 0.002391 Acc: 13.2969\n",
      " |~~ train@14976  Loss: 0.001933 Acc: 13.4531\n",
      " |~~ train@15040  Loss: 0.002108 Acc: 13.3125\n",
      " |~~ train@15104  Loss: 0.002071 Acc: 13.4219\n",
      " |~~ train@15168  Loss: 0.002481 Acc: 13.2500\n",
      " |~~ train@15232  Loss: 0.002506 Acc: 13.2031\n",
      " |~~ train@15296  Loss: 0.002942 Acc: 13.1250\n",
      " |~~ train@15360  Loss: 0.002288 Acc: 13.4062\n",
      " |~~ train@15424  Loss: 0.003048 Acc: 13.0781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@15488  Loss: 0.002445 Acc: 13.3594\n",
      " |~~ train@15552  Loss: 0.002796 Acc: 13.1562\n",
      " |~~ train@15616  Loss: 0.002059 Acc: 13.3594\n",
      " |~~ train@15680  Loss: 0.002818 Acc: 13.2188\n",
      " |~~ train@15744  Loss: 0.002314 Acc: 13.3438\n",
      " |~~ train@15808  Loss: 0.002613 Acc: 13.2812\n",
      " |~~ train@15872  Loss: 0.002090 Acc: 13.3750\n",
      " |~~ train@15936  Loss: 0.002456 Acc: 13.2344\n",
      " |~~ train@16000  Loss: 0.002180 Acc: 13.3438\n",
      " |~~ train@16064  Loss: 0.003284 Acc: 13.0469\n",
      " |~~ train@16128  Loss: 0.001821 Acc: 13.4844\n",
      " |~~ train@16192  Loss: 0.003168 Acc: 13.0625\n",
      " |~~ train@16256  Loss: 0.002917 Acc: 13.0938\n",
      " |~~ train@16320  Loss: 0.002571 Acc: 13.2812\n",
      " |~~ train@16384  Loss: 0.002586 Acc: 13.2500\n",
      " |~~ train@16448  Loss: 0.001596 Acc: 13.6406\n",
      " |~~ train@16512  Loss: 0.002325 Acc: 13.4375\n",
      " |~~ train@16576  Loss: 0.001872 Acc: 13.4531\n",
      " |~~ train@16640  Loss: 0.002673 Acc: 13.2031\n",
      " |~~ train@16704  Loss: 0.002362 Acc: 13.3594\n",
      " |~~ train@16768  Loss: 0.002278 Acc: 13.2969\n",
      " |~~ train@16832  Loss: 0.002608 Acc: 13.2188\n",
      " |~~ train@16896  Loss: 0.002693 Acc: 13.1406\n",
      " |~~ train@16960  Loss: 0.002400 Acc: 13.2812\n",
      " |~~ train@17024  Loss: 0.002420 Acc: 13.2031\n",
      " |~~ train@17088  Loss: 0.002540 Acc: 13.1875\n",
      " |~~ train@17152  Loss: 0.002441 Acc: 13.3125\n",
      " |~~ train@17216  Loss: 0.002395 Acc: 13.2969\n",
      " |~~ train@17280  Loss: 0.002638 Acc: 13.2031\n",
      " |~~ train@17344  Loss: 0.001759 Acc: 13.5469\n",
      " |~~ train@17408  Loss: 0.002623 Acc: 13.2500\n",
      " |~~ train@17472  Loss: 0.002159 Acc: 13.3125\n",
      " |~~ train@17536  Loss: 0.002434 Acc: 13.2188\n",
      " |~~ train@17600  Loss: 0.002266 Acc: 13.3594\n",
      " |~~ train@17664  Loss: 0.002265 Acc: 13.4375\n",
      " |~~ train@17728  Loss: 0.002173 Acc: 13.3750\n",
      " |~~ train@17792  Loss: 0.002086 Acc: 13.4844\n",
      " |~~ train@17856  Loss: 0.002681 Acc: 13.1719\n",
      " |~~ train@17920  Loss: 0.002710 Acc: 13.1406\n",
      " |~~ train@17984  Loss: 0.002100 Acc: 13.4062\n",
      " |~~ train@18048  Loss: 0.002171 Acc: 13.3594\n",
      " |~~ train@18112  Loss: 0.002717 Acc: 13.1562\n",
      " |~~ train@18176  Loss: 0.002901 Acc: 13.2031\n",
      " |~~ train@18240  Loss: 0.002368 Acc: 13.2656\n",
      " |~~ train@18304  Loss: 0.002406 Acc: 13.3438\n",
      " |~~ train@18368  Loss: 0.001867 Acc: 13.4844\n",
      " |~~ train@18432  Loss: 0.002507 Acc: 13.3438\n",
      " |~~ train@18496  Loss: 0.002317 Acc: 13.3438\n",
      " |~~ train@18560  Loss: 0.002376 Acc: 13.2656\n",
      " |~~ train@18624  Loss: 0.002053 Acc: 13.4219\n",
      " |~~ train@18688  Loss: 0.001992 Acc: 13.4375\n",
      " |~~ train@18752  Loss: 0.002864 Acc: 13.1562\n",
      " |~~ train@18816  Loss: 0.002572 Acc: 13.2031\n",
      " |~~ train@18880  Loss: 0.002026 Acc: 13.4688\n",
      " |~~ train@18944  Loss: 0.001754 Acc: 13.5312\n",
      " |~~ train@19008  Loss: 0.003121 Acc: 13.0312\n",
      " |~~ train@19072  Loss: 0.002542 Acc: 13.2344\n",
      " |~~ train@19136  Loss: 0.002668 Acc: 13.2969\n",
      " |~~ train@19200  Loss: 0.002933 Acc: 13.0938\n",
      " |~~ train@19264  Loss: 0.002110 Acc: 13.4688\n",
      " |~~ train@19328  Loss: 0.002560 Acc: 13.2656\n",
      " |~~ train@19392  Loss: 0.002408 Acc: 13.2969\n",
      " |~~ train@19456  Loss: 0.003079 Acc: 13.0625\n",
      " |~~ train@19520  Loss: 0.003126 Acc: 13.0781\n",
      " |~~ train@19584  Loss: 0.002609 Acc: 13.2969\n",
      " |~~ train@19648  Loss: 0.002779 Acc: 13.1250\n",
      " |~~ train@19712  Loss: 0.002871 Acc: 13.1406\n",
      " |~~ train@19776  Loss: 0.002701 Acc: 13.1094\n",
      " |~~ train@19840  Loss: 0.002794 Acc: 13.2188\n",
      " |~~ train@19904  Loss: 0.001975 Acc: 13.5625\n",
      " |~~ train@19968  Loss: 0.002340 Acc: 13.2500\n",
      " |~~ train@20032  Loss: 0.002682 Acc: 13.1562\n",
      " |~~ train@20096  Loss: 0.002086 Acc: 13.3906\n",
      " |~~ train@20160  Loss: 0.001987 Acc: 13.4062\n",
      " |~~ train@20224  Loss: 0.002068 Acc: 13.3594\n",
      " |~~ train@20288  Loss: 0.002764 Acc: 13.1562\n",
      " |~~ train@20352  Loss: 0.002811 Acc: 13.1719\n",
      " |~~ train@20416  Loss: 0.001852 Acc: 13.4531\n",
      " |~~ train@20480  Loss: 0.002031 Acc: 13.4219\n",
      " |~~ train@20544  Loss: 0.002930 Acc: 13.0938\n",
      " |~~ train@20608  Loss: 0.002478 Acc: 13.2812\n",
      " |~~ train@20672  Loss: 0.003073 Acc: 13.0625\n",
      " |~~ train@20736  Loss: 0.002501 Acc: 13.3281\n",
      " |~~ train@20800  Loss: 0.002486 Acc: 13.2500\n",
      " |~~ train@20864  Loss: 0.002266 Acc: 13.3906\n",
      " |~~ train@20928  Loss: 0.002092 Acc: 13.3438\n",
      " |~~ train@20992  Loss: 0.002083 Acc: 13.4375\n",
      " |~~ train@21056  Loss: 0.001992 Acc: 13.4531\n",
      " |~~ train@21120  Loss: 0.002557 Acc: 13.2656\n",
      " |~~ train@21184  Loss: 0.002714 Acc: 13.2188\n",
      " |~~ train@21248  Loss: 0.002266 Acc: 13.3906\n",
      " |~~ train@21312  Loss: 0.001949 Acc: 13.5000\n",
      " |~~ train@21376  Loss: 0.002522 Acc: 13.2969\n",
      " |~~ train@21440  Loss: 0.002217 Acc: 13.3281\n",
      " |~~ train@21504  Loss: 0.002563 Acc: 13.2500\n",
      " |~~ train@21568  Loss: 0.002389 Acc: 13.3125\n",
      " |~~ train@21632  Loss: 0.002658 Acc: 13.2656\n",
      " |~~ train@21696  Loss: 0.001765 Acc: 13.5625\n",
      " |~~ train@21760  Loss: 0.002141 Acc: 13.3594\n",
      " |~~ train@21824  Loss: 0.001987 Acc: 13.4688\n",
      " |~~ train@21888  Loss: 0.002047 Acc: 13.4531\n",
      " |~~ train@21952  Loss: 0.002021 Acc: 13.3906\n",
      " |~~ train@22016  Loss: 0.002151 Acc: 13.3438\n",
      " |~~ train@22080  Loss: 0.002251 Acc: 13.2969\n",
      " |~~ train@22144  Loss: 0.002613 Acc: 13.2031\n",
      " |~~ train@22208  Loss: 0.002658 Acc: 13.1875\n",
      " |~~ train@22272  Loss: 0.003357 Acc: 13.0469\n",
      " |~~ train@22336  Loss: 0.002370 Acc: 13.3438\n",
      " |~~ train@22400  Loss: 0.001898 Acc: 13.5469\n",
      " |~~ train@22464  Loss: 0.001914 Acc: 13.4844\n",
      " |~~ train@22528  Loss: 0.002038 Acc: 13.3438\n",
      " |~~ train@22592  Loss: 0.002049 Acc: 13.4531\n",
      " |~~ train@22656  Loss: 0.002385 Acc: 13.2500\n",
      " |~~ train@22720  Loss: 0.002081 Acc: 13.3281\n",
      " |~~ train@22784  Loss: 0.002719 Acc: 13.1719\n",
      " |~~ train@22848  Loss: 0.003269 Acc: 12.9844\n",
      " |~~ train@22912  Loss: 0.002973 Acc: 13.1406\n",
      " |~~ train@22976  Loss: 0.002603 Acc: 13.3438\n",
      " |~~ train@23040  Loss: 0.002099 Acc: 13.3125\n",
      " |~~ train@23104  Loss: 0.001959 Acc: 13.4375\n",
      " |~~ train@23168  Loss: 0.002375 Acc: 13.2188\n",
      " |~~ train@23232  Loss: 0.002802 Acc: 13.1562\n",
      " |~~ train@23296  Loss: 0.002790 Acc: 13.1562\n",
      " |~~ train@23360  Loss: 0.002389 Acc: 13.2188\n",
      " |~~ train@23424  Loss: 0.002453 Acc: 13.2500\n",
      " |~~ train@23488  Loss: 0.002854 Acc: 13.1875\n",
      " |~~ train@23552  Loss: 0.002479 Acc: 13.2812\n",
      " |~~ train@23616  Loss: 0.001920 Acc: 13.4688\n",
      " |~~ train@23680  Loss: 0.002092 Acc: 13.4219\n",
      " |~~ train@23744  Loss: 0.002663 Acc: 13.1719\n",
      " |~~ train@23808  Loss: 0.002022 Acc: 13.4062\n",
      " |~~ train@23872  Loss: 0.002583 Acc: 13.2656\n",
      " |~~ train@23936  Loss: 0.002902 Acc: 13.1875\n",
      " |~~ train@24000  Loss: 0.002669 Acc: 13.1562\n",
      " |~~ train@24064  Loss: 0.002920 Acc: 13.0156\n",
      " |~~ train@24128  Loss: 0.002885 Acc: 13.1250\n",
      " |~~ train@24192  Loss: 0.002323 Acc: 13.2656\n",
      " |~~ train@24256  Loss: 0.002816 Acc: 13.1719\n",
      " |~~ train@24320  Loss: 0.002664 Acc: 13.1875\n",
      " |~~ train@24384  Loss: 0.002232 Acc: 13.3594\n",
      " |~~ train@24448  Loss: 0.002192 Acc: 13.3750\n",
      " |~~ train@24512  Loss: 0.002609 Acc: 13.1250\n",
      " |~~ train@24576  Loss: 0.002528 Acc: 13.3125\n",
      " |~~ train@24640  Loss: 0.002569 Acc: 13.2969\n",
      " |~~ train@24704  Loss: 0.002659 Acc: 13.2500\n",
      " |~~ train@24768  Loss: 0.002438 Acc: 13.4062\n",
      " |~~ train@24832  Loss: 0.002578 Acc: 13.2656\n",
      " |~~ train@24896  Loss: 0.002712 Acc: 13.2500\n",
      " |~~ train@24960  Loss: 0.001825 Acc: 13.4688\n",
      " |~~ train@25024  Loss: 0.003087 Acc: 13.1094\n",
      " |~~ train@25088  Loss: 0.002161 Acc: 13.4531\n",
      " |~~ train@25152  Loss: 0.002778 Acc: 13.0938\n",
      " |~~ train@25216  Loss: 0.002882 Acc: 13.1562\n",
      " |~~ train@25280  Loss: 0.002192 Acc: 13.3594\n",
      " |~~ train@25344  Loss: 0.001946 Acc: 13.4375\n",
      " |~~ train@25408  Loss: 0.002590 Acc: 13.2656\n",
      " |~~ train@25472  Loss: 0.002566 Acc: 13.1562\n",
      " |~~ train@25536  Loss: 0.002088 Acc: 13.3281\n",
      " |~~ train@25600  Loss: 0.002157 Acc: 13.3750\n",
      " |~~ train@25664  Loss: 0.002752 Acc: 13.1719\n",
      " |~~ train@25728  Loss: 0.002539 Acc: 13.2500\n",
      " |~~ train@25792  Loss: 0.002165 Acc: 13.4375\n",
      " |~~ train@25856  Loss: 0.002342 Acc: 13.3281\n",
      " |~~ train@25920  Loss: 0.002139 Acc: 13.4219\n",
      " |~~ train@25984  Loss: 0.002327 Acc: 13.3438\n",
      " |~~ train@26048  Loss: 0.002733 Acc: 13.1562\n",
      " |~~ train@26112  Loss: 0.002104 Acc: 13.3750\n",
      " |~~ train@26176  Loss: 0.001783 Acc: 13.5312\n",
      " |~~ train@26240  Loss: 0.002440 Acc: 13.2969\n",
      " |~~ train@26304  Loss: 0.001582 Acc: 13.6406\n",
      " |~~ train@26368  Loss: 0.002378 Acc: 13.2500\n",
      " |~~ train@26432  Loss: 0.002461 Acc: 13.2500\n",
      " |~~ train@26496  Loss: 0.002889 Acc: 13.1250\n",
      " |~~ train@26560  Loss: 0.002331 Acc: 13.2188\n",
      " |~~ train@26624  Loss: 0.002449 Acc: 13.2812\n",
      " |~~ train@26688  Loss: 0.002206 Acc: 13.3750\n",
      " |~~ train@26752  Loss: 0.002371 Acc: 13.3125\n",
      " |~~ train@26816  Loss: 0.002135 Acc: 13.4219\n",
      " |~~ train@26880  Loss: 0.002379 Acc: 13.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@26944  Loss: 0.002830 Acc: 13.1875\n",
      " |~~ train@27008  Loss: 0.002358 Acc: 13.3125\n",
      " |~~ train@27072  Loss: 0.002367 Acc: 13.3594\n",
      " |~~ train@27136  Loss: 0.002229 Acc: 13.3750\n",
      " |~~ train@27200  Loss: 0.003430 Acc: 12.9219\n",
      " |~~ train@27264  Loss: 0.001882 Acc: 13.4688\n",
      " |~~ train@27328  Loss: 0.002384 Acc: 13.2812\n",
      " |~~ train@27392  Loss: 0.002306 Acc: 13.2656\n",
      " |~~ train@27456  Loss: 0.002621 Acc: 13.1719\n",
      " |~~ train@27520  Loss: 0.001948 Acc: 13.4062\n",
      " |~~ train@27584  Loss: 0.001937 Acc: 13.3906\n",
      " |~~ train@27648  Loss: 0.003124 Acc: 13.0156\n",
      " |~~ train@27712  Loss: 0.002089 Acc: 13.4219\n",
      " |~~ train@27776  Loss: 0.002560 Acc: 13.1875\n",
      " |~~ train@27840  Loss: 0.002411 Acc: 13.2344\n",
      " |~~ train@27904  Loss: 0.002489 Acc: 13.1562\n",
      " |~~ train@27968  Loss: 0.002599 Acc: 13.1562\n",
      " |~~ train@28032  Loss: 0.002674 Acc: 13.2500\n",
      " |~~ train@28096  Loss: 0.002214 Acc: 13.4688\n",
      " |~~ train@28160  Loss: 0.002298 Acc: 13.2656\n",
      " |~~ train@28224  Loss: 0.002123 Acc: 13.3594\n",
      " |~~ train@28288  Loss: 0.001961 Acc: 13.4062\n",
      " |~~ train@28352  Loss: 0.002800 Acc: 13.1875\n",
      " |~~ train@28416  Loss: 0.002134 Acc: 13.2812\n",
      " |~~ train@28480  Loss: 0.002414 Acc: 13.2188\n",
      " |~~ train@28544  Loss: 0.002285 Acc: 13.2812\n",
      " |~~ train@28608  Loss: 0.002016 Acc: 13.4219\n",
      " |~~ train@28672  Loss: 0.002071 Acc: 13.3281\n",
      " |~~ train@28736  Loss: 0.002504 Acc: 13.2656\n",
      " |~~ train@28800  Loss: 0.001864 Acc: 13.4375\n",
      " |~~ train@28864  Loss: 0.002216 Acc: 13.2812\n",
      " |~~ train@28928  Loss: 0.002468 Acc: 13.2969\n",
      " |~~ train@28992  Loss: 0.001916 Acc: 13.4219\n",
      " |~~ train@29056  Loss: 0.002070 Acc: 13.3125\n",
      " |~~ train@29120  Loss: 0.002393 Acc: 13.2031\n",
      " |~~ train@29184  Loss: 0.001821 Acc: 13.4688\n",
      " |~~ train@29248  Loss: 0.002347 Acc: 13.2969\n",
      " |~~ train@29312  Loss: 0.002196 Acc: 13.3438\n",
      " |~~ train@29376  Loss: 0.002251 Acc: 13.3594\n",
      " |~~ train@29440  Loss: 0.002092 Acc: 13.4062\n",
      " |~~ train@29504  Loss: 0.002607 Acc: 13.2344\n",
      " |~~ train@29568  Loss: 0.002410 Acc: 13.3125\n",
      " |~~ train@29632  Loss: 0.002329 Acc: 13.3438\n",
      " |~~ train@29696  Loss: 0.002310 Acc: 13.3594\n",
      " |~~ train@29760  Loss: 0.002613 Acc: 13.1562\n",
      " |~~ train@29824  Loss: 0.002174 Acc: 13.4219\n",
      " |~~ train@29888  Loss: 0.002072 Acc: 13.3438\n",
      " |~~ train@29952  Loss: 0.002472 Acc: 13.1875\n",
      " |~~ train@30016  Loss: 0.002352 Acc: 13.3125\n",
      " |~~ train@30080  Loss: 0.002620 Acc: 13.2500\n",
      " |~~ train@30144  Loss: 0.002272 Acc: 13.2812\n",
      " |~~ train@30208  Loss: 0.001985 Acc: 13.4219\n",
      " |~~ train@30272  Loss: 0.002116 Acc: 13.3750\n",
      " |~~ train@30336  Loss: 0.002377 Acc: 13.3750\n",
      " |~~ train@30400  Loss: 0.002185 Acc: 13.2969\n",
      " |~~ train@30464  Loss: 0.002296 Acc: 13.3438\n",
      " |~~ train@30528  Loss: 0.002103 Acc: 13.3594\n",
      " |~~ train@30592  Loss: 0.002357 Acc: 13.2969\n",
      " |~~ train@30656  Loss: 0.002398 Acc: 13.2188\n",
      " |~~ train@30720  Loss: 0.002398 Acc: 13.3438\n",
      " |~~ train@30784  Loss: 0.002093 Acc: 13.3906\n",
      " |~~ train@30848  Loss: 0.002013 Acc: 13.3906\n",
      " |~~ train@30912  Loss: 0.002678 Acc: 13.2812\n",
      " |~~ train@30976  Loss: 0.001984 Acc: 13.4531\n",
      " |~~ train@31040  Loss: 0.002190 Acc: 13.3750\n",
      " |~~ train@31104  Loss: 0.002945 Acc: 13.1875\n",
      " |~~ train@31168  Loss: 0.002382 Acc: 13.2656\n",
      " |~~ train@31232  Loss: 0.002349 Acc: 13.2656\n",
      " |~~ train@31296  Loss: 0.002916 Acc: 13.1562\n",
      " |~~ train@31360  Loss: 0.002195 Acc: 13.3438\n",
      " |~~ train@31424  Loss: 0.002627 Acc: 13.2031\n",
      " |~~ train@31488  Loss: 0.002774 Acc: 13.1094\n",
      " |~~ train@31552  Loss: 0.002215 Acc: 13.2969\n",
      " |~~ train@31616  Loss: 0.002123 Acc: 13.4688\n",
      " |~~ train@31680  Loss: 0.002012 Acc: 13.4531\n",
      " |~~ train@31744  Loss: 0.002794 Acc: 13.1250\n",
      " |~~ train@31808  Loss: 0.002461 Acc: 13.3125\n",
      " |~~ train@31872  Loss: 0.002578 Acc: 13.1562\n",
      " |~~ train@31936  Loss: 0.002628 Acc: 13.1562\n",
      " |~~ train@32000  Loss: 0.001967 Acc: 13.3281\n",
      " |~~ train@32064  Loss: 0.002202 Acc: 13.3750\n",
      " |~~ train@32128  Loss: 0.002284 Acc: 13.3281\n",
      " |~~ train@32192  Loss: 0.001907 Acc: 13.4688\n",
      " |~~ train@32256  Loss: 0.002819 Acc: 13.1250\n",
      " |~~ train@32320  Loss: 0.002720 Acc: 13.1406\n",
      " |~~ train@32384  Loss: 0.002453 Acc: 13.2500\n",
      " |~~ train@32448  Loss: 0.002541 Acc: 13.3281\n",
      " |~~ train@32512  Loss: 0.002062 Acc: 13.4062\n",
      " |~~ train@32576  Loss: 0.002528 Acc: 13.2969\n",
      " |~~ train@32640  Loss: 0.002414 Acc: 13.2969\n",
      " |~~ train@32704  Loss: 0.002193 Acc: 13.2969\n",
      " |~~ train@32768  Loss: 0.002369 Acc: 13.3594\n",
      " |~~ train@32832  Loss: 0.003455 Acc: 12.9688\n",
      " |~~ train@32896  Loss: 0.002339 Acc: 13.3281\n",
      " |~~ train@32960  Loss: 0.002609 Acc: 13.1250\n",
      " |~~ train@33024  Loss: 0.002890 Acc: 13.0312\n",
      " |~~ train@33088  Loss: 0.003195 Acc: 13.0156\n",
      " |~~ train@33152  Loss: 0.002358 Acc: 13.3750\n",
      " |~~ train@33216  Loss: 0.002918 Acc: 13.1406\n",
      " |~~ train@33280  Loss: 0.002607 Acc: 13.2969\n",
      " |~~ train@33344  Loss: 0.002668 Acc: 13.1406\n",
      " |~~ train@33408  Loss: 0.002443 Acc: 13.2500\n",
      " |~~ train@33472  Loss: 0.002050 Acc: 13.3594\n",
      " |~~ train@33536  Loss: 0.002193 Acc: 13.4062\n",
      " |~~ train@33600  Loss: 0.002560 Acc: 13.0938\n",
      " |~~ train@33664  Loss: 0.002331 Acc: 13.3125\n",
      " |~~ train@33728  Loss: 0.002206 Acc: 13.3438\n",
      " |~~ train@33792  Loss: 0.002309 Acc: 13.3750\n",
      " |~~ train@33856  Loss: 0.002126 Acc: 13.3906\n",
      " |~~ train@33920  Loss: 0.002451 Acc: 13.2500\n",
      " |~~ train@33984  Loss: 0.002037 Acc: 13.3594\n",
      " |~~ train@34048  Loss: 0.002273 Acc: 13.3125\n",
      " |~~ train@34112  Loss: 0.002256 Acc: 13.3125\n",
      " |~~ train@34176  Loss: 0.002231 Acc: 13.3594\n",
      " |~~ train@34240  Loss: 0.002563 Acc: 13.1562\n",
      " |~~ train@34304  Loss: 0.002810 Acc: 13.0781\n",
      " |~~ train@34368  Loss: 0.002564 Acc: 13.2812\n",
      " |~~ train@34432  Loss: 0.001948 Acc: 13.5156\n",
      " |~~ train@34496  Loss: 0.002883 Acc: 13.1250\n",
      " |~~ train@34560  Loss: 0.001771 Acc: 13.4844\n",
      " |~~ train@34624  Loss: 0.002482 Acc: 13.2344\n",
      " |~~ train@34688  Loss: 0.002604 Acc: 13.2031\n",
      " |~~ train@34752  Loss: 0.002048 Acc: 13.3906\n",
      " |~~ train@34816  Loss: 0.002398 Acc: 13.3594\n",
      " |~~ train@34880  Loss: 0.001779 Acc: 13.5469\n",
      " |~~ train@34944  Loss: 0.002428 Acc: 13.2812\n",
      " |~~ train@35008  Loss: 0.002218 Acc: 13.2812\n",
      " |~~ train@35072  Loss: 0.002041 Acc: 13.4375\n",
      " |~~ train@35136  Loss: 0.002470 Acc: 13.2500\n",
      " |~~ train@35200  Loss: 0.002881 Acc: 13.1406\n",
      " |~~ train@35264  Loss: 0.002094 Acc: 13.4219\n",
      " |~~ train@35328  Loss: 0.002366 Acc: 13.3125\n",
      " |~~ train@35392  Loss: 0.002184 Acc: 13.3438\n",
      " |~~ train@35456  Loss: 0.002128 Acc: 13.3750\n",
      " |~~ train@35520  Loss: 0.001885 Acc: 13.4688\n",
      " |~~ train@35584  Loss: 0.002302 Acc: 13.3906\n",
      " |~~ train@35648  Loss: 0.002940 Acc: 13.1250\n",
      " |~~ train@35712  Loss: 0.002230 Acc: 13.3125\n",
      " |~~ train@35776  Loss: 0.002673 Acc: 13.1719\n",
      " |~~ train@35840  Loss: 0.002130 Acc: 13.4375\n",
      " |~~ train@35904  Loss: 0.002006 Acc: 13.4062\n",
      " |~~ train@35968  Loss: 0.002259 Acc: 13.2969\n",
      " |~~ train@36032  Loss: 0.002463 Acc: 13.2656\n",
      " |~~ train@36096  Loss: 0.002120 Acc: 13.3125\n",
      " |~~ train@36160  Loss: 0.002102 Acc: 13.4062\n",
      " |~~ train@36224  Loss: 0.002581 Acc: 13.2812\n",
      " |~~ train@36288  Loss: 0.001973 Acc: 13.4688\n",
      " |~~ train@36352  Loss: 0.002538 Acc: 13.2031\n",
      " |~~ train@36416  Loss: 0.002526 Acc: 13.3281\n",
      " |~~ train@36480  Loss: 0.002354 Acc: 13.2656\n",
      " |~~ train@36544  Loss: 0.002408 Acc: 13.1719\n",
      " |~~ train@36608  Loss: 0.003062 Acc: 12.9844\n",
      " |~~ train@36672  Loss: 0.002427 Acc: 13.2656\n",
      " |~~ train@36736  Loss: 0.002141 Acc: 13.3750\n",
      " |~~ train@36800  Loss: 0.002594 Acc: 13.2031\n",
      " |~~ train@36864  Loss: 0.003219 Acc: 12.9375\n",
      " |~~ train@36928  Loss: 0.002843 Acc: 13.1406\n",
      " |~~ train@36992  Loss: 0.002096 Acc: 13.3281\n",
      " |~~ train@37056  Loss: 0.002578 Acc: 13.2656\n",
      " |~~ train@37120  Loss: 0.002504 Acc: 13.2344\n",
      " |~~ train@37184  Loss: 0.003013 Acc: 13.0781\n",
      " |~~ train@37248  Loss: 0.002316 Acc: 13.2969\n",
      " |~~ train@37312  Loss: 0.002727 Acc: 13.1406\n",
      " |~~ train@37376  Loss: 0.002548 Acc: 13.2031\n",
      " |~~ train@37440  Loss: 0.002653 Acc: 13.1719\n",
      " |~~ train@37504  Loss: 0.002518 Acc: 13.2188\n",
      " |~~ train@37568  Loss: 0.002309 Acc: 13.3125\n",
      " |~~ train@37632  Loss: 0.002848 Acc: 13.1094\n",
      " |~~ train@37696  Loss: 0.002053 Acc: 13.3281\n",
      " |~~ train@37760  Loss: 0.002729 Acc: 13.1719\n",
      " |~~ train@37824  Loss: 0.001782 Acc: 13.5312\n",
      " |~~ train@37888  Loss: 0.002495 Acc: 13.1875\n",
      " |~~ train@37952  Loss: 0.002523 Acc: 13.3125\n",
      " |~~ train@38016  Loss: 0.002562 Acc: 13.3438\n",
      " |~~ train@38080  Loss: 0.002405 Acc: 13.2500\n",
      " |~~ train@38144  Loss: 0.002692 Acc: 13.2812\n",
      " |~~ train@38208  Loss: 0.001949 Acc: 13.4375\n",
      " |~~ train@38272  Loss: 0.002276 Acc: 13.3438\n",
      " |~~ train@38336  Loss: 0.002060 Acc: 13.4531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@38400  Loss: 0.002297 Acc: 13.2969\n",
      " |~~ train@38464  Loss: 0.002347 Acc: 13.3281\n",
      " |~~ train@38528  Loss: 0.002579 Acc: 13.2500\n",
      " |~~ train@38592  Loss: 0.002436 Acc: 13.2812\n",
      " |~~ train@38656  Loss: 0.001810 Acc: 13.4844\n",
      " |~~ train@38720  Loss: 0.002237 Acc: 13.4219\n",
      " |~~ train@38784  Loss: 0.002363 Acc: 13.2344\n",
      " |~~ train@38848  Loss: 0.002882 Acc: 13.0938\n",
      " |~~ train@38912  Loss: 0.002163 Acc: 13.3750\n",
      " |~~ train@38976  Loss: 0.002580 Acc: 13.2031\n",
      " |~~ train@39040  Loss: 0.002662 Acc: 13.2031\n",
      " |~~ train@39104  Loss: 0.002283 Acc: 13.2969\n",
      " |~~ train@39168  Loss: 0.002484 Acc: 13.2656\n",
      " |~~ train@39232  Loss: 0.002300 Acc: 13.3438\n",
      " |~~ train@39296  Loss: 0.002797 Acc: 13.0938\n",
      " |~~ train@39360  Loss: 0.002161 Acc: 13.3438\n",
      " |~~ train@39424  Loss: 0.001975 Acc: 13.3906\n",
      " |~~ train@39488  Loss: 0.002795 Acc: 13.2188\n",
      " |~~ train@39552  Loss: 0.002158 Acc: 13.3906\n",
      " |~~ train@39616  Loss: 0.002025 Acc: 13.3750\n",
      " |~~ train@39680  Loss: 0.002695 Acc: 13.1406\n",
      " |~~ train@39744  Loss: 0.002183 Acc: 13.2969\n",
      " |~~ train@39808  Loss: 0.002428 Acc: 13.3281\n",
      " |~~ train@39872  Loss: 0.002826 Acc: 13.0781\n",
      " |~~ train@39936  Loss: 0.002736 Acc: 13.0469\n",
      " |~~ train@40000  Loss: 0.002000 Acc: 13.4531\n",
      " |~~ train@40064  Loss: 0.002291 Acc: 13.1875\n",
      " |~~ train@40128  Loss: 0.002515 Acc: 13.2188\n",
      " |~~ train@40192  Loss: 0.002543 Acc: 13.2500\n",
      " |~~ train@40256  Loss: 0.002204 Acc: 13.3906\n",
      " |~~ train@40320  Loss: 0.002405 Acc: 13.3281\n",
      " |~~ train@40384  Loss: 0.002296 Acc: 13.2969\n",
      " |~~ train@40448  Loss: 0.002651 Acc: 13.2031\n",
      " |~~ train@40512  Loss: 0.002260 Acc: 13.4688\n",
      " |~~ train@40576  Loss: 0.002257 Acc: 13.3125\n",
      " |~~ train@40640  Loss: 0.002244 Acc: 13.3750\n",
      " |~~ train@40704  Loss: 0.002311 Acc: 13.3281\n",
      " |~~ train@40768  Loss: 0.002389 Acc: 13.2188\n",
      " |~~ train@40832  Loss: 0.002365 Acc: 13.2500\n",
      " |~~ train@40896  Loss: 0.002363 Acc: 13.3438\n",
      " |~~ train@40960  Loss: 0.002485 Acc: 13.2969\n",
      " |~~ train@41024  Loss: 0.002330 Acc: 13.2812\n",
      " |~~ train@41088  Loss: 0.001851 Acc: 13.5000\n",
      " |~~ train@41152  Loss: 0.002744 Acc: 13.0781\n",
      " |~~ train@41216  Loss: 0.002088 Acc: 13.3750\n",
      " |~~ train@41280  Loss: 0.002435 Acc: 13.1875\n",
      " |~~ train@41344  Loss: 0.002292 Acc: 13.3750\n",
      " |~~ train@41408  Loss: 0.002025 Acc: 13.4531\n",
      " |~~ train@41472  Loss: 0.002496 Acc: 13.1562\n",
      " |~~ train@41536  Loss: 0.002417 Acc: 13.3594\n",
      " |~~ train@41600  Loss: 0.002413 Acc: 13.3594\n",
      " |~~ train@41664  Loss: 0.002857 Acc: 13.0781\n",
      " |~~ train@41728  Loss: 0.002628 Acc: 13.2188\n",
      " |~~ train@41792  Loss: 0.001839 Acc: 13.5156\n",
      " |~~ train@41856  Loss: 0.002760 Acc: 13.1562\n",
      " |~~ train@41920  Loss: 0.002521 Acc: 13.2969\n",
      " |~~ train@41984  Loss: 0.002845 Acc: 13.1094\n",
      " |~~ train@42048  Loss: 0.002156 Acc: 13.4062\n",
      " |~~ train@42112  Loss: 0.002230 Acc: 13.4375\n",
      " |~~ train@42176  Loss: 0.002595 Acc: 13.1562\n",
      " |~~ train@42240  Loss: 0.002594 Acc: 13.3438\n",
      " |~~ train@42304  Loss: 0.002630 Acc: 13.2344\n",
      " |~~ train@42368  Loss: 0.002447 Acc: 13.1719\n",
      " |~~ train@42432  Loss: 0.002357 Acc: 13.3125\n",
      " |~~ train@42496  Loss: 0.001808 Acc: 13.4688\n",
      " |~~ train@42560  Loss: 0.001986 Acc: 13.3750\n",
      " |~~ train@42624  Loss: 0.002350 Acc: 13.3438\n",
      " |~~ train@42688  Loss: 0.002093 Acc: 13.4844\n",
      " |~~ train@42752  Loss: 0.002667 Acc: 13.2969\n",
      " |~~ train@42816  Loss: 0.002857 Acc: 13.1875\n",
      " |~~ train@42880  Loss: 0.002727 Acc: 13.1094\n",
      " |~~ train@42944  Loss: 0.002218 Acc: 13.4062\n",
      " |~~ train@43008  Loss: 0.002433 Acc: 13.2031\n",
      " |~~ train@43072  Loss: 0.002679 Acc: 13.2344\n",
      " |~~ train@43136  Loss: 0.002679 Acc: 13.1406\n",
      " |~~ train@43200  Loss: 0.002043 Acc: 13.4531\n",
      " |~~ train@43264  Loss: 0.002228 Acc: 13.2656\n",
      " |~~ train@43328  Loss: 0.002088 Acc: 13.3594\n",
      " |~~ train@43392  Loss: 0.002613 Acc: 13.2188\n",
      " |~~ train@43456  Loss: 0.002336 Acc: 13.3750\n",
      " |~~ train@43520  Loss: 0.002845 Acc: 13.1094\n",
      " |~~ train@43584  Loss: 0.002515 Acc: 13.2656\n",
      " |~~ train@43648  Loss: 0.002971 Acc: 13.0312\n",
      " |~~ train@43712  Loss: 0.002277 Acc: 13.3281\n",
      " |~~ train@43776  Loss: 0.002007 Acc: 13.5000\n",
      " |~~ train@43840  Loss: 0.002309 Acc: 13.2969\n",
      " |~~ train@43904  Loss: 0.002161 Acc: 13.3594\n",
      " |~~ train@43968  Loss: 0.002921 Acc: 13.1250\n",
      " |~~ train@44032  Loss: 0.002746 Acc: 13.1719\n",
      " |~~ train@44096  Loss: 0.002177 Acc: 13.3594\n",
      " |~~ train@44160  Loss: 0.002500 Acc: 13.3281\n",
      " |~~ train@44224  Loss: 0.002544 Acc: 13.2031\n",
      " |~~ train@44288  Loss: 0.002622 Acc: 13.1250\n",
      " |~~ train@44352  Loss: 0.001763 Acc: 13.5312\n",
      " |~~ train@44416  Loss: 0.003116 Acc: 13.0625\n",
      " |~~ train@44480  Loss: 0.002513 Acc: 13.2812\n",
      " |~~ train@44544  Loss: 0.002103 Acc: 13.3125\n",
      " |~~ train@44608  Loss: 0.002297 Acc: 13.2656\n",
      " |~~ train@44672  Loss: 0.002709 Acc: 13.1562\n",
      " |~~ train@44736  Loss: 0.001863 Acc: 13.4531\n",
      " |~~ train@44800  Loss: 0.002008 Acc: 13.4219\n",
      " |~~ train@44864  Loss: 0.002205 Acc: 13.3594\n",
      " |~~ train@44928  Loss: 0.002183 Acc: 13.3906\n",
      " |~~ train@44992  Loss: 0.002711 Acc: 13.1562\n",
      " |~~ train@45056  Loss: 0.002054 Acc: 13.3438\n",
      " |~~ train@45120  Loss: 0.002524 Acc: 13.3125\n",
      " |~~ train@45184  Loss: 0.002271 Acc: 13.3906\n",
      " |~~ train@45248  Loss: 0.002715 Acc: 13.2656\n",
      " |~~ train@45312  Loss: 0.002218 Acc: 13.3281\n",
      " |~~ train@45376  Loss: 0.002272 Acc: 13.4531\n",
      " |~~ train@45440  Loss: 0.002636 Acc: 13.1562\n",
      " |~~ train@45504  Loss: 0.002720 Acc: 13.1719\n",
      " |~~ train@45568  Loss: 0.002982 Acc: 13.1719\n",
      " |~~ train@45632  Loss: 0.002931 Acc: 13.0469\n",
      " |~~ train@45696  Loss: 0.002261 Acc: 13.2344\n",
      " |~~ train@45760  Loss: 0.002326 Acc: 13.3281\n",
      " |~~ train@45824  Loss: 0.001954 Acc: 13.4844\n",
      " |~~ train@45888  Loss: 0.002618 Acc: 13.2344\n",
      " |~~ train@45952  Loss: 0.002219 Acc: 13.2969\n",
      " |~~ train@46016  Loss: 0.002311 Acc: 13.2969\n",
      " |~~ train@46080  Loss: 0.002707 Acc: 13.2031\n",
      " |~~ train@46144  Loss: 0.002572 Acc: 13.2969\n",
      " |~~ train@46208  Loss: 0.002018 Acc: 13.4062\n",
      " |~~ train@46272  Loss: 0.002527 Acc: 13.2656\n",
      " |~~ train@46336  Loss: 0.001930 Acc: 13.4844\n",
      " |~~ train@46400  Loss: 0.002132 Acc: 13.3438\n",
      " |~~ train@46464  Loss: 0.002444 Acc: 13.2188\n",
      " |~~ train@46528  Loss: 0.002026 Acc: 13.4688\n",
      " |~~ train@46592  Loss: 0.002556 Acc: 13.1562\n",
      " |~~ train@46656  Loss: 0.002395 Acc: 13.3281\n",
      " |~~ train@46720  Loss: 0.002509 Acc: 13.2031\n",
      " |~~ train@46784  Loss: 0.002687 Acc: 13.1562\n",
      " |~~ train@46848  Loss: 0.002342 Acc: 13.2812\n",
      " |~~ train@46912  Loss: 0.002095 Acc: 13.3594\n",
      " |~~ train@46976  Loss: 0.002279 Acc: 13.2969\n",
      " |~~ train@47040  Loss: 0.002710 Acc: 13.1406\n",
      " |~~ train@47104  Loss: 0.001747 Acc: 13.4531\n",
      " |~~ train@47168  Loss: 0.002520 Acc: 13.2656\n",
      " |~~ train@47232  Loss: 0.002267 Acc: 13.3594\n",
      " |~~ train@47296  Loss: 0.002536 Acc: 13.2656\n",
      " |~~ train@47360  Loss: 0.002179 Acc: 13.3125\n",
      " |~~ train@47424  Loss: 0.002087 Acc: 13.4375\n",
      " |~~ train@47488  Loss: 0.002096 Acc: 13.3750\n",
      " |~~ train@47552  Loss: 0.002575 Acc: 13.2188\n",
      " |~~ train@47616  Loss: 0.002337 Acc: 13.3125\n",
      " |~~ train@47680  Loss: 0.003169 Acc: 13.1094\n",
      " |~~ train@47744  Loss: 0.002581 Acc: 13.2344\n",
      " |~~ train@47808  Loss: 0.002137 Acc: 13.3906\n",
      " |~~ train@47872  Loss: 0.002595 Acc: 13.2812\n",
      " |~~ train@47936  Loss: 0.002191 Acc: 13.3281\n",
      " |~~ train@48000  Loss: 0.002775 Acc: 13.1719\n",
      " |~~ train@48064  Loss: 0.002589 Acc: 13.2656\n",
      " |~~ train@48128  Loss: 0.002367 Acc: 13.2031\n",
      " |~~ train@48192  Loss: 0.002435 Acc: 13.3125\n",
      " |~~ train@48256  Loss: 0.002038 Acc: 13.4688\n",
      " |~~ train@48320  Loss: 0.002326 Acc: 13.3438\n",
      " |~~ train@48384  Loss: 0.002365 Acc: 13.3438\n",
      " |~~ train@48448  Loss: 0.002664 Acc: 13.2031\n",
      " |~~ train@48512  Loss: 0.002137 Acc: 13.3750\n",
      " |~~ train@48576  Loss: 0.003189 Acc: 12.9688\n",
      " |~~ train@48640  Loss: 0.002188 Acc: 13.2812\n",
      " |~~ train@48704  Loss: 0.002438 Acc: 13.2656\n",
      " |~~ train@48768  Loss: 0.002487 Acc: 13.2031\n",
      " |~~ train@48832  Loss: 0.002855 Acc: 13.0781\n",
      " |~~ train@48896  Loss: 0.002527 Acc: 13.1719\n",
      " |~~ train@48960  Loss: 0.002337 Acc: 13.3594\n",
      " |~~ train@49024  Loss: 0.002402 Acc: 13.3125\n",
      " |~~ train@49088  Loss: 0.003450 Acc: 12.9688\n",
      " |~~ train@49152  Loss: 0.002269 Acc: 13.3594\n",
      " |~~ train@49216  Loss: 0.002443 Acc: 13.3281\n",
      " |~~ train@49280  Loss: 0.002337 Acc: 13.2969\n",
      " |~~ train@49344  Loss: 0.002166 Acc: 13.3594\n",
      " |~~ train@49408  Loss: 0.002341 Acc: 13.2969\n",
      " |~~ train@49472  Loss: 0.002112 Acc: 13.3750\n",
      " |~~ train@49536  Loss: 0.002921 Acc: 13.0312\n",
      " |~~ train@49600  Loss: 0.002144 Acc: 13.4062\n",
      " |~~ train@49664  Loss: 0.001838 Acc: 13.4531\n",
      " |~~ train@49728  Loss: 0.002613 Acc: 13.2031\n",
      " |~~ train@49792  Loss: 0.002659 Acc: 13.1875\n",
      " |~~ train@49856  Loss: 0.002741 Acc: 13.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@49920  Loss: 0.002293 Acc: 13.3281\n",
      " |~~ train@49984  Loss: 0.002066 Acc: 13.2812\n",
      " |~~ train@50048  Loss: 0.002905 Acc: 13.0938\n",
      " |~~ train@50112  Loss: 0.002482 Acc: 13.2656\n",
      " |~~ train@50176  Loss: 0.002104 Acc: 13.3594\n",
      " |~~ train@50240  Loss: 0.002832 Acc: 13.1406\n",
      " |~~ train@50304  Loss: 0.002930 Acc: 13.0938\n",
      " |~~ train@50368  Loss: 0.002613 Acc: 13.2031\n",
      " |~~ train@50432  Loss: 0.002617 Acc: 13.2344\n",
      " |~~ train@50496  Loss: 0.002543 Acc: 13.1719\n",
      " |~~ train@50560  Loss: 0.002705 Acc: 13.1562\n",
      " |~~ train@50624  Loss: 0.002390 Acc: 13.4219\n",
      " |~~ train@50688  Loss: 0.002578 Acc: 13.1250\n",
      " |~~ train@50752  Loss: 0.002382 Acc: 13.2031\n",
      " |~~ train@50816  Loss: 0.003102 Acc: 13.0000\n",
      " |~~ train@50880  Loss: 0.002680 Acc: 13.1562\n",
      " |~~ train@50944  Loss: 0.002145 Acc: 13.3594\n",
      " |~~ train@51008  Loss: 0.002448 Acc: 13.2812\n",
      " |~~ train@51072  Loss: 0.002282 Acc: 13.3281\n",
      " |~~ train@51136  Loss: 0.002698 Acc: 13.0938\n",
      " |~~ train@51200  Loss: 0.002293 Acc: 13.3750\n",
      " |~~ train@51264  Loss: 0.002363 Acc: 13.3281\n",
      " |~~ train@51328  Loss: 0.002030 Acc: 13.3750\n",
      " |~~ train@51392  Loss: 0.002509 Acc: 13.2344\n",
      " |~~ train@51456  Loss: 0.002475 Acc: 13.2656\n",
      " |~~ train@51520  Loss: 0.002720 Acc: 13.1562\n",
      " |~~ train@51584  Loss: 0.002377 Acc: 13.3125\n",
      " |~~ train@51648  Loss: 0.002483 Acc: 13.2656\n",
      " |~~ train@51712  Loss: 0.002170 Acc: 13.3281\n",
      " |~~ train@51776  Loss: 0.001866 Acc: 13.5469\n",
      " |~~ train@51840  Loss: 0.002193 Acc: 13.4688\n",
      " |~~ train@51904  Loss: 0.002524 Acc: 13.1875\n",
      " |~~ train@51968  Loss: 0.002647 Acc: 13.1875\n",
      " |~~ train@52032  Loss: 0.002208 Acc: 13.3438\n",
      " |~~ train@52096  Loss: 0.002111 Acc: 13.3750\n",
      " |~~ train@52160  Loss: 0.002608 Acc: 13.2500\n",
      " |~~ train@52224  Loss: 0.002835 Acc: 13.1562\n",
      " |~~ train@52288  Loss: 0.002456 Acc: 13.2344\n",
      " |~~ train@52352  Loss: 0.002360 Acc: 13.3438\n",
      " |~~ train@52416  Loss: 0.002528 Acc: 13.2969\n",
      " |~~ train@52480  Loss: 0.002725 Acc: 13.2344\n",
      " |~~ train@52544  Loss: 0.001767 Acc: 13.5156\n",
      " |~~ train@52608  Loss: 0.002067 Acc: 13.4219\n",
      " |~~ train@52672  Loss: 0.002450 Acc: 13.3281\n",
      " |~~ train@52736  Loss: 0.003103 Acc: 13.1250\n",
      " |~~ train@52800  Loss: 0.001916 Acc: 13.4219\n",
      " |~~ train@52864  Loss: 0.001986 Acc: 13.5000\n",
      " |~~ train@52928  Loss: 0.002318 Acc: 13.3125\n",
      " |~~ train@52992  Loss: 0.001845 Acc: 13.4375\n",
      " |~~ train@53056  Loss: 0.002461 Acc: 13.2656\n",
      " |~~ train@53120  Loss: 0.001895 Acc: 13.4688\n",
      " |~~ train@53184  Loss: 0.002714 Acc: 13.0469\n",
      " |~~ train@53248  Loss: 0.002378 Acc: 13.3438\n",
      " |~~ train@53312  Loss: 0.002938 Acc: 13.0781\n",
      " |~~ train@53376  Loss: 0.002328 Acc: 13.2969\n",
      " |~~ train@53440  Loss: 0.002518 Acc: 13.3594\n",
      " |~~ train@53504  Loss: 0.002279 Acc: 13.3281\n",
      " |~~ train@53568  Loss: 0.002821 Acc: 13.1406\n",
      " |~~ train@53632  Loss: 0.002529 Acc: 13.2500\n",
      " |~~ train@53696  Loss: 0.002380 Acc: 13.3438\n",
      " |~~ train@53760  Loss: 0.002256 Acc: 13.1562\n",
      " |~~ train@53824  Loss: 0.002592 Acc: 13.2812\n",
      " |~~ train@53888  Loss: 0.002319 Acc: 13.3438\n",
      " |~~ train@53952  Loss: 0.001974 Acc: 13.4219\n",
      " |~~ train@54016  Loss: 0.001727 Acc: 13.5312\n",
      " |~~ train@54080  Loss: 0.002313 Acc: 13.3125\n",
      " |~~ train@54144  Loss: 0.002534 Acc: 13.2031\n",
      " |~~ train@54208  Loss: 0.002486 Acc: 13.1562\n",
      " |~~ train@54272  Loss: 0.002860 Acc: 13.1094\n",
      " |~~ train@54336  Loss: 0.002892 Acc: 13.1094\n",
      " |~~ train@54400  Loss: 0.002500 Acc: 13.3750\n",
      " |~~ train@54464  Loss: 0.002301 Acc: 13.3125\n",
      " |~~ train@54528  Loss: 0.002578 Acc: 13.3125\n",
      " |~~ train@54592  Loss: 0.002137 Acc: 13.3750\n",
      " |~~ train@54656  Loss: 0.002302 Acc: 13.3750\n",
      " |~~ train@54720  Loss: 0.001915 Acc: 13.4688\n",
      " |~~ train@54784  Loss: 0.003066 Acc: 13.0312\n",
      " |~~ train@54848  Loss: 0.002667 Acc: 13.1875\n",
      " |~~ train@54912  Loss: 0.002646 Acc: 13.2344\n",
      " |~~ train@54976  Loss: 0.002318 Acc: 13.3438\n",
      " |~~ train@55040  Loss: 0.002704 Acc: 13.2656\n",
      " |~~ train@55104  Loss: 0.002903 Acc: 13.0625\n",
      " |~~ train@55168  Loss: 0.002634 Acc: 13.1406\n",
      " |~~ train@55232  Loss: 0.001751 Acc: 13.4844\n",
      " |~~ train@55296  Loss: 0.002487 Acc: 13.2344\n",
      " |~~ train@55360  Loss: 0.002478 Acc: 13.2969\n",
      " |~~ train@55424  Loss: 0.002507 Acc: 13.2812\n",
      " |~~ train@55488  Loss: 0.002372 Acc: 13.2500\n",
      " |~~ train@55552  Loss: 0.002611 Acc: 13.2656\n",
      " |~~ train@55616  Loss: 0.002274 Acc: 13.3750\n",
      " |~~ train@55680  Loss: 0.002236 Acc: 13.3906\n",
      " |~~ train@55744  Loss: 0.002780 Acc: 13.1719\n",
      " |~~ train@55808  Loss: 0.002138 Acc: 13.2969\n",
      " |~~ train@55872  Loss: 0.002005 Acc: 13.3750\n",
      " |~~ train@55936  Loss: 0.002090 Acc: 13.4219\n",
      " |~~ train@56000  Loss: 0.002372 Acc: 13.2656\n",
      " |~~ train@56064  Loss: 0.002331 Acc: 13.2969\n",
      " |~~ train@56128  Loss: 0.002192 Acc: 13.3281\n",
      " |~~ train@56192  Loss: 0.002013 Acc: 13.2812\n",
      " |~~ train@56256  Loss: 0.002557 Acc: 13.1719\n",
      " |~~ train@56320  Loss: 0.002596 Acc: 13.2031\n",
      " |~~ train@56384  Loss: 0.002106 Acc: 13.4219\n",
      " |~~ train@56448  Loss: 0.002170 Acc: 13.3906\n",
      " |~~ train@56512  Loss: 0.001824 Acc: 13.4688\n",
      " |~~ train@56576  Loss: 0.001971 Acc: 13.4219\n",
      " |~~ train@56640  Loss: 0.002451 Acc: 13.3281\n",
      " |~~ train@56704  Loss: 0.002074 Acc: 13.3750\n",
      " |~~ train@56768  Loss: 0.002034 Acc: 13.4219\n",
      " |~~ train@56832  Loss: 0.002486 Acc: 13.2031\n",
      " |~~ train@56896  Loss: 0.002378 Acc: 13.2969\n",
      " |~~ train@56960  Loss: 0.002173 Acc: 13.3750\n",
      " |~~ train@57024  Loss: 0.002101 Acc: 13.4062\n",
      " |~~ train@57088  Loss: 0.002491 Acc: 13.2812\n",
      " |~~ train@57152  Loss: 0.002602 Acc: 13.2188\n",
      " |~~ train@57216  Loss: 0.002816 Acc: 13.1562\n",
      " |~~ train@57280  Loss: 0.002026 Acc: 13.4062\n",
      " |~~ train@57344  Loss: 0.002348 Acc: 13.2969\n",
      " |~~ train@57408  Loss: 0.002283 Acc: 13.3438\n",
      " |~~ train@57472  Loss: 0.002422 Acc: 13.2500\n",
      " |~~ train@57536  Loss: 0.002237 Acc: 13.3281\n",
      " |~~ train@57600  Loss: 0.002644 Acc: 13.2656\n",
      " |~~ train@57664  Loss: 0.002969 Acc: 13.0312\n",
      " |~~ train@57728  Loss: 0.001818 Acc: 13.4844\n",
      " |~~ train@57792  Loss: 0.002491 Acc: 13.1875\n",
      " |~~ train@57856  Loss: 0.002179 Acc: 13.2812\n",
      " |~~ train@57920  Loss: 0.001967 Acc: 13.3125\n",
      " |~~ train@57984  Loss: 0.002908 Acc: 13.2188\n",
      " |~~ train@58048  Loss: 0.002869 Acc: 13.2031\n",
      " |~~ train@58112  Loss: 0.002364 Acc: 13.2031\n",
      " |~~ train@58176  Loss: 0.002166 Acc: 13.3594\n",
      " |~~ train@58240  Loss: 0.002519 Acc: 13.2656\n",
      " |~~ train@58304  Loss: 0.002111 Acc: 13.3125\n",
      " |~~ train@58368  Loss: 0.002033 Acc: 13.3750\n",
      " |~~ train@58432  Loss: 0.002092 Acc: 13.4375\n",
      " |~~ train@58496  Loss: 0.002149 Acc: 13.3125\n",
      " |~~ train@58560  Loss: 0.002769 Acc: 13.2812\n",
      " |~~ train@58624  Loss: 0.002195 Acc: 13.3125\n",
      " |~~ train@58688  Loss: 0.001823 Acc: 13.5156\n",
      " |~~ train@58752  Loss: 0.002352 Acc: 13.2969\n",
      " |~~ train@58816  Loss: 0.002723 Acc: 13.1719\n",
      " |~~ train@58880  Loss: 0.002422 Acc: 13.2969\n",
      " |~~ train@58944  Loss: 0.002516 Acc: 13.2500\n",
      " |~~ train@59008  Loss: 0.002538 Acc: 13.2500\n",
      " |~~ train@59072  Loss: 0.002353 Acc: 13.2344\n",
      " |~~ train@59136  Loss: 0.002734 Acc: 13.1875\n",
      " |~~ train@59200  Loss: 0.002682 Acc: 13.1562\n",
      " |~~ train@59264  Loss: 0.002730 Acc: 13.1406\n",
      " |~~ train@59328  Loss: 0.002475 Acc: 13.2656\n",
      " |~~ train@59392  Loss: 0.002137 Acc: 13.3750\n",
      " |~~ train@59456  Loss: 0.002669 Acc: 13.2344\n",
      " |~~ train@59520  Loss: 0.002158 Acc: 13.3750\n",
      " |~~ train@59584  Loss: 0.002184 Acc: 13.3594\n",
      " |~~ train@59648  Loss: 0.001794 Acc: 13.4688\n",
      " |~~ train@59712  Loss: 0.002988 Acc: 13.1719\n",
      " |~~ train@59776  Loss: 0.001966 Acc: 13.4375\n",
      " |~~ train@59840  Loss: 0.002222 Acc: 13.2969\n",
      " |~~ train@59904  Loss: 0.002289 Acc: 13.2969\n",
      " |~~ train@59968  Loss: 0.002415 Acc: 13.3125\n",
      " |~~ train@60032  Loss: 0.002266 Acc: 13.3125\n",
      " |~~ train@60096  Loss: 0.002641 Acc: 13.1719\n",
      " |~~ train@60160  Loss: 0.002443 Acc: 13.3125\n",
      " |~~ train@60224  Loss: 0.002795 Acc: 13.1250\n",
      " |~~ train@60288  Loss: 0.002834 Acc: 13.0781\n",
      " |~~ train@60352  Loss: 0.002400 Acc: 13.2344\n",
      " |~~ train@60416  Loss: 0.002101 Acc: 13.4375\n",
      " |~~ train@60480  Loss: 0.002647 Acc: 13.2344\n",
      " |~~ train@60544  Loss: 0.002223 Acc: 13.2969\n",
      " |~~ train@60608  Loss: 0.002458 Acc: 13.2500\n",
      " |~~ train@60672  Loss: 0.002247 Acc: 13.3125\n",
      " |~~ train@60736  Loss: 0.002363 Acc: 13.2812\n",
      " |~~ train@60800  Loss: 0.002270 Acc: 13.2031\n",
      " |~~ train@60864  Loss: 0.002259 Acc: 13.3594\n",
      " |~~ train@60928  Loss: 0.001972 Acc: 13.5312\n",
      " |~~ train@60992  Loss: 0.002255 Acc: 13.2656\n",
      " |~~ train@61056  Loss: 0.002828 Acc: 13.1875\n",
      " |~~ train@61120  Loss: 0.002305 Acc: 13.2969\n",
      " |~~ train@61184  Loss: 0.002275 Acc: 13.3906\n",
      " |~~ train@61248  Loss: 0.002291 Acc: 13.3750\n",
      " |~~ train@61312  Loss: 0.002079 Acc: 13.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@61376  Loss: 0.002434 Acc: 13.2969\n",
      " |~~ train@61440  Loss: 0.002355 Acc: 13.2188\n",
      " |~~ train@61504  Loss: 0.002399 Acc: 13.3125\n",
      " |~~ train@61568  Loss: 0.002655 Acc: 13.1875\n",
      " |~~ train@61632  Loss: 0.001987 Acc: 13.3906\n",
      " |~~ train@61696  Loss: 0.001939 Acc: 13.5000\n",
      " |~~ train@61760  Loss: 0.003166 Acc: 13.0625\n",
      " |~~ train@61824  Loss: 0.002096 Acc: 13.3281\n",
      " |~~ train@61888  Loss: 0.002270 Acc: 13.3125\n",
      " |~~ train@61952  Loss: 0.002186 Acc: 13.3281\n",
      " |~~ train@62016  Loss: 0.001901 Acc: 13.4688\n",
      " |~~ train@62080  Loss: 0.002889 Acc: 13.0938\n",
      " |~~ train@62144  Loss: 0.002206 Acc: 13.3438\n",
      " |~~ train@62208  Loss: 0.002069 Acc: 13.3750\n",
      " |~~ train@62272  Loss: 0.001922 Acc: 13.4531\n",
      " |~~ train@62336  Loss: 0.002270 Acc: 13.3281\n",
      " |~~ train@62400  Loss: 0.002144 Acc: 13.3594\n",
      " |~~ train@62464  Loss: 0.003134 Acc: 13.1562\n",
      " |~~ train@62528  Loss: 0.001905 Acc: 13.4531\n",
      " |~~ train@62592  Loss: 0.002398 Acc: 13.2656\n",
      " |~~ train@62656  Loss: 0.002840 Acc: 13.1406\n",
      " |~~ train@62720  Loss: 0.001964 Acc: 13.4375\n",
      " |~~ train@62784  Loss: 0.002166 Acc: 13.4219\n",
      " |~~ train@62848  Loss: 0.002615 Acc: 13.1562\n",
      " |~~ train@62912  Loss: 0.002672 Acc: 13.1406\n",
      " |~~ train@62976  Loss: 0.002286 Acc: 13.4219\n",
      " |~~ train@63040  Loss: 0.002458 Acc: 13.2812\n",
      " |~~ train@63104  Loss: 0.002342 Acc: 13.2969\n",
      " |~~ train@63168  Loss: 0.002811 Acc: 13.1250\n",
      " |~~ train@63232  Loss: 0.002350 Acc: 13.2344\n",
      " |~~ train@63296  Loss: 0.002589 Acc: 13.1562\n",
      " |~~ train@63360  Loss: 0.002477 Acc: 13.2656\n",
      " |~~ train@63424  Loss: 0.002687 Acc: 13.1719\n",
      " |~~ train@63488  Loss: 0.002289 Acc: 13.3125\n",
      " |~~ train@63552  Loss: 0.002461 Acc: 13.2500\n",
      " |~~ train@63616  Loss: 0.001840 Acc: 13.4688\n",
      " |~~ train@63680  Loss: 0.002566 Acc: 13.1406\n",
      " |~~ train@63744  Loss: 0.002360 Acc: 13.1562\n",
      " |~~ train@63808  Loss: 0.002049 Acc: 13.3125\n",
      " |~~ train@63872  Loss: 0.002581 Acc: 13.2188\n",
      " |~~ train@63936  Loss: 0.002643 Acc: 13.3125\n",
      " |~~ train@64000  Loss: 0.002521 Acc: 13.1719\n",
      " |~~ train@64064  Loss: 0.002183 Acc: 13.3594\n",
      " |~~ train@64128  Loss: 0.002455 Acc: 13.2656\n",
      " |~~ train@64192  Loss: 0.002175 Acc: 13.4062\n",
      " |~~ train@64256  Loss: 0.003235 Acc: 12.9375\n",
      " |~~ train@64320  Loss: 0.002114 Acc: 13.4531\n",
      " |~~ train@64384  Loss: 0.002650 Acc: 13.1094\n",
      " |~~ train@64448  Loss: 0.002497 Acc: 13.2812\n",
      " |~~ train@64512  Loss: 0.003306 Acc: 13.0312\n",
      " |~~ train@64576  Loss: 0.002158 Acc: 13.3594\n",
      " |~~ train@64640  Loss: 0.002545 Acc: 13.1562\n",
      " |~~ train@64704  Loss: 0.002048 Acc: 13.5156\n",
      " |~~ train@64768  Loss: 0.002159 Acc: 13.4062\n",
      " |~~ train@64832  Loss: 0.002655 Acc: 13.2344\n",
      " |~~ train@64896  Loss: 0.001767 Acc: 13.5000\n",
      " |~~ train@64960  Loss: 0.002643 Acc: 13.1719\n",
      " |~~ train@65024  Loss: 0.002243 Acc: 13.4375\n",
      " |~~ train@65088  Loss: 0.002500 Acc: 13.2656\n",
      " |~~ train@65152  Loss: 0.002557 Acc: 13.3125\n",
      " |~~ train@65216  Loss: 0.002334 Acc: 13.3438\n",
      " |~~ train@65280  Loss: 0.002302 Acc: 13.2969\n",
      " |~~ train@65344  Loss: 0.002234 Acc: 13.3281\n",
      " |~~ train@65408  Loss: 0.002526 Acc: 13.2188\n",
      " |~~ train@65472  Loss: 0.002483 Acc: 13.2656\n",
      " |~~ train@65536  Loss: 0.002128 Acc: 13.3594\n",
      " |~~ train@65600  Loss: 0.002822 Acc: 13.1562\n",
      " |~~ train@65664  Loss: 0.002633 Acc: 13.1719\n",
      " |~~ train@65728  Loss: 0.002632 Acc: 13.2188\n",
      " |~~ train@65792  Loss: 0.002279 Acc: 13.2969\n",
      " |~~ train@65856  Loss: 0.002474 Acc: 13.1875\n",
      " |~~ train@65920  Loss: 0.001992 Acc: 13.3906\n",
      " |~~ train@65984  Loss: 0.002882 Acc: 13.0781\n",
      " |~~ train@66048  Loss: 0.002856 Acc: 13.1250\n",
      " |~~ train@66112  Loss: 0.002610 Acc: 13.2500\n",
      " |~~ train@66176  Loss: 0.002239 Acc: 13.2656\n",
      " |~~ train@66240  Loss: 0.002577 Acc: 13.2188\n",
      " |~~ train@66304  Loss: 0.003147 Acc: 13.0000\n",
      " |~~ train@66368  Loss: 0.002440 Acc: 13.2500\n",
      " |~~ train@66432  Loss: 0.002058 Acc: 13.3438\n",
      " |~~ train@66496  Loss: 0.002073 Acc: 13.3281\n",
      " |~~ train@66560  Loss: 0.002102 Acc: 13.3281\n",
      " |~~ train@66624  Loss: 0.002358 Acc: 13.2969\n",
      " |~~ train@66688  Loss: 0.002843 Acc: 13.1562\n",
      " |~~ train@66752  Loss: 0.002196 Acc: 13.3750\n",
      " |~~ train@66816  Loss: 0.002261 Acc: 13.4375\n",
      " |~~ train@66880  Loss: 0.002667 Acc: 13.1250\n",
      " |~~ train@66944  Loss: 0.002399 Acc: 13.2344\n",
      " |~~ train@67008  Loss: 0.002299 Acc: 13.2969\n",
      " |~~ train@67072  Loss: 0.002570 Acc: 13.1875\n",
      " |~~ train@67136  Loss: 0.002503 Acc: 13.2812\n",
      " |~~ train@67200  Loss: 0.002232 Acc: 13.2656\n",
      " |~~ train@67264  Loss: 0.002181 Acc: 13.3750\n",
      " |~~ train@67328  Loss: 0.002152 Acc: 13.3438\n",
      " |~~ train@67392  Loss: 0.002301 Acc: 13.3125\n",
      " |~~ train@67456  Loss: 0.002019 Acc: 13.3438\n",
      " |~~ train@67520  Loss: 0.002687 Acc: 13.1250\n",
      " |~~ train@67584  Loss: 0.002502 Acc: 13.2188\n",
      " |~~ train@67648  Loss: 0.002817 Acc: 13.2500\n",
      " |~~ train@67712  Loss: 0.002179 Acc: 13.2969\n",
      " |~~ train@67776  Loss: 0.002641 Acc: 13.1250\n",
      " |~~ train@67840  Loss: 0.002191 Acc: 13.3906\n",
      " |~~ train@67904  Loss: 0.002804 Acc: 13.1406\n",
      " |~~ train@67968  Loss: 0.002286 Acc: 13.2656\n",
      " |~~ train@68032  Loss: 0.002530 Acc: 13.2812\n",
      " |~~ train@68096  Loss: 0.002305 Acc: 13.2656\n",
      " |~~ train@68160  Loss: 0.002204 Acc: 13.3594\n",
      " |~~ train@68224  Loss: 0.002482 Acc: 13.2812\n",
      " |~~ train@68288  Loss: 0.001982 Acc: 13.4375\n",
      " |~~ train@68352  Loss: 0.002359 Acc: 13.2344\n",
      " |~~ train@68416  Loss: 0.001903 Acc: 13.4844\n",
      " |~~ train@68480  Loss: 0.002473 Acc: 13.2031\n",
      " |~~ train@68544  Loss: 0.002589 Acc: 13.3594\n",
      " |~~ train@68608  Loss: 0.002472 Acc: 13.3750\n",
      " |~~ train@68672  Loss: 0.002548 Acc: 13.2500\n",
      " |~~ train@68736  Loss: 0.002335 Acc: 13.2656\n",
      " |~~ train@68800  Loss: 0.002402 Acc: 13.3125\n",
      " |~~ train@68864  Loss: 0.002531 Acc: 13.2344\n",
      " |~~ train@68928  Loss: 0.002810 Acc: 13.2188\n",
      " |~~ train@68992  Loss: 0.001865 Acc: 13.4375\n",
      " |~~ train@69056  Loss: 0.001947 Acc: 13.4219\n",
      " |~~ train@69120  Loss: 0.002133 Acc: 13.3750\n",
      " |~~ train@69184  Loss: 0.002215 Acc: 13.2969\n",
      " |~~ train@69248  Loss: 0.001825 Acc: 13.4844\n",
      " |~~ train@69312  Loss: 0.002418 Acc: 13.1875\n",
      " |~~ train@69376  Loss: 0.002400 Acc: 13.2656\n",
      " |~~ train@69440  Loss: 0.002236 Acc: 13.2344\n",
      " |~~ train@69504  Loss: 0.002058 Acc: 13.4062\n",
      " |~~ train@69568  Loss: 0.002268 Acc: 13.2969\n",
      " |~~ train@69632  Loss: 0.001976 Acc: 13.4062\n",
      " |~~ train@69696  Loss: 0.002220 Acc: 13.3125\n",
      " |~~ train@69760  Loss: 0.002889 Acc: 13.1875\n",
      " |~~ train@69824  Loss: 0.002581 Acc: 13.1094\n",
      " |~~ train@69888  Loss: 0.002780 Acc: 13.0469\n",
      " |~~ train@69952  Loss: 0.002640 Acc: 13.1562\n",
      " |~~ train@70016  Loss: 0.002148 Acc: 13.3281\n",
      " |~~ train@70080  Loss: 0.002715 Acc: 13.2344\n",
      " |~~ train@70144  Loss: 0.002197 Acc: 13.3125\n",
      " |~~ train@70208  Loss: 0.002245 Acc: 13.3438\n",
      " |~~ train@70272  Loss: 0.002490 Acc: 13.2969\n",
      " |~~ train@70336  Loss: 0.002380 Acc: 13.2812\n",
      " |~~ train@70400  Loss: 0.002268 Acc: 13.3438\n",
      " |~~ train@70464  Loss: 0.002456 Acc: 13.3594\n",
      " |~~ train@70528  Loss: 0.002521 Acc: 13.2344\n",
      " |~~ train@70592  Loss: 0.002685 Acc: 13.1562\n",
      " |~~ train@70656  Loss: 0.002559 Acc: 13.2500\n",
      " |~~ train@70720  Loss: 0.002760 Acc: 13.1406\n",
      " |~~ train@70784  Loss: 0.002705 Acc: 13.0781\n",
      " |~~ train@70848  Loss: 0.002442 Acc: 13.3281\n",
      " |~~ train@70912  Loss: 0.002042 Acc: 13.4844\n",
      " |~~ train@70976  Loss: 0.002878 Acc: 13.1406\n",
      " |~~ train@71040  Loss: 0.002445 Acc: 13.2500\n",
      " |~~ train@71104  Loss: 0.002405 Acc: 13.3125\n",
      " |~~ train@71168  Loss: 0.002717 Acc: 13.1406\n",
      " |~~ train@71232  Loss: 0.002809 Acc: 13.2188\n",
      " |~~ train@71296  Loss: 0.002495 Acc: 13.1562\n",
      " |~~ train@71360  Loss: 0.002238 Acc: 13.4062\n",
      " |~~ train@71424  Loss: 0.002205 Acc: 13.3281\n",
      " |~~ train@71488  Loss: 0.002713 Acc: 13.2656\n",
      " |~~ train@71552  Loss: 0.002321 Acc: 13.3438\n",
      " |~~ train@71616  Loss: 0.002400 Acc: 13.3281\n",
      " |~~ train@71680  Loss: 0.002010 Acc: 13.4844\n",
      " |~~ train@71744  Loss: 0.002860 Acc: 13.1094\n",
      " |~~ train@71808  Loss: 0.002713 Acc: 13.1250\n",
      " |~~ train@71872  Loss: 0.002539 Acc: 13.2500\n",
      " |~~ train@71936  Loss: 0.002659 Acc: 13.1875\n",
      " |~~ train@72000  Loss: 0.002416 Acc: 13.2500\n",
      " |~~ train@72064  Loss: 0.002339 Acc: 13.3281\n",
      " |~~ train@72128  Loss: 0.002088 Acc: 13.3594\n",
      " |~~ train@72192  Loss: 0.002462 Acc: 13.2969\n",
      " |~~ train@72256  Loss: 0.002791 Acc: 13.1406\n",
      " |~~ train@72320  Loss: 0.002340 Acc: 13.3125\n",
      " |~~ train@72384  Loss: 0.002752 Acc: 13.2031\n",
      " |~~ train@72448  Loss: 0.002663 Acc: 13.1406\n",
      " |~~ train@72512  Loss: 0.002578 Acc: 13.2500\n",
      " |~~ train@72576  Loss: 0.002388 Acc: 13.2812\n",
      " |~~ train@72640  Loss: 0.002008 Acc: 13.4375\n",
      " |~~ train@72704  Loss: 0.002968 Acc: 13.0938\n",
      " |~~ train@72768  Loss: 0.002667 Acc: 13.2188\n",
      " |~~ train@72832  Loss: 0.002513 Acc: 13.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@72896  Loss: 0.002580 Acc: 13.2344\n",
      " |~~ train@72960  Loss: 0.002105 Acc: 13.4531\n",
      " |~~ train@73024  Loss: 0.003026 Acc: 13.0938\n",
      " |~~ train@73088  Loss: 0.002639 Acc: 13.1875\n",
      " |~~ train@73152  Loss: 0.002279 Acc: 13.2031\n",
      " |~~ train@73216  Loss: 0.002678 Acc: 13.1562\n",
      " |~~ train@73280  Loss: 0.002658 Acc: 13.2031\n",
      " |~~ train@73344  Loss: 0.002824 Acc: 13.1250\n",
      " |~~ train@73408  Loss: 0.002287 Acc: 13.4375\n",
      " |~~ train@73472  Loss: 0.002189 Acc: 13.3906\n",
      " |~~ train@73536  Loss: 0.002382 Acc: 13.2656\n",
      " |~~ train@73600  Loss: 0.002384 Acc: 13.2500\n",
      " |~~ train@73664  Loss: 0.002781 Acc: 13.1875\n",
      " |~~ train@73728  Loss: 0.002183 Acc: 13.4219\n",
      " |~~ train@73792  Loss: 0.002539 Acc: 13.2500\n",
      " |~~ train@73856  Loss: 0.002387 Acc: 13.2969\n",
      " |~~ train@73920  Loss: 0.003103 Acc: 13.1250\n",
      " |~~ train@73984  Loss: 0.002437 Acc: 13.2188\n",
      " |~~ train@74048  Loss: 0.002156 Acc: 13.2500\n",
      " |~~ train@74112  Loss: 0.001739 Acc: 13.6094\n",
      " |~~ train@74176  Loss: 0.002735 Acc: 13.1406\n",
      " |~~ train@74240  Loss: 0.002264 Acc: 13.3438\n",
      " |~~ train@74304  Loss: 0.002432 Acc: 13.3125\n",
      " |~~ train@74368  Loss: 0.003252 Acc: 13.0000\n",
      " |~~ train@74432  Loss: 0.002350 Acc: 13.3438\n",
      " |~~ train@74496  Loss: 0.002510 Acc: 13.2344\n",
      " |~~ train@74560  Loss: 0.002809 Acc: 13.1094\n",
      " |~~ train@74624  Loss: 0.002733 Acc: 13.1719\n",
      " |~~ train@74688  Loss: 0.002356 Acc: 13.2031\n",
      " |~~ train@74752  Loss: 0.002220 Acc: 13.3281\n",
      " |~~ train@74816  Loss: 0.002154 Acc: 13.3906\n",
      " |~~ train@74880  Loss: 0.002036 Acc: 13.4375\n",
      " |~~ train@74944  Loss: 0.001889 Acc: 13.4219\n",
      " |~~ train@75008  Loss: 0.002417 Acc: 13.2344\n",
      " |~~ train@75072  Loss: 0.002550 Acc: 13.2812\n",
      " |~~ train@75136  Loss: 0.001930 Acc: 13.2969\n",
      " |~~ train@75200  Loss: 0.002470 Acc: 13.3281\n",
      " |~~ train@75264  Loss: 0.002195 Acc: 13.2812\n",
      " |~~ train@75328  Loss: 0.002022 Acc: 13.4219\n",
      " |~~ train@75392  Loss: 0.002625 Acc: 13.1875\n",
      " |~~ train@75456  Loss: 0.002381 Acc: 13.2656\n",
      " |~~ train@75520  Loss: 0.002501 Acc: 13.2500\n",
      " |~~ train@75584  Loss: 0.002074 Acc: 13.4062\n",
      " |~~ train@75648  Loss: 0.002433 Acc: 13.3281\n",
      " |~~ train@75712  Loss: 0.002445 Acc: 13.2500\n",
      " |~~ train@75776  Loss: 0.002649 Acc: 13.2188\n",
      " |~~ train@75840  Loss: 0.002770 Acc: 13.1875\n",
      " |~~ train@75904  Loss: 0.002486 Acc: 13.2188\n",
      " |~~ train@75968  Loss: 0.002284 Acc: 13.3125\n",
      " |~~ train@76032  Loss: 0.002135 Acc: 13.3438\n",
      " |~~ train@76096  Loss: 0.001761 Acc: 13.4688\n",
      " |~~ train@76160  Loss: 0.001621 Acc: 13.6094\n",
      " |~~ train@76224  Loss: 0.002589 Acc: 13.2188\n",
      " |~~ train@76288  Loss: 0.003114 Acc: 12.9688\n",
      " |~~ train@76352  Loss: 0.002265 Acc: 13.3594\n",
      " |~~ train@76416  Loss: 0.002413 Acc: 13.2812\n",
      " |~~ train@76480  Loss: 0.002558 Acc: 13.2500\n",
      " |~~ train@76544  Loss: 0.002663 Acc: 13.2344\n",
      " |~~ train@76608  Loss: 0.002525 Acc: 13.2656\n",
      " |~~ train@76672  Loss: 0.002459 Acc: 13.2344\n",
      " |~~ train@76736  Loss: 0.001877 Acc: 13.4844\n",
      " |~~ train@76800  Loss: 0.001921 Acc: 13.3906\n",
      " |~~ train@76864  Loss: 0.002583 Acc: 13.2969\n",
      " |~~ train@76928  Loss: 0.002691 Acc: 13.2344\n",
      " |~~ train@76992  Loss: 0.002286 Acc: 13.2969\n",
      " |~~ train@77056  Loss: 0.002079 Acc: 13.4219\n",
      " |~~ train@77120  Loss: 0.002501 Acc: 13.2656\n",
      " |~~ train@77184  Loss: 0.002477 Acc: 13.1875\n",
      " |~~ train@77248  Loss: 0.002311 Acc: 13.2188\n",
      " |~~ train@77312  Loss: 0.002658 Acc: 13.1562\n",
      " |~~ train@77376  Loss: 0.002019 Acc: 13.4219\n",
      " |~~ train@77440  Loss: 0.002543 Acc: 13.3125\n",
      " |~~ train@77504  Loss: 0.003026 Acc: 13.1562\n",
      " |~~ train@77568  Loss: 0.002568 Acc: 13.2656\n",
      " |~~ train@77632  Loss: 0.002365 Acc: 13.2188\n",
      " |~~ train@77696  Loss: 0.002287 Acc: 13.2969\n",
      " |~~ train@77760  Loss: 0.002543 Acc: 13.1875\n",
      " |~~ train@77824  Loss: 0.002687 Acc: 13.1406\n",
      " |~~ train@77888  Loss: 0.001926 Acc: 13.4531\n",
      " |~~ train@77952  Loss: 0.002700 Acc: 13.1562\n",
      " |~~ train@78016  Loss: 0.001840 Acc: 13.4531\n",
      " |~~ train@78080  Loss: 0.002290 Acc: 13.3281\n",
      " |~~ train@78144  Loss: 0.001882 Acc: 13.5000\n",
      " |~~ train@78208  Loss: 0.002354 Acc: 13.2812\n",
      " |~~ train@78272  Loss: 0.002204 Acc: 13.3281\n",
      " |~~ train@78336  Loss: 0.002152 Acc: 13.4062\n",
      " |~~ train@78400  Loss: 0.002595 Acc: 13.1875\n",
      " |~~ train@78464  Loss: 0.002002 Acc: 13.4062\n",
      " |~~ train@78484  Loss: 0.008384 Acc: 13.2000\n",
      "train  Loss: 0.002396 Acc: 13.2890\n",
      " |~~ val@64  Loss: 0.002691 Acc: 13.2188\n",
      " |~~ val@128  Loss: 0.002290 Acc: 13.3750\n",
      " |~~ val@192  Loss: 0.001994 Acc: 13.3906\n",
      " |~~ val@256  Loss: 0.002056 Acc: 13.4531\n",
      " |~~ val@320  Loss: 0.002880 Acc: 13.1875\n",
      " |~~ val@384  Loss: 0.002352 Acc: 13.4219\n",
      " |~~ val@448  Loss: 0.002111 Acc: 13.3125\n",
      " |~~ val@512  Loss: 0.002509 Acc: 13.1562\n",
      " |~~ val@576  Loss: 0.002799 Acc: 13.0938\n",
      " |~~ val@640  Loss: 0.001997 Acc: 13.4531\n",
      " |~~ val@704  Loss: 0.002697 Acc: 13.1562\n",
      " |~~ val@768  Loss: 0.002550 Acc: 13.2500\n",
      " |~~ val@832  Loss: 0.002021 Acc: 13.4375\n",
      " |~~ val@896  Loss: 0.002170 Acc: 13.3438\n",
      " |~~ val@960  Loss: 0.002557 Acc: 13.2812\n",
      " |~~ val@1024  Loss: 0.001904 Acc: 13.4688\n",
      " |~~ val@1088  Loss: 0.002631 Acc: 13.1719\n",
      " |~~ val@1152  Loss: 0.002905 Acc: 13.1406\n",
      " |~~ val@1216  Loss: 0.002442 Acc: 13.2188\n",
      " |~~ val@1280  Loss: 0.002465 Acc: 13.3125\n",
      " |~~ val@1344  Loss: 0.002723 Acc: 13.0938\n",
      " |~~ val@1408  Loss: 0.002271 Acc: 13.3281\n",
      " |~~ val@1472  Loss: 0.002444 Acc: 13.2500\n",
      " |~~ val@1536  Loss: 0.002324 Acc: 13.3125\n",
      " |~~ val@1600  Loss: 0.002021 Acc: 13.4062\n",
      " |~~ val@1664  Loss: 0.002592 Acc: 13.2188\n",
      " |~~ val@1728  Loss: 0.002380 Acc: 13.2812\n",
      " |~~ val@1792  Loss: 0.002306 Acc: 13.3438\n",
      " |~~ val@1856  Loss: 0.002383 Acc: 13.2500\n",
      " |~~ val@1920  Loss: 0.002332 Acc: 13.3438\n",
      " |~~ val@1984  Loss: 0.002353 Acc: 13.2969\n",
      " |~~ val@2048  Loss: 0.002297 Acc: 13.3594\n",
      " |~~ val@2112  Loss: 0.002016 Acc: 13.4375\n",
      " |~~ val@2176  Loss: 0.002381 Acc: 13.2656\n",
      " |~~ val@2240  Loss: 0.002127 Acc: 13.3125\n",
      " |~~ val@2304  Loss: 0.002502 Acc: 13.3125\n",
      " |~~ val@2368  Loss: 0.002197 Acc: 13.4219\n",
      " |~~ val@2432  Loss: 0.002007 Acc: 13.4844\n",
      " |~~ val@2496  Loss: 0.002819 Acc: 13.0938\n",
      " |~~ val@2560  Loss: 0.002508 Acc: 13.1719\n",
      " |~~ val@2624  Loss: 0.001944 Acc: 13.4844\n",
      " |~~ val@2688  Loss: 0.002578 Acc: 13.2344\n",
      " |~~ val@2752  Loss: 0.002356 Acc: 13.3438\n",
      " |~~ val@2816  Loss: 0.002332 Acc: 13.4062\n",
      " |~~ val@2880  Loss: 0.002088 Acc: 13.4219\n",
      " |~~ val@2944  Loss: 0.001913 Acc: 13.4219\n",
      " |~~ val@3008  Loss: 0.002406 Acc: 13.2969\n",
      " |~~ val@3072  Loss: 0.002077 Acc: 13.3594\n",
      " |~~ val@3136  Loss: 0.002558 Acc: 13.2031\n",
      " |~~ val@3200  Loss: 0.002075 Acc: 13.4375\n",
      " |~~ val@3264  Loss: 0.002138 Acc: 13.4062\n",
      " |~~ val@3328  Loss: 0.002579 Acc: 13.2031\n",
      " |~~ val@3392  Loss: 0.002513 Acc: 13.2656\n",
      " |~~ val@3456  Loss: 0.002885 Acc: 13.1094\n",
      " |~~ val@3520  Loss: 0.002135 Acc: 13.3750\n",
      " |~~ val@3584  Loss: 0.002268 Acc: 13.2500\n",
      " |~~ val@3648  Loss: 0.002434 Acc: 13.3594\n",
      " |~~ val@3712  Loss: 0.001743 Acc: 13.4688\n",
      " |~~ val@3776  Loss: 0.002755 Acc: 13.1875\n",
      " |~~ val@3840  Loss: 0.002296 Acc: 13.3281\n",
      " |~~ val@3904  Loss: 0.002526 Acc: 13.2656\n",
      " |~~ val@3968  Loss: 0.002267 Acc: 13.3750\n",
      " |~~ val@4032  Loss: 0.002389 Acc: 13.2500\n",
      " |~~ val@4096  Loss: 0.002338 Acc: 13.2500\n",
      " |~~ val@4160  Loss: 0.002794 Acc: 13.1406\n",
      " |~~ val@4224  Loss: 0.001676 Acc: 13.4375\n",
      " |~~ val@4288  Loss: 0.003116 Acc: 12.9531\n",
      " |~~ val@4352  Loss: 0.002270 Acc: 13.3438\n",
      " |~~ val@4416  Loss: 0.002429 Acc: 13.1875\n",
      " |~~ val@4480  Loss: 0.002820 Acc: 13.2188\n",
      " |~~ val@4544  Loss: 0.002019 Acc: 13.3906\n",
      " |~~ val@4608  Loss: 0.002296 Acc: 13.3438\n",
      " |~~ val@4672  Loss: 0.002258 Acc: 13.2969\n",
      " |~~ val@4736  Loss: 0.002267 Acc: 13.3125\n",
      " |~~ val@4800  Loss: 0.002257 Acc: 13.2812\n",
      " |~~ val@4864  Loss: 0.002008 Acc: 13.4062\n",
      " |~~ val@4928  Loss: 0.002537 Acc: 13.2812\n",
      " |~~ val@4992  Loss: 0.002351 Acc: 13.3906\n",
      " |~~ val@5056  Loss: 0.003032 Acc: 13.2188\n",
      " |~~ val@5120  Loss: 0.002328 Acc: 13.2812\n",
      " |~~ val@5184  Loss: 0.002975 Acc: 13.0469\n",
      " |~~ val@5248  Loss: 0.002325 Acc: 13.2500\n",
      " |~~ val@5312  Loss: 0.002446 Acc: 13.2344\n",
      " |~~ val@5376  Loss: 0.002162 Acc: 13.3125\n",
      " |~~ val@5440  Loss: 0.002876 Acc: 13.0938\n",
      " |~~ val@5504  Loss: 0.002462 Acc: 13.2344\n",
      " |~~ val@5568  Loss: 0.002750 Acc: 13.1094\n",
      " |~~ val@5632  Loss: 0.002054 Acc: 13.4062\n",
      " |~~ val@5696  Loss: 0.002231 Acc: 13.3438\n",
      " |~~ val@5760  Loss: 0.002206 Acc: 13.3750\n",
      " |~~ val@5824  Loss: 0.002140 Acc: 13.3438\n",
      " |~~ val@5888  Loss: 0.002018 Acc: 13.3750\n",
      " |~~ val@5952  Loss: 0.002504 Acc: 13.2500\n",
      " |~~ val@6016  Loss: 0.002472 Acc: 13.2344\n",
      " |~~ val@6080  Loss: 0.002188 Acc: 13.2812\n",
      " |~~ val@6144  Loss: 0.002786 Acc: 13.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@6208  Loss: 0.002637 Acc: 13.2031\n",
      " |~~ val@6272  Loss: 0.002396 Acc: 13.2031\n",
      " |~~ val@6336  Loss: 0.002174 Acc: 13.3281\n",
      " |~~ val@6400  Loss: 0.002103 Acc: 13.3906\n",
      " |~~ val@6464  Loss: 0.002061 Acc: 13.4062\n",
      " |~~ val@6528  Loss: 0.002089 Acc: 13.4531\n",
      " |~~ val@6592  Loss: 0.002396 Acc: 13.2500\n",
      " |~~ val@6656  Loss: 0.002680 Acc: 13.2969\n",
      " |~~ val@6720  Loss: 0.003207 Acc: 12.9844\n",
      " |~~ val@6784  Loss: 0.002748 Acc: 13.2344\n",
      " |~~ val@6848  Loss: 0.002704 Acc: 13.1250\n",
      " |~~ val@6912  Loss: 0.003001 Acc: 13.0469\n",
      " |~~ val@6976  Loss: 0.002448 Acc: 13.3281\n",
      " |~~ val@7040  Loss: 0.002258 Acc: 13.3438\n",
      " |~~ val@7104  Loss: 0.002156 Acc: 13.3438\n",
      " |~~ val@7168  Loss: 0.002318 Acc: 13.2656\n",
      " |~~ val@7232  Loss: 0.002246 Acc: 13.4375\n",
      " |~~ val@7296  Loss: 0.002469 Acc: 13.2656\n",
      " |~~ val@7360  Loss: 0.002600 Acc: 13.1875\n",
      " |~~ val@7424  Loss: 0.002869 Acc: 13.1719\n",
      " |~~ val@7488  Loss: 0.002422 Acc: 13.3125\n",
      " |~~ val@7552  Loss: 0.002328 Acc: 13.1562\n",
      " |~~ val@7616  Loss: 0.002519 Acc: 13.1875\n",
      " |~~ val@7680  Loss: 0.002538 Acc: 13.2188\n",
      " |~~ val@7744  Loss: 0.001870 Acc: 13.4688\n",
      " |~~ val@7808  Loss: 0.002532 Acc: 13.1875\n",
      " |~~ val@7872  Loss: 0.002937 Acc: 13.0625\n",
      " |~~ val@7936  Loss: 0.002869 Acc: 13.1250\n",
      " |~~ val@8000  Loss: 0.002327 Acc: 13.2656\n",
      " |~~ val@8064  Loss: 0.002049 Acc: 13.3750\n",
      " |~~ val@8128  Loss: 0.003104 Acc: 13.0156\n",
      " |~~ val@8192  Loss: 0.002034 Acc: 13.4375\n",
      " |~~ val@8256  Loss: 0.002237 Acc: 13.3594\n",
      " |~~ val@8320  Loss: 0.002560 Acc: 13.2969\n",
      " |~~ val@8384  Loss: 0.002435 Acc: 13.2500\n",
      " |~~ val@8448  Loss: 0.002253 Acc: 13.3594\n",
      " |~~ val@8512  Loss: 0.002945 Acc: 13.0625\n",
      " |~~ val@8576  Loss: 0.002368 Acc: 13.2969\n",
      " |~~ val@8640  Loss: 0.002685 Acc: 13.1562\n",
      " |~~ val@8704  Loss: 0.002532 Acc: 13.2188\n",
      " |~~ val@8768  Loss: 0.002252 Acc: 13.3750\n",
      " |~~ val@8832  Loss: 0.002832 Acc: 13.1250\n",
      " |~~ val@8896  Loss: 0.002143 Acc: 13.3594\n",
      " |~~ val@8960  Loss: 0.002169 Acc: 13.4062\n",
      " |~~ val@9024  Loss: 0.003090 Acc: 13.0156\n",
      " |~~ val@9088  Loss: 0.002394 Acc: 13.2500\n",
      " |~~ val@9152  Loss: 0.002519 Acc: 13.2812\n",
      " |~~ val@9216  Loss: 0.002144 Acc: 13.3438\n",
      " |~~ val@9280  Loss: 0.001825 Acc: 13.4062\n",
      " |~~ val@9344  Loss: 0.002169 Acc: 13.3281\n",
      " |~~ val@9408  Loss: 0.002293 Acc: 13.3594\n",
      " |~~ val@9472  Loss: 0.002695 Acc: 13.1875\n",
      " |~~ val@9536  Loss: 0.002969 Acc: 13.0938\n",
      " |~~ val@9600  Loss: 0.002374 Acc: 13.2969\n",
      " |~~ val@9664  Loss: 0.002897 Acc: 13.1562\n",
      " |~~ val@9728  Loss: 0.002590 Acc: 13.2656\n",
      " |~~ val@9792  Loss: 0.002152 Acc: 13.4219\n",
      " |~~ val@9856  Loss: 0.002179 Acc: 13.3906\n",
      " |~~ val@9920  Loss: 0.002826 Acc: 13.2344\n",
      " |~~ val@9984  Loss: 0.002258 Acc: 13.3750\n",
      " |~~ val@10048  Loss: 0.002858 Acc: 13.0625\n",
      " |~~ val@10112  Loss: 0.002764 Acc: 13.1562\n",
      " |~~ val@10176  Loss: 0.002254 Acc: 13.2500\n",
      " |~~ val@10240  Loss: 0.002296 Acc: 13.3125\n",
      " |~~ val@10304  Loss: 0.002431 Acc: 13.3594\n",
      " |~~ val@10368  Loss: 0.002869 Acc: 13.2188\n",
      " |~~ val@10432  Loss: 0.002065 Acc: 13.3594\n",
      " |~~ val@10496  Loss: 0.002529 Acc: 13.2188\n",
      " |~~ val@10560  Loss: 0.002673 Acc: 13.2188\n",
      " |~~ val@10624  Loss: 0.002089 Acc: 13.3438\n",
      " |~~ val@10688  Loss: 0.002620 Acc: 13.1406\n",
      " |~~ val@10752  Loss: 0.002582 Acc: 13.2812\n",
      " |~~ val@10816  Loss: 0.002297 Acc: 13.3281\n",
      " |~~ val@10880  Loss: 0.002885 Acc: 13.1250\n",
      " |~~ val@10944  Loss: 0.002575 Acc: 13.1562\n",
      " |~~ val@11008  Loss: 0.002274 Acc: 13.3906\n",
      " |~~ val@11072  Loss: 0.002351 Acc: 13.2344\n",
      " |~~ val@11136  Loss: 0.002423 Acc: 13.1875\n",
      " |~~ val@11200  Loss: 0.002176 Acc: 13.2500\n",
      " |~~ val@11264  Loss: 0.002431 Acc: 13.2188\n",
      " |~~ val@11328  Loss: 0.002120 Acc: 13.4219\n",
      " |~~ val@11392  Loss: 0.002613 Acc: 13.1719\n",
      " |~~ val@11456  Loss: 0.002145 Acc: 13.3281\n",
      " |~~ val@11520  Loss: 0.002228 Acc: 13.3906\n",
      " |~~ val@11584  Loss: 0.002499 Acc: 13.3125\n",
      " |~~ val@11648  Loss: 0.002089 Acc: 13.4062\n",
      " |~~ val@11712  Loss: 0.002560 Acc: 13.2188\n",
      " |~~ val@11776  Loss: 0.002508 Acc: 13.3125\n",
      " |~~ val@11840  Loss: 0.001805 Acc: 13.5156\n",
      " |~~ val@11904  Loss: 0.002052 Acc: 13.4219\n",
      " |~~ val@11968  Loss: 0.002120 Acc: 13.2969\n",
      " |~~ val@12032  Loss: 0.002823 Acc: 13.1094\n",
      " |~~ val@12096  Loss: 0.002202 Acc: 13.2969\n",
      " |~~ val@12160  Loss: 0.002496 Acc: 13.2812\n",
      " |~~ val@12224  Loss: 0.002582 Acc: 13.2812\n",
      " |~~ val@12288  Loss: 0.002615 Acc: 13.1719\n",
      " |~~ val@12352  Loss: 0.001972 Acc: 13.4219\n",
      " |~~ val@12416  Loss: 0.002154 Acc: 13.4062\n",
      " |~~ val@12480  Loss: 0.002376 Acc: 13.2344\n",
      " |~~ val@12544  Loss: 0.002249 Acc: 13.2812\n",
      " |~~ val@12608  Loss: 0.002926 Acc: 13.1562\n",
      " |~~ val@12672  Loss: 0.003078 Acc: 13.1250\n",
      " |~~ val@12736  Loss: 0.002611 Acc: 13.1562\n",
      " |~~ val@12800  Loss: 0.002864 Acc: 13.1094\n",
      " |~~ val@12864  Loss: 0.002496 Acc: 13.2500\n",
      " |~~ val@12928  Loss: 0.002579 Acc: 13.2812\n",
      " |~~ val@12992  Loss: 0.003004 Acc: 13.1406\n",
      " |~~ val@13056  Loss: 0.002237 Acc: 13.3594\n",
      " |~~ val@13120  Loss: 0.002533 Acc: 13.2656\n",
      " |~~ val@13184  Loss: 0.001992 Acc: 13.4219\n",
      " |~~ val@13248  Loss: 0.002038 Acc: 13.4219\n",
      " |~~ val@13312  Loss: 0.002369 Acc: 13.2344\n",
      " |~~ val@13376  Loss: 0.002516 Acc: 13.2344\n",
      " |~~ val@13440  Loss: 0.002768 Acc: 13.1719\n",
      " |~~ val@13504  Loss: 0.002158 Acc: 13.3750\n",
      " |~~ val@13568  Loss: 0.002409 Acc: 13.3281\n",
      " |~~ val@13632  Loss: 0.002239 Acc: 13.2969\n",
      " |~~ val@13696  Loss: 0.002551 Acc: 13.2656\n",
      " |~~ val@13760  Loss: 0.002816 Acc: 13.1719\n",
      " |~~ val@13824  Loss: 0.002733 Acc: 13.2031\n",
      " |~~ val@13888  Loss: 0.002673 Acc: 13.2812\n",
      " |~~ val@13952  Loss: 0.002236 Acc: 13.3281\n",
      " |~~ val@14016  Loss: 0.002003 Acc: 13.4219\n",
      " |~~ val@14080  Loss: 0.002605 Acc: 13.2812\n",
      " |~~ val@14144  Loss: 0.002695 Acc: 13.1719\n",
      " |~~ val@14208  Loss: 0.001988 Acc: 13.4375\n",
      " |~~ val@14272  Loss: 0.002545 Acc: 13.2656\n",
      " |~~ val@14336  Loss: 0.002306 Acc: 13.2969\n",
      " |~~ val@14400  Loss: 0.002113 Acc: 13.4062\n",
      " |~~ val@14464  Loss: 0.002346 Acc: 13.3125\n",
      " |~~ val@14528  Loss: 0.002522 Acc: 13.2500\n",
      " |~~ val@14592  Loss: 0.003498 Acc: 12.9219\n",
      " |~~ val@14656  Loss: 0.002295 Acc: 13.3281\n",
      " |~~ val@14720  Loss: 0.001690 Acc: 13.5781\n",
      " |~~ val@14784  Loss: 0.002723 Acc: 13.1406\n",
      " |~~ val@14848  Loss: 0.002643 Acc: 13.2344\n",
      " |~~ val@14912  Loss: 0.002339 Acc: 13.1875\n",
      " |~~ val@14976  Loss: 0.002055 Acc: 13.3750\n",
      " |~~ val@15040  Loss: 0.002524 Acc: 13.2812\n",
      " |~~ val@15104  Loss: 0.002552 Acc: 13.1875\n",
      " |~~ val@15168  Loss: 0.002276 Acc: 13.2656\n",
      " |~~ val@15232  Loss: 0.002623 Acc: 13.2656\n",
      " |~~ val@15296  Loss: 0.002273 Acc: 13.3594\n",
      " |~~ val@15360  Loss: 0.001899 Acc: 13.4062\n",
      " |~~ val@15424  Loss: 0.002340 Acc: 13.3594\n",
      " |~~ val@15488  Loss: 0.002223 Acc: 13.3594\n",
      " |~~ val@15552  Loss: 0.002785 Acc: 13.1094\n",
      " |~~ val@15616  Loss: 0.002746 Acc: 13.1562\n",
      " |~~ val@15680  Loss: 0.002021 Acc: 13.3906\n",
      " |~~ val@15744  Loss: 0.003333 Acc: 13.0469\n",
      " |~~ val@15808  Loss: 0.002601 Acc: 13.1875\n",
      " |~~ val@15872  Loss: 0.002559 Acc: 13.2188\n",
      " |~~ val@15936  Loss: 0.002051 Acc: 13.4062\n",
      " |~~ val@16000  Loss: 0.002146 Acc: 13.3281\n",
      " |~~ val@16064  Loss: 0.003011 Acc: 13.0781\n",
      " |~~ val@16128  Loss: 0.002533 Acc: 13.3438\n",
      " |~~ val@16192  Loss: 0.001939 Acc: 13.4375\n",
      " |~~ val@16256  Loss: 0.002419 Acc: 13.3125\n",
      " |~~ val@16320  Loss: 0.002399 Acc: 13.2656\n",
      " |~~ val@16384  Loss: 0.002469 Acc: 13.2969\n",
      " |~~ val@16448  Loss: 0.001909 Acc: 13.3906\n",
      " |~~ val@16512  Loss: 0.002118 Acc: 13.3125\n",
      " |~~ val@16576  Loss: 0.002057 Acc: 13.3906\n",
      " |~~ val@16640  Loss: 0.002793 Acc: 13.1094\n",
      " |~~ val@16704  Loss: 0.002160 Acc: 13.2344\n",
      " |~~ val@16768  Loss: 0.002444 Acc: 13.2656\n",
      " |~~ val@16832  Loss: 0.002514 Acc: 13.2188\n",
      " |~~ val@16896  Loss: 0.001665 Acc: 13.5781\n",
      " |~~ val@16960  Loss: 0.002633 Acc: 13.2500\n",
      " |~~ val@17024  Loss: 0.002496 Acc: 13.2969\n",
      " |~~ val@17088  Loss: 0.002737 Acc: 13.2812\n",
      " |~~ val@17152  Loss: 0.002655 Acc: 13.1875\n",
      " |~~ val@17216  Loss: 0.002188 Acc: 13.3906\n",
      " |~~ val@17280  Loss: 0.002456 Acc: 13.2031\n",
      " |~~ val@17344  Loss: 0.002178 Acc: 13.3906\n",
      " |~~ val@17408  Loss: 0.002752 Acc: 13.1719\n",
      " |~~ val@17472  Loss: 0.002888 Acc: 13.1562\n",
      " |~~ val@17536  Loss: 0.001614 Acc: 13.5938\n",
      " |~~ val@17600  Loss: 0.002503 Acc: 13.2500\n",
      " |~~ val@17664  Loss: 0.002350 Acc: 13.3438\n",
      " |~~ val@17728  Loss: 0.002107 Acc: 13.4062\n",
      " |~~ val@17792  Loss: 0.002522 Acc: 13.2656\n",
      " |~~ val@17856  Loss: 0.002107 Acc: 13.4219\n",
      " |~~ val@17920  Loss: 0.002650 Acc: 13.1562\n",
      " |~~ val@17984  Loss: 0.002274 Acc: 13.4062\n",
      " |~~ val@18048  Loss: 0.002738 Acc: 13.1094\n",
      " |~~ val@18112  Loss: 0.002452 Acc: 13.2812\n",
      " |~~ val@18176  Loss: 0.001948 Acc: 13.5000\n",
      " |~~ val@18240  Loss: 0.002849 Acc: 13.0781\n",
      " |~~ val@18304  Loss: 0.003219 Acc: 13.0625\n",
      " |~~ val@18368  Loss: 0.002784 Acc: 13.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@18432  Loss: 0.001822 Acc: 13.5312\n",
      " |~~ val@18496  Loss: 0.001888 Acc: 13.5156\n",
      " |~~ val@18560  Loss: 0.002101 Acc: 13.3750\n",
      " |~~ val@18624  Loss: 0.002402 Acc: 13.1719\n",
      " |~~ val@18688  Loss: 0.002168 Acc: 13.3906\n",
      " |~~ val@18752  Loss: 0.002398 Acc: 13.3750\n",
      " |~~ val@18816  Loss: 0.002383 Acc: 13.3594\n",
      " |~~ val@18880  Loss: 0.001983 Acc: 13.4062\n",
      " |~~ val@18944  Loss: 0.002381 Acc: 13.2812\n",
      " |~~ val@19008  Loss: 0.002048 Acc: 13.4219\n",
      " |~~ val@19072  Loss: 0.002980 Acc: 13.1562\n",
      " |~~ val@19136  Loss: 0.001935 Acc: 13.3750\n",
      " |~~ val@19200  Loss: 0.002716 Acc: 13.2031\n",
      " |~~ val@19264  Loss: 0.002556 Acc: 13.2500\n",
      " |~~ val@19328  Loss: 0.003328 Acc: 12.9375\n",
      " |~~ val@19392  Loss: 0.002873 Acc: 13.1094\n",
      " |~~ val@19456  Loss: 0.002466 Acc: 13.2500\n",
      " |~~ val@19520  Loss: 0.002659 Acc: 13.2344\n",
      " |~~ val@19584  Loss: 0.002437 Acc: 13.2188\n",
      " |~~ val@19648  Loss: 0.002428 Acc: 13.2500\n",
      " |~~ val@19712  Loss: 0.002355 Acc: 13.2344\n",
      " |~~ val@19776  Loss: 0.002211 Acc: 13.2969\n",
      " |~~ val@19840  Loss: 0.002273 Acc: 13.3125\n",
      " |~~ val@19904  Loss: 0.002198 Acc: 13.3594\n",
      " |~~ val@19968  Loss: 0.002599 Acc: 13.2656\n",
      " |~~ val@20032  Loss: 0.002592 Acc: 13.3281\n",
      " |~~ val@20096  Loss: 0.002099 Acc: 13.3438\n",
      " |~~ val@20160  Loss: 0.002345 Acc: 13.3438\n",
      " |~~ val@20224  Loss: 0.002426 Acc: 13.2656\n",
      " |~~ val@20288  Loss: 0.002425 Acc: 13.2656\n",
      " |~~ val@20352  Loss: 0.002413 Acc: 13.3750\n",
      " |~~ val@20416  Loss: 0.001631 Acc: 13.6406\n",
      " |~~ val@20480  Loss: 0.002375 Acc: 13.2969\n",
      " |~~ val@20544  Loss: 0.001840 Acc: 13.5156\n",
      " |~~ val@20608  Loss: 0.002370 Acc: 13.3438\n",
      " |~~ val@20672  Loss: 0.002106 Acc: 13.3281\n",
      " |~~ val@20736  Loss: 0.002728 Acc: 13.1562\n",
      " |~~ val@20800  Loss: 0.002581 Acc: 13.2969\n",
      " |~~ val@20864  Loss: 0.001840 Acc: 13.5000\n",
      " |~~ val@20928  Loss: 0.002337 Acc: 13.3281\n",
      " |~~ val@20992  Loss: 0.002407 Acc: 13.1875\n",
      " |~~ val@21056  Loss: 0.002262 Acc: 13.3281\n",
      " |~~ val@21120  Loss: 0.002339 Acc: 13.2969\n",
      " |~~ val@21184  Loss: 0.002056 Acc: 13.3125\n",
      " |~~ val@21248  Loss: 0.002654 Acc: 13.2188\n",
      " |~~ val@21312  Loss: 0.002408 Acc: 13.3125\n",
      " |~~ val@21376  Loss: 0.002196 Acc: 13.4375\n",
      " |~~ val@21440  Loss: 0.002218 Acc: 13.3594\n",
      " |~~ val@21504  Loss: 0.002558 Acc: 13.1562\n",
      " |~~ val@21568  Loss: 0.002175 Acc: 13.4531\n",
      " |~~ val@21632  Loss: 0.002835 Acc: 13.1719\n",
      " |~~ val@21696  Loss: 0.002120 Acc: 13.3594\n",
      " |~~ val@21760  Loss: 0.002277 Acc: 13.4375\n",
      " |~~ val@21824  Loss: 0.002518 Acc: 13.1562\n",
      " |~~ val@21888  Loss: 0.002453 Acc: 13.2812\n",
      " |~~ val@21952  Loss: 0.002616 Acc: 13.2969\n",
      " |~~ val@22016  Loss: 0.002479 Acc: 13.3125\n",
      " |~~ val@22080  Loss: 0.002470 Acc: 13.2656\n",
      " |~~ val@22144  Loss: 0.002599 Acc: 13.3125\n",
      " |~~ val@22208  Loss: 0.002717 Acc: 13.1875\n",
      " |~~ val@22272  Loss: 0.001897 Acc: 13.3906\n",
      " |~~ val@22336  Loss: 0.002685 Acc: 13.2344\n",
      " |~~ val@22400  Loss: 0.002410 Acc: 13.1875\n",
      " |~~ val@22424  Loss: 0.011738 Acc: 12.6250\n",
      "val  Loss: 0.002418 Acc: 13.2829\n",
      "Epoch 2/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.002864 Acc: 13.1094\n",
      " |~~ train@128  Loss: 0.002177 Acc: 13.3906\n",
      " |~~ train@192  Loss: 0.001793 Acc: 13.4062\n",
      " |~~ train@256  Loss: 0.002298 Acc: 13.2031\n",
      " |~~ train@320  Loss: 0.002301 Acc: 13.3438\n",
      " |~~ train@384  Loss: 0.002767 Acc: 13.0938\n",
      " |~~ train@448  Loss: 0.002524 Acc: 13.2188\n",
      " |~~ train@512  Loss: 0.002149 Acc: 13.2969\n",
      " |~~ train@576  Loss: 0.002996 Acc: 12.9219\n",
      " |~~ train@640  Loss: 0.002197 Acc: 13.4062\n",
      " |~~ train@704  Loss: 0.002265 Acc: 13.3750\n",
      " |~~ train@768  Loss: 0.002351 Acc: 13.2344\n",
      " |~~ train@832  Loss: 0.002336 Acc: 13.2812\n",
      " |~~ train@896  Loss: 0.002384 Acc: 13.3438\n",
      " |~~ train@960  Loss: 0.002384 Acc: 13.2500\n",
      " |~~ train@1024  Loss: 0.001929 Acc: 13.4688\n",
      " |~~ train@1088  Loss: 0.002114 Acc: 13.3125\n",
      " |~~ train@1152  Loss: 0.002639 Acc: 13.1094\n",
      " |~~ train@1216  Loss: 0.002662 Acc: 13.1406\n",
      " |~~ train@1280  Loss: 0.002556 Acc: 13.2656\n",
      " |~~ train@1344  Loss: 0.002680 Acc: 13.2500\n",
      " |~~ train@1408  Loss: 0.002223 Acc: 13.3594\n",
      " |~~ train@1472  Loss: 0.002898 Acc: 13.1719\n",
      " |~~ train@1536  Loss: 0.002556 Acc: 13.3594\n",
      " |~~ train@1600  Loss: 0.002896 Acc: 13.1406\n",
      " |~~ train@1664  Loss: 0.002069 Acc: 13.4062\n",
      " |~~ train@1728  Loss: 0.002768 Acc: 13.1094\n",
      " |~~ train@1792  Loss: 0.001970 Acc: 13.4531\n",
      " |~~ train@1856  Loss: 0.002258 Acc: 13.2656\n",
      " |~~ train@1920  Loss: 0.001739 Acc: 13.5312\n",
      " |~~ train@1984  Loss: 0.002134 Acc: 13.4375\n",
      " |~~ train@2048  Loss: 0.002032 Acc: 13.4375\n",
      " |~~ train@2112  Loss: 0.002192 Acc: 13.3438\n",
      " |~~ train@2176  Loss: 0.002681 Acc: 13.1719\n",
      " |~~ train@2240  Loss: 0.001785 Acc: 13.5000\n",
      " |~~ train@2304  Loss: 0.002003 Acc: 13.4062\n",
      " |~~ train@2368  Loss: 0.002073 Acc: 13.3906\n",
      " |~~ train@2432  Loss: 0.002344 Acc: 13.3750\n",
      " |~~ train@2496  Loss: 0.001991 Acc: 13.4219\n",
      " |~~ train@2560  Loss: 0.002539 Acc: 13.2500\n",
      " |~~ train@2624  Loss: 0.002317 Acc: 13.2344\n",
      " |~~ train@2688  Loss: 0.002788 Acc: 13.1562\n",
      " |~~ train@2752  Loss: 0.002366 Acc: 13.2812\n",
      " |~~ train@2816  Loss: 0.002618 Acc: 13.1875\n",
      " |~~ train@2880  Loss: 0.001893 Acc: 13.3906\n",
      " |~~ train@2944  Loss: 0.002338 Acc: 13.2344\n",
      " |~~ train@3008  Loss: 0.002118 Acc: 13.3906\n",
      " |~~ train@3072  Loss: 0.003081 Acc: 12.9531\n",
      " |~~ train@3136  Loss: 0.002600 Acc: 13.1562\n",
      " |~~ train@3200  Loss: 0.002381 Acc: 13.3438\n",
      " |~~ train@3264  Loss: 0.002376 Acc: 13.2188\n",
      " |~~ train@3328  Loss: 0.002454 Acc: 13.3438\n",
      " |~~ train@3392  Loss: 0.002380 Acc: 13.3125\n",
      " |~~ train@3456  Loss: 0.001956 Acc: 13.4219\n",
      " |~~ train@3520  Loss: 0.002105 Acc: 13.3438\n",
      " |~~ train@3584  Loss: 0.002114 Acc: 13.3750\n",
      " |~~ train@3648  Loss: 0.002436 Acc: 13.2969\n",
      " |~~ train@3712  Loss: 0.002211 Acc: 13.3125\n",
      " |~~ train@3776  Loss: 0.002643 Acc: 13.1719\n",
      " |~~ train@3840  Loss: 0.002173 Acc: 13.3906\n",
      " |~~ train@3904  Loss: 0.002185 Acc: 13.3438\n",
      " |~~ train@3968  Loss: 0.002076 Acc: 13.3906\n",
      " |~~ train@4032  Loss: 0.002325 Acc: 13.2656\n",
      " |~~ train@4096  Loss: 0.002769 Acc: 13.1094\n",
      " |~~ train@4160  Loss: 0.002208 Acc: 13.3750\n",
      " |~~ train@4224  Loss: 0.002566 Acc: 13.2500\n",
      " |~~ train@4288  Loss: 0.002821 Acc: 13.1562\n",
      " |~~ train@4352  Loss: 0.001883 Acc: 13.3906\n",
      " |~~ train@4416  Loss: 0.001705 Acc: 13.5469\n",
      " |~~ train@4480  Loss: 0.002372 Acc: 13.2344\n",
      " |~~ train@4544  Loss: 0.002072 Acc: 13.3594\n",
      " |~~ train@4608  Loss: 0.003119 Acc: 13.0000\n",
      " |~~ train@4672  Loss: 0.002072 Acc: 13.4219\n",
      " |~~ train@4736  Loss: 0.001949 Acc: 13.4844\n",
      " |~~ train@4800  Loss: 0.002170 Acc: 13.3438\n",
      " |~~ train@4864  Loss: 0.002403 Acc: 13.2656\n",
      " |~~ train@4928  Loss: 0.002117 Acc: 13.3281\n",
      " |~~ train@4992  Loss: 0.002388 Acc: 13.2812\n",
      " |~~ train@5056  Loss: 0.002399 Acc: 13.2500\n",
      " |~~ train@5120  Loss: 0.002678 Acc: 13.2188\n",
      " |~~ train@5184  Loss: 0.002746 Acc: 13.1875\n",
      " |~~ train@5248  Loss: 0.002644 Acc: 13.2031\n",
      " |~~ train@5312  Loss: 0.001874 Acc: 13.4219\n",
      " |~~ train@5376  Loss: 0.002522 Acc: 13.2188\n",
      " |~~ train@5440  Loss: 0.002020 Acc: 13.3906\n",
      " |~~ train@5504  Loss: 0.002056 Acc: 13.3594\n",
      " |~~ train@5568  Loss: 0.002397 Acc: 13.3438\n",
      " |~~ train@5632  Loss: 0.002210 Acc: 13.3281\n",
      " |~~ train@5696  Loss: 0.002166 Acc: 13.2812\n",
      " |~~ train@5760  Loss: 0.002158 Acc: 13.4219\n",
      " |~~ train@5824  Loss: 0.002118 Acc: 13.2812\n",
      " |~~ train@5888  Loss: 0.002147 Acc: 13.3125\n",
      " |~~ train@5952  Loss: 0.002499 Acc: 13.2812\n",
      " |~~ train@6016  Loss: 0.002545 Acc: 13.1719\n",
      " |~~ train@6080  Loss: 0.001703 Acc: 13.4531\n",
      " |~~ train@6144  Loss: 0.002433 Acc: 13.2188\n",
      " |~~ train@6208  Loss: 0.001903 Acc: 13.4844\n",
      " |~~ train@6272  Loss: 0.002009 Acc: 13.4531\n",
      " |~~ train@6336  Loss: 0.002063 Acc: 13.4531\n",
      " |~~ train@6400  Loss: 0.002437 Acc: 13.2656\n",
      " |~~ train@6464  Loss: 0.001937 Acc: 13.4375\n",
      " |~~ train@6528  Loss: 0.002186 Acc: 13.2969\n",
      " |~~ train@6592  Loss: 0.002726 Acc: 13.2188\n",
      " |~~ train@6656  Loss: 0.002321 Acc: 13.2969\n",
      " |~~ train@6720  Loss: 0.001924 Acc: 13.4531\n",
      " |~~ train@6784  Loss: 0.002059 Acc: 13.3750\n",
      " |~~ train@6848  Loss: 0.002270 Acc: 13.4375\n",
      " |~~ train@6912  Loss: 0.002565 Acc: 13.2188\n",
      " |~~ train@6976  Loss: 0.002385 Acc: 13.2031\n",
      " |~~ train@7040  Loss: 0.002198 Acc: 13.2500\n",
      " |~~ train@7104  Loss: 0.002165 Acc: 13.2344\n",
      " |~~ train@7168  Loss: 0.002612 Acc: 13.1875\n",
      " |~~ train@7232  Loss: 0.002431 Acc: 13.2812\n",
      " |~~ train@7296  Loss: 0.002297 Acc: 13.4375\n",
      " |~~ train@7360  Loss: 0.002655 Acc: 13.0625\n",
      " |~~ train@7424  Loss: 0.002292 Acc: 13.3281\n",
      " |~~ train@7488  Loss: 0.002191 Acc: 13.2969\n",
      " |~~ train@7552  Loss: 0.002339 Acc: 13.2188\n",
      " |~~ train@7616  Loss: 0.002003 Acc: 13.3594\n",
      " |~~ train@7680  Loss: 0.002518 Acc: 13.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@7744  Loss: 0.002152 Acc: 13.3594\n",
      " |~~ train@7808  Loss: 0.002774 Acc: 13.2344\n",
      " |~~ train@7872  Loss: 0.002820 Acc: 13.1875\n",
      " |~~ train@7936  Loss: 0.002329 Acc: 13.3125\n",
      " |~~ train@8000  Loss: 0.002337 Acc: 13.3438\n",
      " |~~ train@8064  Loss: 0.001919 Acc: 13.3906\n",
      " |~~ train@8128  Loss: 0.002444 Acc: 13.2656\n",
      " |~~ train@8192  Loss: 0.001781 Acc: 13.4844\n",
      " |~~ train@8256  Loss: 0.002551 Acc: 13.2188\n",
      " |~~ train@8320  Loss: 0.002569 Acc: 13.1562\n",
      " |~~ train@8384  Loss: 0.002537 Acc: 13.2969\n",
      " |~~ train@8448  Loss: 0.002225 Acc: 13.3281\n",
      " |~~ train@8512  Loss: 0.002204 Acc: 13.3438\n",
      " |~~ train@8576  Loss: 0.002065 Acc: 13.4375\n",
      " |~~ train@8640  Loss: 0.001991 Acc: 13.3906\n",
      " |~~ train@8704  Loss: 0.002405 Acc: 13.2969\n",
      " |~~ train@8768  Loss: 0.002719 Acc: 13.2188\n",
      " |~~ train@8832  Loss: 0.002252 Acc: 13.2656\n",
      " |~~ train@8896  Loss: 0.002181 Acc: 13.4219\n",
      " |~~ train@8960  Loss: 0.002501 Acc: 13.2344\n",
      " |~~ train@9024  Loss: 0.002429 Acc: 13.2188\n",
      " |~~ train@9088  Loss: 0.002018 Acc: 13.4531\n",
      " |~~ train@9152  Loss: 0.001836 Acc: 13.4688\n",
      " |~~ train@9216  Loss: 0.002333 Acc: 13.2031\n",
      " |~~ train@9280  Loss: 0.002397 Acc: 13.1875\n",
      " |~~ train@9344  Loss: 0.002176 Acc: 13.3594\n",
      " |~~ train@9408  Loss: 0.002713 Acc: 13.2500\n",
      " |~~ train@9472  Loss: 0.002072 Acc: 13.4375\n",
      " |~~ train@9536  Loss: 0.001972 Acc: 13.3281\n",
      " |~~ train@9600  Loss: 0.002043 Acc: 13.3750\n",
      " |~~ train@9664  Loss: 0.002356 Acc: 13.3125\n",
      " |~~ train@9728  Loss: 0.002674 Acc: 13.0000\n",
      " |~~ train@9792  Loss: 0.001957 Acc: 13.4062\n",
      " |~~ train@9856  Loss: 0.002734 Acc: 13.2344\n",
      " |~~ train@9920  Loss: 0.002537 Acc: 13.2188\n",
      " |~~ train@9984  Loss: 0.002033 Acc: 13.2969\n",
      " |~~ train@10048  Loss: 0.002158 Acc: 13.3750\n",
      " |~~ train@10112  Loss: 0.002324 Acc: 13.3125\n",
      " |~~ train@10176  Loss: 0.002144 Acc: 13.3750\n",
      " |~~ train@10240  Loss: 0.002170 Acc: 13.3438\n",
      " |~~ train@10304  Loss: 0.002088 Acc: 13.4062\n",
      " |~~ train@10368  Loss: 0.002734 Acc: 13.1719\n",
      " |~~ train@10432  Loss: 0.002558 Acc: 13.2969\n",
      " |~~ train@10496  Loss: 0.002429 Acc: 13.1562\n",
      " |~~ train@10560  Loss: 0.002538 Acc: 13.2031\n",
      " |~~ train@10624  Loss: 0.002454 Acc: 13.2500\n",
      " |~~ train@10688  Loss: 0.002427 Acc: 13.3281\n",
      " |~~ train@10752  Loss: 0.002056 Acc: 13.2656\n",
      " |~~ train@10816  Loss: 0.002148 Acc: 13.2969\n",
      " |~~ train@10880  Loss: 0.002457 Acc: 13.1875\n",
      " |~~ train@10944  Loss: 0.001888 Acc: 13.4844\n",
      " |~~ train@11008  Loss: 0.002285 Acc: 13.3750\n",
      " |~~ train@11072  Loss: 0.002278 Acc: 13.2656\n",
      " |~~ train@11136  Loss: 0.002497 Acc: 13.3125\n",
      " |~~ train@11200  Loss: 0.002178 Acc: 13.3594\n",
      " |~~ train@11264  Loss: 0.001933 Acc: 13.3906\n",
      " |~~ train@11328  Loss: 0.002207 Acc: 13.3438\n",
      " |~~ train@11392  Loss: 0.002035 Acc: 13.2969\n",
      " |~~ train@11456  Loss: 0.002035 Acc: 13.3594\n",
      " |~~ train@11520  Loss: 0.002347 Acc: 13.3281\n",
      " |~~ train@11584  Loss: 0.002325 Acc: 13.3750\n",
      " |~~ train@11648  Loss: 0.002402 Acc: 13.2812\n",
      " |~~ train@11712  Loss: 0.002165 Acc: 13.2969\n",
      " |~~ train@11776  Loss: 0.001830 Acc: 13.4219\n",
      " |~~ train@11840  Loss: 0.002329 Acc: 13.2188\n",
      " |~~ train@11904  Loss: 0.002400 Acc: 13.2344\n",
      " |~~ train@11968  Loss: 0.002083 Acc: 13.3281\n",
      " |~~ train@12032  Loss: 0.002605 Acc: 13.1094\n",
      " |~~ train@12096  Loss: 0.002957 Acc: 13.1250\n",
      " |~~ train@12160  Loss: 0.002019 Acc: 13.3594\n",
      " |~~ train@12224  Loss: 0.002524 Acc: 13.2656\n",
      " |~~ train@12288  Loss: 0.002328 Acc: 13.3438\n",
      " |~~ train@12352  Loss: 0.002924 Acc: 13.0625\n",
      " |~~ train@12416  Loss: 0.002200 Acc: 13.2656\n",
      " |~~ train@12480  Loss: 0.002292 Acc: 13.3281\n",
      " |~~ train@12544  Loss: 0.002838 Acc: 13.1406\n",
      " |~~ train@12608  Loss: 0.002066 Acc: 13.3750\n",
      " |~~ train@12672  Loss: 0.001611 Acc: 13.5938\n",
      " |~~ train@12736  Loss: 0.002206 Acc: 13.3125\n",
      " |~~ train@12800  Loss: 0.002388 Acc: 13.3125\n",
      " |~~ train@12864  Loss: 0.002691 Acc: 13.2344\n",
      " |~~ train@12928  Loss: 0.002756 Acc: 13.0938\n",
      " |~~ train@12992  Loss: 0.002434 Acc: 13.2344\n",
      " |~~ train@13056  Loss: 0.002507 Acc: 13.2188\n",
      " |~~ train@13120  Loss: 0.003010 Acc: 12.9375\n",
      " |~~ train@13184  Loss: 0.002385 Acc: 13.2969\n",
      " |~~ train@13248  Loss: 0.002410 Acc: 13.2344\n",
      " |~~ train@13312  Loss: 0.002620 Acc: 13.1875\n",
      " |~~ train@13376  Loss: 0.002217 Acc: 13.3125\n",
      " |~~ train@13440  Loss: 0.002324 Acc: 13.3594\n",
      " |~~ train@13504  Loss: 0.002182 Acc: 13.2969\n",
      " |~~ train@13568  Loss: 0.002750 Acc: 13.0469\n",
      " |~~ train@13632  Loss: 0.002251 Acc: 13.3281\n",
      " |~~ train@13696  Loss: 0.002507 Acc: 13.3125\n",
      " |~~ train@13760  Loss: 0.001921 Acc: 13.3906\n",
      " |~~ train@13824  Loss: 0.001973 Acc: 13.3750\n",
      " |~~ train@13888  Loss: 0.002314 Acc: 13.3750\n",
      " |~~ train@13952  Loss: 0.002609 Acc: 13.2344\n",
      " |~~ train@14016  Loss: 0.002639 Acc: 13.1719\n",
      " |~~ train@14080  Loss: 0.002268 Acc: 13.2031\n",
      " |~~ train@14144  Loss: 0.002727 Acc: 13.2188\n",
      " |~~ train@14208  Loss: 0.002190 Acc: 13.2812\n",
      " |~~ train@14272  Loss: 0.002442 Acc: 13.2500\n",
      " |~~ train@14336  Loss: 0.002746 Acc: 13.1406\n",
      " |~~ train@14400  Loss: 0.002282 Acc: 13.2812\n",
      " |~~ train@14464  Loss: 0.002107 Acc: 13.3594\n",
      " |~~ train@14528  Loss: 0.002045 Acc: 13.3906\n",
      " |~~ train@14592  Loss: 0.002395 Acc: 13.2500\n",
      " |~~ train@14656  Loss: 0.002294 Acc: 13.3125\n",
      " |~~ train@14720  Loss: 0.002083 Acc: 13.4375\n",
      " |~~ train@14784  Loss: 0.001964 Acc: 13.3906\n",
      " |~~ train@14848  Loss: 0.002238 Acc: 13.3281\n",
      " |~~ train@14912  Loss: 0.001966 Acc: 13.4062\n",
      " |~~ train@14976  Loss: 0.002556 Acc: 13.0781\n",
      " |~~ train@15040  Loss: 0.002388 Acc: 13.1875\n",
      " |~~ train@15104  Loss: 0.002335 Acc: 13.2969\n",
      " |~~ train@15168  Loss: 0.002135 Acc: 13.3594\n",
      " |~~ train@15232  Loss: 0.002223 Acc: 13.3125\n",
      " |~~ train@15296  Loss: 0.002522 Acc: 13.2500\n",
      " |~~ train@15360  Loss: 0.002352 Acc: 13.2969\n",
      " |~~ train@15424  Loss: 0.002497 Acc: 13.2656\n",
      " |~~ train@15488  Loss: 0.002609 Acc: 13.2500\n",
      " |~~ train@15552  Loss: 0.002225 Acc: 13.3594\n",
      " |~~ train@15616  Loss: 0.002120 Acc: 13.3125\n",
      " |~~ train@15680  Loss: 0.002233 Acc: 13.3594\n",
      " |~~ train@15744  Loss: 0.002003 Acc: 13.4219\n",
      " |~~ train@15808  Loss: 0.002158 Acc: 13.3438\n",
      " |~~ train@15872  Loss: 0.002345 Acc: 13.3750\n",
      " |~~ train@15936  Loss: 0.002334 Acc: 13.2969\n",
      " |~~ train@16000  Loss: 0.001990 Acc: 13.3906\n",
      " |~~ train@16064  Loss: 0.002244 Acc: 13.3438\n",
      " |~~ train@16128  Loss: 0.002117 Acc: 13.4375\n",
      " |~~ train@16192  Loss: 0.002053 Acc: 13.3594\n",
      " |~~ train@16256  Loss: 0.002261 Acc: 13.3281\n",
      " |~~ train@16320  Loss: 0.001748 Acc: 13.5312\n",
      " |~~ train@16384  Loss: 0.002255 Acc: 13.2969\n",
      " |~~ train@16448  Loss: 0.001986 Acc: 13.4375\n",
      " |~~ train@16512  Loss: 0.002980 Acc: 13.0469\n",
      " |~~ train@16576  Loss: 0.001800 Acc: 13.4531\n",
      " |~~ train@16640  Loss: 0.002200 Acc: 13.3906\n",
      " |~~ train@16704  Loss: 0.002828 Acc: 13.1562\n",
      " |~~ train@16768  Loss: 0.002512 Acc: 13.3281\n",
      " |~~ train@16832  Loss: 0.002450 Acc: 13.2969\n",
      " |~~ train@16896  Loss: 0.002335 Acc: 13.2344\n",
      " |~~ train@16960  Loss: 0.002585 Acc: 13.2031\n",
      " |~~ train@17024  Loss: 0.002599 Acc: 13.2188\n",
      " |~~ train@17088  Loss: 0.001859 Acc: 13.4062\n",
      " |~~ train@17152  Loss: 0.002296 Acc: 13.2969\n",
      " |~~ train@17216  Loss: 0.003081 Acc: 12.9844\n",
      " |~~ train@17280  Loss: 0.002720 Acc: 13.1406\n",
      " |~~ train@17344  Loss: 0.002031 Acc: 13.3594\n",
      " |~~ train@17408  Loss: 0.002082 Acc: 13.3750\n",
      " |~~ train@17472  Loss: 0.002258 Acc: 13.2969\n",
      " |~~ train@17536  Loss: 0.002302 Acc: 13.2812\n",
      " |~~ train@17600  Loss: 0.002604 Acc: 13.1875\n",
      " |~~ train@17664  Loss: 0.002671 Acc: 13.1406\n",
      " |~~ train@17728  Loss: 0.001981 Acc: 13.3750\n",
      " |~~ train@17792  Loss: 0.002053 Acc: 13.3281\n",
      " |~~ train@17856  Loss: 0.001958 Acc: 13.4844\n",
      " |~~ train@17920  Loss: 0.002507 Acc: 13.1875\n",
      " |~~ train@17984  Loss: 0.002188 Acc: 13.4375\n",
      " |~~ train@18048  Loss: 0.002141 Acc: 13.2969\n",
      " |~~ train@18112  Loss: 0.002252 Acc: 13.4531\n",
      " |~~ train@18176  Loss: 0.002960 Acc: 13.0000\n",
      " |~~ train@18240  Loss: 0.002531 Acc: 13.2812\n",
      " |~~ train@18304  Loss: 0.002831 Acc: 13.1719\n",
      " |~~ train@18368  Loss: 0.001874 Acc: 13.4062\n",
      " |~~ train@18432  Loss: 0.002369 Acc: 13.3438\n",
      " |~~ train@18496  Loss: 0.002066 Acc: 13.4219\n",
      " |~~ train@18560  Loss: 0.002673 Acc: 13.1562\n",
      " |~~ train@18624  Loss: 0.002458 Acc: 13.3125\n",
      " |~~ train@18688  Loss: 0.002093 Acc: 13.3281\n",
      " |~~ train@18752  Loss: 0.002064 Acc: 13.4688\n",
      " |~~ train@18816  Loss: 0.002214 Acc: 13.3281\n",
      " |~~ train@18880  Loss: 0.002427 Acc: 13.2969\n",
      " |~~ train@18944  Loss: 0.001920 Acc: 13.4688\n",
      " |~~ train@19008  Loss: 0.002641 Acc: 13.2500\n",
      " |~~ train@19072  Loss: 0.001978 Acc: 13.4219\n",
      " |~~ train@19136  Loss: 0.003087 Acc: 13.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@19200  Loss: 0.002274 Acc: 13.3281\n",
      " |~~ train@19264  Loss: 0.002217 Acc: 13.2656\n",
      " |~~ train@19328  Loss: 0.002083 Acc: 13.3750\n",
      " |~~ train@19392  Loss: 0.002279 Acc: 13.3438\n",
      " |~~ train@19456  Loss: 0.002630 Acc: 13.1250\n",
      " |~~ train@19520  Loss: 0.001950 Acc: 13.3750\n",
      " |~~ train@19584  Loss: 0.002293 Acc: 13.3438\n",
      " |~~ train@19648  Loss: 0.002390 Acc: 13.2500\n",
      " |~~ train@19712  Loss: 0.001953 Acc: 13.4531\n",
      " |~~ train@19776  Loss: 0.001950 Acc: 13.4219\n",
      " |~~ train@19840  Loss: 0.002404 Acc: 13.3594\n",
      " |~~ train@19904  Loss: 0.001440 Acc: 13.6094\n",
      " |~~ train@19968  Loss: 0.002315 Acc: 13.2812\n",
      " |~~ train@20032  Loss: 0.002693 Acc: 13.1875\n",
      " |~~ train@20096  Loss: 0.002863 Acc: 13.1094\n",
      " |~~ train@20160  Loss: 0.002257 Acc: 13.3125\n",
      " |~~ train@20224  Loss: 0.002457 Acc: 13.2812\n",
      " |~~ train@20288  Loss: 0.002267 Acc: 13.2969\n",
      " |~~ train@20352  Loss: 0.002098 Acc: 13.4375\n",
      " |~~ train@20416  Loss: 0.002340 Acc: 13.1719\n",
      " |~~ train@20480  Loss: 0.002286 Acc: 13.2812\n",
      " |~~ train@20544  Loss: 0.002626 Acc: 13.2188\n",
      " |~~ train@20608  Loss: 0.002645 Acc: 13.1562\n",
      " |~~ train@20672  Loss: 0.002125 Acc: 13.3906\n",
      " |~~ train@20736  Loss: 0.001989 Acc: 13.4219\n",
      " |~~ train@20800  Loss: 0.002512 Acc: 13.1719\n",
      " |~~ train@20864  Loss: 0.002219 Acc: 13.2969\n",
      " |~~ train@20928  Loss: 0.002893 Acc: 13.0781\n",
      " |~~ train@20992  Loss: 0.002111 Acc: 13.4062\n",
      " |~~ train@21056  Loss: 0.001923 Acc: 13.4531\n",
      " |~~ train@21120  Loss: 0.002397 Acc: 13.2500\n",
      " |~~ train@21184  Loss: 0.002314 Acc: 13.3281\n",
      " |~~ train@21248  Loss: 0.002196 Acc: 13.2969\n",
      " |~~ train@21312  Loss: 0.002567 Acc: 13.1875\n",
      " |~~ train@21376  Loss: 0.002048 Acc: 13.3281\n",
      " |~~ train@21440  Loss: 0.002403 Acc: 13.2188\n",
      " |~~ train@21504  Loss: 0.002570 Acc: 13.1719\n",
      " |~~ train@21568  Loss: 0.002404 Acc: 13.2656\n",
      " |~~ train@21632  Loss: 0.002922 Acc: 13.0625\n",
      " |~~ train@21696  Loss: 0.002169 Acc: 13.2812\n",
      " |~~ train@21760  Loss: 0.002598 Acc: 13.1875\n",
      " |~~ train@21824  Loss: 0.002769 Acc: 13.0625\n",
      " |~~ train@21888  Loss: 0.003048 Acc: 13.0938\n",
      " |~~ train@21952  Loss: 0.002575 Acc: 13.2031\n",
      " |~~ train@22016  Loss: 0.002205 Acc: 13.3125\n",
      " |~~ train@22080  Loss: 0.002192 Acc: 13.3594\n",
      " |~~ train@22144  Loss: 0.002220 Acc: 13.3594\n",
      " |~~ train@22208  Loss: 0.002668 Acc: 13.1406\n",
      " |~~ train@22272  Loss: 0.002389 Acc: 13.2500\n",
      " |~~ train@22336  Loss: 0.002498 Acc: 13.2031\n",
      " |~~ train@22400  Loss: 0.002228 Acc: 13.4688\n",
      " |~~ train@22464  Loss: 0.001925 Acc: 13.4062\n",
      " |~~ train@22528  Loss: 0.002427 Acc: 13.2500\n",
      " |~~ train@22592  Loss: 0.002438 Acc: 13.2812\n",
      " |~~ train@22656  Loss: 0.002636 Acc: 13.2188\n",
      " |~~ train@22720  Loss: 0.002448 Acc: 13.2031\n",
      " |~~ train@22784  Loss: 0.001968 Acc: 13.4062\n",
      " |~~ train@22848  Loss: 0.002385 Acc: 13.2812\n",
      " |~~ train@22912  Loss: 0.002887 Acc: 13.0625\n",
      " |~~ train@22976  Loss: 0.002020 Acc: 13.4219\n",
      " |~~ train@23040  Loss: 0.002148 Acc: 13.3438\n",
      " |~~ train@23104  Loss: 0.002868 Acc: 13.0938\n",
      " |~~ train@23168  Loss: 0.002178 Acc: 13.3750\n",
      " |~~ train@23232  Loss: 0.002285 Acc: 13.2656\n",
      " |~~ train@23296  Loss: 0.001985 Acc: 13.3281\n",
      " |~~ train@23360  Loss: 0.001856 Acc: 13.3906\n",
      " |~~ train@23424  Loss: 0.002509 Acc: 13.2500\n",
      " |~~ train@23488  Loss: 0.002804 Acc: 13.1562\n",
      " |~~ train@23552  Loss: 0.002157 Acc: 13.3594\n",
      " |~~ train@23616  Loss: 0.002956 Acc: 13.1562\n",
      " |~~ train@23680  Loss: 0.002260 Acc: 13.2656\n",
      " |~~ train@23744  Loss: 0.002362 Acc: 13.3594\n",
      " |~~ train@23808  Loss: 0.002148 Acc: 13.3750\n",
      " |~~ train@23872  Loss: 0.002073 Acc: 13.3594\n",
      " |~~ train@23936  Loss: 0.002325 Acc: 13.2969\n",
      " |~~ train@24000  Loss: 0.002241 Acc: 13.3125\n",
      " |~~ train@24064  Loss: 0.002364 Acc: 13.2500\n",
      " |~~ train@24128  Loss: 0.002319 Acc: 13.3906\n",
      " |~~ train@24192  Loss: 0.002268 Acc: 13.2500\n",
      " |~~ train@24256  Loss: 0.001999 Acc: 13.3594\n",
      " |~~ train@24320  Loss: 0.002115 Acc: 13.3594\n",
      " |~~ train@24384  Loss: 0.001766 Acc: 13.4844\n",
      " |~~ train@24448  Loss: 0.002289 Acc: 13.3750\n",
      " |~~ train@24512  Loss: 0.002181 Acc: 13.3594\n",
      " |~~ train@24576  Loss: 0.001831 Acc: 13.4219\n",
      " |~~ train@24640  Loss: 0.002375 Acc: 13.3281\n",
      " |~~ train@24704  Loss: 0.002463 Acc: 13.1719\n",
      " |~~ train@24768  Loss: 0.002269 Acc: 13.3438\n",
      " |~~ train@24832  Loss: 0.001969 Acc: 13.5000\n",
      " |~~ train@24896  Loss: 0.002026 Acc: 13.4688\n",
      " |~~ train@24960  Loss: 0.002961 Acc: 13.0312\n",
      " |~~ train@25024  Loss: 0.002126 Acc: 13.3906\n",
      " |~~ train@25088  Loss: 0.002622 Acc: 13.2344\n",
      " |~~ train@25152  Loss: 0.001602 Acc: 13.5156\n",
      " |~~ train@25216  Loss: 0.002380 Acc: 13.2656\n",
      " |~~ train@25280  Loss: 0.002202 Acc: 13.4688\n",
      " |~~ train@25344  Loss: 0.001875 Acc: 13.4531\n",
      " |~~ train@25408  Loss: 0.002220 Acc: 13.2344\n",
      " |~~ train@25472  Loss: 0.002286 Acc: 13.3438\n",
      " |~~ train@25536  Loss: 0.002709 Acc: 13.1562\n",
      " |~~ train@25600  Loss: 0.002960 Acc: 13.0156\n",
      " |~~ train@25664  Loss: 0.002577 Acc: 13.2656\n",
      " |~~ train@25728  Loss: 0.002375 Acc: 13.2969\n",
      " |~~ train@25792  Loss: 0.001810 Acc: 13.4844\n",
      " |~~ train@25856  Loss: 0.001998 Acc: 13.4219\n",
      " |~~ train@25920  Loss: 0.002399 Acc: 13.3594\n",
      " |~~ train@25984  Loss: 0.002672 Acc: 13.1875\n",
      " |~~ train@26048  Loss: 0.002348 Acc: 13.3281\n",
      " |~~ train@26112  Loss: 0.001868 Acc: 13.4531\n",
      " |~~ train@26176  Loss: 0.002429 Acc: 13.2500\n",
      " |~~ train@26240  Loss: 0.002909 Acc: 13.1250\n",
      " |~~ train@26304  Loss: 0.002684 Acc: 13.0938\n",
      " |~~ train@26368  Loss: 0.002299 Acc: 13.3750\n",
      " |~~ train@26432  Loss: 0.002654 Acc: 13.1406\n",
      " |~~ train@26496  Loss: 0.002251 Acc: 13.3594\n",
      " |~~ train@26560  Loss: 0.002077 Acc: 13.3281\n",
      " |~~ train@26624  Loss: 0.001899 Acc: 13.5156\n",
      " |~~ train@26688  Loss: 0.002475 Acc: 13.3125\n",
      " |~~ train@26752  Loss: 0.001844 Acc: 13.5156\n",
      " |~~ train@26816  Loss: 0.002763 Acc: 13.1562\n",
      " |~~ train@26880  Loss: 0.002385 Acc: 13.2344\n",
      " |~~ train@26944  Loss: 0.002035 Acc: 13.4375\n",
      " |~~ train@27008  Loss: 0.002088 Acc: 13.3906\n",
      " |~~ train@27072  Loss: 0.002273 Acc: 13.3281\n",
      " |~~ train@27136  Loss: 0.002773 Acc: 13.1250\n",
      " |~~ train@27200  Loss: 0.002198 Acc: 13.3750\n",
      " |~~ train@27264  Loss: 0.001898 Acc: 13.4531\n",
      " |~~ train@27328  Loss: 0.002257 Acc: 13.3594\n",
      " |~~ train@27392  Loss: 0.001991 Acc: 13.4062\n",
      " |~~ train@27456  Loss: 0.002246 Acc: 13.3594\n",
      " |~~ train@27520  Loss: 0.002603 Acc: 13.2500\n",
      " |~~ train@27584  Loss: 0.002443 Acc: 13.3281\n",
      " |~~ train@27648  Loss: 0.002132 Acc: 13.3281\n",
      " |~~ train@27712  Loss: 0.002431 Acc: 13.2031\n",
      " |~~ train@27776  Loss: 0.002780 Acc: 13.0938\n",
      " |~~ train@27840  Loss: 0.002533 Acc: 13.2344\n",
      " |~~ train@27904  Loss: 0.002469 Acc: 13.2031\n",
      " |~~ train@27968  Loss: 0.002141 Acc: 13.3281\n",
      " |~~ train@28032  Loss: 0.002367 Acc: 13.2188\n",
      " |~~ train@28096  Loss: 0.002841 Acc: 13.0469\n",
      " |~~ train@28160  Loss: 0.002423 Acc: 13.3125\n",
      " |~~ train@28224  Loss: 0.002195 Acc: 13.2812\n",
      " |~~ train@28288  Loss: 0.002082 Acc: 13.3906\n",
      " |~~ train@28352  Loss: 0.002393 Acc: 13.2812\n",
      " |~~ train@28416  Loss: 0.001961 Acc: 13.3750\n",
      " |~~ train@28480  Loss: 0.002529 Acc: 13.1406\n",
      " |~~ train@28544  Loss: 0.002414 Acc: 13.2812\n",
      " |~~ train@28608  Loss: 0.002062 Acc: 13.4062\n",
      " |~~ train@28672  Loss: 0.002412 Acc: 13.1875\n",
      " |~~ train@28736  Loss: 0.002331 Acc: 13.3281\n",
      " |~~ train@28800  Loss: 0.002043 Acc: 13.4531\n",
      " |~~ train@28864  Loss: 0.002542 Acc: 13.1250\n",
      " |~~ train@28928  Loss: 0.001636 Acc: 13.5469\n",
      " |~~ train@28992  Loss: 0.002359 Acc: 13.2969\n",
      " |~~ train@29056  Loss: 0.002407 Acc: 13.3281\n",
      " |~~ train@29120  Loss: 0.002278 Acc: 13.1719\n",
      " |~~ train@29184  Loss: 0.002323 Acc: 13.2969\n",
      " |~~ train@29248  Loss: 0.002001 Acc: 13.2969\n",
      " |~~ train@29312  Loss: 0.002401 Acc: 13.3125\n",
      " |~~ train@29376  Loss: 0.001652 Acc: 13.5312\n",
      " |~~ train@29440  Loss: 0.001831 Acc: 13.3750\n",
      " |~~ train@29504  Loss: 0.002344 Acc: 13.2812\n",
      " |~~ train@29568  Loss: 0.002134 Acc: 13.3594\n",
      " |~~ train@29632  Loss: 0.002317 Acc: 13.3281\n",
      " |~~ train@29696  Loss: 0.002474 Acc: 13.3125\n",
      " |~~ train@29760  Loss: 0.002754 Acc: 13.1719\n",
      " |~~ train@29824  Loss: 0.002327 Acc: 13.2812\n",
      " |~~ train@29888  Loss: 0.003293 Acc: 13.0156\n",
      " |~~ train@29952  Loss: 0.002875 Acc: 13.1875\n",
      " |~~ train@30016  Loss: 0.002345 Acc: 13.3125\n",
      " |~~ train@30080  Loss: 0.002140 Acc: 13.3750\n",
      " |~~ train@30144  Loss: 0.002601 Acc: 13.2188\n",
      " |~~ train@30208  Loss: 0.002685 Acc: 13.1406\n",
      " |~~ train@30272  Loss: 0.002220 Acc: 13.4219\n",
      " |~~ train@30336  Loss: 0.002296 Acc: 13.3281\n",
      " |~~ train@30400  Loss: 0.002601 Acc: 13.2656\n",
      " |~~ train@30464  Loss: 0.002159 Acc: 13.2656\n",
      " |~~ train@30528  Loss: 0.001867 Acc: 13.4219\n",
      " |~~ train@30592  Loss: 0.002434 Acc: 13.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@30656  Loss: 0.002374 Acc: 13.3594\n",
      " |~~ train@30720  Loss: 0.002638 Acc: 13.2188\n",
      " |~~ train@30784  Loss: 0.002157 Acc: 13.3281\n",
      " |~~ train@30848  Loss: 0.001996 Acc: 13.3750\n",
      " |~~ train@30912  Loss: 0.002502 Acc: 13.2188\n",
      " |~~ train@30976  Loss: 0.002315 Acc: 13.2031\n",
      " |~~ train@31040  Loss: 0.002111 Acc: 13.3125\n",
      " |~~ train@31104  Loss: 0.002703 Acc: 13.1250\n",
      " |~~ train@31168  Loss: 0.002487 Acc: 13.3125\n",
      " |~~ train@31232  Loss: 0.002404 Acc: 13.2500\n",
      " |~~ train@31296  Loss: 0.002331 Acc: 13.2344\n",
      " |~~ train@31360  Loss: 0.002204 Acc: 13.4219\n",
      " |~~ train@31424  Loss: 0.002236 Acc: 13.2031\n",
      " |~~ train@31488  Loss: 0.002568 Acc: 13.2344\n",
      " |~~ train@31552  Loss: 0.002210 Acc: 13.3594\n",
      " |~~ train@31616  Loss: 0.002193 Acc: 13.3906\n",
      " |~~ train@31680  Loss: 0.002405 Acc: 13.2188\n",
      " |~~ train@31744  Loss: 0.002467 Acc: 13.2812\n",
      " |~~ train@31808  Loss: 0.002020 Acc: 13.3438\n",
      " |~~ train@31872  Loss: 0.002499 Acc: 13.2031\n",
      " |~~ train@31936  Loss: 0.002098 Acc: 13.3906\n",
      " |~~ train@32000  Loss: 0.002288 Acc: 13.3750\n",
      " |~~ train@32064  Loss: 0.002477 Acc: 13.2344\n",
      " |~~ train@32128  Loss: 0.002213 Acc: 13.3906\n",
      " |~~ train@32192  Loss: 0.002623 Acc: 13.2969\n",
      " |~~ train@32256  Loss: 0.002069 Acc: 13.4062\n",
      " |~~ train@32320  Loss: 0.002467 Acc: 13.2656\n",
      " |~~ train@32384  Loss: 0.002497 Acc: 13.3125\n",
      " |~~ train@32448  Loss: 0.002234 Acc: 13.4062\n",
      " |~~ train@32512  Loss: 0.002946 Acc: 13.0781\n",
      " |~~ train@32576  Loss: 0.002264 Acc: 13.2344\n",
      " |~~ train@32640  Loss: 0.002616 Acc: 13.1094\n",
      " |~~ train@32704  Loss: 0.002246 Acc: 13.3438\n",
      " |~~ train@32768  Loss: 0.001952 Acc: 13.3125\n",
      " |~~ train@32832  Loss: 0.002082 Acc: 13.4375\n",
      " |~~ train@32896  Loss: 0.002235 Acc: 13.3281\n",
      " |~~ train@32960  Loss: 0.002844 Acc: 13.2188\n",
      " |~~ train@33024  Loss: 0.002362 Acc: 13.2031\n",
      " |~~ train@33088  Loss: 0.002636 Acc: 13.2188\n",
      " |~~ train@33152  Loss: 0.002755 Acc: 13.2188\n",
      " |~~ train@33216  Loss: 0.002490 Acc: 13.2188\n",
      " |~~ train@33280  Loss: 0.002001 Acc: 13.4688\n",
      " |~~ train@33344  Loss: 0.002888 Acc: 13.2031\n",
      " |~~ train@33408  Loss: 0.002707 Acc: 13.1562\n",
      " |~~ train@33472  Loss: 0.002337 Acc: 13.4062\n",
      " |~~ train@33536  Loss: 0.001712 Acc: 13.4844\n",
      " |~~ train@33600  Loss: 0.002277 Acc: 13.3750\n",
      " |~~ train@33664  Loss: 0.002371 Acc: 13.3438\n",
      " |~~ train@33728  Loss: 0.001885 Acc: 13.4062\n",
      " |~~ train@33792  Loss: 0.002922 Acc: 13.1406\n",
      " |~~ train@33856  Loss: 0.002087 Acc: 13.3438\n",
      " |~~ train@33920  Loss: 0.003555 Acc: 12.9219\n",
      " |~~ train@33984  Loss: 0.002263 Acc: 13.3438\n",
      " |~~ train@34048  Loss: 0.001947 Acc: 13.4062\n",
      " |~~ train@34112  Loss: 0.002188 Acc: 13.2656\n",
      " |~~ train@34176  Loss: 0.001930 Acc: 13.4062\n",
      " |~~ train@34240  Loss: 0.002315 Acc: 13.3281\n",
      " |~~ train@34304  Loss: 0.002189 Acc: 13.4219\n",
      " |~~ train@34368  Loss: 0.002071 Acc: 13.3906\n",
      " |~~ train@34432  Loss: 0.002217 Acc: 13.3594\n",
      " |~~ train@34496  Loss: 0.002560 Acc: 13.2031\n",
      " |~~ train@34560  Loss: 0.002180 Acc: 13.2031\n",
      " |~~ train@34624  Loss: 0.002871 Acc: 13.0469\n",
      " |~~ train@34688  Loss: 0.001899 Acc: 13.4062\n",
      " |~~ train@34752  Loss: 0.002548 Acc: 13.2188\n",
      " |~~ train@34816  Loss: 0.002499 Acc: 13.2344\n",
      " |~~ train@34880  Loss: 0.002481 Acc: 13.1250\n",
      " |~~ train@34944  Loss: 0.002582 Acc: 13.2344\n",
      " |~~ train@35008  Loss: 0.002028 Acc: 13.3906\n",
      " |~~ train@35072  Loss: 0.001737 Acc: 13.5625\n",
      " |~~ train@35136  Loss: 0.002498 Acc: 13.2344\n",
      " |~~ train@35200  Loss: 0.002389 Acc: 13.2344\n",
      " |~~ train@35264  Loss: 0.002486 Acc: 13.1875\n",
      " |~~ train@35328  Loss: 0.002281 Acc: 13.2188\n",
      " |~~ train@35392  Loss: 0.002698 Acc: 13.1094\n",
      " |~~ train@35456  Loss: 0.002501 Acc: 13.2656\n",
      " |~~ train@35520  Loss: 0.001552 Acc: 13.5938\n",
      " |~~ train@35584  Loss: 0.002422 Acc: 13.2969\n",
      " |~~ train@35648  Loss: 0.002199 Acc: 13.4375\n",
      " |~~ train@35712  Loss: 0.002267 Acc: 13.2500\n",
      " |~~ train@35776  Loss: 0.002319 Acc: 13.2969\n",
      " |~~ train@35840  Loss: 0.001968 Acc: 13.4531\n",
      " |~~ train@35904  Loss: 0.002172 Acc: 13.1875\n",
      " |~~ train@35968  Loss: 0.002143 Acc: 13.3906\n",
      " |~~ train@36032  Loss: 0.002564 Acc: 13.1094\n",
      " |~~ train@36096  Loss: 0.002391 Acc: 13.2500\n",
      " |~~ train@36160  Loss: 0.002427 Acc: 13.2031\n",
      " |~~ train@36224  Loss: 0.002307 Acc: 13.3281\n",
      " |~~ train@36288  Loss: 0.001774 Acc: 13.4219\n",
      " |~~ train@36352  Loss: 0.002256 Acc: 13.2656\n",
      " |~~ train@36416  Loss: 0.002507 Acc: 13.2188\n",
      " |~~ train@36480  Loss: 0.002565 Acc: 13.1406\n",
      " |~~ train@36544  Loss: 0.002020 Acc: 13.4219\n",
      " |~~ train@36608  Loss: 0.002010 Acc: 13.4375\n",
      " |~~ train@36672  Loss: 0.002107 Acc: 13.3750\n",
      " |~~ train@36736  Loss: 0.002088 Acc: 13.4375\n",
      " |~~ train@36800  Loss: 0.001514 Acc: 13.5781\n",
      " |~~ train@36864  Loss: 0.002258 Acc: 13.3594\n",
      " |~~ train@36928  Loss: 0.002057 Acc: 13.3906\n",
      " |~~ train@36992  Loss: 0.002013 Acc: 13.3594\n",
      " |~~ train@37056  Loss: 0.002230 Acc: 13.3906\n",
      " |~~ train@37120  Loss: 0.002109 Acc: 13.3125\n",
      " |~~ train@37184  Loss: 0.002363 Acc: 13.2969\n",
      " |~~ train@37248  Loss: 0.002799 Acc: 13.1406\n",
      " |~~ train@37312  Loss: 0.002370 Acc: 13.2969\n",
      " |~~ train@37376  Loss: 0.001911 Acc: 13.4219\n",
      " |~~ train@37440  Loss: 0.002089 Acc: 13.4062\n",
      " |~~ train@37504  Loss: 0.002293 Acc: 13.3125\n",
      " |~~ train@37568  Loss: 0.001940 Acc: 13.4844\n",
      " |~~ train@37632  Loss: 0.002117 Acc: 13.3438\n",
      " |~~ train@37696  Loss: 0.002173 Acc: 13.4844\n",
      " |~~ train@37760  Loss: 0.001731 Acc: 13.4688\n",
      " |~~ train@37824  Loss: 0.002506 Acc: 13.2969\n",
      " |~~ train@37888  Loss: 0.002682 Acc: 13.1719\n",
      " |~~ train@37952  Loss: 0.002271 Acc: 13.3750\n",
      " |~~ train@38016  Loss: 0.002217 Acc: 13.4062\n",
      " |~~ train@38080  Loss: 0.002635 Acc: 13.1406\n",
      " |~~ train@38144  Loss: 0.002454 Acc: 13.3125\n",
      " |~~ train@38208  Loss: 0.002589 Acc: 13.2344\n",
      " |~~ train@38272  Loss: 0.002251 Acc: 13.3438\n",
      " |~~ train@38336  Loss: 0.002109 Acc: 13.4062\n",
      " |~~ train@38400  Loss: 0.001791 Acc: 13.5156\n",
      " |~~ train@38464  Loss: 0.002202 Acc: 13.2969\n",
      " |~~ train@38528  Loss: 0.002044 Acc: 13.3125\n",
      " |~~ train@38592  Loss: 0.002079 Acc: 13.2969\n",
      " |~~ train@38656  Loss: 0.002448 Acc: 13.2344\n",
      " |~~ train@38720  Loss: 0.002517 Acc: 13.1406\n",
      " |~~ train@38784  Loss: 0.002256 Acc: 13.2344\n",
      " |~~ train@38848  Loss: 0.002428 Acc: 13.3125\n",
      " |~~ train@38912  Loss: 0.002161 Acc: 13.2812\n",
      " |~~ train@38976  Loss: 0.002420 Acc: 13.2500\n",
      " |~~ train@39040  Loss: 0.002872 Acc: 13.0938\n",
      " |~~ train@39104  Loss: 0.002508 Acc: 13.2031\n",
      " |~~ train@39168  Loss: 0.002008 Acc: 13.4219\n",
      " |~~ train@39232  Loss: 0.002913 Acc: 13.0625\n",
      " |~~ train@39296  Loss: 0.002334 Acc: 13.2500\n",
      " |~~ train@39360  Loss: 0.002311 Acc: 13.2500\n",
      " |~~ train@39424  Loss: 0.002665 Acc: 13.1875\n",
      " |~~ train@39488  Loss: 0.002580 Acc: 13.1094\n",
      " |~~ train@39552  Loss: 0.002316 Acc: 13.2812\n",
      " |~~ train@39616  Loss: 0.002316 Acc: 13.2031\n",
      " |~~ train@39680  Loss: 0.002320 Acc: 13.3281\n",
      " |~~ train@39744  Loss: 0.002362 Acc: 13.2500\n",
      " |~~ train@39808  Loss: 0.002328 Acc: 13.2656\n",
      " |~~ train@39872  Loss: 0.002437 Acc: 13.2969\n",
      " |~~ train@39936  Loss: 0.002316 Acc: 13.2812\n",
      " |~~ train@40000  Loss: 0.002203 Acc: 13.2500\n",
      " |~~ train@40064  Loss: 0.002365 Acc: 13.3125\n",
      " |~~ train@40128  Loss: 0.002218 Acc: 13.3594\n",
      " |~~ train@40192  Loss: 0.002475 Acc: 13.1875\n",
      " |~~ train@40256  Loss: 0.002062 Acc: 13.3125\n",
      " |~~ train@40320  Loss: 0.002491 Acc: 13.2188\n",
      " |~~ train@40384  Loss: 0.002239 Acc: 13.2656\n",
      " |~~ train@40448  Loss: 0.002210 Acc: 13.3125\n",
      " |~~ train@40512  Loss: 0.002431 Acc: 13.1875\n",
      " |~~ train@40576  Loss: 0.002100 Acc: 13.2812\n",
      " |~~ train@40640  Loss: 0.002252 Acc: 13.3594\n",
      " |~~ train@40704  Loss: 0.002264 Acc: 13.3438\n",
      " |~~ train@40768  Loss: 0.002238 Acc: 13.2500\n",
      " |~~ train@40832  Loss: 0.002122 Acc: 13.4531\n",
      " |~~ train@40896  Loss: 0.002109 Acc: 13.2969\n",
      " |~~ train@40960  Loss: 0.002297 Acc: 13.3125\n",
      " |~~ train@41024  Loss: 0.002308 Acc: 13.3281\n",
      " |~~ train@41088  Loss: 0.002179 Acc: 13.2969\n",
      " |~~ train@41152  Loss: 0.002645 Acc: 13.2656\n",
      " |~~ train@41216  Loss: 0.002188 Acc: 13.2188\n",
      " |~~ train@41280  Loss: 0.002369 Acc: 13.2656\n",
      " |~~ train@41344  Loss: 0.003436 Acc: 12.9062\n",
      " |~~ train@41408  Loss: 0.002378 Acc: 13.2656\n",
      " |~~ train@41472  Loss: 0.001958 Acc: 13.4375\n",
      " |~~ train@41536  Loss: 0.001680 Acc: 13.5312\n",
      " |~~ train@41600  Loss: 0.002890 Acc: 13.2031\n",
      " |~~ train@41664  Loss: 0.002050 Acc: 13.2969\n",
      " |~~ train@41728  Loss: 0.002652 Acc: 13.1562\n",
      " |~~ train@41792  Loss: 0.002178 Acc: 13.3125\n",
      " |~~ train@41856  Loss: 0.002131 Acc: 13.3906\n",
      " |~~ train@41920  Loss: 0.003082 Acc: 12.9688\n",
      " |~~ train@41984  Loss: 0.002264 Acc: 13.2812\n",
      " |~~ train@42048  Loss: 0.001966 Acc: 13.3594\n",
      " |~~ train@42112  Loss: 0.002740 Acc: 13.1406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@42176  Loss: 0.002186 Acc: 13.3438\n",
      " |~~ train@42240  Loss: 0.002436 Acc: 13.2656\n",
      " |~~ train@42304  Loss: 0.002341 Acc: 13.2812\n",
      " |~~ train@42368  Loss: 0.002401 Acc: 13.3281\n",
      " |~~ train@42432  Loss: 0.002318 Acc: 13.3906\n",
      " |~~ train@42496  Loss: 0.002012 Acc: 13.2500\n",
      " |~~ train@42560  Loss: 0.002798 Acc: 13.1250\n",
      " |~~ train@42624  Loss: 0.002599 Acc: 13.2188\n",
      " |~~ train@42688  Loss: 0.002458 Acc: 13.1562\n",
      " |~~ train@42752  Loss: 0.002075 Acc: 13.3281\n",
      " |~~ train@42816  Loss: 0.001941 Acc: 13.3906\n",
      " |~~ train@42880  Loss: 0.002193 Acc: 13.3906\n",
      " |~~ train@42944  Loss: 0.002282 Acc: 13.2969\n",
      " |~~ train@43008  Loss: 0.002461 Acc: 13.2031\n",
      " |~~ train@43072  Loss: 0.002172 Acc: 13.3281\n",
      " |~~ train@43136  Loss: 0.002319 Acc: 13.3125\n",
      " |~~ train@43200  Loss: 0.002185 Acc: 13.3750\n",
      " |~~ train@43264  Loss: 0.001966 Acc: 13.3906\n",
      " |~~ train@43328  Loss: 0.002281 Acc: 13.2188\n",
      " |~~ train@43392  Loss: 0.003172 Acc: 13.0625\n",
      " |~~ train@43456  Loss: 0.002692 Acc: 13.1406\n",
      " |~~ train@43520  Loss: 0.001985 Acc: 13.3906\n",
      " |~~ train@43584  Loss: 0.002366 Acc: 13.2656\n",
      " |~~ train@43648  Loss: 0.002255 Acc: 13.2812\n",
      " |~~ train@43712  Loss: 0.002725 Acc: 13.1562\n",
      " |~~ train@43776  Loss: 0.002322 Acc: 13.3281\n",
      " |~~ train@43840  Loss: 0.002217 Acc: 13.3750\n",
      " |~~ train@43904  Loss: 0.002118 Acc: 13.4531\n",
      " |~~ train@43968  Loss: 0.002290 Acc: 13.2812\n",
      " |~~ train@44032  Loss: 0.001958 Acc: 13.4219\n",
      " |~~ train@44096  Loss: 0.002070 Acc: 13.3906\n",
      " |~~ train@44160  Loss: 0.002031 Acc: 13.3594\n",
      " |~~ train@44224  Loss: 0.002793 Acc: 13.1406\n",
      " |~~ train@44288  Loss: 0.001880 Acc: 13.4375\n",
      " |~~ train@44352  Loss: 0.002206 Acc: 13.3125\n",
      " |~~ train@44416  Loss: 0.002394 Acc: 13.3125\n",
      " |~~ train@44480  Loss: 0.002182 Acc: 13.3125\n",
      " |~~ train@44544  Loss: 0.002361 Acc: 13.3281\n",
      " |~~ train@44608  Loss: 0.002147 Acc: 13.4375\n",
      " |~~ train@44672  Loss: 0.002337 Acc: 13.3438\n",
      " |~~ train@44736  Loss: 0.003093 Acc: 13.0781\n",
      " |~~ train@44800  Loss: 0.002112 Acc: 13.2969\n",
      " |~~ train@44864  Loss: 0.002203 Acc: 13.2656\n",
      " |~~ train@44928  Loss: 0.002518 Acc: 13.3125\n",
      " |~~ train@44992  Loss: 0.001572 Acc: 13.5469\n",
      " |~~ train@45056  Loss: 0.003052 Acc: 13.0625\n",
      " |~~ train@45120  Loss: 0.002089 Acc: 13.3281\n",
      " |~~ train@45184  Loss: 0.002262 Acc: 13.2656\n",
      " |~~ train@45248  Loss: 0.002432 Acc: 13.2969\n",
      " |~~ train@45312  Loss: 0.001998 Acc: 13.3594\n",
      " |~~ train@45376  Loss: 0.002347 Acc: 13.3594\n",
      " |~~ train@45440  Loss: 0.002476 Acc: 13.2188\n",
      " |~~ train@45504  Loss: 0.002208 Acc: 13.3750\n",
      " |~~ train@45568  Loss: 0.001913 Acc: 13.4375\n",
      " |~~ train@45632  Loss: 0.002461 Acc: 13.2031\n",
      " |~~ train@45696  Loss: 0.002185 Acc: 13.3438\n",
      " |~~ train@45760  Loss: 0.002713 Acc: 13.1250\n",
      " |~~ train@45824  Loss: 0.002366 Acc: 13.2031\n",
      " |~~ train@45888  Loss: 0.002882 Acc: 13.0781\n",
      " |~~ train@45952  Loss: 0.002350 Acc: 13.1250\n",
      " |~~ train@46016  Loss: 0.002127 Acc: 13.3906\n",
      " |~~ train@46080  Loss: 0.002614 Acc: 13.2500\n",
      " |~~ train@46144  Loss: 0.002700 Acc: 13.1094\n",
      " |~~ train@46208  Loss: 0.002402 Acc: 13.3125\n",
      " |~~ train@46272  Loss: 0.002490 Acc: 13.2188\n",
      " |~~ train@46336  Loss: 0.002226 Acc: 13.3125\n",
      " |~~ train@46400  Loss: 0.002365 Acc: 13.3125\n",
      " |~~ train@46464  Loss: 0.002232 Acc: 13.3750\n",
      " |~~ train@46528  Loss: 0.002980 Acc: 13.0156\n",
      " |~~ train@46592  Loss: 0.002683 Acc: 13.2812\n",
      " |~~ train@46656  Loss: 0.002183 Acc: 13.3750\n",
      " |~~ train@46720  Loss: 0.002299 Acc: 13.3125\n",
      " |~~ train@46784  Loss: 0.002018 Acc: 13.3594\n",
      " |~~ train@46848  Loss: 0.002114 Acc: 13.3750\n",
      " |~~ train@46912  Loss: 0.002061 Acc: 13.3750\n",
      " |~~ train@46976  Loss: 0.002459 Acc: 13.3750\n",
      " |~~ train@47040  Loss: 0.002342 Acc: 13.3438\n",
      " |~~ train@47104  Loss: 0.002451 Acc: 13.2344\n",
      " |~~ train@47168  Loss: 0.001984 Acc: 13.4219\n",
      " |~~ train@47232  Loss: 0.002147 Acc: 13.3125\n",
      " |~~ train@47296  Loss: 0.002096 Acc: 13.3594\n",
      " |~~ train@47360  Loss: 0.002372 Acc: 13.2031\n",
      " |~~ train@47424  Loss: 0.002311 Acc: 13.2188\n",
      " |~~ train@47488  Loss: 0.001924 Acc: 13.3906\n",
      " |~~ train@47552  Loss: 0.002500 Acc: 13.2188\n",
      " |~~ train@47616  Loss: 0.002938 Acc: 13.0312\n",
      " |~~ train@47680  Loss: 0.002238 Acc: 13.2969\n",
      " |~~ train@47744  Loss: 0.001861 Acc: 13.4531\n",
      " |~~ train@47808  Loss: 0.002344 Acc: 13.2812\n",
      " |~~ train@47872  Loss: 0.002458 Acc: 13.1719\n",
      " |~~ train@47936  Loss: 0.002234 Acc: 13.2969\n",
      " |~~ train@48000  Loss: 0.002121 Acc: 13.3594\n",
      " |~~ train@48064  Loss: 0.002164 Acc: 13.3438\n",
      " |~~ train@48128  Loss: 0.002405 Acc: 13.2969\n",
      " |~~ train@48192  Loss: 0.002868 Acc: 13.1406\n",
      " |~~ train@48256  Loss: 0.001929 Acc: 13.5312\n",
      " |~~ train@48320  Loss: 0.002060 Acc: 13.4688\n",
      " |~~ train@48384  Loss: 0.002078 Acc: 13.3750\n",
      " |~~ train@48448  Loss: 0.002567 Acc: 13.2656\n",
      " |~~ train@48512  Loss: 0.002628 Acc: 13.1250\n",
      " |~~ train@48576  Loss: 0.002338 Acc: 13.2656\n",
      " |~~ train@48640  Loss: 0.002347 Acc: 13.2656\n",
      " |~~ train@48704  Loss: 0.001674 Acc: 13.4688\n",
      " |~~ train@48768  Loss: 0.001964 Acc: 13.4219\n",
      " |~~ train@48832  Loss: 0.002096 Acc: 13.3125\n",
      " |~~ train@48896  Loss: 0.002256 Acc: 13.3125\n",
      " |~~ train@48960  Loss: 0.002305 Acc: 13.3438\n",
      " |~~ train@49024  Loss: 0.002375 Acc: 13.2344\n",
      " |~~ train@49088  Loss: 0.002360 Acc: 13.2500\n",
      " |~~ train@49152  Loss: 0.002594 Acc: 13.2656\n",
      " |~~ train@49216  Loss: 0.002711 Acc: 13.2969\n",
      " |~~ train@49280  Loss: 0.002171 Acc: 13.3750\n",
      " |~~ train@49344  Loss: 0.002640 Acc: 13.0938\n",
      " |~~ train@49408  Loss: 0.002357 Acc: 13.3281\n",
      " |~~ train@49472  Loss: 0.002158 Acc: 13.3594\n",
      " |~~ train@49536  Loss: 0.002347 Acc: 13.2500\n",
      " |~~ train@49600  Loss: 0.002422 Acc: 13.2500\n",
      " |~~ train@49664  Loss: 0.002647 Acc: 13.2031\n",
      " |~~ train@49728  Loss: 0.002233 Acc: 13.2969\n",
      " |~~ train@49792  Loss: 0.002584 Acc: 13.1094\n",
      " |~~ train@49856  Loss: 0.002090 Acc: 13.3594\n",
      " |~~ train@49920  Loss: 0.002514 Acc: 13.2500\n",
      " |~~ train@49984  Loss: 0.002579 Acc: 13.2969\n",
      " |~~ train@50048  Loss: 0.001938 Acc: 13.4375\n",
      " |~~ train@50112  Loss: 0.002838 Acc: 13.0000\n",
      " |~~ train@50176  Loss: 0.002240 Acc: 13.2969\n",
      " |~~ train@50240  Loss: 0.002085 Acc: 13.3750\n",
      " |~~ train@50304  Loss: 0.002578 Acc: 13.1562\n",
      " |~~ train@50368  Loss: 0.002338 Acc: 13.3906\n",
      " |~~ train@50432  Loss: 0.002321 Acc: 13.3438\n",
      " |~~ train@50496  Loss: 0.002679 Acc: 13.2344\n",
      " |~~ train@50560  Loss: 0.002681 Acc: 13.2969\n",
      " |~~ train@50624  Loss: 0.002130 Acc: 13.4062\n",
      " |~~ train@50688  Loss: 0.002265 Acc: 13.3750\n",
      " |~~ train@50752  Loss: 0.002155 Acc: 13.3125\n",
      " |~~ train@50816  Loss: 0.002061 Acc: 13.3438\n",
      " |~~ train@50880  Loss: 0.001864 Acc: 13.3594\n",
      " |~~ train@50944  Loss: 0.001836 Acc: 13.4375\n",
      " |~~ train@51008  Loss: 0.002351 Acc: 13.2031\n",
      " |~~ train@51072  Loss: 0.002241 Acc: 13.3281\n",
      " |~~ train@51136  Loss: 0.002316 Acc: 13.2969\n",
      " |~~ train@51200  Loss: 0.002391 Acc: 13.3906\n",
      " |~~ train@51264  Loss: 0.002572 Acc: 13.2188\n",
      " |~~ train@51328  Loss: 0.002029 Acc: 13.3125\n",
      " |~~ train@51392  Loss: 0.002269 Acc: 13.3750\n",
      " |~~ train@51456  Loss: 0.002794 Acc: 13.1406\n",
      " |~~ train@51520  Loss: 0.002589 Acc: 13.1719\n",
      " |~~ train@51584  Loss: 0.001921 Acc: 13.3906\n",
      " |~~ train@51648  Loss: 0.001714 Acc: 13.4688\n",
      " |~~ train@51712  Loss: 0.001722 Acc: 13.5156\n",
      " |~~ train@51776  Loss: 0.002716 Acc: 13.1719\n",
      " |~~ train@51840  Loss: 0.001723 Acc: 13.4844\n",
      " |~~ train@51904  Loss: 0.002787 Acc: 13.1875\n",
      " |~~ train@51968  Loss: 0.002427 Acc: 13.1875\n",
      " |~~ train@52032  Loss: 0.001941 Acc: 13.5312\n",
      " |~~ train@52096  Loss: 0.002348 Acc: 13.2500\n",
      " |~~ train@52160  Loss: 0.002422 Acc: 13.2188\n",
      " |~~ train@52224  Loss: 0.002546 Acc: 13.2656\n",
      " |~~ train@52288  Loss: 0.002458 Acc: 13.2188\n",
      " |~~ train@52352  Loss: 0.002255 Acc: 13.3125\n",
      " |~~ train@52416  Loss: 0.001926 Acc: 13.4688\n",
      " |~~ train@52480  Loss: 0.002329 Acc: 13.2500\n",
      " |~~ train@52544  Loss: 0.002359 Acc: 13.2969\n",
      " |~~ train@52608  Loss: 0.002622 Acc: 13.1250\n",
      " |~~ train@52672  Loss: 0.002217 Acc: 13.4375\n",
      " |~~ train@52736  Loss: 0.002103 Acc: 13.3750\n",
      " |~~ train@52800  Loss: 0.002954 Acc: 13.0625\n",
      " |~~ train@52864  Loss: 0.002567 Acc: 13.1250\n",
      " |~~ train@52928  Loss: 0.002605 Acc: 13.2656\n",
      " |~~ train@52992  Loss: 0.002293 Acc: 13.3750\n",
      " |~~ train@53056  Loss: 0.002474 Acc: 13.2969\n",
      " |~~ train@53120  Loss: 0.002584 Acc: 13.2656\n",
      " |~~ train@53184  Loss: 0.002162 Acc: 13.3281\n",
      " |~~ train@53248  Loss: 0.002328 Acc: 13.2812\n",
      " |~~ train@53312  Loss: 0.002600 Acc: 13.2500\n",
      " |~~ train@53376  Loss: 0.002211 Acc: 13.2656\n",
      " |~~ train@53440  Loss: 0.002183 Acc: 13.4219\n",
      " |~~ train@53504  Loss: 0.002888 Acc: 12.9844\n",
      " |~~ train@53568  Loss: 0.002574 Acc: 13.1562\n",
      " |~~ train@53632  Loss: 0.002896 Acc: 13.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@53696  Loss: 0.002431 Acc: 13.2969\n",
      " |~~ train@53760  Loss: 0.001834 Acc: 13.4531\n",
      " |~~ train@53824  Loss: 0.002145 Acc: 13.3438\n",
      " |~~ train@53888  Loss: 0.002278 Acc: 13.2812\n",
      " |~~ train@53952  Loss: 0.002398 Acc: 13.2812\n",
      " |~~ train@54016  Loss: 0.002420 Acc: 13.3125\n",
      " |~~ train@54080  Loss: 0.002111 Acc: 13.3125\n",
      " |~~ train@54144  Loss: 0.002370 Acc: 13.3281\n",
      " |~~ train@54208  Loss: 0.002492 Acc: 13.2188\n",
      " |~~ train@54272  Loss: 0.002177 Acc: 13.3906\n",
      " |~~ train@54336  Loss: 0.002281 Acc: 13.2812\n",
      " |~~ train@54400  Loss: 0.001892 Acc: 13.5156\n",
      " |~~ train@54464  Loss: 0.002246 Acc: 13.3438\n",
      " |~~ train@54528  Loss: 0.002214 Acc: 13.2812\n",
      " |~~ train@54592  Loss: 0.002428 Acc: 13.1719\n",
      " |~~ train@54656  Loss: 0.001669 Acc: 13.4688\n",
      " |~~ train@54720  Loss: 0.002540 Acc: 13.2188\n",
      " |~~ train@54784  Loss: 0.002737 Acc: 13.1094\n",
      " |~~ train@54848  Loss: 0.002345 Acc: 13.2188\n",
      " |~~ train@54912  Loss: 0.002344 Acc: 13.2969\n",
      " |~~ train@54976  Loss: 0.001790 Acc: 13.5000\n",
      " |~~ train@55040  Loss: 0.001956 Acc: 13.4375\n",
      " |~~ train@55104  Loss: 0.001801 Acc: 13.4375\n",
      " |~~ train@55168  Loss: 0.002160 Acc: 13.3125\n",
      " |~~ train@55232  Loss: 0.002532 Acc: 13.2031\n",
      " |~~ train@55296  Loss: 0.002339 Acc: 13.3594\n",
      " |~~ train@55360  Loss: 0.002741 Acc: 13.1406\n",
      " |~~ train@55424  Loss: 0.002127 Acc: 13.4219\n",
      " |~~ train@55488  Loss: 0.002247 Acc: 13.2969\n",
      " |~~ train@55552  Loss: 0.002321 Acc: 13.2969\n",
      " |~~ train@55616  Loss: 0.002493 Acc: 13.2500\n",
      " |~~ train@55680  Loss: 0.002071 Acc: 13.3750\n",
      " |~~ train@55744  Loss: 0.002508 Acc: 13.2031\n",
      " |~~ train@55808  Loss: 0.002372 Acc: 13.2500\n",
      " |~~ train@55872  Loss: 0.002461 Acc: 13.1094\n",
      " |~~ train@55936  Loss: 0.002100 Acc: 13.3750\n",
      " |~~ train@56000  Loss: 0.001920 Acc: 13.4219\n",
      " |~~ train@56064  Loss: 0.002639 Acc: 13.2188\n",
      " |~~ train@56128  Loss: 0.002073 Acc: 13.3750\n",
      " |~~ train@56192  Loss: 0.002368 Acc: 13.2500\n",
      " |~~ train@56256  Loss: 0.002018 Acc: 13.4219\n",
      " |~~ train@56320  Loss: 0.002340 Acc: 13.3281\n",
      " |~~ train@56384  Loss: 0.002183 Acc: 13.4219\n",
      " |~~ train@56448  Loss: 0.001942 Acc: 13.4375\n",
      " |~~ train@56512  Loss: 0.002168 Acc: 13.2969\n",
      " |~~ train@56576  Loss: 0.002318 Acc: 13.3750\n",
      " |~~ train@56640  Loss: 0.002552 Acc: 13.2500\n",
      " |~~ train@56704  Loss: 0.001829 Acc: 13.5000\n",
      " |~~ train@56768  Loss: 0.002256 Acc: 13.1875\n",
      " |~~ train@56832  Loss: 0.002317 Acc: 13.3438\n",
      " |~~ train@56896  Loss: 0.002520 Acc: 13.2812\n",
      " |~~ train@56960  Loss: 0.002064 Acc: 13.4219\n",
      " |~~ train@57024  Loss: 0.001586 Acc: 13.5469\n",
      " |~~ train@57088  Loss: 0.001863 Acc: 13.4531\n",
      " |~~ train@57152  Loss: 0.002360 Acc: 13.1719\n",
      " |~~ train@57216  Loss: 0.001813 Acc: 13.3750\n",
      " |~~ train@57280  Loss: 0.002471 Acc: 13.2500\n",
      " |~~ train@57344  Loss: 0.002573 Acc: 13.1562\n",
      " |~~ train@57408  Loss: 0.002229 Acc: 13.4062\n",
      " |~~ train@57472  Loss: 0.001991 Acc: 13.3750\n",
      " |~~ train@57536  Loss: 0.002458 Acc: 13.1875\n",
      " |~~ train@57600  Loss: 0.002419 Acc: 13.2031\n",
      " |~~ train@57664  Loss: 0.002595 Acc: 13.1719\n",
      " |~~ train@57728  Loss: 0.001877 Acc: 13.4688\n",
      " |~~ train@57792  Loss: 0.002023 Acc: 13.3125\n",
      " |~~ train@57856  Loss: 0.001945 Acc: 13.4219\n",
      " |~~ train@57920  Loss: 0.002482 Acc: 13.2812\n",
      " |~~ train@57984  Loss: 0.002329 Acc: 13.3125\n",
      " |~~ train@58048  Loss: 0.002562 Acc: 13.2656\n",
      " |~~ train@58112  Loss: 0.002621 Acc: 13.1875\n",
      " |~~ train@58176  Loss: 0.001718 Acc: 13.5469\n",
      " |~~ train@58240  Loss: 0.002094 Acc: 13.3906\n",
      " |~~ train@58304  Loss: 0.002723 Acc: 13.1719\n",
      " |~~ train@58368  Loss: 0.002060 Acc: 13.3438\n",
      " |~~ train@58432  Loss: 0.002104 Acc: 13.4688\n",
      " |~~ train@58496  Loss: 0.002822 Acc: 13.0938\n",
      " |~~ train@58560  Loss: 0.001792 Acc: 13.5156\n",
      " |~~ train@58624  Loss: 0.002428 Acc: 13.1875\n",
      " |~~ train@58688  Loss: 0.002141 Acc: 13.3438\n",
      " |~~ train@58752  Loss: 0.001907 Acc: 13.3906\n",
      " |~~ train@58816  Loss: 0.003326 Acc: 13.0000\n",
      " |~~ train@58880  Loss: 0.002333 Acc: 13.3594\n",
      " |~~ train@58944  Loss: 0.003210 Acc: 12.9531\n",
      " |~~ train@59008  Loss: 0.002646 Acc: 13.2969\n",
      " |~~ train@59072  Loss: 0.002548 Acc: 13.2500\n",
      " |~~ train@59136  Loss: 0.002289 Acc: 13.2812\n",
      " |~~ train@59200  Loss: 0.002299 Acc: 13.2812\n",
      " |~~ train@59264  Loss: 0.002007 Acc: 13.3438\n",
      " |~~ train@59328  Loss: 0.001733 Acc: 13.5312\n",
      " |~~ train@59392  Loss: 0.002090 Acc: 13.3281\n",
      " |~~ train@59456  Loss: 0.002331 Acc: 13.2969\n",
      " |~~ train@59520  Loss: 0.002180 Acc: 13.4062\n",
      " |~~ train@59584  Loss: 0.002329 Acc: 13.3750\n",
      " |~~ train@59648  Loss: 0.002237 Acc: 13.2656\n",
      " |~~ train@59712  Loss: 0.002269 Acc: 13.3281\n",
      " |~~ train@59776  Loss: 0.002305 Acc: 13.3438\n",
      " |~~ train@59840  Loss: 0.002020 Acc: 13.4219\n",
      " |~~ train@59904  Loss: 0.001866 Acc: 13.3125\n",
      " |~~ train@59968  Loss: 0.002523 Acc: 13.3125\n",
      " |~~ train@60032  Loss: 0.001680 Acc: 13.5312\n",
      " |~~ train@60096  Loss: 0.002193 Acc: 13.2812\n",
      " |~~ train@60160  Loss: 0.002143 Acc: 13.3594\n",
      " |~~ train@60224  Loss: 0.001696 Acc: 13.5469\n",
      " |~~ train@60288  Loss: 0.002562 Acc: 13.1875\n",
      " |~~ train@60352  Loss: 0.001669 Acc: 13.6094\n",
      " |~~ train@60416  Loss: 0.002203 Acc: 13.3281\n",
      " |~~ train@60480  Loss: 0.002045 Acc: 13.4844\n",
      " |~~ train@60544  Loss: 0.002202 Acc: 13.3750\n",
      " |~~ train@60608  Loss: 0.002262 Acc: 13.2500\n",
      " |~~ train@60672  Loss: 0.002385 Acc: 13.2969\n",
      " |~~ train@60736  Loss: 0.002043 Acc: 13.3906\n",
      " |~~ train@60800  Loss: 0.002635 Acc: 13.2188\n",
      " |~~ train@60864  Loss: 0.002511 Acc: 13.2031\n",
      " |~~ train@60928  Loss: 0.002651 Acc: 13.2500\n",
      " |~~ train@60992  Loss: 0.002663 Acc: 13.1719\n",
      " |~~ train@61056  Loss: 0.001772 Acc: 13.4062\n",
      " |~~ train@61120  Loss: 0.002424 Acc: 13.2656\n",
      " |~~ train@61184  Loss: 0.002797 Acc: 13.1406\n",
      " |~~ train@61248  Loss: 0.002461 Acc: 13.1406\n",
      " |~~ train@61312  Loss: 0.002519 Acc: 13.2031\n",
      " |~~ train@61376  Loss: 0.002531 Acc: 13.2500\n",
      " |~~ train@61440  Loss: 0.002597 Acc: 13.2656\n",
      " |~~ train@61504  Loss: 0.002079 Acc: 13.3594\n",
      " |~~ train@61568  Loss: 0.001943 Acc: 13.4531\n",
      " |~~ train@61632  Loss: 0.002426 Acc: 13.2500\n",
      " |~~ train@61696  Loss: 0.001980 Acc: 13.4062\n",
      " |~~ train@61760  Loss: 0.002389 Acc: 13.2344\n",
      " |~~ train@61824  Loss: 0.002412 Acc: 13.2344\n",
      " |~~ train@61888  Loss: 0.002549 Acc: 13.2344\n",
      " |~~ train@61952  Loss: 0.002492 Acc: 13.3281\n",
      " |~~ train@62016  Loss: 0.001869 Acc: 13.4219\n",
      " |~~ train@62080  Loss: 0.002016 Acc: 13.3594\n",
      " |~~ train@62144  Loss: 0.002357 Acc: 13.3281\n",
      " |~~ train@62208  Loss: 0.002255 Acc: 13.2188\n",
      " |~~ train@62272  Loss: 0.002396 Acc: 13.3125\n",
      " |~~ train@62336  Loss: 0.002514 Acc: 13.3438\n",
      " |~~ train@62400  Loss: 0.002992 Acc: 12.9688\n",
      " |~~ train@62464  Loss: 0.001959 Acc: 13.3750\n",
      " |~~ train@62528  Loss: 0.002209 Acc: 13.4062\n",
      " |~~ train@62592  Loss: 0.002126 Acc: 13.4375\n",
      " |~~ train@62656  Loss: 0.002434 Acc: 13.2188\n",
      " |~~ train@62720  Loss: 0.001990 Acc: 13.2969\n",
      " |~~ train@62784  Loss: 0.002404 Acc: 13.2344\n",
      " |~~ train@62848  Loss: 0.002162 Acc: 13.3906\n",
      " |~~ train@62912  Loss: 0.002169 Acc: 13.3281\n",
      " |~~ train@62976  Loss: 0.002234 Acc: 13.3438\n",
      " |~~ train@63040  Loss: 0.002217 Acc: 13.3594\n",
      " |~~ train@63104  Loss: 0.002659 Acc: 13.2031\n",
      " |~~ train@63168  Loss: 0.002451 Acc: 13.2031\n",
      " |~~ train@63232  Loss: 0.002480 Acc: 13.2500\n",
      " |~~ train@63296  Loss: 0.002280 Acc: 13.2656\n",
      " |~~ train@63360  Loss: 0.001861 Acc: 13.5156\n",
      " |~~ train@63424  Loss: 0.002303 Acc: 13.2031\n",
      " |~~ train@63488  Loss: 0.002721 Acc: 13.1250\n",
      " |~~ train@63552  Loss: 0.002247 Acc: 13.3281\n",
      " |~~ train@63616  Loss: 0.002082 Acc: 13.4688\n",
      " |~~ train@63680  Loss: 0.002635 Acc: 13.1094\n",
      " |~~ train@63744  Loss: 0.002278 Acc: 13.3438\n",
      " |~~ train@63808  Loss: 0.002331 Acc: 13.2031\n",
      " |~~ train@63872  Loss: 0.002289 Acc: 13.2500\n",
      " |~~ train@63936  Loss: 0.002431 Acc: 13.3281\n",
      " |~~ train@64000  Loss: 0.002690 Acc: 13.1250\n",
      " |~~ train@64064  Loss: 0.002216 Acc: 13.3750\n",
      " |~~ train@64128  Loss: 0.002742 Acc: 13.2344\n",
      " |~~ train@64192  Loss: 0.002383 Acc: 13.2500\n",
      " |~~ train@64256  Loss: 0.002049 Acc: 13.3594\n",
      " |~~ train@64320  Loss: 0.002749 Acc: 13.2031\n",
      " |~~ train@64384  Loss: 0.002353 Acc: 13.2344\n",
      " |~~ train@64448  Loss: 0.002409 Acc: 13.2812\n",
      " |~~ train@64512  Loss: 0.002136 Acc: 13.3594\n",
      " |~~ train@64576  Loss: 0.002544 Acc: 13.2031\n",
      " |~~ train@64640  Loss: 0.002778 Acc: 13.1250\n",
      " |~~ train@64704  Loss: 0.001911 Acc: 13.3750\n",
      " |~~ train@64768  Loss: 0.002344 Acc: 13.2500\n",
      " |~~ train@64832  Loss: 0.002540 Acc: 13.2188\n",
      " |~~ train@64896  Loss: 0.001979 Acc: 13.4688\n",
      " |~~ train@64960  Loss: 0.002346 Acc: 13.3125\n",
      " |~~ train@65024  Loss: 0.001916 Acc: 13.4531\n",
      " |~~ train@65088  Loss: 0.002411 Acc: 13.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@65152  Loss: 0.002047 Acc: 13.3750\n",
      " |~~ train@65216  Loss: 0.002273 Acc: 13.3281\n",
      " |~~ train@65280  Loss: 0.002400 Acc: 13.2500\n",
      " |~~ train@65344  Loss: 0.002461 Acc: 13.2188\n",
      " |~~ train@65408  Loss: 0.001684 Acc: 13.4688\n",
      " |~~ train@65472  Loss: 0.002669 Acc: 13.1562\n",
      " |~~ train@65536  Loss: 0.002308 Acc: 13.2500\n",
      " |~~ train@65600  Loss: 0.002041 Acc: 13.4688\n",
      " |~~ train@65664  Loss: 0.002382 Acc: 13.2500\n",
      " |~~ train@65728  Loss: 0.002297 Acc: 13.3438\n",
      " |~~ train@65792  Loss: 0.001710 Acc: 13.5156\n",
      " |~~ train@65856  Loss: 0.003057 Acc: 13.0625\n",
      " |~~ train@65920  Loss: 0.002216 Acc: 13.3438\n",
      " |~~ train@65984  Loss: 0.002958 Acc: 13.0312\n",
      " |~~ train@66048  Loss: 0.002074 Acc: 13.4062\n",
      " |~~ train@66112  Loss: 0.001861 Acc: 13.4219\n",
      " |~~ train@66176  Loss: 0.002554 Acc: 13.2344\n",
      " |~~ train@66240  Loss: 0.002864 Acc: 13.0312\n",
      " |~~ train@66304  Loss: 0.002772 Acc: 13.1719\n",
      " |~~ train@66368  Loss: 0.001896 Acc: 13.4062\n",
      " |~~ train@66432  Loss: 0.001887 Acc: 13.4219\n",
      " |~~ train@66496  Loss: 0.002534 Acc: 13.2500\n",
      " |~~ train@66560  Loss: 0.002311 Acc: 13.2812\n",
      " |~~ train@66624  Loss: 0.002562 Acc: 13.1719\n",
      " |~~ train@66688  Loss: 0.002882 Acc: 12.9531\n",
      " |~~ train@66752  Loss: 0.002130 Acc: 13.3906\n",
      " |~~ train@66816  Loss: 0.002241 Acc: 13.3438\n",
      " |~~ train@66880  Loss: 0.002298 Acc: 13.2500\n",
      " |~~ train@66944  Loss: 0.002610 Acc: 13.2500\n",
      " |~~ train@67008  Loss: 0.002349 Acc: 13.1875\n",
      " |~~ train@67072  Loss: 0.002039 Acc: 13.4062\n",
      " |~~ train@67136  Loss: 0.002037 Acc: 13.3906\n",
      " |~~ train@67200  Loss: 0.002264 Acc: 13.3125\n",
      " |~~ train@67264  Loss: 0.002285 Acc: 13.2500\n",
      " |~~ train@67328  Loss: 0.002079 Acc: 13.3750\n",
      " |~~ train@67392  Loss: 0.001781 Acc: 13.5469\n",
      " |~~ train@67456  Loss: 0.002642 Acc: 13.2031\n",
      " |~~ train@67520  Loss: 0.001955 Acc: 13.4062\n",
      " |~~ train@67584  Loss: 0.002299 Acc: 13.3125\n",
      " |~~ train@67648  Loss: 0.002304 Acc: 13.2812\n",
      " |~~ train@67712  Loss: 0.002029 Acc: 13.3594\n",
      " |~~ train@67776  Loss: 0.002487 Acc: 13.2656\n",
      " |~~ train@67840  Loss: 0.002293 Acc: 13.2656\n",
      " |~~ train@67904  Loss: 0.002482 Acc: 13.2812\n",
      " |~~ train@67968  Loss: 0.002519 Acc: 13.2500\n",
      " |~~ train@68032  Loss: 0.001993 Acc: 13.4688\n",
      " |~~ train@68096  Loss: 0.002489 Acc: 13.2031\n",
      " |~~ train@68160  Loss: 0.001972 Acc: 13.4219\n",
      " |~~ train@68224  Loss: 0.001737 Acc: 13.5312\n",
      " |~~ train@68288  Loss: 0.001921 Acc: 13.4531\n",
      " |~~ train@68352  Loss: 0.002580 Acc: 13.1875\n",
      " |~~ train@68416  Loss: 0.002765 Acc: 13.1875\n",
      " |~~ train@68480  Loss: 0.002419 Acc: 13.2656\n",
      " |~~ train@68544  Loss: 0.002223 Acc: 13.3750\n",
      " |~~ train@68608  Loss: 0.002993 Acc: 13.0469\n",
      " |~~ train@68672  Loss: 0.002552 Acc: 13.1250\n",
      " |~~ train@68736  Loss: 0.001960 Acc: 13.4531\n",
      " |~~ train@68800  Loss: 0.001782 Acc: 13.4375\n",
      " |~~ train@68864  Loss: 0.002497 Acc: 13.2500\n",
      " |~~ train@68928  Loss: 0.002398 Acc: 13.2031\n",
      " |~~ train@68992  Loss: 0.001662 Acc: 13.5312\n",
      " |~~ train@69056  Loss: 0.002184 Acc: 13.3125\n",
      " |~~ train@69120  Loss: 0.002444 Acc: 13.2656\n",
      " |~~ train@69184  Loss: 0.001867 Acc: 13.5000\n",
      " |~~ train@69248  Loss: 0.002597 Acc: 13.1875\n",
      " |~~ train@69312  Loss: 0.002609 Acc: 13.1562\n",
      " |~~ train@69376  Loss: 0.001919 Acc: 13.3906\n",
      " |~~ train@69440  Loss: 0.001827 Acc: 13.5000\n",
      " |~~ train@69504  Loss: 0.002171 Acc: 13.3125\n",
      " |~~ train@69568  Loss: 0.002296 Acc: 13.3281\n",
      " |~~ train@69632  Loss: 0.002761 Acc: 13.0312\n",
      " |~~ train@69696  Loss: 0.002247 Acc: 13.3438\n",
      " |~~ train@69760  Loss: 0.002616 Acc: 13.1875\n",
      " |~~ train@69824  Loss: 0.002022 Acc: 13.3594\n",
      " |~~ train@69888  Loss: 0.002661 Acc: 13.1562\n",
      " |~~ train@69952  Loss: 0.001662 Acc: 13.4375\n",
      " |~~ train@70016  Loss: 0.002008 Acc: 13.2656\n",
      " |~~ train@70080  Loss: 0.002305 Acc: 13.2656\n",
      " |~~ train@70144  Loss: 0.002618 Acc: 13.2344\n",
      " |~~ train@70208  Loss: 0.002437 Acc: 13.2500\n",
      " |~~ train@70272  Loss: 0.002307 Acc: 13.2031\n",
      " |~~ train@70336  Loss: 0.002578 Acc: 13.3438\n",
      " |~~ train@70400  Loss: 0.002398 Acc: 13.1562\n",
      " |~~ train@70464  Loss: 0.002621 Acc: 13.1875\n",
      " |~~ train@70528  Loss: 0.001892 Acc: 13.3594\n",
      " |~~ train@70592  Loss: 0.002466 Acc: 13.2812\n",
      " |~~ train@70656  Loss: 0.002328 Acc: 13.3906\n",
      " |~~ train@70720  Loss: 0.001945 Acc: 13.4062\n",
      " |~~ train@70784  Loss: 0.002613 Acc: 13.2344\n",
      " |~~ train@70848  Loss: 0.002671 Acc: 13.2188\n",
      " |~~ train@70912  Loss: 0.002192 Acc: 13.3594\n",
      " |~~ train@70976  Loss: 0.002398 Acc: 13.3125\n",
      " |~~ train@71040  Loss: 0.002463 Acc: 13.1719\n",
      " |~~ train@71104  Loss: 0.001943 Acc: 13.3906\n",
      " |~~ train@71168  Loss: 0.002288 Acc: 13.3594\n",
      " |~~ train@71232  Loss: 0.002470 Acc: 13.1719\n",
      " |~~ train@71296  Loss: 0.002242 Acc: 13.4062\n",
      " |~~ train@71360  Loss: 0.002270 Acc: 13.4219\n",
      " |~~ train@71424  Loss: 0.002487 Acc: 13.1719\n",
      " |~~ train@71488  Loss: 0.002133 Acc: 13.3281\n",
      " |~~ train@71552  Loss: 0.002149 Acc: 13.4062\n",
      " |~~ train@71616  Loss: 0.002464 Acc: 13.2812\n",
      " |~~ train@71680  Loss: 0.002725 Acc: 13.1719\n",
      " |~~ train@71744  Loss: 0.002194 Acc: 13.2969\n",
      " |~~ train@71808  Loss: 0.002897 Acc: 13.2031\n",
      " |~~ train@71872  Loss: 0.002497 Acc: 13.1875\n",
      " |~~ train@71936  Loss: 0.002633 Acc: 13.0938\n",
      " |~~ train@72000  Loss: 0.002701 Acc: 13.1250\n",
      " |~~ train@72064  Loss: 0.002508 Acc: 13.2500\n",
      " |~~ train@72128  Loss: 0.002209 Acc: 13.4062\n",
      " |~~ train@72192  Loss: 0.002558 Acc: 13.2500\n",
      " |~~ train@72256  Loss: 0.002191 Acc: 13.3125\n",
      " |~~ train@72320  Loss: 0.002658 Acc: 13.1406\n",
      " |~~ train@72384  Loss: 0.002105 Acc: 13.3281\n",
      " |~~ train@72448  Loss: 0.002603 Acc: 13.2344\n",
      " |~~ train@72512  Loss: 0.002058 Acc: 13.3281\n",
      " |~~ train@72576  Loss: 0.002505 Acc: 13.2344\n",
      " |~~ train@72640  Loss: 0.002175 Acc: 13.4062\n",
      " |~~ train@72704  Loss: 0.001884 Acc: 13.4375\n",
      " |~~ train@72768  Loss: 0.002514 Acc: 13.3281\n",
      " |~~ train@72832  Loss: 0.002343 Acc: 13.3594\n",
      " |~~ train@72896  Loss: 0.001890 Acc: 13.4375\n",
      " |~~ train@72960  Loss: 0.002243 Acc: 13.2969\n",
      " |~~ train@73024  Loss: 0.002400 Acc: 13.2344\n",
      " |~~ train@73088  Loss: 0.002978 Acc: 13.0312\n",
      " |~~ train@73152  Loss: 0.002302 Acc: 13.2500\n",
      " |~~ train@73216  Loss: 0.002070 Acc: 13.3906\n",
      " |~~ train@73280  Loss: 0.002450 Acc: 13.2812\n",
      " |~~ train@73344  Loss: 0.002649 Acc: 13.2188\n",
      " |~~ train@73408  Loss: 0.002057 Acc: 13.3594\n",
      " |~~ train@73472  Loss: 0.002185 Acc: 13.3281\n",
      " |~~ train@73536  Loss: 0.001819 Acc: 13.4531\n",
      " |~~ train@73600  Loss: 0.002399 Acc: 13.2500\n",
      " |~~ train@73664  Loss: 0.002407 Acc: 13.2344\n",
      " |~~ train@73728  Loss: 0.002184 Acc: 13.3594\n",
      " |~~ train@73792  Loss: 0.001991 Acc: 13.4531\n",
      " |~~ train@73856  Loss: 0.002690 Acc: 13.2031\n",
      " |~~ train@73920  Loss: 0.002376 Acc: 13.2812\n",
      " |~~ train@73984  Loss: 0.002929 Acc: 13.1406\n",
      " |~~ train@74048  Loss: 0.001950 Acc: 13.3438\n",
      " |~~ train@74112  Loss: 0.001791 Acc: 13.5625\n",
      " |~~ train@74176  Loss: 0.002124 Acc: 13.3438\n",
      " |~~ train@74240  Loss: 0.002013 Acc: 13.3906\n",
      " |~~ train@74304  Loss: 0.002239 Acc: 13.3906\n",
      " |~~ train@74368  Loss: 0.002900 Acc: 13.1250\n",
      " |~~ train@74432  Loss: 0.002407 Acc: 13.2812\n",
      " |~~ train@74496  Loss: 0.001998 Acc: 13.4688\n",
      " |~~ train@74560  Loss: 0.002573 Acc: 13.2812\n",
      " |~~ train@74624  Loss: 0.002004 Acc: 13.3281\n",
      " |~~ train@74688  Loss: 0.002339 Acc: 13.2812\n",
      " |~~ train@74752  Loss: 0.003157 Acc: 12.9688\n",
      " |~~ train@74816  Loss: 0.002093 Acc: 13.4062\n",
      " |~~ train@74880  Loss: 0.002394 Acc: 13.1875\n",
      " |~~ train@74944  Loss: 0.002519 Acc: 13.2656\n",
      " |~~ train@75008  Loss: 0.002452 Acc: 13.1406\n",
      " |~~ train@75072  Loss: 0.002277 Acc: 13.3125\n",
      " |~~ train@75136  Loss: 0.002417 Acc: 13.2500\n",
      " |~~ train@75200  Loss: 0.001965 Acc: 13.4531\n",
      " |~~ train@75264  Loss: 0.001788 Acc: 13.5156\n",
      " |~~ train@75328  Loss: 0.002456 Acc: 13.2344\n",
      " |~~ train@75392  Loss: 0.002262 Acc: 13.2500\n",
      " |~~ train@75456  Loss: 0.002380 Acc: 13.3125\n",
      " |~~ train@75520  Loss: 0.002286 Acc: 13.3281\n",
      " |~~ train@75584  Loss: 0.002640 Acc: 13.2188\n",
      " |~~ train@75648  Loss: 0.002283 Acc: 13.4062\n",
      " |~~ train@75712  Loss: 0.002474 Acc: 13.2812\n",
      " |~~ train@75776  Loss: 0.002399 Acc: 13.2969\n",
      " |~~ train@75840  Loss: 0.001855 Acc: 13.3750\n",
      " |~~ train@75904  Loss: 0.001889 Acc: 13.4375\n",
      " |~~ train@75968  Loss: 0.002832 Acc: 13.1250\n",
      " |~~ train@76032  Loss: 0.002162 Acc: 13.4062\n",
      " |~~ train@76096  Loss: 0.002799 Acc: 13.2031\n",
      " |~~ train@76160  Loss: 0.002452 Acc: 13.2500\n",
      " |~~ train@76224  Loss: 0.002510 Acc: 13.3125\n",
      " |~~ train@76288  Loss: 0.002040 Acc: 13.4219\n",
      " |~~ train@76352  Loss: 0.001794 Acc: 13.5312\n",
      " |~~ train@76416  Loss: 0.002068 Acc: 13.4062\n",
      " |~~ train@76480  Loss: 0.002325 Acc: 13.2812\n",
      " |~~ train@76544  Loss: 0.001808 Acc: 13.4531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@76608  Loss: 0.002167 Acc: 13.3281\n",
      " |~~ train@76672  Loss: 0.002188 Acc: 13.3281\n",
      " |~~ train@76736  Loss: 0.001773 Acc: 13.5000\n",
      " |~~ train@76800  Loss: 0.002152 Acc: 13.3594\n",
      " |~~ train@76864  Loss: 0.002165 Acc: 13.3906\n",
      " |~~ train@76928  Loss: 0.002175 Acc: 13.3594\n",
      " |~~ train@76992  Loss: 0.001936 Acc: 13.4062\n",
      " |~~ train@77056  Loss: 0.002652 Acc: 13.1250\n",
      " |~~ train@77120  Loss: 0.002178 Acc: 13.3125\n",
      " |~~ train@77184  Loss: 0.002037 Acc: 13.4531\n",
      " |~~ train@77248  Loss: 0.002184 Acc: 13.3438\n",
      " |~~ train@77312  Loss: 0.002524 Acc: 13.1562\n",
      " |~~ train@77376  Loss: 0.002602 Acc: 13.1719\n",
      " |~~ train@77440  Loss: 0.001903 Acc: 13.3906\n",
      " |~~ train@77504  Loss: 0.002374 Acc: 13.2344\n",
      " |~~ train@77568  Loss: 0.003085 Acc: 13.0000\n",
      " |~~ train@77632  Loss: 0.001787 Acc: 13.5000\n",
      " |~~ train@77696  Loss: 0.002388 Acc: 13.2031\n",
      " |~~ train@77760  Loss: 0.002473 Acc: 13.2500\n",
      " |~~ train@77824  Loss: 0.002345 Acc: 13.2500\n",
      " |~~ train@77888  Loss: 0.002477 Acc: 13.4062\n",
      " |~~ train@77952  Loss: 0.002398 Acc: 13.1719\n",
      " |~~ train@78016  Loss: 0.002519 Acc: 13.2344\n",
      " |~~ train@78080  Loss: 0.002530 Acc: 13.2344\n",
      " |~~ train@78144  Loss: 0.002953 Acc: 13.1719\n",
      " |~~ train@78208  Loss: 0.002742 Acc: 13.0625\n",
      " |~~ train@78272  Loss: 0.002135 Acc: 13.3594\n",
      " |~~ train@78336  Loss: 0.002195 Acc: 13.3438\n",
      " |~~ train@78400  Loss: 0.002817 Acc: 13.1094\n",
      " |~~ train@78464  Loss: 0.002184 Acc: 13.3594\n",
      " |~~ train@78484  Loss: 0.007500 Acc: 13.2500\n",
      "train  Loss: 0.002315 Acc: 13.2968\n",
      " |~~ val@64  Loss: 0.003362 Acc: 13.0000\n",
      " |~~ val@128  Loss: 0.002480 Acc: 13.2812\n",
      " |~~ val@192  Loss: 0.002801 Acc: 13.1406\n",
      " |~~ val@256  Loss: 0.001798 Acc: 13.5312\n",
      " |~~ val@320  Loss: 0.002463 Acc: 13.2188\n",
      " |~~ val@384  Loss: 0.001815 Acc: 13.5000\n",
      " |~~ val@448  Loss: 0.002013 Acc: 13.4531\n",
      " |~~ val@512  Loss: 0.001839 Acc: 13.4375\n",
      " |~~ val@576  Loss: 0.002606 Acc: 13.2344\n",
      " |~~ val@640  Loss: 0.002518 Acc: 13.2656\n",
      " |~~ val@704  Loss: 0.002330 Acc: 13.2656\n",
      " |~~ val@768  Loss: 0.002222 Acc: 13.2812\n",
      " |~~ val@832  Loss: 0.002213 Acc: 13.2812\n",
      " |~~ val@896  Loss: 0.002222 Acc: 13.3125\n",
      " |~~ val@960  Loss: 0.002791 Acc: 13.1094\n",
      " |~~ val@1024  Loss: 0.002124 Acc: 13.4062\n",
      " |~~ val@1088  Loss: 0.002131 Acc: 13.3438\n",
      " |~~ val@1152  Loss: 0.002493 Acc: 13.1875\n",
      " |~~ val@1216  Loss: 0.002729 Acc: 13.1094\n",
      " |~~ val@1280  Loss: 0.002029 Acc: 13.3906\n",
      " |~~ val@1344  Loss: 0.002238 Acc: 13.4062\n",
      " |~~ val@1408  Loss: 0.002505 Acc: 13.2344\n",
      " |~~ val@1472  Loss: 0.002063 Acc: 13.4219\n",
      " |~~ val@1536  Loss: 0.002317 Acc: 13.3125\n",
      " |~~ val@1600  Loss: 0.002036 Acc: 13.3750\n",
      " |~~ val@1664  Loss: 0.002867 Acc: 13.1250\n",
      " |~~ val@1728  Loss: 0.002826 Acc: 13.2656\n",
      " |~~ val@1792  Loss: 0.002400 Acc: 13.3125\n",
      " |~~ val@1856  Loss: 0.002343 Acc: 13.2812\n",
      " |~~ val@1920  Loss: 0.002109 Acc: 13.3594\n",
      " |~~ val@1984  Loss: 0.002046 Acc: 13.4531\n",
      " |~~ val@2048  Loss: 0.002234 Acc: 13.3438\n",
      " |~~ val@2112  Loss: 0.002605 Acc: 13.3125\n",
      " |~~ val@2176  Loss: 0.002380 Acc: 13.2344\n",
      " |~~ val@2240  Loss: 0.002487 Acc: 13.2500\n",
      " |~~ val@2304  Loss: 0.001972 Acc: 13.4062\n",
      " |~~ val@2368  Loss: 0.002238 Acc: 13.2812\n",
      " |~~ val@2432  Loss: 0.002648 Acc: 13.0938\n",
      " |~~ val@2496  Loss: 0.001935 Acc: 13.4844\n",
      " |~~ val@2560  Loss: 0.002487 Acc: 13.1875\n",
      " |~~ val@2624  Loss: 0.002301 Acc: 13.3906\n",
      " |~~ val@2688  Loss: 0.002226 Acc: 13.3125\n",
      " |~~ val@2752  Loss: 0.002740 Acc: 13.2656\n",
      " |~~ val@2816  Loss: 0.002336 Acc: 13.2500\n",
      " |~~ val@2880  Loss: 0.002239 Acc: 13.3438\n",
      " |~~ val@2944  Loss: 0.002349 Acc: 13.2031\n",
      " |~~ val@3008  Loss: 0.002217 Acc: 13.3906\n",
      " |~~ val@3072  Loss: 0.002851 Acc: 13.1250\n",
      " |~~ val@3136  Loss: 0.002575 Acc: 13.2344\n",
      " |~~ val@3200  Loss: 0.002634 Acc: 13.1250\n",
      " |~~ val@3264  Loss: 0.002999 Acc: 13.1094\n",
      " |~~ val@3328  Loss: 0.002780 Acc: 13.1875\n",
      " |~~ val@3392  Loss: 0.002360 Acc: 13.3281\n",
      " |~~ val@3456  Loss: 0.002809 Acc: 13.1250\n",
      " |~~ val@3520  Loss: 0.002289 Acc: 13.3594\n",
      " |~~ val@3584  Loss: 0.002412 Acc: 13.2812\n",
      " |~~ val@3648  Loss: 0.002638 Acc: 13.1719\n",
      " |~~ val@3712  Loss: 0.002712 Acc: 13.1406\n",
      " |~~ val@3776  Loss: 0.002294 Acc: 13.3281\n",
      " |~~ val@3840  Loss: 0.001942 Acc: 13.4531\n",
      " |~~ val@3904  Loss: 0.001967 Acc: 13.3906\n",
      " |~~ val@3968  Loss: 0.002894 Acc: 13.0938\n",
      " |~~ val@4032  Loss: 0.002468 Acc: 13.2969\n",
      " |~~ val@4096  Loss: 0.002767 Acc: 13.2344\n",
      " |~~ val@4160  Loss: 0.002691 Acc: 13.1562\n",
      " |~~ val@4224  Loss: 0.002644 Acc: 13.1250\n",
      " |~~ val@4288  Loss: 0.002455 Acc: 13.2812\n",
      " |~~ val@4352  Loss: 0.002736 Acc: 13.1406\n",
      " |~~ val@4416  Loss: 0.002713 Acc: 13.0938\n",
      " |~~ val@4480  Loss: 0.002388 Acc: 13.3438\n",
      " |~~ val@4544  Loss: 0.002430 Acc: 13.1562\n",
      " |~~ val@4608  Loss: 0.003283 Acc: 12.9531\n",
      " |~~ val@4672  Loss: 0.002026 Acc: 13.3125\n",
      " |~~ val@4736  Loss: 0.002419 Acc: 13.2188\n",
      " |~~ val@4800  Loss: 0.002365 Acc: 13.2812\n",
      " |~~ val@4864  Loss: 0.001932 Acc: 13.4219\n",
      " |~~ val@4928  Loss: 0.002000 Acc: 13.4375\n",
      " |~~ val@4992  Loss: 0.002867 Acc: 13.0156\n",
      " |~~ val@5056  Loss: 0.002842 Acc: 13.1562\n",
      " |~~ val@5120  Loss: 0.002648 Acc: 13.1562\n",
      " |~~ val@5184  Loss: 0.002015 Acc: 13.4219\n",
      " |~~ val@5248  Loss: 0.002199 Acc: 13.2969\n",
      " |~~ val@5312  Loss: 0.002321 Acc: 13.3125\n",
      " |~~ val@5376  Loss: 0.002152 Acc: 13.3594\n",
      " |~~ val@5440  Loss: 0.002054 Acc: 13.3438\n",
      " |~~ val@5504  Loss: 0.001975 Acc: 13.4062\n",
      " |~~ val@5568  Loss: 0.002560 Acc: 13.1875\n",
      " |~~ val@5632  Loss: 0.002496 Acc: 13.1875\n",
      " |~~ val@5696  Loss: 0.002528 Acc: 13.2500\n",
      " |~~ val@5760  Loss: 0.002131 Acc: 13.4062\n",
      " |~~ val@5824  Loss: 0.002194 Acc: 13.4375\n",
      " |~~ val@5888  Loss: 0.003099 Acc: 13.0000\n",
      " |~~ val@5952  Loss: 0.002429 Acc: 13.2500\n",
      " |~~ val@6016  Loss: 0.002148 Acc: 13.4219\n",
      " |~~ val@6080  Loss: 0.002104 Acc: 13.3438\n",
      " |~~ val@6144  Loss: 0.002956 Acc: 13.0781\n",
      " |~~ val@6208  Loss: 0.002539 Acc: 13.1719\n",
      " |~~ val@6272  Loss: 0.003021 Acc: 12.9844\n",
      " |~~ val@6336  Loss: 0.002470 Acc: 13.2344\n",
      " |~~ val@6400  Loss: 0.001842 Acc: 13.4375\n",
      " |~~ val@6464  Loss: 0.002115 Acc: 13.2500\n",
      " |~~ val@6528  Loss: 0.002344 Acc: 13.3125\n",
      " |~~ val@6592  Loss: 0.002201 Acc: 13.3438\n",
      " |~~ val@6656  Loss: 0.002353 Acc: 13.3125\n",
      " |~~ val@6720  Loss: 0.001918 Acc: 13.4062\n",
      " |~~ val@6784  Loss: 0.002348 Acc: 13.1406\n",
      " |~~ val@6848  Loss: 0.002464 Acc: 13.2812\n",
      " |~~ val@6912  Loss: 0.002195 Acc: 13.3438\n",
      " |~~ val@6976  Loss: 0.002440 Acc: 13.2031\n",
      " |~~ val@7040  Loss: 0.002447 Acc: 13.3125\n",
      " |~~ val@7104  Loss: 0.002361 Acc: 13.3438\n",
      " |~~ val@7168  Loss: 0.002607 Acc: 13.2344\n",
      " |~~ val@7232  Loss: 0.001824 Acc: 13.4688\n",
      " |~~ val@7296  Loss: 0.002195 Acc: 13.4062\n",
      " |~~ val@7360  Loss: 0.002592 Acc: 13.3594\n",
      " |~~ val@7424  Loss: 0.002348 Acc: 13.2812\n",
      " |~~ val@7488  Loss: 0.002294 Acc: 13.3750\n",
      " |~~ val@7552  Loss: 0.002341 Acc: 13.3281\n",
      " |~~ val@7616  Loss: 0.001800 Acc: 13.4531\n",
      " |~~ val@7680  Loss: 0.002145 Acc: 13.3750\n",
      " |~~ val@7744  Loss: 0.002333 Acc: 13.3125\n",
      " |~~ val@7808  Loss: 0.001939 Acc: 13.5000\n",
      " |~~ val@7872  Loss: 0.002253 Acc: 13.3438\n",
      " |~~ val@7936  Loss: 0.002416 Acc: 13.2656\n",
      " |~~ val@8000  Loss: 0.002236 Acc: 13.2812\n",
      " |~~ val@8064  Loss: 0.002212 Acc: 13.4062\n",
      " |~~ val@8128  Loss: 0.002185 Acc: 13.3594\n",
      " |~~ val@8192  Loss: 0.002716 Acc: 13.0781\n",
      " |~~ val@8256  Loss: 0.002182 Acc: 13.4062\n",
      " |~~ val@8320  Loss: 0.002560 Acc: 13.2656\n",
      " |~~ val@8384  Loss: 0.002651 Acc: 13.2031\n",
      " |~~ val@8448  Loss: 0.003670 Acc: 12.9375\n",
      " |~~ val@8512  Loss: 0.002555 Acc: 13.2188\n",
      " |~~ val@8576  Loss: 0.001750 Acc: 13.4688\n",
      " |~~ val@8640  Loss: 0.002451 Acc: 13.2188\n",
      " |~~ val@8704  Loss: 0.002790 Acc: 13.1094\n",
      " |~~ val@8768  Loss: 0.002017 Acc: 13.3906\n",
      " |~~ val@8832  Loss: 0.002450 Acc: 13.4219\n",
      " |~~ val@8896  Loss: 0.002381 Acc: 13.3125\n",
      " |~~ val@8960  Loss: 0.002759 Acc: 13.0938\n",
      " |~~ val@9024  Loss: 0.002055 Acc: 13.4531\n",
      " |~~ val@9088  Loss: 0.002364 Acc: 13.2969\n",
      " |~~ val@9152  Loss: 0.002169 Acc: 13.3906\n",
      " |~~ val@9216  Loss: 0.002700 Acc: 13.2188\n",
      " |~~ val@9280  Loss: 0.002202 Acc: 13.3438\n",
      " |~~ val@9344  Loss: 0.002345 Acc: 13.3438\n",
      " |~~ val@9408  Loss: 0.002021 Acc: 13.4688\n",
      " |~~ val@9472  Loss: 0.003045 Acc: 13.1406\n",
      " |~~ val@9536  Loss: 0.002251 Acc: 13.3438\n",
      " |~~ val@9600  Loss: 0.002383 Acc: 13.3125\n",
      " |~~ val@9664  Loss: 0.002811 Acc: 13.1250\n",
      " |~~ val@9728  Loss: 0.002438 Acc: 13.3438\n",
      " |~~ val@9792  Loss: 0.002892 Acc: 13.0938\n",
      " |~~ val@9856  Loss: 0.002303 Acc: 13.3125\n",
      " |~~ val@9920  Loss: 0.002841 Acc: 13.1562\n",
      " |~~ val@9984  Loss: 0.002281 Acc: 13.3750\n",
      " |~~ val@10048  Loss: 0.002213 Acc: 13.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@10112  Loss: 0.002054 Acc: 13.3906\n",
      " |~~ val@10176  Loss: 0.002064 Acc: 13.3438\n",
      " |~~ val@10240  Loss: 0.002314 Acc: 13.2344\n",
      " |~~ val@10304  Loss: 0.002057 Acc: 13.3594\n",
      " |~~ val@10368  Loss: 0.002273 Acc: 13.3281\n",
      " |~~ val@10432  Loss: 0.002359 Acc: 13.2188\n",
      " |~~ val@10496  Loss: 0.002898 Acc: 13.1250\n",
      " |~~ val@10560  Loss: 0.002511 Acc: 13.3281\n",
      " |~~ val@10624  Loss: 0.002757 Acc: 13.1875\n",
      " |~~ val@10688  Loss: 0.002512 Acc: 13.2344\n",
      " |~~ val@10752  Loss: 0.002666 Acc: 13.2812\n",
      " |~~ val@10816  Loss: 0.002899 Acc: 13.0781\n",
      " |~~ val@10880  Loss: 0.002410 Acc: 13.2969\n",
      " |~~ val@10944  Loss: 0.002783 Acc: 13.1562\n",
      " |~~ val@11008  Loss: 0.002673 Acc: 13.2188\n",
      " |~~ val@11072  Loss: 0.002327 Acc: 13.3438\n",
      " |~~ val@11136  Loss: 0.002506 Acc: 13.3281\n",
      " |~~ val@11200  Loss: 0.002910 Acc: 13.1250\n",
      " |~~ val@11264  Loss: 0.002614 Acc: 13.1875\n",
      " |~~ val@11328  Loss: 0.001937 Acc: 13.4531\n",
      " |~~ val@11392  Loss: 0.002854 Acc: 13.0625\n",
      " |~~ val@11456  Loss: 0.002098 Acc: 13.3438\n",
      " |~~ val@11520  Loss: 0.002347 Acc: 13.2031\n",
      " |~~ val@11584  Loss: 0.002703 Acc: 13.2188\n",
      " |~~ val@11648  Loss: 0.002208 Acc: 13.3438\n",
      " |~~ val@11712  Loss: 0.002464 Acc: 13.3125\n",
      " |~~ val@11776  Loss: 0.002624 Acc: 13.0938\n",
      " |~~ val@11840  Loss: 0.002724 Acc: 13.1719\n",
      " |~~ val@11904  Loss: 0.003169 Acc: 13.0781\n",
      " |~~ val@11968  Loss: 0.002407 Acc: 13.2969\n",
      " |~~ val@12032  Loss: 0.002461 Acc: 13.2812\n",
      " |~~ val@12096  Loss: 0.002063 Acc: 13.3906\n",
      " |~~ val@12160  Loss: 0.002263 Acc: 13.2188\n",
      " |~~ val@12224  Loss: 0.002920 Acc: 13.1719\n",
      " |~~ val@12288  Loss: 0.002535 Acc: 13.1562\n",
      " |~~ val@12352  Loss: 0.002436 Acc: 13.2812\n",
      " |~~ val@12416  Loss: 0.002263 Acc: 13.2656\n",
      " |~~ val@12480  Loss: 0.002559 Acc: 13.2188\n",
      " |~~ val@12544  Loss: 0.002405 Acc: 13.2969\n",
      " |~~ val@12608  Loss: 0.002090 Acc: 13.4375\n",
      " |~~ val@12672  Loss: 0.002571 Acc: 13.1250\n",
      " |~~ val@12736  Loss: 0.002100 Acc: 13.4688\n",
      " |~~ val@12800  Loss: 0.001757 Acc: 13.5312\n",
      " |~~ val@12864  Loss: 0.002185 Acc: 13.3125\n",
      " |~~ val@12928  Loss: 0.002264 Acc: 13.3750\n",
      " |~~ val@12992  Loss: 0.002399 Acc: 13.2344\n",
      " |~~ val@13056  Loss: 0.002109 Acc: 13.2812\n",
      " |~~ val@13120  Loss: 0.002003 Acc: 13.4375\n",
      " |~~ val@13184  Loss: 0.002259 Acc: 13.3906\n",
      " |~~ val@13248  Loss: 0.002478 Acc: 13.2656\n",
      " |~~ val@13312  Loss: 0.002313 Acc: 13.3438\n",
      " |~~ val@13376  Loss: 0.002206 Acc: 13.3750\n",
      " |~~ val@13440  Loss: 0.002333 Acc: 13.2344\n",
      " |~~ val@13504  Loss: 0.001790 Acc: 13.5000\n",
      " |~~ val@13568  Loss: 0.002175 Acc: 13.2969\n",
      " |~~ val@13632  Loss: 0.001991 Acc: 13.4062\n",
      " |~~ val@13696  Loss: 0.002547 Acc: 13.2500\n",
      " |~~ val@13760  Loss: 0.002114 Acc: 13.2500\n",
      " |~~ val@13824  Loss: 0.002138 Acc: 13.2969\n",
      " |~~ val@13888  Loss: 0.002178 Acc: 13.4375\n",
      " |~~ val@13952  Loss: 0.002730 Acc: 13.2656\n",
      " |~~ val@14016  Loss: 0.002199 Acc: 13.4375\n",
      " |~~ val@14080  Loss: 0.001986 Acc: 13.3906\n",
      " |~~ val@14144  Loss: 0.002472 Acc: 13.3125\n",
      " |~~ val@14208  Loss: 0.003332 Acc: 12.9219\n",
      " |~~ val@14272  Loss: 0.002186 Acc: 13.3281\n",
      " |~~ val@14336  Loss: 0.002371 Acc: 13.2344\n",
      " |~~ val@14400  Loss: 0.002579 Acc: 13.2656\n",
      " |~~ val@14464  Loss: 0.002744 Acc: 13.1562\n",
      " |~~ val@14528  Loss: 0.002526 Acc: 13.2656\n",
      " |~~ val@14592  Loss: 0.002582 Acc: 13.3438\n",
      " |~~ val@14656  Loss: 0.002718 Acc: 13.2188\n",
      " |~~ val@14720  Loss: 0.003024 Acc: 13.0938\n",
      " |~~ val@14784  Loss: 0.002578 Acc: 13.2188\n",
      " |~~ val@14848  Loss: 0.002298 Acc: 13.3594\n",
      " |~~ val@14912  Loss: 0.003201 Acc: 13.1094\n",
      " |~~ val@14976  Loss: 0.002372 Acc: 13.2812\n",
      " |~~ val@15040  Loss: 0.001944 Acc: 13.4688\n",
      " |~~ val@15104  Loss: 0.002541 Acc: 13.2500\n",
      " |~~ val@15168  Loss: 0.002262 Acc: 13.2344\n",
      " |~~ val@15232  Loss: 0.002414 Acc: 13.3750\n",
      " |~~ val@15296  Loss: 0.002628 Acc: 13.1406\n",
      " |~~ val@15360  Loss: 0.001979 Acc: 13.5312\n",
      " |~~ val@15424  Loss: 0.002116 Acc: 13.2656\n",
      " |~~ val@15488  Loss: 0.002521 Acc: 13.2812\n",
      " |~~ val@15552  Loss: 0.002366 Acc: 13.2812\n",
      " |~~ val@15616  Loss: 0.002579 Acc: 13.1719\n",
      " |~~ val@15680  Loss: 0.002531 Acc: 13.2344\n",
      " |~~ val@15744  Loss: 0.002542 Acc: 13.2656\n",
      " |~~ val@15808  Loss: 0.002230 Acc: 13.2344\n",
      " |~~ val@15872  Loss: 0.002442 Acc: 13.2812\n",
      " |~~ val@15936  Loss: 0.002693 Acc: 13.1875\n",
      " |~~ val@16000  Loss: 0.002427 Acc: 13.3125\n",
      " |~~ val@16064  Loss: 0.002654 Acc: 13.2812\n",
      " |~~ val@16128  Loss: 0.002560 Acc: 13.2656\n",
      " |~~ val@16192  Loss: 0.002238 Acc: 13.3125\n",
      " |~~ val@16256  Loss: 0.002121 Acc: 13.3750\n",
      " |~~ val@16320  Loss: 0.001737 Acc: 13.5156\n",
      " |~~ val@16384  Loss: 0.001737 Acc: 13.5781\n",
      " |~~ val@16448  Loss: 0.002011 Acc: 13.3125\n",
      " |~~ val@16512  Loss: 0.002343 Acc: 13.3281\n",
      " |~~ val@16576  Loss: 0.002376 Acc: 13.2656\n",
      " |~~ val@16640  Loss: 0.002192 Acc: 13.3906\n",
      " |~~ val@16704  Loss: 0.002362 Acc: 13.3281\n",
      " |~~ val@16768  Loss: 0.002645 Acc: 13.2812\n",
      " |~~ val@16832  Loss: 0.002282 Acc: 13.3906\n",
      " |~~ val@16896  Loss: 0.002772 Acc: 13.1406\n",
      " |~~ val@16960  Loss: 0.002737 Acc: 13.1094\n",
      " |~~ val@17024  Loss: 0.002829 Acc: 13.1250\n",
      " |~~ val@17088  Loss: 0.002214 Acc: 13.4844\n",
      " |~~ val@17152  Loss: 0.001762 Acc: 13.4688\n",
      " |~~ val@17216  Loss: 0.002360 Acc: 13.2500\n",
      " |~~ val@17280  Loss: 0.002657 Acc: 13.2969\n",
      " |~~ val@17344  Loss: 0.001952 Acc: 13.3594\n",
      " |~~ val@17408  Loss: 0.002768 Acc: 13.1250\n",
      " |~~ val@17472  Loss: 0.002970 Acc: 13.1094\n",
      " |~~ val@17536  Loss: 0.002882 Acc: 13.1562\n",
      " |~~ val@17600  Loss: 0.002846 Acc: 13.1719\n",
      " |~~ val@17664  Loss: 0.002559 Acc: 13.1719\n",
      " |~~ val@17728  Loss: 0.002234 Acc: 13.3594\n",
      " |~~ val@17792  Loss: 0.003169 Acc: 12.8594\n",
      " |~~ val@17856  Loss: 0.002545 Acc: 13.1719\n",
      " |~~ val@17920  Loss: 0.001963 Acc: 13.4375\n",
      " |~~ val@17984  Loss: 0.002189 Acc: 13.3594\n",
      " |~~ val@18048  Loss: 0.002247 Acc: 13.3281\n",
      " |~~ val@18112  Loss: 0.002588 Acc: 13.2031\n",
      " |~~ val@18176  Loss: 0.001965 Acc: 13.4062\n",
      " |~~ val@18240  Loss: 0.002921 Acc: 13.0938\n",
      " |~~ val@18304  Loss: 0.002276 Acc: 13.3281\n",
      " |~~ val@18368  Loss: 0.002203 Acc: 13.3750\n",
      " |~~ val@18432  Loss: 0.002161 Acc: 13.2812\n",
      " |~~ val@18496  Loss: 0.002562 Acc: 13.2031\n",
      " |~~ val@18560  Loss: 0.002028 Acc: 13.3906\n",
      " |~~ val@18624  Loss: 0.001841 Acc: 13.4375\n",
      " |~~ val@18688  Loss: 0.002082 Acc: 13.4531\n",
      " |~~ val@18752  Loss: 0.002488 Acc: 13.3125\n",
      " |~~ val@18816  Loss: 0.002702 Acc: 13.2031\n",
      " |~~ val@18880  Loss: 0.002438 Acc: 13.2344\n",
      " |~~ val@18944  Loss: 0.002117 Acc: 13.3438\n",
      " |~~ val@19008  Loss: 0.002816 Acc: 13.1250\n",
      " |~~ val@19072  Loss: 0.001838 Acc: 13.4375\n",
      " |~~ val@19136  Loss: 0.003252 Acc: 13.0312\n",
      " |~~ val@19200  Loss: 0.002261 Acc: 13.3125\n",
      " |~~ val@19264  Loss: 0.002530 Acc: 13.1719\n",
      " |~~ val@19328  Loss: 0.001872 Acc: 13.4844\n",
      " |~~ val@19392  Loss: 0.002238 Acc: 13.3750\n",
      " |~~ val@19456  Loss: 0.002668 Acc: 13.2188\n",
      " |~~ val@19520  Loss: 0.002519 Acc: 13.2188\n",
      " |~~ val@19584  Loss: 0.002680 Acc: 13.2188\n",
      " |~~ val@19648  Loss: 0.002183 Acc: 13.3906\n",
      " |~~ val@19712  Loss: 0.002034 Acc: 13.3906\n",
      " |~~ val@19776  Loss: 0.003168 Acc: 12.9688\n",
      " |~~ val@19840  Loss: 0.002027 Acc: 13.4219\n",
      " |~~ val@19904  Loss: 0.002820 Acc: 13.0156\n",
      " |~~ val@19968  Loss: 0.002034 Acc: 13.3438\n",
      " |~~ val@20032  Loss: 0.003078 Acc: 13.1094\n",
      " |~~ val@20096  Loss: 0.002587 Acc: 13.2031\n",
      " |~~ val@20160  Loss: 0.002613 Acc: 13.2344\n",
      " |~~ val@20224  Loss: 0.002137 Acc: 13.4375\n",
      " |~~ val@20288  Loss: 0.002268 Acc: 13.3438\n",
      " |~~ val@20352  Loss: 0.002182 Acc: 13.3750\n",
      " |~~ val@20416  Loss: 0.002126 Acc: 13.4062\n",
      " |~~ val@20480  Loss: 0.002053 Acc: 13.4219\n",
      " |~~ val@20544  Loss: 0.002397 Acc: 13.3281\n",
      " |~~ val@20608  Loss: 0.002600 Acc: 13.2344\n",
      " |~~ val@20672  Loss: 0.002567 Acc: 13.1094\n",
      " |~~ val@20736  Loss: 0.001807 Acc: 13.4844\n",
      " |~~ val@20800  Loss: 0.002609 Acc: 13.3438\n",
      " |~~ val@20864  Loss: 0.001998 Acc: 13.5000\n",
      " |~~ val@20928  Loss: 0.002145 Acc: 13.3281\n",
      " |~~ val@20992  Loss: 0.002099 Acc: 13.4375\n",
      " |~~ val@21056  Loss: 0.002185 Acc: 13.3438\n",
      " |~~ val@21120  Loss: 0.001987 Acc: 13.3281\n",
      " |~~ val@21184  Loss: 0.002292 Acc: 13.2344\n",
      " |~~ val@21248  Loss: 0.002607 Acc: 13.2812\n",
      " |~~ val@21312  Loss: 0.002269 Acc: 13.3438\n",
      " |~~ val@21376  Loss: 0.002350 Acc: 13.4219\n",
      " |~~ val@21440  Loss: 0.002106 Acc: 13.3906\n",
      " |~~ val@21504  Loss: 0.002915 Acc: 13.1250\n",
      " |~~ val@21568  Loss: 0.002240 Acc: 13.2812\n",
      " |~~ val@21632  Loss: 0.002461 Acc: 13.2812\n",
      " |~~ val@21696  Loss: 0.002449 Acc: 13.3281\n",
      " |~~ val@21760  Loss: 0.002701 Acc: 13.1250\n",
      " |~~ val@21824  Loss: 0.002542 Acc: 13.2031\n",
      " |~~ val@21888  Loss: 0.002606 Acc: 13.1094\n",
      " |~~ val@21952  Loss: 0.001697 Acc: 13.4844\n",
      " |~~ val@22016  Loss: 0.001885 Acc: 13.4688\n",
      " |~~ val@22080  Loss: 0.002141 Acc: 13.3125\n",
      " |~~ val@22144  Loss: 0.002352 Acc: 13.3281\n",
      " |~~ val@22208  Loss: 0.002122 Acc: 13.4375\n",
      " |~~ val@22272  Loss: 0.002139 Acc: 13.3906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@22336  Loss: 0.002388 Acc: 13.2344\n",
      " |~~ val@22400  Loss: 0.002593 Acc: 13.2188\n",
      " |~~ val@22424  Loss: 0.004120 Acc: 13.4583\n",
      "val  Loss: 0.002396 Acc: 13.2829\n",
      "Epoch 3/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.002051 Acc: 13.3906\n",
      " |~~ train@128  Loss: 0.002169 Acc: 13.2656\n",
      " |~~ train@192  Loss: 0.003031 Acc: 13.0781\n",
      " |~~ train@256  Loss: 0.002123 Acc: 13.2031\n",
      " |~~ train@320  Loss: 0.002340 Acc: 13.3125\n",
      " |~~ train@384  Loss: 0.002041 Acc: 13.3281\n",
      " |~~ train@448  Loss: 0.002205 Acc: 13.2656\n",
      " |~~ train@512  Loss: 0.002491 Acc: 13.2344\n",
      " |~~ train@576  Loss: 0.002098 Acc: 13.3750\n",
      " |~~ train@640  Loss: 0.001888 Acc: 13.3750\n",
      " |~~ train@704  Loss: 0.002327 Acc: 13.2500\n",
      " |~~ train@768  Loss: 0.002461 Acc: 13.2500\n",
      " |~~ train@832  Loss: 0.002253 Acc: 13.3281\n",
      " |~~ train@896  Loss: 0.002000 Acc: 13.3594\n",
      " |~~ train@960  Loss: 0.002671 Acc: 13.1250\n",
      " |~~ train@1024  Loss: 0.001742 Acc: 13.4844\n",
      " |~~ train@1088  Loss: 0.002377 Acc: 13.2812\n",
      " |~~ train@1152  Loss: 0.002241 Acc: 13.2344\n",
      " |~~ train@1216  Loss: 0.001884 Acc: 13.4844\n",
      " |~~ train@1280  Loss: 0.001924 Acc: 13.4531\n",
      " |~~ train@1344  Loss: 0.002161 Acc: 13.3125\n",
      " |~~ train@1408  Loss: 0.002100 Acc: 13.4219\n",
      " |~~ train@1472  Loss: 0.002076 Acc: 13.4375\n",
      " |~~ train@1536  Loss: 0.002171 Acc: 13.3594\n",
      " |~~ train@1600  Loss: 0.002614 Acc: 13.1250\n",
      " |~~ train@1664  Loss: 0.002345 Acc: 13.4062\n",
      " |~~ train@1728  Loss: 0.002318 Acc: 13.2969\n",
      " |~~ train@1792  Loss: 0.001954 Acc: 13.4219\n",
      " |~~ train@1856  Loss: 0.001854 Acc: 13.5469\n",
      " |~~ train@1920  Loss: 0.002601 Acc: 13.2812\n",
      " |~~ train@1984  Loss: 0.001926 Acc: 13.3281\n",
      " |~~ train@2048  Loss: 0.002629 Acc: 13.2344\n",
      " |~~ train@2112  Loss: 0.002191 Acc: 13.3281\n",
      " |~~ train@2176  Loss: 0.002282 Acc: 13.2969\n",
      " |~~ train@2240  Loss: 0.002148 Acc: 13.3438\n",
      " |~~ train@2304  Loss: 0.001912 Acc: 13.4219\n",
      " |~~ train@2368  Loss: 0.002267 Acc: 13.2344\n",
      " |~~ train@2432  Loss: 0.002348 Acc: 13.2500\n",
      " |~~ train@2496  Loss: 0.002440 Acc: 13.3438\n",
      " |~~ train@2560  Loss: 0.001888 Acc: 13.4531\n",
      " |~~ train@2624  Loss: 0.002272 Acc: 13.2656\n",
      " |~~ train@2688  Loss: 0.002035 Acc: 13.3906\n",
      " |~~ train@2752  Loss: 0.002191 Acc: 13.3125\n",
      " |~~ train@2816  Loss: 0.002289 Acc: 13.2500\n",
      " |~~ train@2880  Loss: 0.001984 Acc: 13.4531\n",
      " |~~ train@2944  Loss: 0.002180 Acc: 13.4375\n",
      " |~~ train@3008  Loss: 0.002347 Acc: 13.2812\n",
      " |~~ train@3072  Loss: 0.002351 Acc: 13.2344\n",
      " |~~ train@3136  Loss: 0.002203 Acc: 13.2500\n",
      " |~~ train@3200  Loss: 0.001606 Acc: 13.4531\n",
      " |~~ train@3264  Loss: 0.002515 Acc: 13.1094\n",
      " |~~ train@3328  Loss: 0.002133 Acc: 13.2656\n",
      " |~~ train@3392  Loss: 0.001945 Acc: 13.3906\n",
      " |~~ train@3456  Loss: 0.002094 Acc: 13.2969\n",
      " |~~ train@3520  Loss: 0.002718 Acc: 13.1719\n",
      " |~~ train@3584  Loss: 0.002450 Acc: 13.1719\n",
      " |~~ train@3648  Loss: 0.002076 Acc: 13.5156\n",
      " |~~ train@3712  Loss: 0.002059 Acc: 13.3906\n",
      " |~~ train@3776  Loss: 0.002615 Acc: 13.1250\n",
      " |~~ train@3840  Loss: 0.001759 Acc: 13.5000\n",
      " |~~ train@3904  Loss: 0.002279 Acc: 13.3438\n",
      " |~~ train@3968  Loss: 0.002476 Acc: 13.3125\n",
      " |~~ train@4032  Loss: 0.002798 Acc: 13.0312\n",
      " |~~ train@4096  Loss: 0.002135 Acc: 13.3281\n",
      " |~~ train@4160  Loss: 0.002146 Acc: 13.3906\n",
      " |~~ train@4224  Loss: 0.001952 Acc: 13.3906\n",
      " |~~ train@4288  Loss: 0.001864 Acc: 13.5156\n",
      " |~~ train@4352  Loss: 0.002404 Acc: 13.2812\n",
      " |~~ train@4416  Loss: 0.002130 Acc: 13.3750\n",
      " |~~ train@4480  Loss: 0.002277 Acc: 13.3281\n",
      " |~~ train@4544  Loss: 0.001968 Acc: 13.4688\n",
      " |~~ train@4608  Loss: 0.002244 Acc: 13.3438\n",
      " |~~ train@4672  Loss: 0.002123 Acc: 13.3594\n",
      " |~~ train@4736  Loss: 0.001828 Acc: 13.4688\n",
      " |~~ train@4800  Loss: 0.002136 Acc: 13.3281\n",
      " |~~ train@4864  Loss: 0.002210 Acc: 13.3125\n",
      " |~~ train@4928  Loss: 0.002049 Acc: 13.3594\n",
      " |~~ train@4992  Loss: 0.002989 Acc: 12.9688\n",
      " |~~ train@5056  Loss: 0.002118 Acc: 13.3281\n",
      " |~~ train@5120  Loss: 0.002317 Acc: 13.2344\n",
      " |~~ train@5184  Loss: 0.001925 Acc: 13.4844\n",
      " |~~ train@5248  Loss: 0.002379 Acc: 13.2969\n",
      " |~~ train@5312  Loss: 0.002340 Acc: 13.3281\n",
      " |~~ train@5376  Loss: 0.002376 Acc: 13.2812\n",
      " |~~ train@5440  Loss: 0.002647 Acc: 13.1094\n",
      " |~~ train@5504  Loss: 0.002539 Acc: 13.1406\n",
      " |~~ train@5568  Loss: 0.002517 Acc: 13.1719\n",
      " |~~ train@5632  Loss: 0.002153 Acc: 13.4219\n",
      " |~~ train@5696  Loss: 0.002982 Acc: 13.0625\n",
      " |~~ train@5760  Loss: 0.002663 Acc: 13.1875\n",
      " |~~ train@5824  Loss: 0.002276 Acc: 13.2656\n",
      " |~~ train@5888  Loss: 0.001936 Acc: 13.4844\n",
      " |~~ train@5952  Loss: 0.002241 Acc: 13.2812\n",
      " |~~ train@6016  Loss: 0.002660 Acc: 13.0625\n",
      " |~~ train@6080  Loss: 0.001819 Acc: 13.5312\n",
      " |~~ train@6144  Loss: 0.002257 Acc: 13.2969\n",
      " |~~ train@6208  Loss: 0.001927 Acc: 13.3438\n",
      " |~~ train@6272  Loss: 0.001919 Acc: 13.4219\n",
      " |~~ train@6336  Loss: 0.002073 Acc: 13.3594\n",
      " |~~ train@6400  Loss: 0.002378 Acc: 13.2812\n",
      " |~~ train@6464  Loss: 0.002098 Acc: 13.3281\n",
      " |~~ train@6528  Loss: 0.002361 Acc: 13.3281\n",
      " |~~ train@6592  Loss: 0.001911 Acc: 13.4531\n",
      " |~~ train@6656  Loss: 0.002307 Acc: 13.3438\n",
      " |~~ train@6720  Loss: 0.002560 Acc: 13.2656\n",
      " |~~ train@6784  Loss: 0.002241 Acc: 13.2656\n",
      " |~~ train@6848  Loss: 0.002172 Acc: 13.3125\n",
      " |~~ train@6912  Loss: 0.002536 Acc: 13.2344\n",
      " |~~ train@6976  Loss: 0.001673 Acc: 13.4531\n",
      " |~~ train@7040  Loss: 0.002264 Acc: 13.3750\n",
      " |~~ train@7104  Loss: 0.002121 Acc: 13.2812\n",
      " |~~ train@7168  Loss: 0.002024 Acc: 13.3438\n",
      " |~~ train@7232  Loss: 0.002260 Acc: 13.3125\n",
      " |~~ train@7296  Loss: 0.002367 Acc: 13.2812\n",
      " |~~ train@7360  Loss: 0.001646 Acc: 13.5156\n",
      " |~~ train@7424  Loss: 0.002289 Acc: 13.4062\n",
      " |~~ train@7488  Loss: 0.002586 Acc: 13.2656\n",
      " |~~ train@7552  Loss: 0.001992 Acc: 13.3750\n",
      " |~~ train@7616  Loss: 0.001818 Acc: 13.4531\n",
      " |~~ train@7680  Loss: 0.002089 Acc: 13.3281\n",
      " |~~ train@7744  Loss: 0.002285 Acc: 13.3750\n",
      " |~~ train@7808  Loss: 0.002481 Acc: 13.2188\n",
      " |~~ train@7872  Loss: 0.002128 Acc: 13.3438\n",
      " |~~ train@7936  Loss: 0.002271 Acc: 13.2969\n",
      " |~~ train@8000  Loss: 0.001835 Acc: 13.4219\n",
      " |~~ train@8064  Loss: 0.002245 Acc: 13.2500\n",
      " |~~ train@8128  Loss: 0.002027 Acc: 13.3438\n",
      " |~~ train@8192  Loss: 0.002461 Acc: 13.2188\n",
      " |~~ train@8256  Loss: 0.002201 Acc: 13.2500\n",
      " |~~ train@8320  Loss: 0.003202 Acc: 13.0469\n",
      " |~~ train@8384  Loss: 0.002503 Acc: 13.2344\n",
      " |~~ train@8448  Loss: 0.002213 Acc: 13.2656\n",
      " |~~ train@8512  Loss: 0.002102 Acc: 13.2969\n",
      " |~~ train@8576  Loss: 0.002586 Acc: 13.2344\n",
      " |~~ train@8640  Loss: 0.001883 Acc: 13.4375\n",
      " |~~ train@8704  Loss: 0.002486 Acc: 13.2500\n",
      " |~~ train@8768  Loss: 0.002212 Acc: 13.2500\n",
      " |~~ train@8832  Loss: 0.002632 Acc: 13.2031\n",
      " |~~ train@8896  Loss: 0.002356 Acc: 13.3125\n",
      " |~~ train@8960  Loss: 0.002840 Acc: 13.1562\n",
      " |~~ train@9024  Loss: 0.001878 Acc: 13.4375\n",
      " |~~ train@9088  Loss: 0.002394 Acc: 13.2188\n",
      " |~~ train@9152  Loss: 0.002472 Acc: 13.2812\n",
      " |~~ train@9216  Loss: 0.002031 Acc: 13.3750\n",
      " |~~ train@9280  Loss: 0.003331 Acc: 12.9062\n",
      " |~~ train@9344  Loss: 0.002447 Acc: 13.2656\n",
      " |~~ train@9408  Loss: 0.002344 Acc: 13.3125\n",
      " |~~ train@9472  Loss: 0.002177 Acc: 13.2656\n",
      " |~~ train@9536  Loss: 0.002011 Acc: 13.4375\n",
      " |~~ train@9600  Loss: 0.002572 Acc: 13.2344\n",
      " |~~ train@9664  Loss: 0.002004 Acc: 13.3438\n",
      " |~~ train@9728  Loss: 0.002319 Acc: 13.2500\n",
      " |~~ train@9792  Loss: 0.001950 Acc: 13.3750\n",
      " |~~ train@9856  Loss: 0.002705 Acc: 13.0469\n",
      " |~~ train@9920  Loss: 0.002232 Acc: 13.3281\n",
      " |~~ train@9984  Loss: 0.002062 Acc: 13.4062\n",
      " |~~ train@10048  Loss: 0.002387 Acc: 13.2500\n",
      " |~~ train@10112  Loss: 0.001995 Acc: 13.4062\n",
      " |~~ train@10176  Loss: 0.002385 Acc: 13.2500\n",
      " |~~ train@10240  Loss: 0.002130 Acc: 13.4688\n",
      " |~~ train@10304  Loss: 0.002112 Acc: 13.3750\n",
      " |~~ train@10368  Loss: 0.002628 Acc: 13.2031\n",
      " |~~ train@10432  Loss: 0.002438 Acc: 13.2656\n",
      " |~~ train@10496  Loss: 0.002156 Acc: 13.2656\n",
      " |~~ train@10560  Loss: 0.002039 Acc: 13.3906\n",
      " |~~ train@10624  Loss: 0.001771 Acc: 13.4375\n",
      " |~~ train@10688  Loss: 0.002071 Acc: 13.2969\n",
      " |~~ train@10752  Loss: 0.002715 Acc: 13.1250\n",
      " |~~ train@10816  Loss: 0.002041 Acc: 13.4219\n",
      " |~~ train@10880  Loss: 0.002239 Acc: 13.2656\n",
      " |~~ train@10944  Loss: 0.002082 Acc: 13.4219\n",
      " |~~ train@11008  Loss: 0.002336 Acc: 13.2969\n",
      " |~~ train@11072  Loss: 0.002530 Acc: 13.1562\n",
      " |~~ train@11136  Loss: 0.002550 Acc: 13.2031\n",
      " |~~ train@11200  Loss: 0.002506 Acc: 13.2812\n",
      " |~~ train@11264  Loss: 0.002389 Acc: 13.2031\n",
      " |~~ train@11328  Loss: 0.002323 Acc: 13.2656\n",
      " |~~ train@11392  Loss: 0.002405 Acc: 13.2031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@11456  Loss: 0.002343 Acc: 13.2500\n",
      " |~~ train@11520  Loss: 0.002236 Acc: 13.3281\n",
      " |~~ train@11584  Loss: 0.001793 Acc: 13.5000\n",
      " |~~ train@11648  Loss: 0.002435 Acc: 13.2344\n",
      " |~~ train@11712  Loss: 0.002656 Acc: 13.1719\n",
      " |~~ train@11776  Loss: 0.002884 Acc: 13.1719\n",
      " |~~ train@11840  Loss: 0.002250 Acc: 13.2812\n",
      " |~~ train@11904  Loss: 0.002631 Acc: 13.1250\n",
      " |~~ train@11968  Loss: 0.002232 Acc: 13.2344\n",
      " |~~ train@12032  Loss: 0.002102 Acc: 13.2969\n",
      " |~~ train@12096  Loss: 0.002274 Acc: 13.2969\n",
      " |~~ train@12160  Loss: 0.002084 Acc: 13.4531\n",
      " |~~ train@12224  Loss: 0.002358 Acc: 13.2656\n",
      " |~~ train@12288  Loss: 0.002000 Acc: 13.3906\n",
      " |~~ train@12352  Loss: 0.002200 Acc: 13.2812\n",
      " |~~ train@12416  Loss: 0.002215 Acc: 13.3281\n",
      " |~~ train@12480  Loss: 0.002040 Acc: 13.3438\n",
      " |~~ train@12544  Loss: 0.001836 Acc: 13.4688\n",
      " |~~ train@12608  Loss: 0.001901 Acc: 13.3906\n",
      " |~~ train@12672  Loss: 0.002166 Acc: 13.3594\n",
      " |~~ train@12736  Loss: 0.002340 Acc: 13.3281\n",
      " |~~ train@12800  Loss: 0.001941 Acc: 13.4062\n",
      " |~~ train@12864  Loss: 0.002382 Acc: 13.2656\n",
      " |~~ train@12928  Loss: 0.001871 Acc: 13.3906\n",
      " |~~ train@12992  Loss: 0.001727 Acc: 13.4688\n",
      " |~~ train@13056  Loss: 0.001882 Acc: 13.3594\n",
      " |~~ train@13120  Loss: 0.002431 Acc: 13.3281\n",
      " |~~ train@13184  Loss: 0.002320 Acc: 13.2969\n",
      " |~~ train@13248  Loss: 0.002486 Acc: 13.2344\n",
      " |~~ train@13312  Loss: 0.002342 Acc: 13.2969\n",
      " |~~ train@13376  Loss: 0.001661 Acc: 13.5000\n",
      " |~~ train@13440  Loss: 0.002648 Acc: 13.1562\n",
      " |~~ train@13504  Loss: 0.002145 Acc: 13.2500\n",
      " |~~ train@13568  Loss: 0.002378 Acc: 13.2969\n",
      " |~~ train@13632  Loss: 0.002095 Acc: 13.3594\n",
      " |~~ train@13696  Loss: 0.002357 Acc: 13.2188\n",
      " |~~ train@13760  Loss: 0.001796 Acc: 13.4375\n",
      " |~~ train@13824  Loss: 0.002663 Acc: 13.1094\n",
      " |~~ train@13888  Loss: 0.002161 Acc: 13.3438\n",
      " |~~ train@13952  Loss: 0.002287 Acc: 13.3594\n",
      " |~~ train@14016  Loss: 0.001746 Acc: 13.5156\n",
      " |~~ train@14080  Loss: 0.002760 Acc: 13.0938\n",
      " |~~ train@14144  Loss: 0.002357 Acc: 13.2812\n",
      " |~~ train@14208  Loss: 0.002168 Acc: 13.3281\n",
      " |~~ train@14272  Loss: 0.002126 Acc: 13.3594\n",
      " |~~ train@14336  Loss: 0.001949 Acc: 13.3594\n",
      " |~~ train@14400  Loss: 0.002059 Acc: 13.4062\n",
      " |~~ train@14464  Loss: 0.002272 Acc: 13.2500\n",
      " |~~ train@14528  Loss: 0.002737 Acc: 13.1719\n",
      " |~~ train@14592  Loss: 0.002167 Acc: 13.3906\n",
      " |~~ train@14656  Loss: 0.002154 Acc: 13.3281\n",
      " |~~ train@14720  Loss: 0.001581 Acc: 13.5469\n",
      " |~~ train@14784  Loss: 0.002355 Acc: 13.2812\n",
      " |~~ train@14848  Loss: 0.002737 Acc: 13.0625\n",
      " |~~ train@14912  Loss: 0.002087 Acc: 13.2969\n",
      " |~~ train@14976  Loss: 0.002672 Acc: 13.1562\n",
      " |~~ train@15040  Loss: 0.002243 Acc: 13.2812\n",
      " |~~ train@15104  Loss: 0.001800 Acc: 13.3750\n",
      " |~~ train@15168  Loss: 0.001999 Acc: 13.4062\n",
      " |~~ train@15232  Loss: 0.002387 Acc: 13.1406\n",
      " |~~ train@15296  Loss: 0.002381 Acc: 13.2188\n",
      " |~~ train@15360  Loss: 0.002404 Acc: 13.2344\n",
      " |~~ train@15424  Loss: 0.002158 Acc: 13.3594\n",
      " |~~ train@15488  Loss: 0.002318 Acc: 13.3281\n",
      " |~~ train@15552  Loss: 0.001897 Acc: 13.3906\n",
      " |~~ train@15616  Loss: 0.002139 Acc: 13.3750\n",
      " |~~ train@15680  Loss: 0.002077 Acc: 13.4062\n",
      " |~~ train@15744  Loss: 0.002168 Acc: 13.2969\n",
      " |~~ train@15808  Loss: 0.002201 Acc: 13.3438\n",
      " |~~ train@15872  Loss: 0.001875 Acc: 13.4688\n",
      " |~~ train@15936  Loss: 0.002134 Acc: 13.2812\n",
      " |~~ train@16000  Loss: 0.002217 Acc: 13.2656\n",
      " |~~ train@16064  Loss: 0.002102 Acc: 13.4219\n",
      " |~~ train@16128  Loss: 0.002259 Acc: 13.2500\n",
      " |~~ train@16192  Loss: 0.002187 Acc: 13.2969\n",
      " |~~ train@16256  Loss: 0.002428 Acc: 13.2500\n",
      " |~~ train@16320  Loss: 0.002530 Acc: 13.2031\n",
      " |~~ train@16384  Loss: 0.002888 Acc: 13.0625\n",
      " |~~ train@16448  Loss: 0.002399 Acc: 13.3281\n",
      " |~~ train@16512  Loss: 0.002336 Acc: 13.2812\n",
      " |~~ train@16576  Loss: 0.002559 Acc: 13.2500\n",
      " |~~ train@16640  Loss: 0.001893 Acc: 13.4062\n",
      " |~~ train@16704  Loss: 0.001974 Acc: 13.4219\n",
      " |~~ train@16768  Loss: 0.002623 Acc: 13.2031\n",
      " |~~ train@16832  Loss: 0.002247 Acc: 13.3125\n",
      " |~~ train@16896  Loss: 0.001801 Acc: 13.4219\n",
      " |~~ train@16960  Loss: 0.002039 Acc: 13.4219\n",
      " |~~ train@17024  Loss: 0.002133 Acc: 13.2812\n",
      " |~~ train@17088  Loss: 0.002113 Acc: 13.4062\n",
      " |~~ train@17152  Loss: 0.002523 Acc: 13.1562\n",
      " |~~ train@17216  Loss: 0.002422 Acc: 13.2969\n",
      " |~~ train@17280  Loss: 0.002316 Acc: 13.3438\n",
      " |~~ train@17344  Loss: 0.001589 Acc: 13.5312\n",
      " |~~ train@17408  Loss: 0.002849 Acc: 13.1250\n",
      " |~~ train@17472  Loss: 0.002285 Acc: 13.2500\n",
      " |~~ train@17536  Loss: 0.001840 Acc: 13.4844\n",
      " |~~ train@17600  Loss: 0.002584 Acc: 13.1875\n",
      " |~~ train@17664  Loss: 0.002110 Acc: 13.3438\n",
      " |~~ train@17728  Loss: 0.002149 Acc: 13.3438\n",
      " |~~ train@17792  Loss: 0.001706 Acc: 13.5312\n",
      " |~~ train@17856  Loss: 0.002241 Acc: 13.3281\n",
      " |~~ train@17920  Loss: 0.002308 Acc: 13.2031\n",
      " |~~ train@17984  Loss: 0.002036 Acc: 13.3750\n",
      " |~~ train@18048  Loss: 0.002650 Acc: 13.1719\n",
      " |~~ train@18112  Loss: 0.002351 Acc: 13.2656\n",
      " |~~ train@18176  Loss: 0.002375 Acc: 13.2812\n",
      " |~~ train@18240  Loss: 0.002188 Acc: 13.2812\n",
      " |~~ train@18304  Loss: 0.002921 Acc: 13.1094\n",
      " |~~ train@18368  Loss: 0.002195 Acc: 13.3281\n",
      " |~~ train@18432  Loss: 0.002260 Acc: 13.3438\n",
      " |~~ train@18496  Loss: 0.002127 Acc: 13.3594\n",
      " |~~ train@18560  Loss: 0.002093 Acc: 13.3281\n",
      " |~~ train@18624  Loss: 0.002122 Acc: 13.2812\n",
      " |~~ train@18688  Loss: 0.002670 Acc: 13.2344\n",
      " |~~ train@18752  Loss: 0.002089 Acc: 13.2344\n",
      " |~~ train@18816  Loss: 0.002621 Acc: 13.1094\n",
      " |~~ train@18880  Loss: 0.001951 Acc: 13.4062\n",
      " |~~ train@18944  Loss: 0.002042 Acc: 13.4688\n",
      " |~~ train@19008  Loss: 0.002295 Acc: 13.2344\n",
      " |~~ train@19072  Loss: 0.002950 Acc: 13.0312\n",
      " |~~ train@19136  Loss: 0.002377 Acc: 13.2344\n",
      " |~~ train@19200  Loss: 0.002156 Acc: 13.3750\n",
      " |~~ train@19264  Loss: 0.002139 Acc: 13.2344\n",
      " |~~ train@19328  Loss: 0.001730 Acc: 13.5781\n",
      " |~~ train@19392  Loss: 0.001736 Acc: 13.4844\n",
      " |~~ train@19456  Loss: 0.002029 Acc: 13.3594\n",
      " |~~ train@19520  Loss: 0.002197 Acc: 13.2656\n",
      " |~~ train@19584  Loss: 0.002109 Acc: 13.3281\n",
      " |~~ train@19648  Loss: 0.001737 Acc: 13.4531\n",
      " |~~ train@19712  Loss: 0.001795 Acc: 13.5312\n",
      " |~~ train@19776  Loss: 0.002245 Acc: 13.3281\n",
      " |~~ train@19840  Loss: 0.002237 Acc: 13.3594\n",
      " |~~ train@19904  Loss: 0.002152 Acc: 13.4062\n",
      " |~~ train@19968  Loss: 0.002502 Acc: 13.1406\n",
      " |~~ train@20032  Loss: 0.001612 Acc: 13.5469\n",
      " |~~ train@20096  Loss: 0.002623 Acc: 13.0938\n",
      " |~~ train@20160  Loss: 0.002503 Acc: 13.2500\n",
      " |~~ train@20224  Loss: 0.002745 Acc: 13.2031\n",
      " |~~ train@20288  Loss: 0.002099 Acc: 13.3438\n",
      " |~~ train@20352  Loss: 0.002576 Acc: 13.2344\n",
      " |~~ train@20416  Loss: 0.002318 Acc: 13.2500\n",
      " |~~ train@20480  Loss: 0.002372 Acc: 13.3125\n",
      " |~~ train@20544  Loss: 0.001970 Acc: 13.4844\n",
      " |~~ train@20608  Loss: 0.001910 Acc: 13.3906\n",
      " |~~ train@20672  Loss: 0.002206 Acc: 13.3438\n",
      " |~~ train@20736  Loss: 0.002374 Acc: 13.2188\n",
      " |~~ train@20800  Loss: 0.002600 Acc: 13.2500\n",
      " |~~ train@20864  Loss: 0.002791 Acc: 13.1094\n",
      " |~~ train@20928  Loss: 0.002014 Acc: 13.4688\n",
      " |~~ train@20992  Loss: 0.001892 Acc: 13.4531\n",
      " |~~ train@21056  Loss: 0.001875 Acc: 13.4531\n",
      " |~~ train@21120  Loss: 0.002999 Acc: 13.0781\n",
      " |~~ train@21184  Loss: 0.002176 Acc: 13.2969\n",
      " |~~ train@21248  Loss: 0.001923 Acc: 13.4688\n",
      " |~~ train@21312  Loss: 0.002328 Acc: 13.1875\n",
      " |~~ train@21376  Loss: 0.002505 Acc: 13.2188\n",
      " |~~ train@21440  Loss: 0.002042 Acc: 13.3281\n",
      " |~~ train@21504  Loss: 0.002750 Acc: 13.1250\n",
      " |~~ train@21568  Loss: 0.002189 Acc: 13.3438\n",
      " |~~ train@21632  Loss: 0.001879 Acc: 13.5000\n",
      " |~~ train@21696  Loss: 0.002330 Acc: 13.3594\n",
      " |~~ train@21760  Loss: 0.002440 Acc: 13.2656\n",
      " |~~ train@21824  Loss: 0.001695 Acc: 13.4375\n",
      " |~~ train@21888  Loss: 0.002040 Acc: 13.4844\n",
      " |~~ train@21952  Loss: 0.002274 Acc: 13.2188\n",
      " |~~ train@22016  Loss: 0.002138 Acc: 13.3906\n",
      " |~~ train@22080  Loss: 0.002277 Acc: 13.3438\n",
      " |~~ train@22144  Loss: 0.002098 Acc: 13.4219\n",
      " |~~ train@22208  Loss: 0.002126 Acc: 13.3906\n",
      " |~~ train@22272  Loss: 0.003136 Acc: 13.0625\n",
      " |~~ train@22336  Loss: 0.001969 Acc: 13.3750\n",
      " |~~ train@22400  Loss: 0.002217 Acc: 13.2656\n",
      " |~~ train@22464  Loss: 0.002088 Acc: 13.3906\n",
      " |~~ train@22528  Loss: 0.001881 Acc: 13.4531\n",
      " |~~ train@22592  Loss: 0.002061 Acc: 13.3906\n",
      " |~~ train@22656  Loss: 0.002447 Acc: 13.2969\n",
      " |~~ train@22720  Loss: 0.002733 Acc: 13.0781\n",
      " |~~ train@22784  Loss: 0.001907 Acc: 13.5000\n",
      " |~~ train@22848  Loss: 0.002608 Acc: 13.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@22912  Loss: 0.002143 Acc: 13.2656\n",
      " |~~ train@22976  Loss: 0.002905 Acc: 13.0000\n",
      " |~~ train@23040  Loss: 0.002362 Acc: 13.2031\n",
      " |~~ train@23104  Loss: 0.002197 Acc: 13.3750\n",
      " |~~ train@23168  Loss: 0.002487 Acc: 13.1875\n",
      " |~~ train@23232  Loss: 0.002336 Acc: 13.2812\n",
      " |~~ train@23296  Loss: 0.002264 Acc: 13.3125\n",
      " |~~ train@23360  Loss: 0.002112 Acc: 13.2500\n",
      " |~~ train@23424  Loss: 0.002186 Acc: 13.3750\n",
      " |~~ train@23488  Loss: 0.002300 Acc: 13.2969\n",
      " |~~ train@23552  Loss: 0.002523 Acc: 13.1250\n",
      " |~~ train@23616  Loss: 0.002474 Acc: 13.1406\n",
      " |~~ train@23680  Loss: 0.002055 Acc: 13.4219\n",
      " |~~ train@23744  Loss: 0.002685 Acc: 13.1875\n",
      " |~~ train@23808  Loss: 0.002005 Acc: 13.4375\n",
      " |~~ train@23872  Loss: 0.002058 Acc: 13.4688\n",
      " |~~ train@23936  Loss: 0.002196 Acc: 13.3750\n",
      " |~~ train@24000  Loss: 0.002686 Acc: 13.2656\n",
      " |~~ train@24064  Loss: 0.002296 Acc: 13.3438\n",
      " |~~ train@24128  Loss: 0.002371 Acc: 13.2500\n",
      " |~~ train@24192  Loss: 0.002509 Acc: 13.2656\n",
      " |~~ train@24256  Loss: 0.002033 Acc: 13.3281\n",
      " |~~ train@24320  Loss: 0.001977 Acc: 13.4375\n",
      " |~~ train@24384  Loss: 0.001503 Acc: 13.5781\n",
      " |~~ train@24448  Loss: 0.002513 Acc: 13.2344\n",
      " |~~ train@24512  Loss: 0.002354 Acc: 13.2969\n",
      " |~~ train@24576  Loss: 0.002464 Acc: 13.3125\n",
      " |~~ train@24640  Loss: 0.002158 Acc: 13.2656\n",
      " |~~ train@24704  Loss: 0.001888 Acc: 13.4688\n",
      " |~~ train@24768  Loss: 0.002471 Acc: 13.2031\n",
      " |~~ train@24832  Loss: 0.002339 Acc: 13.2344\n",
      " |~~ train@24896  Loss: 0.002534 Acc: 13.2500\n",
      " |~~ train@24960  Loss: 0.002518 Acc: 13.1875\n",
      " |~~ train@25024  Loss: 0.001725 Acc: 13.4531\n",
      " |~~ train@25088  Loss: 0.002481 Acc: 13.0938\n",
      " |~~ train@25152  Loss: 0.002071 Acc: 13.2969\n",
      " |~~ train@25216  Loss: 0.002307 Acc: 13.2812\n",
      " |~~ train@25280  Loss: 0.002273 Acc: 13.2344\n",
      " |~~ train@25344  Loss: 0.002399 Acc: 13.2500\n",
      " |~~ train@25408  Loss: 0.002157 Acc: 13.3750\n",
      " |~~ train@25472  Loss: 0.002588 Acc: 13.2031\n",
      " |~~ train@25536  Loss: 0.002685 Acc: 13.0938\n",
      " |~~ train@25600  Loss: 0.002248 Acc: 13.3125\n",
      " |~~ train@25664  Loss: 0.002167 Acc: 13.3594\n",
      " |~~ train@25728  Loss: 0.001874 Acc: 13.5156\n",
      " |~~ train@25792  Loss: 0.002022 Acc: 13.4062\n",
      " |~~ train@25856  Loss: 0.001963 Acc: 13.4688\n",
      " |~~ train@25920  Loss: 0.002248 Acc: 13.3125\n",
      " |~~ train@25984  Loss: 0.002553 Acc: 13.2188\n",
      " |~~ train@26048  Loss: 0.001524 Acc: 13.4688\n",
      " |~~ train@26112  Loss: 0.003062 Acc: 12.9844\n",
      " |~~ train@26176  Loss: 0.002285 Acc: 13.3125\n",
      " |~~ train@26240  Loss: 0.002073 Acc: 13.4375\n",
      " |~~ train@26304  Loss: 0.002072 Acc: 13.3438\n",
      " |~~ train@26368  Loss: 0.002626 Acc: 13.2031\n",
      " |~~ train@26432  Loss: 0.002240 Acc: 13.2656\n",
      " |~~ train@26496  Loss: 0.002805 Acc: 13.0469\n",
      " |~~ train@26560  Loss: 0.002057 Acc: 13.3906\n",
      " |~~ train@26624  Loss: 0.002508 Acc: 13.2969\n",
      " |~~ train@26688  Loss: 0.002050 Acc: 13.3125\n",
      " |~~ train@26752  Loss: 0.002104 Acc: 13.4219\n",
      " |~~ train@26816  Loss: 0.002400 Acc: 13.1250\n",
      " |~~ train@26880  Loss: 0.001811 Acc: 13.5000\n",
      " |~~ train@26944  Loss: 0.001961 Acc: 13.3438\n",
      " |~~ train@27008  Loss: 0.002576 Acc: 13.1875\n",
      " |~~ train@27072  Loss: 0.002170 Acc: 13.3438\n",
      " |~~ train@27136  Loss: 0.002533 Acc: 13.2188\n",
      " |~~ train@27200  Loss: 0.002744 Acc: 13.2188\n",
      " |~~ train@27264  Loss: 0.002220 Acc: 13.2656\n",
      " |~~ train@27328  Loss: 0.002119 Acc: 13.3906\n",
      " |~~ train@27392  Loss: 0.002389 Acc: 13.3438\n",
      " |~~ train@27456  Loss: 0.001773 Acc: 13.5156\n",
      " |~~ train@27520  Loss: 0.002146 Acc: 13.3438\n",
      " |~~ train@27584  Loss: 0.002407 Acc: 13.2031\n",
      " |~~ train@27648  Loss: 0.002159 Acc: 13.2969\n",
      " |~~ train@27712  Loss: 0.002146 Acc: 13.3594\n",
      " |~~ train@27776  Loss: 0.002537 Acc: 13.2188\n",
      " |~~ train@27840  Loss: 0.002212 Acc: 13.3281\n",
      " |~~ train@27904  Loss: 0.002105 Acc: 13.3438\n",
      " |~~ train@27968  Loss: 0.002317 Acc: 13.2812\n",
      " |~~ train@28032  Loss: 0.001628 Acc: 13.5781\n",
      " |~~ train@28096  Loss: 0.002773 Acc: 13.1719\n",
      " |~~ train@28160  Loss: 0.002630 Acc: 13.1875\n",
      " |~~ train@28224  Loss: 0.002182 Acc: 13.2188\n",
      " |~~ train@28288  Loss: 0.002197 Acc: 13.3750\n",
      " |~~ train@28352  Loss: 0.002228 Acc: 13.3750\n",
      " |~~ train@28416  Loss: 0.001703 Acc: 13.4219\n",
      " |~~ train@28480  Loss: 0.002586 Acc: 13.1406\n",
      " |~~ train@28544  Loss: 0.002616 Acc: 13.1406\n",
      " |~~ train@28608  Loss: 0.002809 Acc: 13.0156\n",
      " |~~ train@28672  Loss: 0.002839 Acc: 13.1094\n",
      " |~~ train@28736  Loss: 0.002315 Acc: 13.3281\n",
      " |~~ train@28800  Loss: 0.002166 Acc: 13.2812\n",
      " |~~ train@28864  Loss: 0.002121 Acc: 13.2969\n",
      " |~~ train@28928  Loss: 0.002091 Acc: 13.3281\n",
      " |~~ train@28992  Loss: 0.002216 Acc: 13.3594\n",
      " |~~ train@29056  Loss: 0.002171 Acc: 13.3281\n",
      " |~~ train@29120  Loss: 0.002555 Acc: 13.1875\n",
      " |~~ train@29184  Loss: 0.002592 Acc: 13.2031\n",
      " |~~ train@29248  Loss: 0.002155 Acc: 13.3750\n",
      " |~~ train@29312  Loss: 0.002418 Acc: 13.1875\n",
      " |~~ train@29376  Loss: 0.001747 Acc: 13.4844\n",
      " |~~ train@29440  Loss: 0.002086 Acc: 13.4219\n",
      " |~~ train@29504  Loss: 0.002601 Acc: 13.2656\n",
      " |~~ train@29568  Loss: 0.001880 Acc: 13.4688\n",
      " |~~ train@29632  Loss: 0.002060 Acc: 13.4062\n",
      " |~~ train@29696  Loss: 0.002133 Acc: 13.3906\n",
      " |~~ train@29760  Loss: 0.002146 Acc: 13.2188\n",
      " |~~ train@29824  Loss: 0.002554 Acc: 13.2188\n",
      " |~~ train@29888  Loss: 0.002053 Acc: 13.3750\n",
      " |~~ train@29952  Loss: 0.001759 Acc: 13.4375\n",
      " |~~ train@30016  Loss: 0.001994 Acc: 13.4688\n",
      " |~~ train@30080  Loss: 0.002327 Acc: 13.2656\n",
      " |~~ train@30144  Loss: 0.002254 Acc: 13.3281\n",
      " |~~ train@30208  Loss: 0.002317 Acc: 13.2500\n",
      " |~~ train@30272  Loss: 0.002022 Acc: 13.4531\n",
      " |~~ train@30336  Loss: 0.002396 Acc: 13.2969\n",
      " |~~ train@30400  Loss: 0.002709 Acc: 13.1719\n",
      " |~~ train@30464  Loss: 0.002548 Acc: 13.1719\n",
      " |~~ train@30528  Loss: 0.002162 Acc: 13.2969\n",
      " |~~ train@30592  Loss: 0.002335 Acc: 13.1875\n",
      " |~~ train@30656  Loss: 0.001895 Acc: 13.3438\n",
      " |~~ train@30720  Loss: 0.002585 Acc: 13.2500\n",
      " |~~ train@30784  Loss: 0.001785 Acc: 13.5000\n",
      " |~~ train@30848  Loss: 0.002348 Acc: 13.3750\n",
      " |~~ train@30912  Loss: 0.002579 Acc: 13.2031\n",
      " |~~ train@30976  Loss: 0.002521 Acc: 13.1719\n",
      " |~~ train@31040  Loss: 0.001817 Acc: 13.5625\n",
      " |~~ train@31104  Loss: 0.001822 Acc: 13.5625\n",
      " |~~ train@31168  Loss: 0.002086 Acc: 13.3125\n",
      " |~~ train@31232  Loss: 0.002431 Acc: 13.2031\n",
      " |~~ train@31296  Loss: 0.002376 Acc: 13.3125\n",
      " |~~ train@31360  Loss: 0.002402 Acc: 13.2812\n",
      " |~~ train@31424  Loss: 0.002343 Acc: 13.1719\n",
      " |~~ train@31488  Loss: 0.002438 Acc: 13.1250\n",
      " |~~ train@31552  Loss: 0.002216 Acc: 13.2344\n",
      " |~~ train@31616  Loss: 0.002036 Acc: 13.4219\n",
      " |~~ train@31680  Loss: 0.001957 Acc: 13.3125\n",
      " |~~ train@31744  Loss: 0.002486 Acc: 13.2031\n",
      " |~~ train@31808  Loss: 0.001873 Acc: 13.4375\n",
      " |~~ train@31872  Loss: 0.001748 Acc: 13.5312\n",
      " |~~ train@31936  Loss: 0.002155 Acc: 13.2500\n",
      " |~~ train@32000  Loss: 0.002150 Acc: 13.2969\n",
      " |~~ train@32064  Loss: 0.002042 Acc: 13.3750\n",
      " |~~ train@32128  Loss: 0.002074 Acc: 13.4062\n",
      " |~~ train@32192  Loss: 0.002407 Acc: 13.2188\n",
      " |~~ train@32256  Loss: 0.002228 Acc: 13.2500\n",
      " |~~ train@32320  Loss: 0.002498 Acc: 13.2656\n",
      " |~~ train@32384  Loss: 0.001778 Acc: 13.4844\n",
      " |~~ train@32448  Loss: 0.002611 Acc: 13.2500\n",
      " |~~ train@32512  Loss: 0.002064 Acc: 13.3906\n",
      " |~~ train@32576  Loss: 0.002384 Acc: 13.3125\n",
      " |~~ train@32640  Loss: 0.002338 Acc: 13.2812\n",
      " |~~ train@32704  Loss: 0.001973 Acc: 13.5156\n",
      " |~~ train@32768  Loss: 0.002120 Acc: 13.2969\n",
      " |~~ train@32832  Loss: 0.001759 Acc: 13.5000\n",
      " |~~ train@32896  Loss: 0.002118 Acc: 13.3281\n",
      " |~~ train@32960  Loss: 0.002589 Acc: 13.1719\n",
      " |~~ train@33024  Loss: 0.002052 Acc: 13.3125\n",
      " |~~ train@33088  Loss: 0.002839 Acc: 13.1406\n",
      " |~~ train@33152  Loss: 0.002078 Acc: 13.3281\n",
      " |~~ train@33216  Loss: 0.002628 Acc: 13.1875\n",
      " |~~ train@33280  Loss: 0.001872 Acc: 13.4219\n",
      " |~~ train@33344  Loss: 0.001777 Acc: 13.4531\n",
      " |~~ train@33408  Loss: 0.002453 Acc: 13.2344\n",
      " |~~ train@33472  Loss: 0.002278 Acc: 13.3281\n",
      " |~~ train@33536  Loss: 0.002073 Acc: 13.4375\n",
      " |~~ train@33600  Loss: 0.002429 Acc: 13.2344\n",
      " |~~ train@33664  Loss: 0.002567 Acc: 13.1875\n",
      " |~~ train@33728  Loss: 0.002528 Acc: 13.1719\n",
      " |~~ train@33792  Loss: 0.002178 Acc: 13.4062\n",
      " |~~ train@33856  Loss: 0.002377 Acc: 13.2500\n",
      " |~~ train@33920  Loss: 0.002755 Acc: 13.1719\n",
      " |~~ train@33984  Loss: 0.002419 Acc: 13.2656\n",
      " |~~ train@34048  Loss: 0.002329 Acc: 13.4375\n",
      " |~~ train@34112  Loss: 0.001902 Acc: 13.3281\n",
      " |~~ train@34176  Loss: 0.001915 Acc: 13.3594\n",
      " |~~ train@34240  Loss: 0.002017 Acc: 13.3594\n",
      " |~~ train@34304  Loss: 0.002140 Acc: 13.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@34368  Loss: 0.002339 Acc: 13.1875\n",
      " |~~ train@34432  Loss: 0.002722 Acc: 13.0469\n",
      " |~~ train@34496  Loss: 0.001887 Acc: 13.3438\n",
      " |~~ train@34560  Loss: 0.001853 Acc: 13.4219\n",
      " |~~ train@34624  Loss: 0.002116 Acc: 13.3438\n",
      " |~~ train@34688  Loss: 0.001935 Acc: 13.4531\n",
      " |~~ train@34752  Loss: 0.002300 Acc: 13.2656\n",
      " |~~ train@34816  Loss: 0.002037 Acc: 13.3594\n",
      " |~~ train@34880  Loss: 0.002574 Acc: 13.1875\n",
      " |~~ train@34944  Loss: 0.002459 Acc: 13.2500\n",
      " |~~ train@35008  Loss: 0.002409 Acc: 13.2812\n",
      " |~~ train@35072  Loss: 0.002658 Acc: 13.1719\n",
      " |~~ train@35136  Loss: 0.002496 Acc: 13.1562\n",
      " |~~ train@35200  Loss: 0.002036 Acc: 13.3750\n",
      " |~~ train@35264  Loss: 0.002448 Acc: 13.1562\n",
      " |~~ train@35328  Loss: 0.002316 Acc: 13.2188\n",
      " |~~ train@35392  Loss: 0.002110 Acc: 13.3906\n",
      " |~~ train@35456  Loss: 0.001754 Acc: 13.4531\n",
      " |~~ train@35520  Loss: 0.002078 Acc: 13.4375\n",
      " |~~ train@35584  Loss: 0.002257 Acc: 13.2969\n",
      " |~~ train@35648  Loss: 0.002385 Acc: 13.1406\n",
      " |~~ train@35712  Loss: 0.003085 Acc: 13.0000\n",
      " |~~ train@35776  Loss: 0.002331 Acc: 13.3594\n",
      " |~~ train@35840  Loss: 0.002311 Acc: 13.2344\n",
      " |~~ train@35904  Loss: 0.002177 Acc: 13.2969\n",
      " |~~ train@35968  Loss: 0.003003 Acc: 13.1250\n",
      " |~~ train@36032  Loss: 0.001937 Acc: 13.4219\n",
      " |~~ train@36096  Loss: 0.002303 Acc: 13.3281\n",
      " |~~ train@36160  Loss: 0.002367 Acc: 13.2188\n",
      " |~~ train@36224  Loss: 0.002137 Acc: 13.4062\n",
      " |~~ train@36288  Loss: 0.002306 Acc: 13.2188\n",
      " |~~ train@36352  Loss: 0.002272 Acc: 13.3750\n",
      " |~~ train@36416  Loss: 0.002170 Acc: 13.2969\n",
      " |~~ train@36480  Loss: 0.002101 Acc: 13.3906\n",
      " |~~ train@36544  Loss: 0.002173 Acc: 13.2344\n",
      " |~~ train@36608  Loss: 0.001622 Acc: 13.5938\n",
      " |~~ train@36672  Loss: 0.002139 Acc: 13.4062\n",
      " |~~ train@36736  Loss: 0.002394 Acc: 13.2344\n",
      " |~~ train@36800  Loss: 0.002282 Acc: 13.4062\n",
      " |~~ train@36864  Loss: 0.002566 Acc: 13.2344\n",
      " |~~ train@36928  Loss: 0.001958 Acc: 13.4062\n",
      " |~~ train@36992  Loss: 0.002223 Acc: 13.3750\n",
      " |~~ train@37056  Loss: 0.002263 Acc: 13.2656\n",
      " |~~ train@37120  Loss: 0.002576 Acc: 13.2031\n",
      " |~~ train@37184  Loss: 0.002282 Acc: 13.3594\n",
      " |~~ train@37248  Loss: 0.001889 Acc: 13.5312\n",
      " |~~ train@37312  Loss: 0.002906 Acc: 13.1719\n",
      " |~~ train@37376  Loss: 0.001621 Acc: 13.4688\n",
      " |~~ train@37440  Loss: 0.001870 Acc: 13.4062\n",
      " |~~ train@37504  Loss: 0.002556 Acc: 13.1719\n",
      " |~~ train@37568  Loss: 0.002029 Acc: 13.2812\n",
      " |~~ train@37632  Loss: 0.002434 Acc: 13.2031\n",
      " |~~ train@37696  Loss: 0.001801 Acc: 13.4844\n",
      " |~~ train@37760  Loss: 0.002759 Acc: 13.2031\n",
      " |~~ train@37824  Loss: 0.001940 Acc: 13.4219\n",
      " |~~ train@37888  Loss: 0.002511 Acc: 13.1250\n",
      " |~~ train@37952  Loss: 0.002201 Acc: 13.3594\n",
      " |~~ train@38016  Loss: 0.002164 Acc: 13.3594\n",
      " |~~ train@38080  Loss: 0.002167 Acc: 13.3750\n",
      " |~~ train@38144  Loss: 0.002310 Acc: 13.2656\n",
      " |~~ train@38208  Loss: 0.002388 Acc: 13.2031\n",
      " |~~ train@38272  Loss: 0.002149 Acc: 13.3281\n",
      " |~~ train@38336  Loss: 0.002333 Acc: 13.2969\n",
      " |~~ train@38400  Loss: 0.002172 Acc: 13.2812\n",
      " |~~ train@38464  Loss: 0.002146 Acc: 13.4062\n",
      " |~~ train@38528  Loss: 0.002218 Acc: 13.3281\n",
      " |~~ train@38592  Loss: 0.002078 Acc: 13.4375\n",
      " |~~ train@38656  Loss: 0.002193 Acc: 13.4219\n",
      " |~~ train@38720  Loss: 0.002907 Acc: 13.0312\n",
      " |~~ train@38784  Loss: 0.002405 Acc: 13.2656\n",
      " |~~ train@38848  Loss: 0.001828 Acc: 13.3594\n",
      " |~~ train@38912  Loss: 0.002675 Acc: 13.2031\n",
      " |~~ train@38976  Loss: 0.002306 Acc: 13.3594\n",
      " |~~ train@39040  Loss: 0.002576 Acc: 13.2188\n",
      " |~~ train@39104  Loss: 0.002500 Acc: 13.2188\n",
      " |~~ train@39168  Loss: 0.002554 Acc: 13.0938\n",
      " |~~ train@39232  Loss: 0.002405 Acc: 13.2344\n",
      " |~~ train@39296  Loss: 0.001791 Acc: 13.4531\n",
      " |~~ train@39360  Loss: 0.002498 Acc: 13.2812\n",
      " |~~ train@39424  Loss: 0.001915 Acc: 13.3750\n",
      " |~~ train@39488  Loss: 0.002095 Acc: 13.4062\n",
      " |~~ train@39552  Loss: 0.002339 Acc: 13.3125\n",
      " |~~ train@39616  Loss: 0.002419 Acc: 13.2188\n",
      " |~~ train@39680  Loss: 0.001767 Acc: 13.4531\n",
      " |~~ train@39744  Loss: 0.002307 Acc: 13.1562\n",
      " |~~ train@39808  Loss: 0.002336 Acc: 13.2812\n",
      " |~~ train@39872  Loss: 0.002514 Acc: 13.2344\n",
      " |~~ train@39936  Loss: 0.002215 Acc: 13.2812\n",
      " |~~ train@40000  Loss: 0.002090 Acc: 13.3438\n",
      " |~~ train@40064  Loss: 0.002140 Acc: 13.3906\n",
      " |~~ train@40128  Loss: 0.002962 Acc: 13.0781\n",
      " |~~ train@40192  Loss: 0.002004 Acc: 13.3906\n",
      " |~~ train@40256  Loss: 0.001772 Acc: 13.4688\n",
      " |~~ train@40320  Loss: 0.002141 Acc: 13.4219\n",
      " |~~ train@40384  Loss: 0.002337 Acc: 13.2812\n",
      " |~~ train@40448  Loss: 0.002230 Acc: 13.2500\n",
      " |~~ train@40512  Loss: 0.001934 Acc: 13.4375\n",
      " |~~ train@40576  Loss: 0.002369 Acc: 13.1875\n",
      " |~~ train@40640  Loss: 0.002172 Acc: 13.3281\n",
      " |~~ train@40704  Loss: 0.002164 Acc: 13.2188\n",
      " |~~ train@40768  Loss: 0.002503 Acc: 13.2344\n",
      " |~~ train@40832  Loss: 0.001891 Acc: 13.3438\n",
      " |~~ train@40896  Loss: 0.001990 Acc: 13.4531\n",
      " |~~ train@40960  Loss: 0.002268 Acc: 13.3438\n",
      " |~~ train@41024  Loss: 0.002102 Acc: 13.3438\n",
      " |~~ train@41088  Loss: 0.002215 Acc: 13.3594\n",
      " |~~ train@41152  Loss: 0.001965 Acc: 13.3281\n",
      " |~~ train@41216  Loss: 0.002250 Acc: 13.2812\n",
      " |~~ train@41280  Loss: 0.001995 Acc: 13.4375\n",
      " |~~ train@41344  Loss: 0.002246 Acc: 13.2500\n",
      " |~~ train@41408  Loss: 0.002008 Acc: 13.3750\n",
      " |~~ train@41472  Loss: 0.002325 Acc: 13.2500\n",
      " |~~ train@41536  Loss: 0.001793 Acc: 13.4688\n",
      " |~~ train@41600  Loss: 0.002153 Acc: 13.3594\n",
      " |~~ train@41664  Loss: 0.002014 Acc: 13.3594\n",
      " |~~ train@41728  Loss: 0.002165 Acc: 13.4375\n",
      " |~~ train@41792  Loss: 0.002486 Acc: 13.2031\n",
      " |~~ train@41856  Loss: 0.002071 Acc: 13.2969\n",
      " |~~ train@41920  Loss: 0.002173 Acc: 13.2969\n",
      " |~~ train@41984  Loss: 0.002183 Acc: 13.3906\n",
      " |~~ train@42048  Loss: 0.002048 Acc: 13.4219\n",
      " |~~ train@42112  Loss: 0.002398 Acc: 13.3594\n",
      " |~~ train@42176  Loss: 0.002307 Acc: 13.3281\n",
      " |~~ train@42240  Loss: 0.002369 Acc: 13.2031\n",
      " |~~ train@42304  Loss: 0.003054 Acc: 13.1406\n",
      " |~~ train@42368  Loss: 0.002231 Acc: 13.2969\n",
      " |~~ train@42432  Loss: 0.002748 Acc: 13.2188\n",
      " |~~ train@42496  Loss: 0.002390 Acc: 13.2031\n",
      " |~~ train@42560  Loss: 0.002290 Acc: 13.1875\n",
      " |~~ train@42624  Loss: 0.002382 Acc: 13.2969\n",
      " |~~ train@42688  Loss: 0.002445 Acc: 13.2812\n",
      " |~~ train@42752  Loss: 0.002210 Acc: 13.2500\n",
      " |~~ train@42816  Loss: 0.002034 Acc: 13.3125\n",
      " |~~ train@42880  Loss: 0.001804 Acc: 13.4531\n",
      " |~~ train@42944  Loss: 0.002828 Acc: 13.0781\n",
      " |~~ train@43008  Loss: 0.002593 Acc: 13.2344\n",
      " |~~ train@43072  Loss: 0.002095 Acc: 13.3438\n",
      " |~~ train@43136  Loss: 0.002286 Acc: 13.4375\n",
      " |~~ train@43200  Loss: 0.002325 Acc: 13.2969\n",
      " |~~ train@43264  Loss: 0.002324 Acc: 13.2188\n",
      " |~~ train@43328  Loss: 0.002106 Acc: 13.3281\n",
      " |~~ train@43392  Loss: 0.003020 Acc: 13.2031\n",
      " |~~ train@43456  Loss: 0.002291 Acc: 13.2344\n",
      " |~~ train@43520  Loss: 0.002140 Acc: 13.3438\n",
      " |~~ train@43584  Loss: 0.002226 Acc: 13.2656\n",
      " |~~ train@43648  Loss: 0.001982 Acc: 13.3281\n",
      " |~~ train@43712  Loss: 0.001964 Acc: 13.3594\n",
      " |~~ train@43776  Loss: 0.002433 Acc: 13.2188\n",
      " |~~ train@43840  Loss: 0.002873 Acc: 13.0781\n",
      " |~~ train@43904  Loss: 0.001869 Acc: 13.4219\n",
      " |~~ train@43968  Loss: 0.002032 Acc: 13.4062\n",
      " |~~ train@44032  Loss: 0.002140 Acc: 13.3281\n",
      " |~~ train@44096  Loss: 0.002459 Acc: 13.2188\n",
      " |~~ train@44160  Loss: 0.001868 Acc: 13.3125\n",
      " |~~ train@44224  Loss: 0.002088 Acc: 13.3906\n",
      " |~~ train@44288  Loss: 0.001932 Acc: 13.4062\n",
      " |~~ train@44352  Loss: 0.002362 Acc: 13.2500\n",
      " |~~ train@44416  Loss: 0.002052 Acc: 13.3281\n",
      " |~~ train@44480  Loss: 0.002728 Acc: 13.0312\n",
      " |~~ train@44544  Loss: 0.002577 Acc: 13.1875\n",
      " |~~ train@44608  Loss: 0.002412 Acc: 13.2031\n",
      " |~~ train@44672  Loss: 0.001868 Acc: 13.4531\n",
      " |~~ train@44736  Loss: 0.002403 Acc: 13.2812\n",
      " |~~ train@44800  Loss: 0.002270 Acc: 13.2969\n",
      " |~~ train@44864  Loss: 0.002171 Acc: 13.3750\n",
      " |~~ train@44928  Loss: 0.001747 Acc: 13.3906\n",
      " |~~ train@44992  Loss: 0.002498 Acc: 13.1719\n",
      " |~~ train@45056  Loss: 0.002169 Acc: 13.2969\n",
      " |~~ train@45120  Loss: 0.002094 Acc: 13.2969\n",
      " |~~ train@45184  Loss: 0.001914 Acc: 13.3906\n",
      " |~~ train@45248  Loss: 0.001634 Acc: 13.5625\n",
      " |~~ train@45312  Loss: 0.002480 Acc: 13.1719\n",
      " |~~ train@45376  Loss: 0.002572 Acc: 13.1875\n",
      " |~~ train@45440  Loss: 0.002005 Acc: 13.3750\n",
      " |~~ train@45504  Loss: 0.002293 Acc: 13.2812\n",
      " |~~ train@45568  Loss: 0.002354 Acc: 13.2656\n",
      " |~~ train@45632  Loss: 0.001935 Acc: 13.4844\n",
      " |~~ train@45696  Loss: 0.002378 Acc: 13.2656\n",
      " |~~ train@45760  Loss: 0.002336 Acc: 13.2969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@45824  Loss: 0.001676 Acc: 13.5156\n",
      " |~~ train@45888  Loss: 0.001916 Acc: 13.3750\n",
      " |~~ train@45952  Loss: 0.002580 Acc: 13.2812\n",
      " |~~ train@46016  Loss: 0.002798 Acc: 13.0938\n",
      " |~~ train@46080  Loss: 0.002309 Acc: 13.1875\n",
      " |~~ train@46144  Loss: 0.002517 Acc: 13.2344\n",
      " |~~ train@46208  Loss: 0.002337 Acc: 13.3125\n",
      " |~~ train@46272  Loss: 0.002510 Acc: 13.2031\n",
      " |~~ train@46336  Loss: 0.001973 Acc: 13.3750\n",
      " |~~ train@46400  Loss: 0.002129 Acc: 13.3281\n",
      " |~~ train@46464  Loss: 0.002283 Acc: 13.2031\n",
      " |~~ train@46528  Loss: 0.002074 Acc: 13.3125\n",
      " |~~ train@46592  Loss: 0.001960 Acc: 13.3750\n",
      " |~~ train@46656  Loss: 0.002205 Acc: 13.2812\n",
      " |~~ train@46720  Loss: 0.002235 Acc: 13.3594\n",
      " |~~ train@46784  Loss: 0.002050 Acc: 13.2656\n",
      " |~~ train@46848  Loss: 0.002015 Acc: 13.3906\n",
      " |~~ train@46912  Loss: 0.002825 Acc: 13.1406\n",
      " |~~ train@46976  Loss: 0.002179 Acc: 13.4375\n",
      " |~~ train@47040  Loss: 0.002352 Acc: 13.2656\n",
      " |~~ train@47104  Loss: 0.003085 Acc: 12.9688\n",
      " |~~ train@47168  Loss: 0.002321 Acc: 13.2188\n",
      " |~~ train@47232  Loss: 0.002016 Acc: 13.3750\n",
      " |~~ train@47296  Loss: 0.002000 Acc: 13.3594\n",
      " |~~ train@47360  Loss: 0.002262 Acc: 13.3281\n",
      " |~~ train@47424  Loss: 0.002010 Acc: 13.3281\n",
      " |~~ train@47488  Loss: 0.001881 Acc: 13.4062\n",
      " |~~ train@47552  Loss: 0.002408 Acc: 13.2656\n",
      " |~~ train@47616  Loss: 0.002564 Acc: 13.2812\n",
      " |~~ train@47680  Loss: 0.002691 Acc: 13.1406\n",
      " |~~ train@47744  Loss: 0.002302 Acc: 13.2812\n",
      " |~~ train@47808  Loss: 0.002120 Acc: 13.3281\n",
      " |~~ train@47872  Loss: 0.002452 Acc: 13.2656\n",
      " |~~ train@47936  Loss: 0.002249 Acc: 13.2344\n",
      " |~~ train@48000  Loss: 0.001953 Acc: 13.3906\n",
      " |~~ train@48064  Loss: 0.001548 Acc: 13.5312\n",
      " |~~ train@48128  Loss: 0.001880 Acc: 13.4219\n",
      " |~~ train@48192  Loss: 0.002486 Acc: 13.0781\n",
      " |~~ train@48256  Loss: 0.002497 Acc: 13.2500\n",
      " |~~ train@48320  Loss: 0.001914 Acc: 13.4219\n",
      " |~~ train@48384  Loss: 0.001889 Acc: 13.4219\n",
      " |~~ train@48448  Loss: 0.002606 Acc: 13.2031\n",
      " |~~ train@48512  Loss: 0.002329 Acc: 13.2656\n",
      " |~~ train@48576  Loss: 0.002703 Acc: 13.1406\n",
      " |~~ train@48640  Loss: 0.001948 Acc: 13.3750\n",
      " |~~ train@48704  Loss: 0.002344 Acc: 13.2344\n",
      " |~~ train@48768  Loss: 0.002385 Acc: 13.1719\n",
      " |~~ train@48832  Loss: 0.002220 Acc: 13.4375\n",
      " |~~ train@48896  Loss: 0.002581 Acc: 13.2188\n",
      " |~~ train@48960  Loss: 0.001993 Acc: 13.3594\n",
      " |~~ train@49024  Loss: 0.002812 Acc: 13.0938\n",
      " |~~ train@49088  Loss: 0.002566 Acc: 13.2656\n",
      " |~~ train@49152  Loss: 0.002041 Acc: 13.3750\n",
      " |~~ train@49216  Loss: 0.002479 Acc: 13.2344\n",
      " |~~ train@49280  Loss: 0.002336 Acc: 13.2188\n",
      " |~~ train@49344  Loss: 0.002313 Acc: 13.2969\n",
      " |~~ train@49408  Loss: 0.002609 Acc: 13.2656\n",
      " |~~ train@49472  Loss: 0.002526 Acc: 13.3125\n",
      " |~~ train@49536  Loss: 0.002324 Acc: 13.2656\n",
      " |~~ train@49600  Loss: 0.002262 Acc: 13.2344\n",
      " |~~ train@49664  Loss: 0.002193 Acc: 13.3125\n",
      " |~~ train@49728  Loss: 0.002629 Acc: 13.0781\n",
      " |~~ train@49792  Loss: 0.002604 Acc: 13.2969\n",
      " |~~ train@49856  Loss: 0.001794 Acc: 13.4531\n",
      " |~~ train@49920  Loss: 0.002121 Acc: 13.3594\n",
      " |~~ train@49984  Loss: 0.002425 Acc: 13.2500\n",
      " |~~ train@50048  Loss: 0.002553 Acc: 13.1406\n",
      " |~~ train@50112  Loss: 0.001833 Acc: 13.4688\n",
      " |~~ train@50176  Loss: 0.002340 Acc: 13.3438\n",
      " |~~ train@50240  Loss: 0.002475 Acc: 13.2031\n",
      " |~~ train@50304  Loss: 0.002170 Acc: 13.3750\n",
      " |~~ train@50368  Loss: 0.002180 Acc: 13.2656\n",
      " |~~ train@50432  Loss: 0.002670 Acc: 13.2031\n",
      " |~~ train@50496  Loss: 0.002139 Acc: 13.3906\n",
      " |~~ train@50560  Loss: 0.002231 Acc: 13.3906\n",
      " |~~ train@50624  Loss: 0.002307 Acc: 13.2344\n",
      " |~~ train@50688  Loss: 0.002015 Acc: 13.4062\n",
      " |~~ train@50752  Loss: 0.002155 Acc: 13.3438\n",
      " |~~ train@50816  Loss: 0.002259 Acc: 13.2344\n",
      " |~~ train@50880  Loss: 0.001696 Acc: 13.5000\n",
      " |~~ train@50944  Loss: 0.002649 Acc: 13.2500\n",
      " |~~ train@51008  Loss: 0.001716 Acc: 13.4844\n",
      " |~~ train@51072  Loss: 0.002088 Acc: 13.3750\n",
      " |~~ train@51136  Loss: 0.001709 Acc: 13.5312\n",
      " |~~ train@51200  Loss: 0.002198 Acc: 13.3594\n",
      " |~~ train@51264  Loss: 0.002233 Acc: 13.2969\n",
      " |~~ train@51328  Loss: 0.001797 Acc: 13.4531\n",
      " |~~ train@51392  Loss: 0.002235 Acc: 13.2656\n",
      " |~~ train@51456  Loss: 0.001952 Acc: 13.3750\n",
      " |~~ train@51520  Loss: 0.001996 Acc: 13.4375\n",
      " |~~ train@51584  Loss: 0.002323 Acc: 13.3281\n",
      " |~~ train@51648  Loss: 0.002523 Acc: 13.3594\n",
      " |~~ train@51712  Loss: 0.002058 Acc: 13.3281\n",
      " |~~ train@51776  Loss: 0.002091 Acc: 13.4219\n",
      " |~~ train@51840  Loss: 0.002398 Acc: 13.3906\n",
      " |~~ train@51904  Loss: 0.002255 Acc: 13.3125\n",
      " |~~ train@51968  Loss: 0.001980 Acc: 13.2969\n",
      " |~~ train@52032  Loss: 0.002967 Acc: 13.1562\n",
      " |~~ train@52096  Loss: 0.002890 Acc: 13.0781\n",
      " |~~ train@52160  Loss: 0.001886 Acc: 13.4219\n",
      " |~~ train@52224  Loss: 0.001727 Acc: 13.5000\n",
      " |~~ train@52288  Loss: 0.001934 Acc: 13.4219\n",
      " |~~ train@52352  Loss: 0.002419 Acc: 13.2969\n",
      " |~~ train@52416  Loss: 0.002118 Acc: 13.4219\n",
      " |~~ train@52480  Loss: 0.001969 Acc: 13.5469\n",
      " |~~ train@52544  Loss: 0.001838 Acc: 13.5625\n",
      " |~~ train@52608  Loss: 0.002419 Acc: 13.2500\n",
      " |~~ train@52672  Loss: 0.002188 Acc: 13.3750\n",
      " |~~ train@52736  Loss: 0.001909 Acc: 13.4219\n",
      " |~~ train@52800  Loss: 0.002154 Acc: 13.2656\n",
      " |~~ train@52864  Loss: 0.002371 Acc: 13.2188\n",
      " |~~ train@52928  Loss: 0.002243 Acc: 13.3281\n",
      " |~~ train@52992  Loss: 0.002449 Acc: 13.2812\n",
      " |~~ train@53056  Loss: 0.001847 Acc: 13.3750\n",
      " |~~ train@53120  Loss: 0.002371 Acc: 13.2812\n",
      " |~~ train@53184  Loss: 0.002261 Acc: 13.3438\n",
      " |~~ train@53248  Loss: 0.001631 Acc: 13.5625\n",
      " |~~ train@53312  Loss: 0.002573 Acc: 13.1719\n",
      " |~~ train@53376  Loss: 0.002003 Acc: 13.4062\n",
      " |~~ train@53440  Loss: 0.002242 Acc: 13.2344\n",
      " |~~ train@53504  Loss: 0.002311 Acc: 13.3125\n",
      " |~~ train@53568  Loss: 0.001847 Acc: 13.5156\n",
      " |~~ train@53632  Loss: 0.002087 Acc: 13.2812\n",
      " |~~ train@53696  Loss: 0.002223 Acc: 13.3125\n",
      " |~~ train@53760  Loss: 0.002486 Acc: 13.0938\n",
      " |~~ train@53824  Loss: 0.002417 Acc: 13.2969\n",
      " |~~ train@53888  Loss: 0.002266 Acc: 13.2969\n",
      " |~~ train@53952  Loss: 0.002082 Acc: 13.4062\n",
      " |~~ train@54016  Loss: 0.002241 Acc: 13.3281\n",
      " |~~ train@54080  Loss: 0.002166 Acc: 13.3438\n",
      " |~~ train@54144  Loss: 0.002434 Acc: 13.2812\n",
      " |~~ train@54208  Loss: 0.001929 Acc: 13.4844\n",
      " |~~ train@54272  Loss: 0.001851 Acc: 13.4375\n",
      " |~~ train@54336  Loss: 0.002030 Acc: 13.4062\n",
      " |~~ train@54400  Loss: 0.002187 Acc: 13.3125\n",
      " |~~ train@54464  Loss: 0.001883 Acc: 13.4375\n",
      " |~~ train@54528  Loss: 0.002018 Acc: 13.4219\n",
      " |~~ train@54592  Loss: 0.002854 Acc: 13.0625\n",
      " |~~ train@54656  Loss: 0.002054 Acc: 13.3438\n",
      " |~~ train@54720  Loss: 0.001848 Acc: 13.5312\n",
      " |~~ train@54784  Loss: 0.002054 Acc: 13.2969\n",
      " |~~ train@54848  Loss: 0.002223 Acc: 13.3594\n",
      " |~~ train@54912  Loss: 0.002148 Acc: 13.2969\n",
      " |~~ train@54976  Loss: 0.001887 Acc: 13.3906\n",
      " |~~ train@55040  Loss: 0.002460 Acc: 13.2812\n",
      " |~~ train@55104  Loss: 0.002245 Acc: 13.2969\n",
      " |~~ train@55168  Loss: 0.002237 Acc: 13.2969\n",
      " |~~ train@55232  Loss: 0.001982 Acc: 13.4844\n",
      " |~~ train@55296  Loss: 0.002486 Acc: 13.2344\n",
      " |~~ train@55360  Loss: 0.001866 Acc: 13.4688\n",
      " |~~ train@55424  Loss: 0.002132 Acc: 13.3438\n",
      " |~~ train@55488  Loss: 0.002208 Acc: 13.3125\n",
      " |~~ train@55552  Loss: 0.003145 Acc: 13.0625\n",
      " |~~ train@55616  Loss: 0.002279 Acc: 13.2188\n",
      " |~~ train@55680  Loss: 0.001852 Acc: 13.3906\n",
      " |~~ train@55744  Loss: 0.001785 Acc: 13.4844\n",
      " |~~ train@55808  Loss: 0.001853 Acc: 13.4844\n",
      " |~~ train@55872  Loss: 0.002218 Acc: 13.2812\n",
      " |~~ train@55936  Loss: 0.001572 Acc: 13.5625\n",
      " |~~ train@56000  Loss: 0.002264 Acc: 13.3594\n",
      " |~~ train@56064  Loss: 0.002177 Acc: 13.2500\n",
      " |~~ train@56128  Loss: 0.002266 Acc: 13.3125\n",
      " |~~ train@56192  Loss: 0.002216 Acc: 13.2969\n",
      " |~~ train@56256  Loss: 0.002392 Acc: 13.2031\n",
      " |~~ train@56320  Loss: 0.001820 Acc: 13.3750\n",
      " |~~ train@56384  Loss: 0.002636 Acc: 13.1094\n",
      " |~~ train@56448  Loss: 0.002438 Acc: 13.2656\n",
      " |~~ train@56512  Loss: 0.002416 Acc: 13.2969\n",
      " |~~ train@56576  Loss: 0.001868 Acc: 13.4844\n",
      " |~~ train@56640  Loss: 0.002370 Acc: 13.2500\n",
      " |~~ train@56704  Loss: 0.002299 Acc: 13.2656\n",
      " |~~ train@56768  Loss: 0.001983 Acc: 13.3906\n",
      " |~~ train@56832  Loss: 0.002781 Acc: 13.0781\n",
      " |~~ train@56896  Loss: 0.002007 Acc: 13.4062\n",
      " |~~ train@56960  Loss: 0.002405 Acc: 13.1875\n",
      " |~~ train@57024  Loss: 0.002334 Acc: 13.2812\n",
      " |~~ train@57088  Loss: 0.001835 Acc: 13.5000\n",
      " |~~ train@57152  Loss: 0.002032 Acc: 13.3281\n",
      " |~~ train@57216  Loss: 0.002518 Acc: 13.2500\n",
      " |~~ train@57280  Loss: 0.002124 Acc: 13.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@57344  Loss: 0.001987 Acc: 13.3594\n",
      " |~~ train@57408  Loss: 0.002044 Acc: 13.3281\n",
      " |~~ train@57472  Loss: 0.002377 Acc: 13.2344\n",
      " |~~ train@57536  Loss: 0.002744 Acc: 13.1562\n",
      " |~~ train@57600  Loss: 0.002205 Acc: 13.2969\n",
      " |~~ train@57664  Loss: 0.002133 Acc: 13.2188\n",
      " |~~ train@57728  Loss: 0.002176 Acc: 13.3281\n",
      " |~~ train@57792  Loss: 0.002494 Acc: 13.2656\n",
      " |~~ train@57856  Loss: 0.002372 Acc: 13.2500\n",
      " |~~ train@57920  Loss: 0.001643 Acc: 13.5156\n",
      " |~~ train@57984  Loss: 0.002302 Acc: 13.2969\n",
      " |~~ train@58048  Loss: 0.002426 Acc: 13.1406\n",
      " |~~ train@58112  Loss: 0.002713 Acc: 13.2344\n",
      " |~~ train@58176  Loss: 0.002460 Acc: 13.2812\n",
      " |~~ train@58240  Loss: 0.002318 Acc: 13.2500\n",
      " |~~ train@58304  Loss: 0.002246 Acc: 13.2812\n",
      " |~~ train@58368  Loss: 0.002606 Acc: 13.1406\n",
      " |~~ train@58432  Loss: 0.002545 Acc: 13.2812\n",
      " |~~ train@58496  Loss: 0.002509 Acc: 13.1406\n",
      " |~~ train@58560  Loss: 0.001952 Acc: 13.4531\n",
      " |~~ train@58624  Loss: 0.001992 Acc: 13.3281\n",
      " |~~ train@58688  Loss: 0.002296 Acc: 13.2031\n",
      " |~~ train@58752  Loss: 0.002366 Acc: 13.2031\n",
      " |~~ train@58816  Loss: 0.002754 Acc: 13.1719\n",
      " |~~ train@58880  Loss: 0.002197 Acc: 13.3281\n",
      " |~~ train@58944  Loss: 0.002298 Acc: 13.2969\n",
      " |~~ train@59008  Loss: 0.002652 Acc: 13.0938\n",
      " |~~ train@59072  Loss: 0.001823 Acc: 13.4844\n",
      " |~~ train@59136  Loss: 0.002739 Acc: 13.0938\n",
      " |~~ train@59200  Loss: 0.001914 Acc: 13.4844\n",
      " |~~ train@59264  Loss: 0.002398 Acc: 13.2500\n",
      " |~~ train@59328  Loss: 0.002383 Acc: 13.1875\n",
      " |~~ train@59392  Loss: 0.001937 Acc: 13.4062\n",
      " |~~ train@59456  Loss: 0.002242 Acc: 13.2500\n",
      " |~~ train@59520  Loss: 0.002117 Acc: 13.2656\n",
      " |~~ train@59584  Loss: 0.001981 Acc: 13.4531\n",
      " |~~ train@59648  Loss: 0.001772 Acc: 13.4688\n",
      " |~~ train@59712  Loss: 0.002373 Acc: 13.2969\n",
      " |~~ train@59776  Loss: 0.001965 Acc: 13.3906\n",
      " |~~ train@59840  Loss: 0.002294 Acc: 13.2656\n",
      " |~~ train@59904  Loss: 0.002344 Acc: 13.2344\n",
      " |~~ train@59968  Loss: 0.001659 Acc: 13.5312\n",
      " |~~ train@60032  Loss: 0.001796 Acc: 13.4219\n",
      " |~~ train@60096  Loss: 0.001675 Acc: 13.5312\n",
      " |~~ train@60160  Loss: 0.002261 Acc: 13.4062\n",
      " |~~ train@60224  Loss: 0.002012 Acc: 13.4531\n",
      " |~~ train@60288  Loss: 0.002267 Acc: 13.4219\n",
      " |~~ train@60352  Loss: 0.002635 Acc: 13.1875\n",
      " |~~ train@60416  Loss: 0.002892 Acc: 13.1562\n",
      " |~~ train@60480  Loss: 0.001818 Acc: 13.3906\n",
      " |~~ train@60544  Loss: 0.002040 Acc: 13.3906\n",
      " |~~ train@60608  Loss: 0.002294 Acc: 13.3125\n",
      " |~~ train@60672  Loss: 0.002619 Acc: 13.1875\n",
      " |~~ train@60736  Loss: 0.002437 Acc: 13.3125\n",
      " |~~ train@60800  Loss: 0.002692 Acc: 13.1250\n",
      " |~~ train@60864  Loss: 0.002870 Acc: 13.1250\n",
      " |~~ train@60928  Loss: 0.002097 Acc: 13.3594\n",
      " |~~ train@60992  Loss: 0.002250 Acc: 13.3125\n",
      " |~~ train@61056  Loss: 0.002978 Acc: 13.0156\n",
      " |~~ train@61120  Loss: 0.002075 Acc: 13.3281\n",
      " |~~ train@61184  Loss: 0.002502 Acc: 13.2812\n",
      " |~~ train@61248  Loss: 0.002444 Acc: 13.2188\n",
      " |~~ train@61312  Loss: 0.001983 Acc: 13.3906\n",
      " |~~ train@61376  Loss: 0.002233 Acc: 13.2969\n",
      " |~~ train@61440  Loss: 0.002596 Acc: 13.2031\n",
      " |~~ train@61504  Loss: 0.002154 Acc: 13.3438\n",
      " |~~ train@61568  Loss: 0.001941 Acc: 13.4062\n",
      " |~~ train@61632  Loss: 0.002165 Acc: 13.3438\n",
      " |~~ train@61696  Loss: 0.002437 Acc: 13.2500\n",
      " |~~ train@61760  Loss: 0.002177 Acc: 13.3281\n",
      " |~~ train@61824  Loss: 0.002498 Acc: 13.1562\n",
      " |~~ train@61888  Loss: 0.002308 Acc: 13.2812\n",
      " |~~ train@61952  Loss: 0.002215 Acc: 13.2969\n",
      " |~~ train@62016  Loss: 0.002054 Acc: 13.2500\n",
      " |~~ train@62080  Loss: 0.002434 Acc: 13.1250\n",
      " |~~ train@62144  Loss: 0.002401 Acc: 13.1875\n",
      " |~~ train@62208  Loss: 0.002876 Acc: 13.0938\n",
      " |~~ train@62272  Loss: 0.002282 Acc: 13.3281\n",
      " |~~ train@62336  Loss: 0.002062 Acc: 13.3906\n",
      " |~~ train@62400  Loss: 0.002224 Acc: 13.3281\n",
      " |~~ train@62464  Loss: 0.003191 Acc: 13.0156\n",
      " |~~ train@62528  Loss: 0.001961 Acc: 13.4219\n",
      " |~~ train@62592  Loss: 0.002191 Acc: 13.4062\n",
      " |~~ train@62656  Loss: 0.002601 Acc: 13.2344\n",
      " |~~ train@62720  Loss: 0.002474 Acc: 13.2656\n",
      " |~~ train@62784  Loss: 0.002430 Acc: 13.2500\n",
      " |~~ train@62848  Loss: 0.002621 Acc: 13.1719\n",
      " |~~ train@62912  Loss: 0.002075 Acc: 13.3750\n",
      " |~~ train@62976  Loss: 0.002315 Acc: 13.2656\n",
      " |~~ train@63040  Loss: 0.002275 Acc: 13.2812\n",
      " |~~ train@63104  Loss: 0.002162 Acc: 13.4531\n",
      " |~~ train@63168  Loss: 0.002598 Acc: 13.2188\n",
      " |~~ train@63232  Loss: 0.002460 Acc: 13.1562\n",
      " |~~ train@63296  Loss: 0.002581 Acc: 13.2500\n",
      " |~~ train@63360  Loss: 0.002239 Acc: 13.2500\n",
      " |~~ train@63424  Loss: 0.002257 Acc: 13.2188\n",
      " |~~ train@63488  Loss: 0.001974 Acc: 13.3750\n",
      " |~~ train@63552  Loss: 0.001904 Acc: 13.4531\n",
      " |~~ train@63616  Loss: 0.002457 Acc: 13.3438\n",
      " |~~ train@63680  Loss: 0.002241 Acc: 13.1562\n",
      " |~~ train@63744  Loss: 0.001745 Acc: 13.5625\n",
      " |~~ train@63808  Loss: 0.001904 Acc: 13.3750\n",
      " |~~ train@63872  Loss: 0.002175 Acc: 13.3594\n",
      " |~~ train@63936  Loss: 0.002426 Acc: 13.3281\n",
      " |~~ train@64000  Loss: 0.002106 Acc: 13.3438\n",
      " |~~ train@64064  Loss: 0.002195 Acc: 13.2344\n",
      " |~~ train@64128  Loss: 0.002822 Acc: 13.1094\n",
      " |~~ train@64192  Loss: 0.002225 Acc: 13.2656\n",
      " |~~ train@64256  Loss: 0.002363 Acc: 13.3125\n",
      " |~~ train@64320  Loss: 0.002264 Acc: 13.3125\n",
      " |~~ train@64384  Loss: 0.002298 Acc: 13.3438\n",
      " |~~ train@64448  Loss: 0.002293 Acc: 13.2500\n",
      " |~~ train@64512  Loss: 0.002015 Acc: 13.4688\n",
      " |~~ train@64576  Loss: 0.002337 Acc: 13.3281\n",
      " |~~ train@64640  Loss: 0.002187 Acc: 13.2969\n",
      " |~~ train@64704  Loss: 0.002996 Acc: 13.0156\n",
      " |~~ train@64768  Loss: 0.002126 Acc: 13.4375\n",
      " |~~ train@64832  Loss: 0.002491 Acc: 13.2969\n",
      " |~~ train@64896  Loss: 0.001975 Acc: 13.4062\n",
      " |~~ train@64960  Loss: 0.001792 Acc: 13.5156\n",
      " |~~ train@65024  Loss: 0.002282 Acc: 13.2188\n",
      " |~~ train@65088  Loss: 0.002041 Acc: 13.3281\n",
      " |~~ train@65152  Loss: 0.002385 Acc: 13.2500\n",
      " |~~ train@65216  Loss: 0.002132 Acc: 13.3594\n",
      " |~~ train@65280  Loss: 0.001694 Acc: 13.5000\n",
      " |~~ train@65344  Loss: 0.002566 Acc: 13.1719\n",
      " |~~ train@65408  Loss: 0.002057 Acc: 13.3438\n",
      " |~~ train@65472  Loss: 0.002347 Acc: 13.2812\n",
      " |~~ train@65536  Loss: 0.002262 Acc: 13.2344\n",
      " |~~ train@65600  Loss: 0.002670 Acc: 13.1562\n",
      " |~~ train@65664  Loss: 0.002076 Acc: 13.3906\n",
      " |~~ train@65728  Loss: 0.002316 Acc: 13.3750\n",
      " |~~ train@65792  Loss: 0.002319 Acc: 13.3438\n",
      " |~~ train@65856  Loss: 0.002518 Acc: 13.1719\n",
      " |~~ train@65920  Loss: 0.002441 Acc: 13.2344\n",
      " |~~ train@65984  Loss: 0.001938 Acc: 13.3906\n",
      " |~~ train@66048  Loss: 0.001946 Acc: 13.4844\n",
      " |~~ train@66112  Loss: 0.002190 Acc: 13.3125\n",
      " |~~ train@66176  Loss: 0.001920 Acc: 13.5000\n",
      " |~~ train@66240  Loss: 0.002917 Acc: 13.0781\n",
      " |~~ train@66304  Loss: 0.002016 Acc: 13.4375\n",
      " |~~ train@66368  Loss: 0.002370 Acc: 13.2031\n",
      " |~~ train@66432  Loss: 0.002884 Acc: 13.1406\n",
      " |~~ train@66496  Loss: 0.002015 Acc: 13.4062\n",
      " |~~ train@66560  Loss: 0.002015 Acc: 13.4219\n",
      " |~~ train@66624  Loss: 0.002505 Acc: 13.2656\n",
      " |~~ train@66688  Loss: 0.002460 Acc: 13.2031\n",
      " |~~ train@66752  Loss: 0.001716 Acc: 13.4375\n",
      " |~~ train@66816  Loss: 0.002511 Acc: 13.2344\n",
      " |~~ train@66880  Loss: 0.002019 Acc: 13.4062\n",
      " |~~ train@66944  Loss: 0.002902 Acc: 13.0469\n",
      " |~~ train@67008  Loss: 0.001839 Acc: 13.3750\n",
      " |~~ train@67072  Loss: 0.002797 Acc: 13.0938\n",
      " |~~ train@67136  Loss: 0.002336 Acc: 13.3281\n",
      " |~~ train@67200  Loss: 0.002593 Acc: 13.2656\n",
      " |~~ train@67264  Loss: 0.002417 Acc: 13.2188\n",
      " |~~ train@67328  Loss: 0.002243 Acc: 13.3125\n",
      " |~~ train@67392  Loss: 0.001864 Acc: 13.4062\n",
      " |~~ train@67456  Loss: 0.002077 Acc: 13.4219\n",
      " |~~ train@67520  Loss: 0.002184 Acc: 13.3125\n",
      " |~~ train@67584  Loss: 0.002648 Acc: 13.2344\n",
      " |~~ train@67648  Loss: 0.001867 Acc: 13.4688\n",
      " |~~ train@67712  Loss: 0.002232 Acc: 13.2812\n",
      " |~~ train@67776  Loss: 0.002403 Acc: 13.2812\n",
      " |~~ train@67840  Loss: 0.002391 Acc: 13.2500\n",
      " |~~ train@67904  Loss: 0.002222 Acc: 13.3594\n",
      " |~~ train@67968  Loss: 0.002627 Acc: 13.1094\n",
      " |~~ train@68032  Loss: 0.002229 Acc: 13.2656\n",
      " |~~ train@68096  Loss: 0.002168 Acc: 13.3281\n",
      " |~~ train@68160  Loss: 0.001897 Acc: 13.4531\n",
      " |~~ train@68224  Loss: 0.002512 Acc: 13.2188\n",
      " |~~ train@68288  Loss: 0.002145 Acc: 13.4219\n",
      " |~~ train@68352  Loss: 0.002280 Acc: 13.2812\n",
      " |~~ train@68416  Loss: 0.001778 Acc: 13.3906\n",
      " |~~ train@68480  Loss: 0.001816 Acc: 13.5156\n",
      " |~~ train@68544  Loss: 0.002390 Acc: 13.2031\n",
      " |~~ train@68608  Loss: 0.002213 Acc: 13.2812\n",
      " |~~ train@68672  Loss: 0.001801 Acc: 13.4219\n",
      " |~~ train@68736  Loss: 0.002457 Acc: 13.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@68800  Loss: 0.002618 Acc: 13.1875\n",
      " |~~ train@68864  Loss: 0.002252 Acc: 13.3281\n",
      " |~~ train@68928  Loss: 0.001973 Acc: 13.3750\n",
      " |~~ train@68992  Loss: 0.002150 Acc: 13.3594\n",
      " |~~ train@69056  Loss: 0.002211 Acc: 13.2812\n",
      " |~~ train@69120  Loss: 0.002312 Acc: 13.2344\n",
      " |~~ train@69184  Loss: 0.001987 Acc: 13.3594\n",
      " |~~ train@69248  Loss: 0.001825 Acc: 13.4531\n",
      " |~~ train@69312  Loss: 0.002348 Acc: 13.3125\n",
      " |~~ train@69376  Loss: 0.001856 Acc: 13.4219\n",
      " |~~ train@69440  Loss: 0.002088 Acc: 13.3125\n",
      " |~~ train@69504  Loss: 0.002424 Acc: 13.3125\n",
      " |~~ train@69568  Loss: 0.002291 Acc: 13.2969\n",
      " |~~ train@69632  Loss: 0.002230 Acc: 13.2969\n",
      " |~~ train@69696  Loss: 0.002436 Acc: 13.2812\n",
      " |~~ train@69760  Loss: 0.001722 Acc: 13.5156\n",
      " |~~ train@69824  Loss: 0.002721 Acc: 13.0938\n",
      " |~~ train@69888  Loss: 0.001796 Acc: 13.4375\n",
      " |~~ train@69952  Loss: 0.002604 Acc: 13.0938\n",
      " |~~ train@70016  Loss: 0.002375 Acc: 13.2344\n",
      " |~~ train@70080  Loss: 0.001970 Acc: 13.4531\n",
      " |~~ train@70144  Loss: 0.002327 Acc: 13.2656\n",
      " |~~ train@70208  Loss: 0.002002 Acc: 13.2969\n",
      " |~~ train@70272  Loss: 0.002448 Acc: 13.2656\n",
      " |~~ train@70336  Loss: 0.001837 Acc: 13.4062\n",
      " |~~ train@70400  Loss: 0.002027 Acc: 13.4219\n",
      " |~~ train@70464  Loss: 0.002352 Acc: 13.3594\n",
      " |~~ train@70528  Loss: 0.002096 Acc: 13.3906\n",
      " |~~ train@70592  Loss: 0.002702 Acc: 13.0469\n",
      " |~~ train@70656  Loss: 0.002396 Acc: 13.2812\n",
      " |~~ train@70720  Loss: 0.002335 Acc: 13.2812\n",
      " |~~ train@70784  Loss: 0.002333 Acc: 13.2031\n",
      " |~~ train@70848  Loss: 0.002874 Acc: 13.1719\n",
      " |~~ train@70912  Loss: 0.002087 Acc: 13.2969\n",
      " |~~ train@70976  Loss: 0.002187 Acc: 13.3125\n",
      " |~~ train@71040  Loss: 0.002626 Acc: 13.1562\n",
      " |~~ train@71104  Loss: 0.002343 Acc: 13.2500\n",
      " |~~ train@71168  Loss: 0.002033 Acc: 13.3125\n",
      " |~~ train@71232  Loss: 0.002593 Acc: 13.1719\n",
      " |~~ train@71296  Loss: 0.002230 Acc: 13.2812\n",
      " |~~ train@71360  Loss: 0.002076 Acc: 13.4062\n",
      " |~~ train@71424  Loss: 0.002058 Acc: 13.3281\n",
      " |~~ train@71488  Loss: 0.002664 Acc: 13.1562\n",
      " |~~ train@71552  Loss: 0.001984 Acc: 13.3750\n",
      " |~~ train@71616  Loss: 0.002198 Acc: 13.3125\n",
      " |~~ train@71680  Loss: 0.002311 Acc: 13.2656\n",
      " |~~ train@71744  Loss: 0.002232 Acc: 13.2812\n",
      " |~~ train@71808  Loss: 0.001932 Acc: 13.4219\n",
      " |~~ train@71872  Loss: 0.002629 Acc: 13.0625\n",
      " |~~ train@71936  Loss: 0.002292 Acc: 13.3125\n",
      " |~~ train@72000  Loss: 0.002151 Acc: 13.3281\n",
      " |~~ train@72064  Loss: 0.002013 Acc: 13.4219\n",
      " |~~ train@72128  Loss: 0.002430 Acc: 13.1875\n",
      " |~~ train@72192  Loss: 0.002571 Acc: 13.2188\n",
      " |~~ train@72256  Loss: 0.002000 Acc: 13.4531\n",
      " |~~ train@72320  Loss: 0.002717 Acc: 13.0781\n",
      " |~~ train@72384  Loss: 0.001819 Acc: 13.5000\n",
      " |~~ train@72448  Loss: 0.002431 Acc: 13.2969\n",
      " |~~ train@72512  Loss: 0.002025 Acc: 13.3125\n",
      " |~~ train@72576  Loss: 0.002502 Acc: 13.2031\n",
      " |~~ train@72640  Loss: 0.002488 Acc: 13.0938\n",
      " |~~ train@72704  Loss: 0.002279 Acc: 13.3438\n",
      " |~~ train@72768  Loss: 0.003064 Acc: 12.9375\n",
      " |~~ train@72832  Loss: 0.001946 Acc: 13.3281\n",
      " |~~ train@72896  Loss: 0.002622 Acc: 13.2344\n",
      " |~~ train@72960  Loss: 0.002725 Acc: 13.0938\n",
      " |~~ train@73024  Loss: 0.002010 Acc: 13.4219\n",
      " |~~ train@73088  Loss: 0.002278 Acc: 13.2812\n",
      " |~~ train@73152  Loss: 0.002008 Acc: 13.4062\n",
      " |~~ train@73216  Loss: 0.002722 Acc: 13.1875\n",
      " |~~ train@73280  Loss: 0.002222 Acc: 13.3125\n",
      " |~~ train@73344  Loss: 0.002695 Acc: 13.1562\n",
      " |~~ train@73408  Loss: 0.001996 Acc: 13.3281\n",
      " |~~ train@73472  Loss: 0.002169 Acc: 13.3594\n",
      " |~~ train@73536  Loss: 0.002646 Acc: 13.1406\n",
      " |~~ train@73600  Loss: 0.002309 Acc: 13.2500\n",
      " |~~ train@73664  Loss: 0.002294 Acc: 13.4062\n",
      " |~~ train@73728  Loss: 0.001703 Acc: 13.4375\n",
      " |~~ train@73792  Loss: 0.001923 Acc: 13.4531\n",
      " |~~ train@73856  Loss: 0.002010 Acc: 13.3750\n",
      " |~~ train@73920  Loss: 0.002131 Acc: 13.2969\n",
      " |~~ train@73984  Loss: 0.001925 Acc: 13.4375\n",
      " |~~ train@74048  Loss: 0.002524 Acc: 13.2500\n",
      " |~~ train@74112  Loss: 0.002285 Acc: 13.1562\n",
      " |~~ train@74176  Loss: 0.002527 Acc: 13.1875\n",
      " |~~ train@74240  Loss: 0.002239 Acc: 13.2812\n",
      " |~~ train@74304  Loss: 0.002358 Acc: 13.2812\n",
      " |~~ train@74368  Loss: 0.002294 Acc: 13.2812\n",
      " |~~ train@74432  Loss: 0.002931 Acc: 12.9844\n",
      " |~~ train@74496  Loss: 0.002052 Acc: 13.4062\n",
      " |~~ train@74560  Loss: 0.002750 Acc: 13.0781\n",
      " |~~ train@74624  Loss: 0.002566 Acc: 13.2656\n",
      " |~~ train@74688  Loss: 0.002380 Acc: 13.3125\n",
      " |~~ train@74752  Loss: 0.002294 Acc: 13.3438\n",
      " |~~ train@74816  Loss: 0.002751 Acc: 13.1406\n",
      " |~~ train@74880  Loss: 0.001932 Acc: 13.4531\n",
      " |~~ train@74944  Loss: 0.002735 Acc: 13.1094\n",
      " |~~ train@75008  Loss: 0.002123 Acc: 13.3125\n",
      " |~~ train@75072  Loss: 0.002245 Acc: 13.3125\n",
      " |~~ train@75136  Loss: 0.002348 Acc: 13.2031\n",
      " |~~ train@75200  Loss: 0.001694 Acc: 13.4844\n",
      " |~~ train@75264  Loss: 0.002030 Acc: 13.4219\n",
      " |~~ train@75328  Loss: 0.002194 Acc: 13.2812\n",
      " |~~ train@75392  Loss: 0.002217 Acc: 13.3750\n",
      " |~~ train@75456  Loss: 0.002147 Acc: 13.3438\n",
      " |~~ train@75520  Loss: 0.002099 Acc: 13.3438\n",
      " |~~ train@75584  Loss: 0.002980 Acc: 13.0000\n",
      " |~~ train@75648  Loss: 0.002436 Acc: 13.2656\n",
      " |~~ train@75712  Loss: 0.002304 Acc: 13.2344\n",
      " |~~ train@75776  Loss: 0.002673 Acc: 13.1406\n",
      " |~~ train@75840  Loss: 0.002816 Acc: 13.0469\n",
      " |~~ train@75904  Loss: 0.001732 Acc: 13.5156\n",
      " |~~ train@75968  Loss: 0.002140 Acc: 13.3906\n",
      " |~~ train@76032  Loss: 0.002291 Acc: 13.2969\n",
      " |~~ train@76096  Loss: 0.003483 Acc: 13.0469\n",
      " |~~ train@76160  Loss: 0.002744 Acc: 13.1250\n",
      " |~~ train@76224  Loss: 0.002263 Acc: 13.2500\n",
      " |~~ train@76288  Loss: 0.002444 Acc: 13.2031\n",
      " |~~ train@76352  Loss: 0.002269 Acc: 13.3281\n",
      " |~~ train@76416  Loss: 0.002096 Acc: 13.3906\n",
      " |~~ train@76480  Loss: 0.002359 Acc: 13.2656\n",
      " |~~ train@76544  Loss: 0.002626 Acc: 13.2969\n",
      " |~~ train@76608  Loss: 0.002640 Acc: 13.2344\n",
      " |~~ train@76672  Loss: 0.001988 Acc: 13.4062\n",
      " |~~ train@76736  Loss: 0.002115 Acc: 13.3281\n",
      " |~~ train@76800  Loss: 0.003198 Acc: 13.0312\n",
      " |~~ train@76864  Loss: 0.002350 Acc: 13.2656\n",
      " |~~ train@76928  Loss: 0.002172 Acc: 13.3281\n",
      " |~~ train@76992  Loss: 0.002186 Acc: 13.4062\n",
      " |~~ train@77056  Loss: 0.002316 Acc: 13.2188\n",
      " |~~ train@77120  Loss: 0.001874 Acc: 13.4688\n",
      " |~~ train@77184  Loss: 0.002788 Acc: 13.1406\n",
      " |~~ train@77248  Loss: 0.001882 Acc: 13.4219\n",
      " |~~ train@77312  Loss: 0.001509 Acc: 13.6094\n",
      " |~~ train@77376  Loss: 0.002274 Acc: 13.2031\n",
      " |~~ train@77440  Loss: 0.002459 Acc: 13.2812\n",
      " |~~ train@77504  Loss: 0.002948 Acc: 13.0312\n",
      " |~~ train@77568  Loss: 0.002233 Acc: 13.3750\n",
      " |~~ train@77632  Loss: 0.002009 Acc: 13.4375\n",
      " |~~ train@77696  Loss: 0.002244 Acc: 13.2969\n",
      " |~~ train@77760  Loss: 0.002035 Acc: 13.4062\n",
      " |~~ train@77824  Loss: 0.002591 Acc: 13.1719\n",
      " |~~ train@77888  Loss: 0.001928 Acc: 13.4375\n",
      " |~~ train@77952  Loss: 0.002585 Acc: 13.0781\n",
      " |~~ train@78016  Loss: 0.002335 Acc: 13.2500\n",
      " |~~ train@78080  Loss: 0.002415 Acc: 13.2188\n",
      " |~~ train@78144  Loss: 0.001822 Acc: 13.4375\n",
      " |~~ train@78208  Loss: 0.002154 Acc: 13.3438\n",
      " |~~ train@78272  Loss: 0.002535 Acc: 13.2188\n",
      " |~~ train@78336  Loss: 0.002353 Acc: 13.2969\n",
      " |~~ train@78400  Loss: 0.002124 Acc: 13.3438\n",
      " |~~ train@78464  Loss: 0.002441 Acc: 13.2344\n",
      " |~~ train@78484  Loss: 0.005890 Acc: 13.5500\n",
      "train  Loss: 0.002253 Acc: 13.3046\n",
      " |~~ val@64  Loss: 0.002344 Acc: 13.2656\n",
      " |~~ val@128  Loss: 0.002173 Acc: 13.4375\n",
      " |~~ val@192  Loss: 0.002241 Acc: 13.3281\n",
      " |~~ val@256  Loss: 0.002437 Acc: 13.1875\n",
      " |~~ val@320  Loss: 0.001947 Acc: 13.5312\n",
      " |~~ val@384  Loss: 0.003014 Acc: 13.1719\n",
      " |~~ val@448  Loss: 0.002372 Acc: 13.2031\n",
      " |~~ val@512  Loss: 0.002071 Acc: 13.3438\n",
      " |~~ val@576  Loss: 0.001972 Acc: 13.4219\n",
      " |~~ val@640  Loss: 0.002593 Acc: 13.2812\n",
      " |~~ val@704  Loss: 0.002366 Acc: 13.3594\n",
      " |~~ val@768  Loss: 0.002891 Acc: 13.0781\n",
      " |~~ val@832  Loss: 0.002307 Acc: 13.2812\n",
      " |~~ val@896  Loss: 0.002431 Acc: 13.3594\n",
      " |~~ val@960  Loss: 0.001968 Acc: 13.4062\n",
      " |~~ val@1024  Loss: 0.002202 Acc: 13.3594\n",
      " |~~ val@1088  Loss: 0.002677 Acc: 13.1562\n",
      " |~~ val@1152  Loss: 0.002289 Acc: 13.2344\n",
      " |~~ val@1216  Loss: 0.002365 Acc: 13.2656\n",
      " |~~ val@1280  Loss: 0.002053 Acc: 13.4062\n",
      " |~~ val@1344  Loss: 0.002406 Acc: 13.2500\n",
      " |~~ val@1408  Loss: 0.002678 Acc: 13.2344\n",
      " |~~ val@1472  Loss: 0.002658 Acc: 13.1875\n",
      " |~~ val@1536  Loss: 0.002478 Acc: 13.2656\n",
      " |~~ val@1600  Loss: 0.002392 Acc: 13.3438\n",
      " |~~ val@1664  Loss: 0.002284 Acc: 13.3281\n",
      " |~~ val@1728  Loss: 0.002055 Acc: 13.4375\n",
      " |~~ val@1792  Loss: 0.002747 Acc: 13.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@1856  Loss: 0.002045 Acc: 13.4062\n",
      " |~~ val@1920  Loss: 0.002359 Acc: 13.2812\n",
      " |~~ val@1984  Loss: 0.002627 Acc: 13.2656\n",
      " |~~ val@2048  Loss: 0.002531 Acc: 13.2031\n",
      " |~~ val@2112  Loss: 0.002104 Acc: 13.4062\n",
      " |~~ val@2176  Loss: 0.002972 Acc: 12.9844\n",
      " |~~ val@2240  Loss: 0.002961 Acc: 13.1250\n",
      " |~~ val@2304  Loss: 0.002525 Acc: 13.1719\n",
      " |~~ val@2368  Loss: 0.002472 Acc: 13.2188\n",
      " |~~ val@2432  Loss: 0.002765 Acc: 13.0000\n",
      " |~~ val@2496  Loss: 0.002962 Acc: 12.9688\n",
      " |~~ val@2560  Loss: 0.002162 Acc: 13.3438\n",
      " |~~ val@2624  Loss: 0.002432 Acc: 13.2812\n",
      " |~~ val@2688  Loss: 0.002411 Acc: 13.3281\n",
      " |~~ val@2752  Loss: 0.002212 Acc: 13.3125\n",
      " |~~ val@2816  Loss: 0.001987 Acc: 13.3281\n",
      " |~~ val@2880  Loss: 0.003406 Acc: 12.9219\n",
      " |~~ val@2944  Loss: 0.002121 Acc: 13.3594\n",
      " |~~ val@3008  Loss: 0.002239 Acc: 13.3594\n",
      " |~~ val@3072  Loss: 0.002907 Acc: 13.0938\n",
      " |~~ val@3136  Loss: 0.002630 Acc: 13.2812\n",
      " |~~ val@3200  Loss: 0.002504 Acc: 13.2812\n",
      " |~~ val@3264  Loss: 0.002097 Acc: 13.3594\n",
      " |~~ val@3328  Loss: 0.002880 Acc: 13.1094\n",
      " |~~ val@3392  Loss: 0.002195 Acc: 13.3125\n",
      " |~~ val@3456  Loss: 0.002344 Acc: 13.3281\n",
      " |~~ val@3520  Loss: 0.002641 Acc: 13.1875\n",
      " |~~ val@3584  Loss: 0.003074 Acc: 13.1094\n",
      " |~~ val@3648  Loss: 0.002444 Acc: 13.1562\n",
      " |~~ val@3712  Loss: 0.002529 Acc: 13.2188\n",
      " |~~ val@3776  Loss: 0.002090 Acc: 13.3906\n",
      " |~~ val@3840  Loss: 0.003195 Acc: 13.1406\n",
      " |~~ val@3904  Loss: 0.002409 Acc: 13.3281\n",
      " |~~ val@3968  Loss: 0.002509 Acc: 13.2500\n",
      " |~~ val@4032  Loss: 0.002490 Acc: 13.3125\n",
      " |~~ val@4096  Loss: 0.001878 Acc: 13.4531\n",
      " |~~ val@4160  Loss: 0.002349 Acc: 13.2344\n",
      " |~~ val@4224  Loss: 0.002835 Acc: 13.2031\n",
      " |~~ val@4288  Loss: 0.002269 Acc: 13.2969\n",
      " |~~ val@4352  Loss: 0.002249 Acc: 13.3438\n",
      " |~~ val@4416  Loss: 0.002259 Acc: 13.2969\n",
      " |~~ val@4480  Loss: 0.003032 Acc: 13.0000\n",
      " |~~ val@4544  Loss: 0.002482 Acc: 13.2656\n",
      " |~~ val@4608  Loss: 0.001709 Acc: 13.4688\n",
      " |~~ val@4672  Loss: 0.002363 Acc: 13.3438\n",
      " |~~ val@4736  Loss: 0.001612 Acc: 13.5625\n",
      " |~~ val@4800  Loss: 0.002546 Acc: 13.2500\n",
      " |~~ val@4864  Loss: 0.002699 Acc: 13.2031\n",
      " |~~ val@4928  Loss: 0.002544 Acc: 13.1406\n",
      " |~~ val@4992  Loss: 0.002368 Acc: 13.3594\n",
      " |~~ val@5056  Loss: 0.002153 Acc: 13.4062\n",
      " |~~ val@5120  Loss: 0.002832 Acc: 13.1719\n",
      " |~~ val@5184  Loss: 0.002309 Acc: 13.3125\n",
      " |~~ val@5248  Loss: 0.002698 Acc: 13.1719\n",
      " |~~ val@5312  Loss: 0.002787 Acc: 13.1250\n",
      " |~~ val@5376  Loss: 0.002412 Acc: 13.2031\n",
      " |~~ val@5440  Loss: 0.002795 Acc: 13.2188\n",
      " |~~ val@5504  Loss: 0.002136 Acc: 13.4375\n",
      " |~~ val@5568  Loss: 0.002076 Acc: 13.3594\n",
      " |~~ val@5632  Loss: 0.002464 Acc: 13.1406\n",
      " |~~ val@5696  Loss: 0.002616 Acc: 13.1406\n",
      " |~~ val@5760  Loss: 0.002358 Acc: 13.2188\n",
      " |~~ val@5824  Loss: 0.002396 Acc: 13.1875\n",
      " |~~ val@5888  Loss: 0.002236 Acc: 13.3594\n",
      " |~~ val@5952  Loss: 0.001851 Acc: 13.4531\n",
      " |~~ val@6016  Loss: 0.002090 Acc: 13.2812\n",
      " |~~ val@6080  Loss: 0.002310 Acc: 13.3438\n",
      " |~~ val@6144  Loss: 0.002591 Acc: 13.2188\n",
      " |~~ val@6208  Loss: 0.002142 Acc: 13.3438\n",
      " |~~ val@6272  Loss: 0.001937 Acc: 13.4688\n",
      " |~~ val@6336  Loss: 0.002772 Acc: 13.2188\n",
      " |~~ val@6400  Loss: 0.002622 Acc: 13.1562\n",
      " |~~ val@6464  Loss: 0.001953 Acc: 13.3594\n",
      " |~~ val@6528  Loss: 0.001993 Acc: 13.4219\n",
      " |~~ val@6592  Loss: 0.001932 Acc: 13.4531\n",
      " |~~ val@6656  Loss: 0.002167 Acc: 13.3281\n",
      " |~~ val@6720  Loss: 0.002190 Acc: 13.2812\n",
      " |~~ val@6784  Loss: 0.002495 Acc: 13.2812\n",
      " |~~ val@6848  Loss: 0.002536 Acc: 13.2188\n",
      " |~~ val@6912  Loss: 0.002899 Acc: 13.1094\n",
      " |~~ val@6976  Loss: 0.001527 Acc: 13.4844\n",
      " |~~ val@7040  Loss: 0.001939 Acc: 13.3594\n",
      " |~~ val@7104  Loss: 0.003174 Acc: 13.0156\n",
      " |~~ val@7168  Loss: 0.002021 Acc: 13.3906\n",
      " |~~ val@7232  Loss: 0.002238 Acc: 13.3594\n",
      " |~~ val@7296  Loss: 0.002542 Acc: 13.2188\n",
      " |~~ val@7360  Loss: 0.002148 Acc: 13.4062\n",
      " |~~ val@7424  Loss: 0.002853 Acc: 13.0781\n",
      " |~~ val@7488  Loss: 0.002328 Acc: 13.2500\n",
      " |~~ val@7552  Loss: 0.002235 Acc: 13.4688\n",
      " |~~ val@7616  Loss: 0.003008 Acc: 13.0000\n",
      " |~~ val@7680  Loss: 0.002524 Acc: 13.1406\n",
      " |~~ val@7744  Loss: 0.002053 Acc: 13.4531\n",
      " |~~ val@7808  Loss: 0.002350 Acc: 13.2812\n",
      " |~~ val@7872  Loss: 0.002241 Acc: 13.3750\n",
      " |~~ val@7936  Loss: 0.002393 Acc: 13.2500\n",
      " |~~ val@8000  Loss: 0.001603 Acc: 13.6094\n",
      " |~~ val@8064  Loss: 0.002432 Acc: 13.2500\n",
      " |~~ val@8128  Loss: 0.001938 Acc: 13.4062\n",
      " |~~ val@8192  Loss: 0.002222 Acc: 13.3750\n",
      " |~~ val@8256  Loss: 0.002761 Acc: 13.1562\n",
      " |~~ val@8320  Loss: 0.002243 Acc: 13.2969\n",
      " |~~ val@8384  Loss: 0.002468 Acc: 13.1875\n",
      " |~~ val@8448  Loss: 0.002090 Acc: 13.4844\n",
      " |~~ val@8512  Loss: 0.003186 Acc: 12.9844\n",
      " |~~ val@8576  Loss: 0.002189 Acc: 13.3906\n",
      " |~~ val@8640  Loss: 0.002326 Acc: 13.1875\n",
      " |~~ val@8704  Loss: 0.002116 Acc: 13.4375\n",
      " |~~ val@8768  Loss: 0.002342 Acc: 13.2812\n",
      " |~~ val@8832  Loss: 0.002566 Acc: 13.2188\n",
      " |~~ val@8896  Loss: 0.002727 Acc: 13.1250\n",
      " |~~ val@8960  Loss: 0.002241 Acc: 13.3281\n",
      " |~~ val@9024  Loss: 0.002519 Acc: 13.0938\n",
      " |~~ val@9088  Loss: 0.003006 Acc: 13.1562\n",
      " |~~ val@9152  Loss: 0.002515 Acc: 13.2344\n",
      " |~~ val@9216  Loss: 0.002914 Acc: 13.0469\n",
      " |~~ val@9280  Loss: 0.002002 Acc: 13.4531\n",
      " |~~ val@9344  Loss: 0.002132 Acc: 13.2812\n",
      " |~~ val@9408  Loss: 0.002493 Acc: 13.2500\n",
      " |~~ val@9472  Loss: 0.002151 Acc: 13.3906\n",
      " |~~ val@9536  Loss: 0.002638 Acc: 13.3125\n",
      " |~~ val@9600  Loss: 0.002643 Acc: 13.2500\n",
      " |~~ val@9664  Loss: 0.002166 Acc: 13.4375\n",
      " |~~ val@9728  Loss: 0.002251 Acc: 13.2656\n",
      " |~~ val@9792  Loss: 0.002519 Acc: 13.1250\n",
      " |~~ val@9856  Loss: 0.002317 Acc: 13.3125\n",
      " |~~ val@9920  Loss: 0.002753 Acc: 13.1562\n",
      " |~~ val@9984  Loss: 0.002349 Acc: 13.2188\n",
      " |~~ val@10048  Loss: 0.002144 Acc: 13.3594\n",
      " |~~ val@10112  Loss: 0.003018 Acc: 13.0938\n",
      " |~~ val@10176  Loss: 0.001931 Acc: 13.4531\n",
      " |~~ val@10240  Loss: 0.001891 Acc: 13.4844\n",
      " |~~ val@10304  Loss: 0.002869 Acc: 13.2344\n",
      " |~~ val@10368  Loss: 0.002651 Acc: 13.1719\n",
      " |~~ val@10432  Loss: 0.002359 Acc: 13.2188\n",
      " |~~ val@10496  Loss: 0.002788 Acc: 13.0781\n",
      " |~~ val@10560  Loss: 0.002776 Acc: 13.1719\n",
      " |~~ val@10624  Loss: 0.002424 Acc: 13.2812\n",
      " |~~ val@10688  Loss: 0.002477 Acc: 13.1875\n",
      " |~~ val@10752  Loss: 0.002484 Acc: 13.2344\n",
      " |~~ val@10816  Loss: 0.002244 Acc: 13.2188\n",
      " |~~ val@10880  Loss: 0.002411 Acc: 13.2031\n",
      " |~~ val@10944  Loss: 0.001955 Acc: 13.4531\n",
      " |~~ val@11008  Loss: 0.002472 Acc: 13.3125\n",
      " |~~ val@11072  Loss: 0.002540 Acc: 13.2344\n",
      " |~~ val@11136  Loss: 0.002626 Acc: 13.0781\n",
      " |~~ val@11200  Loss: 0.001838 Acc: 13.3906\n",
      " |~~ val@11264  Loss: 0.002348 Acc: 13.2656\n",
      " |~~ val@11328  Loss: 0.002438 Acc: 13.3438\n",
      " |~~ val@11392  Loss: 0.001621 Acc: 13.5156\n",
      " |~~ val@11456  Loss: 0.002518 Acc: 13.3125\n",
      " |~~ val@11520  Loss: 0.002456 Acc: 13.2500\n",
      " |~~ val@11584  Loss: 0.002098 Acc: 13.4062\n",
      " |~~ val@11648  Loss: 0.002801 Acc: 13.2344\n",
      " |~~ val@11712  Loss: 0.002979 Acc: 13.1250\n",
      " |~~ val@11776  Loss: 0.002890 Acc: 13.0625\n",
      " |~~ val@11840  Loss: 0.001732 Acc: 13.5625\n",
      " |~~ val@11904  Loss: 0.002422 Acc: 13.2969\n",
      " |~~ val@11968  Loss: 0.002320 Acc: 13.1562\n",
      " |~~ val@12032  Loss: 0.002382 Acc: 13.2812\n",
      " |~~ val@12096  Loss: 0.002327 Acc: 13.3594\n",
      " |~~ val@12160  Loss: 0.002731 Acc: 13.2500\n",
      " |~~ val@12224  Loss: 0.002816 Acc: 13.0625\n",
      " |~~ val@12288  Loss: 0.001874 Acc: 13.4688\n",
      " |~~ val@12352  Loss: 0.001760 Acc: 13.4844\n",
      " |~~ val@12416  Loss: 0.001858 Acc: 13.5156\n",
      " |~~ val@12480  Loss: 0.002828 Acc: 13.0625\n",
      " |~~ val@12544  Loss: 0.001843 Acc: 13.4375\n",
      " |~~ val@12608  Loss: 0.002704 Acc: 13.2031\n",
      " |~~ val@12672  Loss: 0.002388 Acc: 13.2969\n",
      " |~~ val@12736  Loss: 0.002008 Acc: 13.5000\n",
      " |~~ val@12800  Loss: 0.002614 Acc: 13.1875\n",
      " |~~ val@12864  Loss: 0.002226 Acc: 13.2969\n",
      " |~~ val@12928  Loss: 0.002825 Acc: 13.2188\n",
      " |~~ val@12992  Loss: 0.001637 Acc: 13.4844\n",
      " |~~ val@13056  Loss: 0.002378 Acc: 13.2969\n",
      " |~~ val@13120  Loss: 0.002430 Acc: 13.2969\n",
      " |~~ val@13184  Loss: 0.002748 Acc: 13.1094\n",
      " |~~ val@13248  Loss: 0.002410 Acc: 13.2812\n",
      " |~~ val@13312  Loss: 0.002828 Acc: 13.2500\n",
      " |~~ val@13376  Loss: 0.002435 Acc: 13.2344\n",
      " |~~ val@13440  Loss: 0.002654 Acc: 13.1562\n",
      " |~~ val@13504  Loss: 0.002777 Acc: 13.1719\n",
      " |~~ val@13568  Loss: 0.002364 Acc: 13.4062\n",
      " |~~ val@13632  Loss: 0.002850 Acc: 13.1094\n",
      " |~~ val@13696  Loss: 0.002486 Acc: 13.3125\n",
      " |~~ val@13760  Loss: 0.001863 Acc: 13.5156\n",
      " |~~ val@13824  Loss: 0.002801 Acc: 13.2031\n",
      " |~~ val@13888  Loss: 0.002304 Acc: 13.3750\n",
      " |~~ val@13952  Loss: 0.002133 Acc: 13.3594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@14016  Loss: 0.001872 Acc: 13.4531\n",
      " |~~ val@14080  Loss: 0.002421 Acc: 13.3750\n",
      " |~~ val@14144  Loss: 0.002040 Acc: 13.3281\n",
      " |~~ val@14208  Loss: 0.002288 Acc: 13.3281\n",
      " |~~ val@14272  Loss: 0.002438 Acc: 13.3125\n",
      " |~~ val@14336  Loss: 0.001907 Acc: 13.4688\n",
      " |~~ val@14400  Loss: 0.001964 Acc: 13.4531\n",
      " |~~ val@14464  Loss: 0.002853 Acc: 13.1250\n",
      " |~~ val@14528  Loss: 0.002236 Acc: 13.3125\n",
      " |~~ val@14592  Loss: 0.002695 Acc: 13.1406\n",
      " |~~ val@14656  Loss: 0.002279 Acc: 13.2969\n",
      " |~~ val@14720  Loss: 0.002038 Acc: 13.3125\n",
      " |~~ val@14784  Loss: 0.002369 Acc: 13.2812\n",
      " |~~ val@14848  Loss: 0.001825 Acc: 13.4844\n",
      " |~~ val@14912  Loss: 0.002164 Acc: 13.4219\n",
      " |~~ val@14976  Loss: 0.002407 Acc: 13.2344\n",
      " |~~ val@15040  Loss: 0.002384 Acc: 13.2344\n",
      " |~~ val@15104  Loss: 0.002185 Acc: 13.3750\n",
      " |~~ val@15168  Loss: 0.002204 Acc: 13.3125\n",
      " |~~ val@15232  Loss: 0.002609 Acc: 13.2500\n",
      " |~~ val@15296  Loss: 0.002271 Acc: 13.4531\n",
      " |~~ val@15360  Loss: 0.001618 Acc: 13.5469\n",
      " |~~ val@15424  Loss: 0.002514 Acc: 13.3438\n",
      " |~~ val@15488  Loss: 0.002733 Acc: 13.1719\n",
      " |~~ val@15552  Loss: 0.002058 Acc: 13.3594\n",
      " |~~ val@15616  Loss: 0.002647 Acc: 13.2188\n",
      " |~~ val@15680  Loss: 0.002218 Acc: 13.3594\n",
      " |~~ val@15744  Loss: 0.002587 Acc: 13.2812\n",
      " |~~ val@15808  Loss: 0.002132 Acc: 13.3906\n",
      " |~~ val@15872  Loss: 0.002131 Acc: 13.2812\n",
      " |~~ val@15936  Loss: 0.002288 Acc: 13.2969\n",
      " |~~ val@16000  Loss: 0.002663 Acc: 13.1250\n",
      " |~~ val@16064  Loss: 0.002345 Acc: 13.2188\n",
      " |~~ val@16128  Loss: 0.001711 Acc: 13.5000\n",
      " |~~ val@16192  Loss: 0.002422 Acc: 13.0938\n",
      " |~~ val@16256  Loss: 0.002161 Acc: 13.3906\n",
      " |~~ val@16320  Loss: 0.002078 Acc: 13.2812\n",
      " |~~ val@16384  Loss: 0.002802 Acc: 13.2031\n",
      " |~~ val@16448  Loss: 0.001573 Acc: 13.6094\n",
      " |~~ val@16512  Loss: 0.003148 Acc: 13.1562\n",
      " |~~ val@16576  Loss: 0.002502 Acc: 13.2344\n",
      " |~~ val@16640  Loss: 0.002898 Acc: 13.1250\n",
      " |~~ val@16704  Loss: 0.002520 Acc: 13.2344\n",
      " |~~ val@16768  Loss: 0.002673 Acc: 13.2031\n",
      " |~~ val@16832  Loss: 0.002504 Acc: 13.1875\n",
      " |~~ val@16896  Loss: 0.002121 Acc: 13.3125\n",
      " |~~ val@16960  Loss: 0.002273 Acc: 13.1875\n",
      " |~~ val@17024  Loss: 0.002346 Acc: 13.3125\n",
      " |~~ val@17088  Loss: 0.002274 Acc: 13.2812\n",
      " |~~ val@17152  Loss: 0.002708 Acc: 13.2031\n",
      " |~~ val@17216  Loss: 0.001745 Acc: 13.4688\n",
      " |~~ val@17280  Loss: 0.002858 Acc: 13.1406\n",
      " |~~ val@17344  Loss: 0.002308 Acc: 13.2969\n",
      " |~~ val@17408  Loss: 0.002915 Acc: 13.1250\n",
      " |~~ val@17472  Loss: 0.002280 Acc: 13.3750\n",
      " |~~ val@17536  Loss: 0.001747 Acc: 13.4219\n",
      " |~~ val@17600  Loss: 0.002640 Acc: 13.2344\n",
      " |~~ val@17664  Loss: 0.002590 Acc: 13.2188\n",
      " |~~ val@17728  Loss: 0.002318 Acc: 13.2656\n",
      " |~~ val@17792  Loss: 0.002228 Acc: 13.3594\n",
      " |~~ val@17856  Loss: 0.002360 Acc: 13.2969\n",
      " |~~ val@17920  Loss: 0.002384 Acc: 13.2188\n",
      " |~~ val@17984  Loss: 0.002722 Acc: 13.2188\n",
      " |~~ val@18048  Loss: 0.002146 Acc: 13.4219\n",
      " |~~ val@18112  Loss: 0.002288 Acc: 13.3594\n",
      " |~~ val@18176  Loss: 0.002198 Acc: 13.4062\n",
      " |~~ val@18240  Loss: 0.002611 Acc: 13.1406\n",
      " |~~ val@18304  Loss: 0.002271 Acc: 13.2969\n",
      " |~~ val@18368  Loss: 0.001989 Acc: 13.4375\n",
      " |~~ val@18432  Loss: 0.003056 Acc: 13.0156\n",
      " |~~ val@18496  Loss: 0.002189 Acc: 13.3281\n",
      " |~~ val@18560  Loss: 0.002116 Acc: 13.3750\n",
      " |~~ val@18624  Loss: 0.002423 Acc: 13.2656\n",
      " |~~ val@18688  Loss: 0.002709 Acc: 13.2500\n",
      " |~~ val@18752  Loss: 0.002342 Acc: 13.3438\n",
      " |~~ val@18816  Loss: 0.002596 Acc: 13.1875\n",
      " |~~ val@18880  Loss: 0.002404 Acc: 13.3281\n",
      " |~~ val@18944  Loss: 0.002112 Acc: 13.2969\n",
      " |~~ val@19008  Loss: 0.002802 Acc: 13.1562\n",
      " |~~ val@19072  Loss: 0.002146 Acc: 13.2500\n",
      " |~~ val@19136  Loss: 0.002215 Acc: 13.2812\n",
      " |~~ val@19200  Loss: 0.002661 Acc: 13.1719\n",
      " |~~ val@19264  Loss: 0.001998 Acc: 13.4062\n",
      " |~~ val@19328  Loss: 0.002697 Acc: 13.2500\n",
      " |~~ val@19392  Loss: 0.002350 Acc: 13.2812\n",
      " |~~ val@19456  Loss: 0.002071 Acc: 13.3906\n",
      " |~~ val@19520  Loss: 0.002445 Acc: 13.2500\n",
      " |~~ val@19584  Loss: 0.002203 Acc: 13.2969\n",
      " |~~ val@19648  Loss: 0.002181 Acc: 13.3750\n",
      " |~~ val@19712  Loss: 0.002586 Acc: 13.1406\n",
      " |~~ val@19776  Loss: 0.002121 Acc: 13.3750\n",
      " |~~ val@19840  Loss: 0.002589 Acc: 13.2031\n",
      " |~~ val@19904  Loss: 0.002516 Acc: 13.2188\n",
      " |~~ val@19968  Loss: 0.002743 Acc: 13.2031\n",
      " |~~ val@20032  Loss: 0.002062 Acc: 13.3906\n",
      " |~~ val@20096  Loss: 0.002726 Acc: 13.1875\n",
      " |~~ val@20160  Loss: 0.002425 Acc: 13.2969\n",
      " |~~ val@20224  Loss: 0.002257 Acc: 13.2969\n",
      " |~~ val@20288  Loss: 0.002550 Acc: 13.2500\n",
      " |~~ val@20352  Loss: 0.001983 Acc: 13.4375\n",
      " |~~ val@20416  Loss: 0.002145 Acc: 13.3594\n",
      " |~~ val@20480  Loss: 0.002558 Acc: 13.3125\n",
      " |~~ val@20544  Loss: 0.002112 Acc: 13.3750\n",
      " |~~ val@20608  Loss: 0.001907 Acc: 13.4531\n",
      " |~~ val@20672  Loss: 0.001984 Acc: 13.3750\n",
      " |~~ val@20736  Loss: 0.002589 Acc: 13.2812\n",
      " |~~ val@20800  Loss: 0.002223 Acc: 13.2500\n",
      " |~~ val@20864  Loss: 0.002232 Acc: 13.2500\n",
      " |~~ val@20928  Loss: 0.002436 Acc: 13.3750\n",
      " |~~ val@20992  Loss: 0.002238 Acc: 13.4219\n",
      " |~~ val@21056  Loss: 0.001827 Acc: 13.5156\n",
      " |~~ val@21120  Loss: 0.002472 Acc: 13.1250\n",
      " |~~ val@21184  Loss: 0.002020 Acc: 13.4062\n",
      " |~~ val@21248  Loss: 0.002688 Acc: 13.1406\n",
      " |~~ val@21312  Loss: 0.002407 Acc: 13.3594\n",
      " |~~ val@21376  Loss: 0.002541 Acc: 13.2188\n",
      " |~~ val@21440  Loss: 0.002375 Acc: 13.3125\n",
      " |~~ val@21504  Loss: 0.002240 Acc: 13.3906\n",
      " |~~ val@21568  Loss: 0.002033 Acc: 13.4531\n",
      " |~~ val@21632  Loss: 0.002111 Acc: 13.3594\n",
      " |~~ val@21696  Loss: 0.002607 Acc: 13.2188\n",
      " |~~ val@21760  Loss: 0.001982 Acc: 13.4062\n",
      " |~~ val@21824  Loss: 0.002217 Acc: 13.2969\n",
      " |~~ val@21888  Loss: 0.002403 Acc: 13.3125\n",
      " |~~ val@21952  Loss: 0.002284 Acc: 13.4062\n",
      " |~~ val@22016  Loss: 0.002246 Acc: 13.2969\n",
      " |~~ val@22080  Loss: 0.001798 Acc: 13.5000\n",
      " |~~ val@22144  Loss: 0.002238 Acc: 13.2500\n",
      " |~~ val@22208  Loss: 0.002534 Acc: 13.1562\n",
      " |~~ val@22272  Loss: 0.003376 Acc: 12.8906\n",
      " |~~ val@22336  Loss: 0.002165 Acc: 13.4375\n",
      " |~~ val@22400  Loss: 0.002314 Acc: 13.2188\n",
      " |~~ val@22424  Loss: 0.005961 Acc: 13.4583\n",
      "val  Loss: 0.002381 Acc: 13.2844\n",
      "Epoch 4/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.002499 Acc: 13.1719\n",
      " |~~ train@128  Loss: 0.002315 Acc: 13.2656\n",
      " |~~ train@192  Loss: 0.002612 Acc: 13.1406\n",
      " |~~ train@256  Loss: 0.002503 Acc: 13.2188\n",
      " |~~ train@320  Loss: 0.001840 Acc: 13.3906\n",
      " |~~ train@384  Loss: 0.002240 Acc: 13.3594\n",
      " |~~ train@448  Loss: 0.001826 Acc: 13.4219\n",
      " |~~ train@512  Loss: 0.002271 Acc: 13.2656\n",
      " |~~ train@576  Loss: 0.002375 Acc: 13.1406\n",
      " |~~ train@640  Loss: 0.003003 Acc: 13.0781\n",
      " |~~ train@704  Loss: 0.002068 Acc: 13.2812\n",
      " |~~ train@768  Loss: 0.002351 Acc: 13.2656\n",
      " |~~ train@832  Loss: 0.001919 Acc: 13.3125\n",
      " |~~ train@896  Loss: 0.001923 Acc: 13.3438\n",
      " |~~ train@960  Loss: 0.001946 Acc: 13.3125\n",
      " |~~ train@1024  Loss: 0.002585 Acc: 13.2344\n",
      " |~~ train@1088  Loss: 0.002272 Acc: 13.2969\n",
      " |~~ train@1152  Loss: 0.002655 Acc: 13.2188\n",
      " |~~ train@1216  Loss: 0.001939 Acc: 13.3125\n",
      " |~~ train@1280  Loss: 0.002159 Acc: 13.3594\n",
      " |~~ train@1344  Loss: 0.002305 Acc: 13.2500\n",
      " |~~ train@1408  Loss: 0.002046 Acc: 13.4375\n",
      " |~~ train@1472  Loss: 0.001842 Acc: 13.4688\n",
      " |~~ train@1536  Loss: 0.002553 Acc: 13.1250\n",
      " |~~ train@1600  Loss: 0.002140 Acc: 13.1562\n",
      " |~~ train@1664  Loss: 0.003043 Acc: 12.9375\n",
      " |~~ train@1728  Loss: 0.001911 Acc: 13.3438\n",
      " |~~ train@1792  Loss: 0.002074 Acc: 13.3125\n",
      " |~~ train@1856  Loss: 0.002106 Acc: 13.3594\n",
      " |~~ train@1920  Loss: 0.002569 Acc: 13.2969\n",
      " |~~ train@1984  Loss: 0.002136 Acc: 13.3594\n",
      " |~~ train@2048  Loss: 0.002570 Acc: 13.1094\n",
      " |~~ train@2112  Loss: 0.001994 Acc: 13.4531\n",
      " |~~ train@2176  Loss: 0.001894 Acc: 13.3438\n",
      " |~~ train@2240  Loss: 0.002271 Acc: 13.1719\n",
      " |~~ train@2304  Loss: 0.002474 Acc: 13.2344\n",
      " |~~ train@2368  Loss: 0.002014 Acc: 13.3438\n",
      " |~~ train@2432  Loss: 0.002052 Acc: 13.2656\n",
      " |~~ train@2496  Loss: 0.001875 Acc: 13.3906\n",
      " |~~ train@2560  Loss: 0.002129 Acc: 13.2812\n",
      " |~~ train@2624  Loss: 0.001679 Acc: 13.5781\n",
      " |~~ train@2688  Loss: 0.002173 Acc: 13.3281\n",
      " |~~ train@2752  Loss: 0.002131 Acc: 13.3906\n",
      " |~~ train@2816  Loss: 0.002047 Acc: 13.3750\n",
      " |~~ train@2880  Loss: 0.001976 Acc: 13.3438\n",
      " |~~ train@2944  Loss: 0.002268 Acc: 13.3594\n",
      " |~~ train@3008  Loss: 0.001845 Acc: 13.4688\n",
      " |~~ train@3072  Loss: 0.002720 Acc: 13.2188\n",
      " |~~ train@3136  Loss: 0.002056 Acc: 13.4219\n",
      " |~~ train@3200  Loss: 0.002633 Acc: 13.1562\n",
      " |~~ train@3264  Loss: 0.001966 Acc: 13.3750\n",
      " |~~ train@3328  Loss: 0.002134 Acc: 13.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@3392  Loss: 0.002318 Acc: 13.1875\n",
      " |~~ train@3456  Loss: 0.002761 Acc: 13.1562\n",
      " |~~ train@3520  Loss: 0.002522 Acc: 13.0938\n",
      " |~~ train@3584  Loss: 0.002304 Acc: 13.2812\n",
      " |~~ train@3648  Loss: 0.001885 Acc: 13.3906\n",
      " |~~ train@3712  Loss: 0.002813 Acc: 13.0938\n",
      " |~~ train@3776  Loss: 0.002560 Acc: 13.2969\n",
      " |~~ train@3840  Loss: 0.001872 Acc: 13.5000\n",
      " |~~ train@3904  Loss: 0.002684 Acc: 13.1406\n",
      " |~~ train@3968  Loss: 0.002603 Acc: 13.1094\n",
      " |~~ train@4032  Loss: 0.002043 Acc: 13.4062\n",
      " |~~ train@4096  Loss: 0.002105 Acc: 13.4062\n",
      " |~~ train@4160  Loss: 0.001665 Acc: 13.4531\n",
      " |~~ train@4224  Loss: 0.001699 Acc: 13.4531\n",
      " |~~ train@4288  Loss: 0.002247 Acc: 13.2812\n",
      " |~~ train@4352  Loss: 0.001998 Acc: 13.3594\n",
      " |~~ train@4416  Loss: 0.002062 Acc: 13.3906\n",
      " |~~ train@4480  Loss: 0.001867 Acc: 13.4688\n",
      " |~~ train@4544  Loss: 0.001979 Acc: 13.3594\n",
      " |~~ train@4608  Loss: 0.001491 Acc: 13.5156\n",
      " |~~ train@4672  Loss: 0.001844 Acc: 13.4062\n",
      " |~~ train@4736  Loss: 0.002349 Acc: 13.2656\n",
      " |~~ train@4800  Loss: 0.001794 Acc: 13.4062\n",
      " |~~ train@4864  Loss: 0.001582 Acc: 13.5625\n",
      " |~~ train@4928  Loss: 0.002149 Acc: 13.2812\n",
      " |~~ train@4992  Loss: 0.002081 Acc: 13.3750\n",
      " |~~ train@5056  Loss: 0.001968 Acc: 13.3281\n",
      " |~~ train@5120  Loss: 0.002077 Acc: 13.3438\n",
      " |~~ train@5184  Loss: 0.001847 Acc: 13.4062\n",
      " |~~ train@5248  Loss: 0.001961 Acc: 13.4219\n",
      " |~~ train@5312  Loss: 0.002172 Acc: 13.3750\n",
      " |~~ train@5376  Loss: 0.002430 Acc: 13.2656\n",
      " |~~ train@5440  Loss: 0.001798 Acc: 13.4062\n",
      " |~~ train@5504  Loss: 0.001943 Acc: 13.4219\n",
      " |~~ train@5568  Loss: 0.002637 Acc: 13.1562\n",
      " |~~ train@5632  Loss: 0.002111 Acc: 13.3281\n",
      " |~~ train@5696  Loss: 0.002586 Acc: 13.2344\n",
      " |~~ train@5760  Loss: 0.001860 Acc: 13.3594\n",
      " |~~ train@5824  Loss: 0.002167 Acc: 13.3281\n",
      " |~~ train@5888  Loss: 0.002393 Acc: 13.2500\n",
      " |~~ train@5952  Loss: 0.002216 Acc: 13.2500\n",
      " |~~ train@6016  Loss: 0.001868 Acc: 13.4531\n",
      " |~~ train@6080  Loss: 0.002525 Acc: 13.1875\n",
      " |~~ train@6144  Loss: 0.002243 Acc: 13.2031\n",
      " |~~ train@6208  Loss: 0.002335 Acc: 13.2969\n",
      " |~~ train@6272  Loss: 0.001912 Acc: 13.3906\n",
      " |~~ train@6336  Loss: 0.001826 Acc: 13.4531\n",
      " |~~ train@6400  Loss: 0.002532 Acc: 13.2656\n",
      " |~~ train@6464  Loss: 0.001996 Acc: 13.3906\n",
      " |~~ train@6528  Loss: 0.002014 Acc: 13.4219\n",
      " |~~ train@6592  Loss: 0.002140 Acc: 13.2656\n",
      " |~~ train@6656  Loss: 0.002041 Acc: 13.3906\n",
      " |~~ train@6720  Loss: 0.001977 Acc: 13.3281\n",
      " |~~ train@6784  Loss: 0.002161 Acc: 13.3281\n",
      " |~~ train@6848  Loss: 0.002051 Acc: 13.3438\n",
      " |~~ train@6912  Loss: 0.002028 Acc: 13.4375\n",
      " |~~ train@6976  Loss: 0.002254 Acc: 13.2812\n",
      " |~~ train@7040  Loss: 0.002452 Acc: 13.2188\n",
      " |~~ train@7104  Loss: 0.002028 Acc: 13.4062\n",
      " |~~ train@7168  Loss: 0.002288 Acc: 13.2812\n",
      " |~~ train@7232  Loss: 0.002024 Acc: 13.3438\n",
      " |~~ train@7296  Loss: 0.002514 Acc: 13.2344\n",
      " |~~ train@7360  Loss: 0.002068 Acc: 13.4062\n",
      " |~~ train@7424  Loss: 0.001856 Acc: 13.4688\n",
      " |~~ train@7488  Loss: 0.002193 Acc: 13.2812\n",
      " |~~ train@7552  Loss: 0.002277 Acc: 13.3281\n",
      " |~~ train@7616  Loss: 0.001931 Acc: 13.4062\n",
      " |~~ train@7680  Loss: 0.002775 Acc: 13.1719\n",
      " |~~ train@7744  Loss: 0.002224 Acc: 13.2656\n",
      " |~~ train@7808  Loss: 0.002053 Acc: 13.3438\n",
      " |~~ train@7872  Loss: 0.002632 Acc: 13.0469\n",
      " |~~ train@7936  Loss: 0.002443 Acc: 13.1719\n",
      " |~~ train@8000  Loss: 0.002054 Acc: 13.3594\n",
      " |~~ train@8064  Loss: 0.002316 Acc: 13.1250\n",
      " |~~ train@8128  Loss: 0.002369 Acc: 13.2344\n",
      " |~~ train@8192  Loss: 0.002343 Acc: 13.2656\n",
      " |~~ train@8256  Loss: 0.002269 Acc: 13.2656\n",
      " |~~ train@8320  Loss: 0.002573 Acc: 13.1250\n",
      " |~~ train@8384  Loss: 0.002201 Acc: 13.2969\n",
      " |~~ train@8448  Loss: 0.002505 Acc: 13.1406\n",
      " |~~ train@8512  Loss: 0.001862 Acc: 13.4375\n",
      " |~~ train@8576  Loss: 0.001907 Acc: 13.4219\n",
      " |~~ train@8640  Loss: 0.002128 Acc: 13.3750\n",
      " |~~ train@8704  Loss: 0.002605 Acc: 13.1562\n",
      " |~~ train@8768  Loss: 0.002356 Acc: 13.2969\n",
      " |~~ train@8832  Loss: 0.002053 Acc: 13.3281\n",
      " |~~ train@8896  Loss: 0.002754 Acc: 13.1406\n",
      " |~~ train@8960  Loss: 0.002194 Acc: 13.3281\n",
      " |~~ train@9024  Loss: 0.001723 Acc: 13.5000\n",
      " |~~ train@9088  Loss: 0.001880 Acc: 13.4219\n",
      " |~~ train@9152  Loss: 0.002015 Acc: 13.3438\n",
      " |~~ train@9216  Loss: 0.001836 Acc: 13.4062\n",
      " |~~ train@9280  Loss: 0.002452 Acc: 13.2031\n",
      " |~~ train@9344  Loss: 0.002399 Acc: 13.2031\n",
      " |~~ train@9408  Loss: 0.002652 Acc: 13.0469\n",
      " |~~ train@9472  Loss: 0.001774 Acc: 13.4844\n",
      " |~~ train@9536  Loss: 0.002645 Acc: 13.1875\n",
      " |~~ train@9600  Loss: 0.002131 Acc: 13.3906\n",
      " |~~ train@9664  Loss: 0.002520 Acc: 13.1875\n",
      " |~~ train@9728  Loss: 0.002163 Acc: 13.3906\n",
      " |~~ train@9792  Loss: 0.001929 Acc: 13.3125\n",
      " |~~ train@9856  Loss: 0.002541 Acc: 13.2031\n",
      " |~~ train@9920  Loss: 0.002059 Acc: 13.3906\n",
      " |~~ train@9984  Loss: 0.002135 Acc: 13.3594\n",
      " |~~ train@10048  Loss: 0.001841 Acc: 13.4531\n",
      " |~~ train@10112  Loss: 0.002272 Acc: 13.3125\n",
      " |~~ train@10176  Loss: 0.002431 Acc: 13.2969\n",
      " |~~ train@10240  Loss: 0.002083 Acc: 13.3438\n",
      " |~~ train@10304  Loss: 0.001785 Acc: 13.4219\n",
      " |~~ train@10368  Loss: 0.002244 Acc: 13.3750\n",
      " |~~ train@10432  Loss: 0.002172 Acc: 13.3125\n",
      " |~~ train@10496  Loss: 0.002012 Acc: 13.3594\n",
      " |~~ train@10560  Loss: 0.002412 Acc: 13.2656\n",
      " |~~ train@10624  Loss: 0.002579 Acc: 13.2500\n",
      " |~~ train@10688  Loss: 0.001917 Acc: 13.4062\n",
      " |~~ train@10752  Loss: 0.002649 Acc: 13.1875\n",
      " |~~ train@10816  Loss: 0.002504 Acc: 13.1250\n",
      " |~~ train@10880  Loss: 0.002290 Acc: 13.2656\n",
      " |~~ train@10944  Loss: 0.001824 Acc: 13.3906\n",
      " |~~ train@11008  Loss: 0.002221 Acc: 13.2812\n",
      " |~~ train@11072  Loss: 0.002490 Acc: 13.1719\n",
      " |~~ train@11136  Loss: 0.002618 Acc: 13.1562\n",
      " |~~ train@11200  Loss: 0.001823 Acc: 13.4375\n",
      " |~~ train@11264  Loss: 0.002104 Acc: 13.3281\n",
      " |~~ train@11328  Loss: 0.002030 Acc: 13.3906\n",
      " |~~ train@11392  Loss: 0.001916 Acc: 13.3594\n",
      " |~~ train@11456  Loss: 0.002542 Acc: 13.1094\n",
      " |~~ train@11520  Loss: 0.002033 Acc: 13.4375\n",
      " |~~ train@11584  Loss: 0.002190 Acc: 13.2812\n",
      " |~~ train@11648  Loss: 0.002681 Acc: 13.0938\n",
      " |~~ train@11712  Loss: 0.002260 Acc: 13.3125\n",
      " |~~ train@11776  Loss: 0.002156 Acc: 13.2812\n",
      " |~~ train@11840  Loss: 0.002477 Acc: 13.2500\n",
      " |~~ train@11904  Loss: 0.002250 Acc: 13.3438\n",
      " |~~ train@11968  Loss: 0.002211 Acc: 13.4062\n",
      " |~~ train@12032  Loss: 0.002349 Acc: 13.1719\n",
      " |~~ train@12096  Loss: 0.002450 Acc: 13.2344\n",
      " |~~ train@12160  Loss: 0.002060 Acc: 13.3125\n",
      " |~~ train@12224  Loss: 0.002583 Acc: 13.1562\n",
      " |~~ train@12288  Loss: 0.002098 Acc: 13.3281\n",
      " |~~ train@12352  Loss: 0.002133 Acc: 13.2500\n",
      " |~~ train@12416  Loss: 0.002612 Acc: 13.0781\n",
      " |~~ train@12480  Loss: 0.002183 Acc: 13.3594\n",
      " |~~ train@12544  Loss: 0.001856 Acc: 13.4062\n",
      " |~~ train@12608  Loss: 0.002854 Acc: 13.0938\n",
      " |~~ train@12672  Loss: 0.001993 Acc: 13.3438\n",
      " |~~ train@12736  Loss: 0.002301 Acc: 13.2969\n",
      " |~~ train@12800  Loss: 0.002026 Acc: 13.3281\n",
      " |~~ train@12864  Loss: 0.001960 Acc: 13.3438\n",
      " |~~ train@12928  Loss: 0.001949 Acc: 13.2656\n",
      " |~~ train@12992  Loss: 0.001952 Acc: 13.4531\n",
      " |~~ train@13056  Loss: 0.002469 Acc: 13.2500\n",
      " |~~ train@13120  Loss: 0.002403 Acc: 13.2344\n",
      " |~~ train@13184  Loss: 0.002650 Acc: 13.2344\n",
      " |~~ train@13248  Loss: 0.002053 Acc: 13.4375\n",
      " |~~ train@13312  Loss: 0.002537 Acc: 13.2344\n",
      " |~~ train@13376  Loss: 0.001891 Acc: 13.4688\n",
      " |~~ train@13440  Loss: 0.002121 Acc: 13.2812\n",
      " |~~ train@13504  Loss: 0.002036 Acc: 13.3125\n",
      " |~~ train@13568  Loss: 0.002174 Acc: 13.2344\n",
      " |~~ train@13632  Loss: 0.002173 Acc: 13.2969\n",
      " |~~ train@13696  Loss: 0.002748 Acc: 13.1406\n",
      " |~~ train@13760  Loss: 0.002320 Acc: 13.2500\n",
      " |~~ train@13824  Loss: 0.002425 Acc: 13.2188\n",
      " |~~ train@13888  Loss: 0.001838 Acc: 13.4531\n",
      " |~~ train@13952  Loss: 0.002260 Acc: 13.3125\n",
      " |~~ train@14016  Loss: 0.002845 Acc: 13.0469\n",
      " |~~ train@14080  Loss: 0.001700 Acc: 13.4062\n",
      " |~~ train@14144  Loss: 0.002499 Acc: 13.2031\n",
      " |~~ train@14208  Loss: 0.002394 Acc: 13.2500\n",
      " |~~ train@14272  Loss: 0.002335 Acc: 13.2188\n",
      " |~~ train@14336  Loss: 0.002376 Acc: 13.2500\n",
      " |~~ train@14400  Loss: 0.002058 Acc: 13.3438\n",
      " |~~ train@14464  Loss: 0.001952 Acc: 13.4062\n",
      " |~~ train@14528  Loss: 0.002510 Acc: 13.2969\n",
      " |~~ train@14592  Loss: 0.001893 Acc: 13.3594\n",
      " |~~ train@14656  Loss: 0.002216 Acc: 13.1875\n",
      " |~~ train@14720  Loss: 0.002040 Acc: 13.3281\n",
      " |~~ train@14784  Loss: 0.002447 Acc: 13.2656\n",
      " |~~ train@14848  Loss: 0.001984 Acc: 13.3750\n",
      " |~~ train@14912  Loss: 0.002322 Acc: 13.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@14976  Loss: 0.002709 Acc: 13.1094\n",
      " |~~ train@15040  Loss: 0.002200 Acc: 13.3594\n",
      " |~~ train@15104  Loss: 0.002005 Acc: 13.3750\n",
      " |~~ train@15168  Loss: 0.002359 Acc: 13.2656\n",
      " |~~ train@15232  Loss: 0.002153 Acc: 13.3594\n",
      " |~~ train@15296  Loss: 0.002099 Acc: 13.2969\n",
      " |~~ train@15360  Loss: 0.001941 Acc: 13.4844\n",
      " |~~ train@15424  Loss: 0.001947 Acc: 13.3594\n",
      " |~~ train@15488  Loss: 0.002208 Acc: 13.2969\n",
      " |~~ train@15552  Loss: 0.001766 Acc: 13.4375\n",
      " |~~ train@15616  Loss: 0.001957 Acc: 13.4062\n",
      " |~~ train@15680  Loss: 0.001805 Acc: 13.4375\n",
      " |~~ train@15744  Loss: 0.001986 Acc: 13.3594\n",
      " |~~ train@15808  Loss: 0.002373 Acc: 13.2031\n",
      " |~~ train@15872  Loss: 0.001922 Acc: 13.4844\n",
      " |~~ train@15936  Loss: 0.001837 Acc: 13.3906\n",
      " |~~ train@16000  Loss: 0.002081 Acc: 13.4844\n",
      " |~~ train@16064  Loss: 0.001433 Acc: 13.6094\n",
      " |~~ train@16128  Loss: 0.002291 Acc: 13.2969\n",
      " |~~ train@16192  Loss: 0.002013 Acc: 13.3906\n",
      " |~~ train@16256  Loss: 0.002244 Acc: 13.2344\n",
      " |~~ train@16320  Loss: 0.002449 Acc: 13.2812\n",
      " |~~ train@16384  Loss: 0.002034 Acc: 13.3906\n",
      " |~~ train@16448  Loss: 0.002080 Acc: 13.3281\n",
      " |~~ train@16512  Loss: 0.002133 Acc: 13.4219\n",
      " |~~ train@16576  Loss: 0.001526 Acc: 13.6094\n",
      " |~~ train@16640  Loss: 0.002051 Acc: 13.3281\n",
      " |~~ train@16704  Loss: 0.002120 Acc: 13.3125\n",
      " |~~ train@16768  Loss: 0.001733 Acc: 13.4844\n",
      " |~~ train@16832  Loss: 0.002276 Acc: 13.1250\n",
      " |~~ train@16896  Loss: 0.002001 Acc: 13.4688\n",
      " |~~ train@16960  Loss: 0.002313 Acc: 13.3906\n",
      " |~~ train@17024  Loss: 0.002542 Acc: 13.1875\n",
      " |~~ train@17088  Loss: 0.001990 Acc: 13.4062\n",
      " |~~ train@17152  Loss: 0.001730 Acc: 13.4688\n",
      " |~~ train@17216  Loss: 0.002189 Acc: 13.3281\n",
      " |~~ train@17280  Loss: 0.002675 Acc: 13.0938\n",
      " |~~ train@17344  Loss: 0.001910 Acc: 13.4219\n",
      " |~~ train@17408  Loss: 0.002026 Acc: 13.3750\n",
      " |~~ train@17472  Loss: 0.002057 Acc: 13.3281\n",
      " |~~ train@17536  Loss: 0.002371 Acc: 13.1406\n",
      " |~~ train@17600  Loss: 0.002700 Acc: 13.0625\n",
      " |~~ train@17664  Loss: 0.002329 Acc: 13.2031\n",
      " |~~ train@17728  Loss: 0.001805 Acc: 13.4219\n",
      " |~~ train@17792  Loss: 0.002547 Acc: 13.2344\n",
      " |~~ train@17856  Loss: 0.002076 Acc: 13.3125\n",
      " |~~ train@17920  Loss: 0.001921 Acc: 13.4375\n",
      " |~~ train@17984  Loss: 0.001942 Acc: 13.4062\n",
      " |~~ train@18048  Loss: 0.001812 Acc: 13.4688\n",
      " |~~ train@18112  Loss: 0.002507 Acc: 13.2188\n",
      " |~~ train@18176  Loss: 0.001928 Acc: 13.4375\n",
      " |~~ train@18240  Loss: 0.001674 Acc: 13.5000\n",
      " |~~ train@18304  Loss: 0.002215 Acc: 13.2969\n",
      " |~~ train@18368  Loss: 0.002033 Acc: 13.4062\n",
      " |~~ train@18432  Loss: 0.002415 Acc: 13.2500\n",
      " |~~ train@18496  Loss: 0.002096 Acc: 13.3125\n",
      " |~~ train@18560  Loss: 0.002478 Acc: 13.1875\n",
      " |~~ train@18624  Loss: 0.002963 Acc: 13.0938\n",
      " |~~ train@18688  Loss: 0.002569 Acc: 13.2344\n",
      " |~~ train@18752  Loss: 0.001788 Acc: 13.4844\n",
      " |~~ train@18816  Loss: 0.002214 Acc: 13.3594\n",
      " |~~ train@18880  Loss: 0.001911 Acc: 13.5156\n",
      " |~~ train@18944  Loss: 0.002319 Acc: 13.3281\n",
      " |~~ train@19008  Loss: 0.002176 Acc: 13.3125\n",
      " |~~ train@19072  Loss: 0.002273 Acc: 13.3125\n",
      " |~~ train@19136  Loss: 0.002172 Acc: 13.2500\n",
      " |~~ train@19200  Loss: 0.001978 Acc: 13.3281\n",
      " |~~ train@19264  Loss: 0.001872 Acc: 13.3750\n",
      " |~~ train@19328  Loss: 0.001906 Acc: 13.4531\n",
      " |~~ train@19392  Loss: 0.002167 Acc: 13.4219\n",
      " |~~ train@19456  Loss: 0.001883 Acc: 13.4688\n",
      " |~~ train@19520  Loss: 0.002136 Acc: 13.3594\n",
      " |~~ train@19584  Loss: 0.002481 Acc: 13.2344\n",
      " |~~ train@19648  Loss: 0.001778 Acc: 13.5000\n",
      " |~~ train@19712  Loss: 0.002086 Acc: 13.3281\n",
      " |~~ train@19776  Loss: 0.001883 Acc: 13.3438\n",
      " |~~ train@19840  Loss: 0.001935 Acc: 13.3594\n",
      " |~~ train@19904  Loss: 0.001890 Acc: 13.5156\n",
      " |~~ train@19968  Loss: 0.001890 Acc: 13.5000\n",
      " |~~ train@20032  Loss: 0.002488 Acc: 13.2500\n",
      " |~~ train@20096  Loss: 0.002487 Acc: 13.2188\n",
      " |~~ train@20160  Loss: 0.002394 Acc: 13.3281\n",
      " |~~ train@20224  Loss: 0.002302 Acc: 13.2500\n",
      " |~~ train@20288  Loss: 0.002449 Acc: 13.1719\n",
      " |~~ train@20352  Loss: 0.002056 Acc: 13.3438\n",
      " |~~ train@20416  Loss: 0.001950 Acc: 13.4062\n",
      " |~~ train@20480  Loss: 0.002238 Acc: 13.2188\n",
      " |~~ train@20544  Loss: 0.001865 Acc: 13.4219\n",
      " |~~ train@20608  Loss: 0.002632 Acc: 13.0469\n",
      " |~~ train@20672  Loss: 0.001961 Acc: 13.4219\n",
      " |~~ train@20736  Loss: 0.001561 Acc: 13.5312\n",
      " |~~ train@20800  Loss: 0.002689 Acc: 13.2031\n",
      " |~~ train@20864  Loss: 0.002252 Acc: 13.3125\n",
      " |~~ train@20928  Loss: 0.002052 Acc: 13.3594\n",
      " |~~ train@20992  Loss: 0.002348 Acc: 13.2969\n",
      " |~~ train@21056  Loss: 0.002479 Acc: 13.1406\n",
      " |~~ train@21120  Loss: 0.002406 Acc: 13.1250\n",
      " |~~ train@21184  Loss: 0.001907 Acc: 13.3594\n",
      " |~~ train@21248  Loss: 0.002093 Acc: 13.3594\n",
      " |~~ train@21312  Loss: 0.001903 Acc: 13.3906\n",
      " |~~ train@21376  Loss: 0.002037 Acc: 13.4219\n",
      " |~~ train@21440  Loss: 0.002312 Acc: 13.2656\n",
      " |~~ train@21504  Loss: 0.001881 Acc: 13.4219\n",
      " |~~ train@21568  Loss: 0.001842 Acc: 13.3906\n",
      " |~~ train@21632  Loss: 0.002575 Acc: 13.1250\n",
      " |~~ train@21696  Loss: 0.002308 Acc: 13.2656\n",
      " |~~ train@21760  Loss: 0.002479 Acc: 13.2812\n",
      " |~~ train@21824  Loss: 0.002049 Acc: 13.4219\n",
      " |~~ train@21888  Loss: 0.002721 Acc: 13.1875\n",
      " |~~ train@21952  Loss: 0.002138 Acc: 13.2656\n",
      " |~~ train@22016  Loss: 0.002158 Acc: 13.3438\n",
      " |~~ train@22080  Loss: 0.002286 Acc: 13.2969\n",
      " |~~ train@22144  Loss: 0.002075 Acc: 13.2969\n",
      " |~~ train@22208  Loss: 0.002314 Acc: 13.2812\n",
      " |~~ train@22272  Loss: 0.001798 Acc: 13.4375\n",
      " |~~ train@22336  Loss: 0.002448 Acc: 13.2344\n",
      " |~~ train@22400  Loss: 0.002261 Acc: 13.2500\n",
      " |~~ train@22464  Loss: 0.002127 Acc: 13.3125\n",
      " |~~ train@22528  Loss: 0.002631 Acc: 13.2188\n",
      " |~~ train@22592  Loss: 0.002062 Acc: 13.3281\n",
      " |~~ train@22656  Loss: 0.002084 Acc: 13.2969\n",
      " |~~ train@22720  Loss: 0.001653 Acc: 13.4531\n",
      " |~~ train@22784  Loss: 0.002259 Acc: 13.2500\n",
      " |~~ train@22848  Loss: 0.002331 Acc: 13.3281\n",
      " |~~ train@22912  Loss: 0.001887 Acc: 13.4219\n",
      " |~~ train@22976  Loss: 0.002169 Acc: 13.2812\n",
      " |~~ train@23040  Loss: 0.001849 Acc: 13.4375\n",
      " |~~ train@23104  Loss: 0.002429 Acc: 13.2812\n",
      " |~~ train@23168  Loss: 0.001758 Acc: 13.4062\n",
      " |~~ train@23232  Loss: 0.002382 Acc: 13.2188\n",
      " |~~ train@23296  Loss: 0.001922 Acc: 13.3906\n",
      " |~~ train@23360  Loss: 0.002274 Acc: 13.3750\n",
      " |~~ train@23424  Loss: 0.002536 Acc: 13.2969\n",
      " |~~ train@23488  Loss: 0.002283 Acc: 13.2969\n",
      " |~~ train@23552  Loss: 0.002301 Acc: 13.3594\n",
      " |~~ train@23616  Loss: 0.001901 Acc: 13.5469\n",
      " |~~ train@23680  Loss: 0.002216 Acc: 13.3125\n",
      " |~~ train@23744  Loss: 0.002568 Acc: 13.1406\n",
      " |~~ train@23808  Loss: 0.002061 Acc: 13.4219\n",
      " |~~ train@23872  Loss: 0.001967 Acc: 13.4219\n",
      " |~~ train@23936  Loss: 0.002301 Acc: 13.2812\n",
      " |~~ train@24000  Loss: 0.002221 Acc: 13.2969\n",
      " |~~ train@24064  Loss: 0.003256 Acc: 12.8750\n",
      " |~~ train@24128  Loss: 0.002422 Acc: 13.2344\n",
      " |~~ train@24192  Loss: 0.002498 Acc: 13.2500\n",
      " |~~ train@24256  Loss: 0.002082 Acc: 13.3750\n",
      " |~~ train@24320  Loss: 0.002439 Acc: 13.2812\n",
      " |~~ train@24384  Loss: 0.001882 Acc: 13.5000\n",
      " |~~ train@24448  Loss: 0.001851 Acc: 13.4375\n",
      " |~~ train@24512  Loss: 0.002217 Acc: 13.1719\n",
      " |~~ train@24576  Loss: 0.002432 Acc: 13.2812\n",
      " |~~ train@24640  Loss: 0.002506 Acc: 13.0938\n",
      " |~~ train@24704  Loss: 0.002170 Acc: 13.2344\n",
      " |~~ train@24768  Loss: 0.002759 Acc: 13.0781\n",
      " |~~ train@24832  Loss: 0.002043 Acc: 13.3125\n",
      " |~~ train@24896  Loss: 0.002080 Acc: 13.2500\n",
      " |~~ train@24960  Loss: 0.002149 Acc: 13.3438\n",
      " |~~ train@25024  Loss: 0.002552 Acc: 13.2656\n",
      " |~~ train@25088  Loss: 0.002191 Acc: 13.3438\n",
      " |~~ train@25152  Loss: 0.001951 Acc: 13.3438\n",
      " |~~ train@25216  Loss: 0.001652 Acc: 13.5625\n",
      " |~~ train@25280  Loss: 0.001862 Acc: 13.4375\n",
      " |~~ train@25344  Loss: 0.002181 Acc: 13.3125\n",
      " |~~ train@25408  Loss: 0.002299 Acc: 13.1719\n",
      " |~~ train@25472  Loss: 0.002107 Acc: 13.2812\n",
      " |~~ train@25536  Loss: 0.002440 Acc: 13.1406\n",
      " |~~ train@25600  Loss: 0.002130 Acc: 13.3594\n",
      " |~~ train@25664  Loss: 0.002395 Acc: 13.1719\n",
      " |~~ train@25728  Loss: 0.001936 Acc: 13.3438\n",
      " |~~ train@25792  Loss: 0.002137 Acc: 13.2812\n",
      " |~~ train@25856  Loss: 0.002819 Acc: 13.0000\n",
      " |~~ train@25920  Loss: 0.002216 Acc: 13.3594\n",
      " |~~ train@25984  Loss: 0.002587 Acc: 13.0938\n",
      " |~~ train@26048  Loss: 0.001970 Acc: 13.3281\n",
      " |~~ train@26112  Loss: 0.002248 Acc: 13.3750\n",
      " |~~ train@26176  Loss: 0.002066 Acc: 13.3906\n",
      " |~~ train@26240  Loss: 0.002606 Acc: 13.2188\n",
      " |~~ train@26304  Loss: 0.001769 Acc: 13.5156\n",
      " |~~ train@26368  Loss: 0.002148 Acc: 13.2969\n",
      " |~~ train@26432  Loss: 0.002247 Acc: 13.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@26496  Loss: 0.002231 Acc: 13.2656\n",
      " |~~ train@26560  Loss: 0.002031 Acc: 13.3906\n",
      " |~~ train@26624  Loss: 0.002350 Acc: 13.2812\n",
      " |~~ train@26688  Loss: 0.002457 Acc: 13.2656\n",
      " |~~ train@26752  Loss: 0.002494 Acc: 13.1250\n",
      " |~~ train@26816  Loss: 0.002076 Acc: 13.2969\n",
      " |~~ train@26880  Loss: 0.002388 Acc: 13.2656\n",
      " |~~ train@26944  Loss: 0.001955 Acc: 13.3594\n",
      " |~~ train@27008  Loss: 0.002192 Acc: 13.3438\n",
      " |~~ train@27072  Loss: 0.002007 Acc: 13.3750\n",
      " |~~ train@27136  Loss: 0.002756 Acc: 13.1406\n",
      " |~~ train@27200  Loss: 0.002223 Acc: 13.3438\n",
      " |~~ train@27264  Loss: 0.002502 Acc: 13.2188\n",
      " |~~ train@27328  Loss: 0.002162 Acc: 13.2031\n",
      " |~~ train@27392  Loss: 0.001833 Acc: 13.3750\n",
      " |~~ train@27456  Loss: 0.002108 Acc: 13.2500\n",
      " |~~ train@27520  Loss: 0.002065 Acc: 13.3750\n",
      " |~~ train@27584  Loss: 0.001782 Acc: 13.5312\n",
      " |~~ train@27648  Loss: 0.002364 Acc: 13.1719\n",
      " |~~ train@27712  Loss: 0.002327 Acc: 13.2812\n",
      " |~~ train@27776  Loss: 0.002279 Acc: 13.3594\n",
      " |~~ train@27840  Loss: 0.001958 Acc: 13.4531\n",
      " |~~ train@27904  Loss: 0.002376 Acc: 13.2812\n",
      " |~~ train@27968  Loss: 0.001930 Acc: 13.3906\n",
      " |~~ train@28032  Loss: 0.002122 Acc: 13.3125\n",
      " |~~ train@28096  Loss: 0.002087 Acc: 13.3750\n",
      " |~~ train@28160  Loss: 0.002135 Acc: 13.3281\n",
      " |~~ train@28224  Loss: 0.002362 Acc: 13.3438\n",
      " |~~ train@28288  Loss: 0.002312 Acc: 13.3125\n",
      " |~~ train@28352  Loss: 0.002527 Acc: 13.2969\n",
      " |~~ train@28416  Loss: 0.002008 Acc: 13.4062\n",
      " |~~ train@28480  Loss: 0.001996 Acc: 13.3438\n",
      " |~~ train@28544  Loss: 0.002378 Acc: 13.2656\n",
      " |~~ train@28608  Loss: 0.002020 Acc: 13.3438\n",
      " |~~ train@28672  Loss: 0.001935 Acc: 13.3906\n",
      " |~~ train@28736  Loss: 0.001877 Acc: 13.4375\n",
      " |~~ train@28800  Loss: 0.001837 Acc: 13.3906\n",
      " |~~ train@28864  Loss: 0.001749 Acc: 13.4844\n",
      " |~~ train@28928  Loss: 0.001640 Acc: 13.4688\n",
      " |~~ train@28992  Loss: 0.002412 Acc: 13.2188\n",
      " |~~ train@29056  Loss: 0.002465 Acc: 13.1875\n",
      " |~~ train@29120  Loss: 0.002794 Acc: 13.0938\n",
      " |~~ train@29184  Loss: 0.002030 Acc: 13.2500\n",
      " |~~ train@29248  Loss: 0.001800 Acc: 13.3906\n",
      " |~~ train@29312  Loss: 0.001611 Acc: 13.5312\n",
      " |~~ train@29376  Loss: 0.002101 Acc: 13.3438\n",
      " |~~ train@29440  Loss: 0.002432 Acc: 13.2344\n",
      " |~~ train@29504  Loss: 0.002221 Acc: 13.2812\n",
      " |~~ train@29568  Loss: 0.002318 Acc: 13.2812\n",
      " |~~ train@29632  Loss: 0.002666 Acc: 13.1719\n",
      " |~~ train@29696  Loss: 0.002569 Acc: 13.2031\n",
      " |~~ train@29760  Loss: 0.002759 Acc: 13.0938\n",
      " |~~ train@29824  Loss: 0.001527 Acc: 13.5938\n",
      " |~~ train@29888  Loss: 0.001785 Acc: 13.4219\n",
      " |~~ train@29952  Loss: 0.002561 Acc: 13.1719\n",
      " |~~ train@30016  Loss: 0.001938 Acc: 13.4375\n",
      " |~~ train@30080  Loss: 0.002019 Acc: 13.3281\n",
      " |~~ train@30144  Loss: 0.001798 Acc: 13.4219\n",
      " |~~ train@30208  Loss: 0.002187 Acc: 13.3281\n",
      " |~~ train@30272  Loss: 0.001769 Acc: 13.5000\n",
      " |~~ train@30336  Loss: 0.002119 Acc: 13.3438\n",
      " |~~ train@30400  Loss: 0.002371 Acc: 13.2344\n",
      " |~~ train@30464  Loss: 0.002384 Acc: 13.2344\n",
      " |~~ train@30528  Loss: 0.002452 Acc: 13.2344\n",
      " |~~ train@30592  Loss: 0.002717 Acc: 13.1094\n",
      " |~~ train@30656  Loss: 0.002417 Acc: 13.2031\n",
      " |~~ train@30720  Loss: 0.002214 Acc: 13.2500\n",
      " |~~ train@30784  Loss: 0.002299 Acc: 13.2969\n",
      " |~~ train@30848  Loss: 0.002278 Acc: 13.2656\n",
      " |~~ train@30912  Loss: 0.001907 Acc: 13.4375\n",
      " |~~ train@30976  Loss: 0.002041 Acc: 13.2812\n",
      " |~~ train@31040  Loss: 0.002487 Acc: 13.2188\n",
      " |~~ train@31104  Loss: 0.002445 Acc: 13.1875\n",
      " |~~ train@31168  Loss: 0.001991 Acc: 13.3438\n",
      " |~~ train@31232  Loss: 0.002619 Acc: 13.1719\n",
      " |~~ train@31296  Loss: 0.002264 Acc: 13.2656\n",
      " |~~ train@31360  Loss: 0.001906 Acc: 13.3594\n",
      " |~~ train@31424  Loss: 0.002704 Acc: 13.1406\n",
      " |~~ train@31488  Loss: 0.002171 Acc: 13.2500\n",
      " |~~ train@31552  Loss: 0.002124 Acc: 13.2812\n",
      " |~~ train@31616  Loss: 0.002103 Acc: 13.3281\n",
      " |~~ train@31680  Loss: 0.002008 Acc: 13.3750\n",
      " |~~ train@31744  Loss: 0.002211 Acc: 13.3281\n",
      " |~~ train@31808  Loss: 0.002090 Acc: 13.3906\n",
      " |~~ train@31872  Loss: 0.002603 Acc: 13.0625\n",
      " |~~ train@31936  Loss: 0.002139 Acc: 13.2656\n",
      " |~~ train@32000  Loss: 0.002393 Acc: 13.2188\n",
      " |~~ train@32064  Loss: 0.002530 Acc: 13.2188\n",
      " |~~ train@32128  Loss: 0.001948 Acc: 13.3438\n",
      " |~~ train@32192  Loss: 0.002471 Acc: 13.3750\n",
      " |~~ train@32256  Loss: 0.002374 Acc: 13.2188\n",
      " |~~ train@32320  Loss: 0.002421 Acc: 13.2656\n",
      " |~~ train@32384  Loss: 0.002164 Acc: 13.2656\n",
      " |~~ train@32448  Loss: 0.001924 Acc: 13.3281\n",
      " |~~ train@32512  Loss: 0.002254 Acc: 13.2969\n",
      " |~~ train@32576  Loss: 0.002360 Acc: 13.2656\n",
      " |~~ train@32640  Loss: 0.003059 Acc: 13.0312\n",
      " |~~ train@32704  Loss: 0.002228 Acc: 13.4219\n",
      " |~~ train@32768  Loss: 0.001882 Acc: 13.4688\n",
      " |~~ train@32832  Loss: 0.002104 Acc: 13.4219\n",
      " |~~ train@32896  Loss: 0.001818 Acc: 13.3750\n",
      " |~~ train@32960  Loss: 0.002498 Acc: 13.2188\n",
      " |~~ train@33024  Loss: 0.002360 Acc: 13.2656\n",
      " |~~ train@33088  Loss: 0.001723 Acc: 13.4062\n",
      " |~~ train@33152  Loss: 0.002547 Acc: 13.2500\n",
      " |~~ train@33216  Loss: 0.002182 Acc: 13.3750\n",
      " |~~ train@33280  Loss: 0.001904 Acc: 13.3594\n",
      " |~~ train@33344  Loss: 0.002265 Acc: 13.2812\n",
      " |~~ train@33408  Loss: 0.002240 Acc: 13.3125\n",
      " |~~ train@33472  Loss: 0.002715 Acc: 13.0781\n",
      " |~~ train@33536  Loss: 0.002197 Acc: 13.2656\n",
      " |~~ train@33600  Loss: 0.002231 Acc: 13.4062\n",
      " |~~ train@33664  Loss: 0.002013 Acc: 13.2812\n",
      " |~~ train@33728  Loss: 0.001621 Acc: 13.5781\n",
      " |~~ train@33792  Loss: 0.001981 Acc: 13.5000\n",
      " |~~ train@33856  Loss: 0.001952 Acc: 13.4219\n",
      " |~~ train@33920  Loss: 0.002076 Acc: 13.4219\n",
      " |~~ train@33984  Loss: 0.002200 Acc: 13.3750\n",
      " |~~ train@34048  Loss: 0.001724 Acc: 13.4688\n",
      " |~~ train@34112  Loss: 0.001800 Acc: 13.4219\n",
      " |~~ train@34176  Loss: 0.002149 Acc: 13.2188\n",
      " |~~ train@34240  Loss: 0.002232 Acc: 13.3438\n",
      " |~~ train@34304  Loss: 0.002868 Acc: 13.1562\n",
      " |~~ train@34368  Loss: 0.001668 Acc: 13.5156\n",
      " |~~ train@34432  Loss: 0.002358 Acc: 13.3281\n",
      " |~~ train@34496  Loss: 0.001987 Acc: 13.3750\n",
      " |~~ train@34560  Loss: 0.002634 Acc: 13.1406\n",
      " |~~ train@34624  Loss: 0.002359 Acc: 13.2188\n",
      " |~~ train@34688  Loss: 0.002311 Acc: 13.3594\n",
      " |~~ train@34752  Loss: 0.001852 Acc: 13.4688\n",
      " |~~ train@34816  Loss: 0.001854 Acc: 13.4688\n",
      " |~~ train@34880  Loss: 0.002038 Acc: 13.4219\n",
      " |~~ train@34944  Loss: 0.001794 Acc: 13.4375\n",
      " |~~ train@35008  Loss: 0.002579 Acc: 13.1875\n",
      " |~~ train@35072  Loss: 0.001910 Acc: 13.4219\n",
      " |~~ train@35136  Loss: 0.002301 Acc: 13.3438\n",
      " |~~ train@35200  Loss: 0.002660 Acc: 13.1719\n",
      " |~~ train@35264  Loss: 0.002386 Acc: 13.3438\n",
      " |~~ train@35328  Loss: 0.002329 Acc: 13.2188\n",
      " |~~ train@35392  Loss: 0.001825 Acc: 13.3906\n",
      " |~~ train@35456  Loss: 0.002707 Acc: 13.0625\n",
      " |~~ train@35520  Loss: 0.002837 Acc: 13.1875\n",
      " |~~ train@35584  Loss: 0.002068 Acc: 13.3438\n",
      " |~~ train@35648  Loss: 0.002357 Acc: 13.2188\n",
      " |~~ train@35712  Loss: 0.002485 Acc: 13.1562\n",
      " |~~ train@35776  Loss: 0.002176 Acc: 13.4531\n",
      " |~~ train@35840  Loss: 0.002210 Acc: 13.3125\n",
      " |~~ train@35904  Loss: 0.002758 Acc: 13.0938\n",
      " |~~ train@35968  Loss: 0.002386 Acc: 13.2344\n",
      " |~~ train@36032  Loss: 0.002564 Acc: 13.1875\n",
      " |~~ train@36096  Loss: 0.001960 Acc: 13.4531\n",
      " |~~ train@36160  Loss: 0.002272 Acc: 13.3125\n",
      " |~~ train@36224  Loss: 0.002486 Acc: 13.2031\n",
      " |~~ train@36288  Loss: 0.001785 Acc: 13.4688\n",
      " |~~ train@36352  Loss: 0.002065 Acc: 13.3750\n",
      " |~~ train@36416  Loss: 0.002226 Acc: 13.2500\n",
      " |~~ train@36480  Loss: 0.002201 Acc: 13.2656\n",
      " |~~ train@36544  Loss: 0.001930 Acc: 13.4219\n",
      " |~~ train@36608  Loss: 0.001835 Acc: 13.4219\n",
      " |~~ train@36672  Loss: 0.002393 Acc: 13.2500\n",
      " |~~ train@36736  Loss: 0.002350 Acc: 13.3438\n",
      " |~~ train@36800  Loss: 0.002227 Acc: 13.2969\n",
      " |~~ train@36864  Loss: 0.001690 Acc: 13.4688\n",
      " |~~ train@36928  Loss: 0.001776 Acc: 13.4688\n",
      " |~~ train@36992  Loss: 0.001963 Acc: 13.3125\n",
      " |~~ train@37056  Loss: 0.001950 Acc: 13.3594\n",
      " |~~ train@37120  Loss: 0.002740 Acc: 13.1875\n",
      " |~~ train@37184  Loss: 0.002510 Acc: 13.1719\n",
      " |~~ train@37248  Loss: 0.002319 Acc: 13.2812\n",
      " |~~ train@37312  Loss: 0.002111 Acc: 13.3281\n",
      " |~~ train@37376  Loss: 0.001914 Acc: 13.3594\n",
      " |~~ train@37440  Loss: 0.001584 Acc: 13.5625\n",
      " |~~ train@37504  Loss: 0.002217 Acc: 13.2969\n",
      " |~~ train@37568  Loss: 0.002563 Acc: 13.1250\n",
      " |~~ train@37632  Loss: 0.002107 Acc: 13.3594\n",
      " |~~ train@37696  Loss: 0.002276 Acc: 13.3438\n",
      " |~~ train@37760  Loss: 0.002464 Acc: 13.1875\n",
      " |~~ train@37824  Loss: 0.001868 Acc: 13.4688\n",
      " |~~ train@37888  Loss: 0.002487 Acc: 13.1406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@37952  Loss: 0.001634 Acc: 13.6250\n",
      " |~~ train@38016  Loss: 0.002326 Acc: 13.2500\n",
      " |~~ train@38080  Loss: 0.001811 Acc: 13.4688\n",
      " |~~ train@38144  Loss: 0.001670 Acc: 13.5000\n",
      " |~~ train@38208  Loss: 0.002044 Acc: 13.3438\n",
      " |~~ train@38272  Loss: 0.002403 Acc: 13.2656\n",
      " |~~ train@38336  Loss: 0.002374 Acc: 13.2188\n",
      " |~~ train@38400  Loss: 0.001776 Acc: 13.5000\n",
      " |~~ train@38464  Loss: 0.002009 Acc: 13.3750\n",
      " |~~ train@38528  Loss: 0.002231 Acc: 13.3906\n",
      " |~~ train@38592  Loss: 0.002086 Acc: 13.3750\n",
      " |~~ train@38656  Loss: 0.002308 Acc: 13.1875\n",
      " |~~ train@38720  Loss: 0.001882 Acc: 13.3906\n",
      " |~~ train@38784  Loss: 0.002703 Acc: 13.2188\n",
      " |~~ train@38848  Loss: 0.002259 Acc: 13.2344\n",
      " |~~ train@38912  Loss: 0.002504 Acc: 13.1562\n",
      " |~~ train@38976  Loss: 0.002269 Acc: 13.2656\n",
      " |~~ train@39040  Loss: 0.002387 Acc: 13.2500\n",
      " |~~ train@39104  Loss: 0.001907 Acc: 13.4375\n",
      " |~~ train@39168  Loss: 0.002426 Acc: 13.2344\n",
      " |~~ train@39232  Loss: 0.002212 Acc: 13.2500\n",
      " |~~ train@39296  Loss: 0.002014 Acc: 13.3438\n",
      " |~~ train@39360  Loss: 0.002153 Acc: 13.3281\n",
      " |~~ train@39424  Loss: 0.001762 Acc: 13.4688\n",
      " |~~ train@39488  Loss: 0.001827 Acc: 13.3594\n",
      " |~~ train@39552  Loss: 0.002039 Acc: 13.3594\n",
      " |~~ train@39616  Loss: 0.002180 Acc: 13.2969\n",
      " |~~ train@39680  Loss: 0.001928 Acc: 13.3906\n",
      " |~~ train@39744  Loss: 0.002085 Acc: 13.3594\n",
      " |~~ train@39808  Loss: 0.002005 Acc: 13.4531\n",
      " |~~ train@39872  Loss: 0.002322 Acc: 13.2500\n",
      " |~~ train@39936  Loss: 0.002506 Acc: 13.3125\n",
      " |~~ train@40000  Loss: 0.002033 Acc: 13.4062\n",
      " |~~ train@40064  Loss: 0.002640 Acc: 13.1250\n",
      " |~~ train@40128  Loss: 0.002285 Acc: 13.2188\n",
      " |~~ train@40192  Loss: 0.002421 Acc: 13.1875\n",
      " |~~ train@40256  Loss: 0.002044 Acc: 13.3594\n",
      " |~~ train@40320  Loss: 0.002446 Acc: 13.1875\n",
      " |~~ train@40384  Loss: 0.002032 Acc: 13.2344\n",
      " |~~ train@40448  Loss: 0.002140 Acc: 13.2969\n",
      " |~~ train@40512  Loss: 0.002537 Acc: 13.1406\n",
      " |~~ train@40576  Loss: 0.002590 Acc: 13.2344\n",
      " |~~ train@40640  Loss: 0.002108 Acc: 13.3281\n",
      " |~~ train@40704  Loss: 0.002391 Acc: 13.3438\n",
      " |~~ train@40768  Loss: 0.002543 Acc: 13.1562\n",
      " |~~ train@40832  Loss: 0.001876 Acc: 13.5156\n",
      " |~~ train@40896  Loss: 0.002138 Acc: 13.3750\n",
      " |~~ train@40960  Loss: 0.002380 Acc: 13.2500\n",
      " |~~ train@41024  Loss: 0.002544 Acc: 13.1250\n",
      " |~~ train@41088  Loss: 0.002495 Acc: 13.1719\n",
      " |~~ train@41152  Loss: 0.002223 Acc: 13.2500\n",
      " |~~ train@41216  Loss: 0.001566 Acc: 13.5625\n",
      " |~~ train@41280  Loss: 0.002083 Acc: 13.2812\n",
      " |~~ train@41344  Loss: 0.002418 Acc: 13.3125\n",
      " |~~ train@41408  Loss: 0.001568 Acc: 13.5781\n",
      " |~~ train@41472  Loss: 0.001974 Acc: 13.3906\n",
      " |~~ train@41536  Loss: 0.002491 Acc: 13.1875\n",
      " |~~ train@41600  Loss: 0.002652 Acc: 13.1250\n",
      " |~~ train@41664  Loss: 0.002383 Acc: 13.2188\n",
      " |~~ train@41728  Loss: 0.002234 Acc: 13.2969\n",
      " |~~ train@41792  Loss: 0.002526 Acc: 13.2031\n",
      " |~~ train@41856  Loss: 0.001774 Acc: 13.4844\n",
      " |~~ train@41920  Loss: 0.002421 Acc: 13.2344\n",
      " |~~ train@41984  Loss: 0.001612 Acc: 13.4375\n",
      " |~~ train@42048  Loss: 0.002630 Acc: 13.1406\n",
      " |~~ train@42112  Loss: 0.002259 Acc: 13.2500\n",
      " |~~ train@42176  Loss: 0.002328 Acc: 13.3750\n",
      " |~~ train@42240  Loss: 0.002311 Acc: 13.2656\n",
      " |~~ train@42304  Loss: 0.002747 Acc: 13.2031\n",
      " |~~ train@42368  Loss: 0.002475 Acc: 13.1406\n",
      " |~~ train@42432  Loss: 0.002038 Acc: 13.4375\n",
      " |~~ train@42496  Loss: 0.002570 Acc: 13.1094\n",
      " |~~ train@42560  Loss: 0.002663 Acc: 13.1094\n",
      " |~~ train@42624  Loss: 0.002328 Acc: 13.1719\n",
      " |~~ train@42688  Loss: 0.001959 Acc: 13.3594\n",
      " |~~ train@42752  Loss: 0.002212 Acc: 13.3438\n",
      " |~~ train@42816  Loss: 0.001820 Acc: 13.3906\n",
      " |~~ train@42880  Loss: 0.002095 Acc: 13.4062\n",
      " |~~ train@42944  Loss: 0.002052 Acc: 13.4062\n",
      " |~~ train@43008  Loss: 0.002398 Acc: 13.2031\n",
      " |~~ train@43072  Loss: 0.002240 Acc: 13.3125\n",
      " |~~ train@43136  Loss: 0.002162 Acc: 13.2344\n",
      " |~~ train@43200  Loss: 0.002151 Acc: 13.2812\n",
      " |~~ train@43264  Loss: 0.002442 Acc: 13.2500\n",
      " |~~ train@43328  Loss: 0.001969 Acc: 13.2812\n",
      " |~~ train@43392  Loss: 0.001811 Acc: 13.5000\n",
      " |~~ train@43456  Loss: 0.001697 Acc: 13.4844\n",
      " |~~ train@43520  Loss: 0.001758 Acc: 13.5156\n",
      " |~~ train@43584  Loss: 0.002119 Acc: 13.3750\n",
      " |~~ train@43648  Loss: 0.002087 Acc: 13.3438\n",
      " |~~ train@43712  Loss: 0.001647 Acc: 13.4062\n",
      " |~~ train@43776  Loss: 0.001587 Acc: 13.5000\n",
      " |~~ train@43840  Loss: 0.001961 Acc: 13.3750\n",
      " |~~ train@43904  Loss: 0.002038 Acc: 13.4375\n",
      " |~~ train@43968  Loss: 0.002065 Acc: 13.2969\n",
      " |~~ train@44032  Loss: 0.002333 Acc: 13.3281\n",
      " |~~ train@44096  Loss: 0.002422 Acc: 13.2188\n",
      " |~~ train@44160  Loss: 0.002228 Acc: 13.3906\n",
      " |~~ train@44224  Loss: 0.002052 Acc: 13.3281\n",
      " |~~ train@44288  Loss: 0.002340 Acc: 13.2969\n",
      " |~~ train@44352  Loss: 0.002080 Acc: 13.3906\n",
      " |~~ train@44416  Loss: 0.002236 Acc: 13.2500\n",
      " |~~ train@44480  Loss: 0.002079 Acc: 13.4375\n",
      " |~~ train@44544  Loss: 0.002370 Acc: 13.2031\n",
      " |~~ train@44608  Loss: 0.001883 Acc: 13.4844\n",
      " |~~ train@44672  Loss: 0.002240 Acc: 13.3906\n",
      " |~~ train@44736  Loss: 0.002449 Acc: 13.1094\n",
      " |~~ train@44800  Loss: 0.002431 Acc: 13.1094\n",
      " |~~ train@44864  Loss: 0.002188 Acc: 13.2812\n",
      " |~~ train@44928  Loss: 0.002049 Acc: 13.4062\n",
      " |~~ train@44992  Loss: 0.002475 Acc: 13.2500\n",
      " |~~ train@45056  Loss: 0.002296 Acc: 13.2031\n",
      " |~~ train@45120  Loss: 0.002338 Acc: 13.2188\n",
      " |~~ train@45184  Loss: 0.001874 Acc: 13.4688\n",
      " |~~ train@45248  Loss: 0.002691 Acc: 13.0781\n",
      " |~~ train@45312  Loss: 0.001940 Acc: 13.3438\n",
      " |~~ train@45376  Loss: 0.003030 Acc: 12.9688\n",
      " |~~ train@45440  Loss: 0.001793 Acc: 13.4375\n",
      " |~~ train@45504  Loss: 0.001920 Acc: 13.3906\n",
      " |~~ train@45568  Loss: 0.001672 Acc: 13.5156\n",
      " |~~ train@45632  Loss: 0.002356 Acc: 13.3125\n",
      " |~~ train@45696  Loss: 0.002589 Acc: 13.1562\n",
      " |~~ train@45760  Loss: 0.001904 Acc: 13.3750\n",
      " |~~ train@45824  Loss: 0.002371 Acc: 13.2656\n",
      " |~~ train@45888  Loss: 0.002367 Acc: 13.2500\n",
      " |~~ train@45952  Loss: 0.001835 Acc: 13.3750\n",
      " |~~ train@46016  Loss: 0.001982 Acc: 13.3594\n",
      " |~~ train@46080  Loss: 0.002536 Acc: 13.1719\n",
      " |~~ train@46144  Loss: 0.002683 Acc: 13.1875\n",
      " |~~ train@46208  Loss: 0.002510 Acc: 13.2344\n",
      " |~~ train@46272  Loss: 0.002731 Acc: 13.1250\n",
      " |~~ train@46336  Loss: 0.002382 Acc: 13.2969\n",
      " |~~ train@46400  Loss: 0.002198 Acc: 13.3125\n",
      " |~~ train@46464  Loss: 0.002038 Acc: 13.2500\n",
      " |~~ train@46528  Loss: 0.002408 Acc: 13.3281\n",
      " |~~ train@46592  Loss: 0.002305 Acc: 13.1562\n",
      " |~~ train@46656  Loss: 0.001811 Acc: 13.4219\n",
      " |~~ train@46720  Loss: 0.002491 Acc: 13.2812\n",
      " |~~ train@46784  Loss: 0.001793 Acc: 13.4375\n",
      " |~~ train@46848  Loss: 0.001962 Acc: 13.3906\n",
      " |~~ train@46912  Loss: 0.001629 Acc: 13.4844\n",
      " |~~ train@46976  Loss: 0.002356 Acc: 13.2656\n",
      " |~~ train@47040  Loss: 0.002516 Acc: 13.1406\n",
      " |~~ train@47104  Loss: 0.001903 Acc: 13.4219\n",
      " |~~ train@47168  Loss: 0.001654 Acc: 13.5781\n",
      " |~~ train@47232  Loss: 0.002525 Acc: 13.2188\n",
      " |~~ train@47296  Loss: 0.003016 Acc: 13.0312\n",
      " |~~ train@47360  Loss: 0.001871 Acc: 13.4688\n",
      " |~~ train@47424  Loss: 0.002089 Acc: 13.3125\n",
      " |~~ train@47488  Loss: 0.001935 Acc: 13.3906\n",
      " |~~ train@47552  Loss: 0.002368 Acc: 13.2031\n",
      " |~~ train@47616  Loss: 0.001712 Acc: 13.5781\n",
      " |~~ train@47680  Loss: 0.002462 Acc: 13.2344\n",
      " |~~ train@47744  Loss: 0.001915 Acc: 13.4688\n",
      " |~~ train@47808  Loss: 0.001905 Acc: 13.2812\n",
      " |~~ train@47872  Loss: 0.002116 Acc: 13.2344\n",
      " |~~ train@47936  Loss: 0.002397 Acc: 13.2812\n",
      " |~~ train@48000  Loss: 0.002058 Acc: 13.3281\n",
      " |~~ train@48064  Loss: 0.002327 Acc: 13.3125\n",
      " |~~ train@48128  Loss: 0.002356 Acc: 13.2969\n",
      " |~~ train@48192  Loss: 0.002338 Acc: 13.2344\n",
      " |~~ train@48256  Loss: 0.001865 Acc: 13.3750\n",
      " |~~ train@48320  Loss: 0.002530 Acc: 13.2500\n",
      " |~~ train@48384  Loss: 0.002398 Acc: 13.2031\n",
      " |~~ train@48448  Loss: 0.002412 Acc: 13.2344\n",
      " |~~ train@48512  Loss: 0.002300 Acc: 13.2031\n",
      " |~~ train@48576  Loss: 0.002606 Acc: 13.1719\n",
      " |~~ train@48640  Loss: 0.002299 Acc: 13.2188\n",
      " |~~ train@48704  Loss: 0.002240 Acc: 13.3125\n",
      " |~~ train@48768  Loss: 0.002077 Acc: 13.4062\n",
      " |~~ train@48832  Loss: 0.002273 Acc: 13.2969\n",
      " |~~ train@48896  Loss: 0.002359 Acc: 13.2031\n",
      " |~~ train@48960  Loss: 0.002523 Acc: 13.1719\n",
      " |~~ train@49024  Loss: 0.002161 Acc: 13.2969\n",
      " |~~ train@49088  Loss: 0.001680 Acc: 13.4531\n",
      " |~~ train@49152  Loss: 0.002238 Acc: 13.3750\n",
      " |~~ train@49216  Loss: 0.002193 Acc: 13.2031\n",
      " |~~ train@49280  Loss: 0.001729 Acc: 13.5156\n",
      " |~~ train@49344  Loss: 0.002084 Acc: 13.3281\n",
      " |~~ train@49408  Loss: 0.001926 Acc: 13.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@49472  Loss: 0.002018 Acc: 13.3750\n",
      " |~~ train@49536  Loss: 0.002092 Acc: 13.3125\n",
      " |~~ train@49600  Loss: 0.002087 Acc: 13.3906\n",
      " |~~ train@49664  Loss: 0.002728 Acc: 13.2031\n",
      " |~~ train@49728  Loss: 0.002077 Acc: 13.4375\n",
      " |~~ train@49792  Loss: 0.002495 Acc: 13.0938\n",
      " |~~ train@49856  Loss: 0.001928 Acc: 13.4062\n",
      " |~~ train@49920  Loss: 0.001655 Acc: 13.4375\n",
      " |~~ train@49984  Loss: 0.002036 Acc: 13.3594\n",
      " |~~ train@50048  Loss: 0.001770 Acc: 13.5000\n",
      " |~~ train@50112  Loss: 0.002305 Acc: 13.2344\n",
      " |~~ train@50176  Loss: 0.001865 Acc: 13.4375\n",
      " |~~ train@50240  Loss: 0.002692 Acc: 13.0312\n",
      " |~~ train@50304  Loss: 0.002348 Acc: 13.2812\n",
      " |~~ train@50368  Loss: 0.001996 Acc: 13.2812\n",
      " |~~ train@50432  Loss: 0.002218 Acc: 13.2344\n",
      " |~~ train@50496  Loss: 0.002254 Acc: 13.2656\n",
      " |~~ train@50560  Loss: 0.002197 Acc: 13.3281\n",
      " |~~ train@50624  Loss: 0.002168 Acc: 13.2969\n",
      " |~~ train@50688  Loss: 0.002678 Acc: 13.1094\n",
      " |~~ train@50752  Loss: 0.002190 Acc: 13.2969\n",
      " |~~ train@50816  Loss: 0.002410 Acc: 13.2969\n",
      " |~~ train@50880  Loss: 0.002468 Acc: 13.2656\n",
      " |~~ train@50944  Loss: 0.002017 Acc: 13.4219\n",
      " |~~ train@51008  Loss: 0.001986 Acc: 13.5000\n",
      " |~~ train@51072  Loss: 0.002493 Acc: 13.2656\n",
      " |~~ train@51136  Loss: 0.002455 Acc: 13.2656\n",
      " |~~ train@51200  Loss: 0.002608 Acc: 13.1406\n",
      " |~~ train@51264  Loss: 0.002123 Acc: 13.3125\n",
      " |~~ train@51328  Loss: 0.002567 Acc: 13.1250\n",
      " |~~ train@51392  Loss: 0.002516 Acc: 13.2500\n",
      " |~~ train@51456  Loss: 0.002173 Acc: 13.3438\n",
      " |~~ train@51520  Loss: 0.002116 Acc: 13.3438\n",
      " |~~ train@51584  Loss: 0.002029 Acc: 13.3438\n",
      " |~~ train@51648  Loss: 0.002338 Acc: 13.2188\n",
      " |~~ train@51712  Loss: 0.002063 Acc: 13.4219\n",
      " |~~ train@51776  Loss: 0.002243 Acc: 13.2188\n",
      " |~~ train@51840  Loss: 0.002649 Acc: 13.1562\n",
      " |~~ train@51904  Loss: 0.002542 Acc: 13.2031\n",
      " |~~ train@51968  Loss: 0.002357 Acc: 13.1875\n",
      " |~~ train@52032  Loss: 0.001867 Acc: 13.4375\n",
      " |~~ train@52096  Loss: 0.002391 Acc: 13.3281\n",
      " |~~ train@52160  Loss: 0.002485 Acc: 13.3281\n",
      " |~~ train@52224  Loss: 0.002184 Acc: 13.3594\n",
      " |~~ train@52288  Loss: 0.002181 Acc: 13.2969\n",
      " |~~ train@52352  Loss: 0.002154 Acc: 13.3594\n",
      " |~~ train@52416  Loss: 0.002202 Acc: 13.3594\n",
      " |~~ train@52480  Loss: 0.002081 Acc: 13.4375\n",
      " |~~ train@52544  Loss: 0.002238 Acc: 13.2969\n",
      " |~~ train@52608  Loss: 0.002167 Acc: 13.3281\n",
      " |~~ train@52672  Loss: 0.002115 Acc: 13.3125\n",
      " |~~ train@52736  Loss: 0.002239 Acc: 13.3281\n",
      " |~~ train@52800  Loss: 0.002307 Acc: 13.2812\n",
      " |~~ train@52864  Loss: 0.002240 Acc: 13.4062\n",
      " |~~ train@52928  Loss: 0.001925 Acc: 13.4531\n",
      " |~~ train@52992  Loss: 0.002024 Acc: 13.3750\n",
      " |~~ train@53056  Loss: 0.001791 Acc: 13.4375\n",
      " |~~ train@53120  Loss: 0.002111 Acc: 13.3438\n",
      " |~~ train@53184  Loss: 0.001979 Acc: 13.3906\n",
      " |~~ train@53248  Loss: 0.002006 Acc: 13.3438\n",
      " |~~ train@53312  Loss: 0.002158 Acc: 13.4375\n",
      " |~~ train@53376  Loss: 0.001917 Acc: 13.3281\n",
      " |~~ train@53440  Loss: 0.002089 Acc: 13.4219\n",
      " |~~ train@53504  Loss: 0.002186 Acc: 13.2031\n",
      " |~~ train@53568  Loss: 0.002090 Acc: 13.2969\n",
      " |~~ train@53632  Loss: 0.002501 Acc: 13.2031\n",
      " |~~ train@53696  Loss: 0.002135 Acc: 13.4375\n",
      " |~~ train@53760  Loss: 0.002754 Acc: 13.2188\n",
      " |~~ train@53824  Loss: 0.002308 Acc: 13.1719\n",
      " |~~ train@53888  Loss: 0.002514 Acc: 13.3281\n",
      " |~~ train@53952  Loss: 0.002043 Acc: 13.3125\n",
      " |~~ train@54016  Loss: 0.002578 Acc: 13.1719\n",
      " |~~ train@54080  Loss: 0.002229 Acc: 13.2969\n",
      " |~~ train@54144  Loss: 0.001901 Acc: 13.3750\n",
      " |~~ train@54208  Loss: 0.002423 Acc: 13.2500\n",
      " |~~ train@54272  Loss: 0.001846 Acc: 13.4062\n",
      " |~~ train@54336  Loss: 0.001689 Acc: 13.4844\n",
      " |~~ train@54400  Loss: 0.001815 Acc: 13.4531\n",
      " |~~ train@54464  Loss: 0.001877 Acc: 13.3438\n",
      " |~~ train@54528  Loss: 0.002617 Acc: 13.2344\n",
      " |~~ train@54592  Loss: 0.002183 Acc: 13.3438\n",
      " |~~ train@54656  Loss: 0.002328 Acc: 13.2656\n",
      " |~~ train@54720  Loss: 0.002026 Acc: 13.3281\n",
      " |~~ train@54784  Loss: 0.002047 Acc: 13.3594\n",
      " |~~ train@54848  Loss: 0.002377 Acc: 13.2188\n",
      " |~~ train@54912  Loss: 0.002453 Acc: 13.2031\n",
      " |~~ train@54976  Loss: 0.002060 Acc: 13.4062\n",
      " |~~ train@55040  Loss: 0.002326 Acc: 13.2188\n",
      " |~~ train@55104  Loss: 0.002176 Acc: 13.2969\n",
      " |~~ train@55168  Loss: 0.002598 Acc: 13.2031\n",
      " |~~ train@55232  Loss: 0.001965 Acc: 13.4531\n",
      " |~~ train@55296  Loss: 0.002057 Acc: 13.3750\n",
      " |~~ train@55360  Loss: 0.002032 Acc: 13.3125\n",
      " |~~ train@55424  Loss: 0.002289 Acc: 13.1875\n",
      " |~~ train@55488  Loss: 0.002464 Acc: 13.2500\n",
      " |~~ train@55552  Loss: 0.001825 Acc: 13.4219\n",
      " |~~ train@55616  Loss: 0.002493 Acc: 13.0781\n",
      " |~~ train@55680  Loss: 0.001955 Acc: 13.4688\n",
      " |~~ train@55744  Loss: 0.002114 Acc: 13.2656\n",
      " |~~ train@55808  Loss: 0.002313 Acc: 13.3125\n",
      " |~~ train@55872  Loss: 0.002069 Acc: 13.3281\n",
      " |~~ train@55936  Loss: 0.002503 Acc: 13.3750\n",
      " |~~ train@56000  Loss: 0.002398 Acc: 13.3125\n",
      " |~~ train@56064  Loss: 0.002199 Acc: 13.3281\n",
      " |~~ train@56128  Loss: 0.002775 Acc: 13.1562\n",
      " |~~ train@56192  Loss: 0.002068 Acc: 13.3438\n",
      " |~~ train@56256  Loss: 0.001665 Acc: 13.5156\n",
      " |~~ train@56320  Loss: 0.002569 Acc: 13.2344\n",
      " |~~ train@56384  Loss: 0.002055 Acc: 13.2969\n",
      " |~~ train@56448  Loss: 0.002047 Acc: 13.4219\n",
      " |~~ train@56512  Loss: 0.002110 Acc: 13.2969\n",
      " |~~ train@56576  Loss: 0.001801 Acc: 13.3594\n",
      " |~~ train@56640  Loss: 0.002036 Acc: 13.3281\n",
      " |~~ train@56704  Loss: 0.001891 Acc: 13.4219\n",
      " |~~ train@56768  Loss: 0.002114 Acc: 13.3281\n",
      " |~~ train@56832  Loss: 0.002026 Acc: 13.4688\n",
      " |~~ train@56896  Loss: 0.002415 Acc: 13.3125\n",
      " |~~ train@56960  Loss: 0.002176 Acc: 13.3594\n",
      " |~~ train@57024  Loss: 0.002089 Acc: 13.4062\n",
      " |~~ train@57088  Loss: 0.001910 Acc: 13.5000\n",
      " |~~ train@57152  Loss: 0.002591 Acc: 13.1875\n",
      " |~~ train@57216  Loss: 0.001717 Acc: 13.4688\n",
      " |~~ train@57280  Loss: 0.002476 Acc: 13.2656\n",
      " |~~ train@57344  Loss: 0.002053 Acc: 13.4062\n",
      " |~~ train@57408  Loss: 0.001812 Acc: 13.4062\n",
      " |~~ train@57472  Loss: 0.002214 Acc: 13.3125\n",
      " |~~ train@57536  Loss: 0.002294 Acc: 13.3594\n",
      " |~~ train@57600  Loss: 0.002283 Acc: 13.2969\n",
      " |~~ train@57664  Loss: 0.001636 Acc: 13.4688\n",
      " |~~ train@57728  Loss: 0.002180 Acc: 13.3438\n",
      " |~~ train@57792  Loss: 0.001968 Acc: 13.4219\n",
      " |~~ train@57856  Loss: 0.002439 Acc: 13.2656\n",
      " |~~ train@57920  Loss: 0.002470 Acc: 13.2812\n",
      " |~~ train@57984  Loss: 0.001554 Acc: 13.5312\n",
      " |~~ train@58048  Loss: 0.002324 Acc: 13.3125\n",
      " |~~ train@58112  Loss: 0.001921 Acc: 13.3906\n",
      " |~~ train@58176  Loss: 0.002282 Acc: 13.2188\n",
      " |~~ train@58240  Loss: 0.002216 Acc: 13.2969\n",
      " |~~ train@58304  Loss: 0.002404 Acc: 13.2188\n",
      " |~~ train@58368  Loss: 0.002169 Acc: 13.3438\n",
      " |~~ train@58432  Loss: 0.002125 Acc: 13.3750\n",
      " |~~ train@58496  Loss: 0.002189 Acc: 13.3438\n",
      " |~~ train@58560  Loss: 0.002451 Acc: 13.2031\n",
      " |~~ train@58624  Loss: 0.002219 Acc: 13.3281\n",
      " |~~ train@58688  Loss: 0.002422 Acc: 13.2500\n",
      " |~~ train@58752  Loss: 0.001573 Acc: 13.5625\n",
      " |~~ train@58816  Loss: 0.001968 Acc: 13.3438\n",
      " |~~ train@58880  Loss: 0.002362 Acc: 13.2969\n",
      " |~~ train@58944  Loss: 0.002341 Acc: 13.2969\n",
      " |~~ train@59008  Loss: 0.001963 Acc: 13.3438\n",
      " |~~ train@59072  Loss: 0.002620 Acc: 13.1094\n",
      " |~~ train@59136  Loss: 0.002162 Acc: 13.2812\n",
      " |~~ train@59200  Loss: 0.001904 Acc: 13.4062\n",
      " |~~ train@59264  Loss: 0.001653 Acc: 13.5469\n",
      " |~~ train@59328  Loss: 0.001905 Acc: 13.4219\n",
      " |~~ train@59392  Loss: 0.002396 Acc: 13.3125\n",
      " |~~ train@59456  Loss: 0.002696 Acc: 13.1250\n",
      " |~~ train@59520  Loss: 0.001942 Acc: 13.4219\n",
      " |~~ train@59584  Loss: 0.002120 Acc: 13.4375\n",
      " |~~ train@59648  Loss: 0.002106 Acc: 13.3750\n",
      " |~~ train@59712  Loss: 0.002035 Acc: 13.2812\n",
      " |~~ train@59776  Loss: 0.002420 Acc: 13.3125\n",
      " |~~ train@59840  Loss: 0.002626 Acc: 13.0625\n",
      " |~~ train@59904  Loss: 0.002132 Acc: 13.3594\n",
      " |~~ train@59968  Loss: 0.002265 Acc: 13.2500\n",
      " |~~ train@60032  Loss: 0.002559 Acc: 13.2500\n",
      " |~~ train@60096  Loss: 0.001756 Acc: 13.5000\n",
      " |~~ train@60160  Loss: 0.002565 Acc: 13.2031\n",
      " |~~ train@60224  Loss: 0.002390 Acc: 13.2031\n",
      " |~~ train@60288  Loss: 0.002368 Acc: 13.3125\n",
      " |~~ train@60352  Loss: 0.002340 Acc: 13.3438\n",
      " |~~ train@60416  Loss: 0.002020 Acc: 13.3906\n",
      " |~~ train@60480  Loss: 0.002055 Acc: 13.4375\n",
      " |~~ train@60544  Loss: 0.001982 Acc: 13.2969\n",
      " |~~ train@60608  Loss: 0.002316 Acc: 13.2812\n",
      " |~~ train@60672  Loss: 0.003185 Acc: 12.9844\n",
      " |~~ train@60736  Loss: 0.002137 Acc: 13.3125\n",
      " |~~ train@60800  Loss: 0.001799 Acc: 13.5156\n",
      " |~~ train@60864  Loss: 0.002228 Acc: 13.2969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@60928  Loss: 0.002763 Acc: 13.0938\n",
      " |~~ train@60992  Loss: 0.001920 Acc: 13.3750\n",
      " |~~ train@61056  Loss: 0.002758 Acc: 13.0781\n",
      " |~~ train@61120  Loss: 0.002393 Acc: 13.2500\n",
      " |~~ train@61184  Loss: 0.002080 Acc: 13.3438\n",
      " |~~ train@61248  Loss: 0.002078 Acc: 13.3438\n",
      " |~~ train@61312  Loss: 0.002743 Acc: 13.2031\n",
      " |~~ train@61376  Loss: 0.002091 Acc: 13.4844\n",
      " |~~ train@61440  Loss: 0.002709 Acc: 13.1094\n",
      " |~~ train@61504  Loss: 0.001944 Acc: 13.3438\n",
      " |~~ train@61568  Loss: 0.002073 Acc: 13.4219\n",
      " |~~ train@61632  Loss: 0.002318 Acc: 13.2344\n",
      " |~~ train@61696  Loss: 0.002140 Acc: 13.3125\n",
      " |~~ train@61760  Loss: 0.002326 Acc: 13.3594\n",
      " |~~ train@61824  Loss: 0.002457 Acc: 13.2344\n",
      " |~~ train@61888  Loss: 0.002057 Acc: 13.3281\n",
      " |~~ train@61952  Loss: 0.002459 Acc: 13.2344\n",
      " |~~ train@62016  Loss: 0.001864 Acc: 13.5000\n",
      " |~~ train@62080  Loss: 0.001933 Acc: 13.3438\n",
      " |~~ train@62144  Loss: 0.002221 Acc: 13.3281\n",
      " |~~ train@62208  Loss: 0.001762 Acc: 13.4531\n",
      " |~~ train@62272  Loss: 0.002395 Acc: 13.3125\n",
      " |~~ train@62336  Loss: 0.002176 Acc: 13.3281\n",
      " |~~ train@62400  Loss: 0.002168 Acc: 13.3438\n",
      " |~~ train@62464  Loss: 0.002519 Acc: 13.2344\n",
      " |~~ train@62528  Loss: 0.002140 Acc: 13.3906\n",
      " |~~ train@62592  Loss: 0.002357 Acc: 13.2500\n",
      " |~~ train@62656  Loss: 0.002869 Acc: 13.0469\n",
      " |~~ train@62720  Loss: 0.002565 Acc: 13.2344\n",
      " |~~ train@62784  Loss: 0.002027 Acc: 13.3438\n",
      " |~~ train@62848  Loss: 0.001966 Acc: 13.3750\n",
      " |~~ train@62912  Loss: 0.002089 Acc: 13.3750\n",
      " |~~ train@62976  Loss: 0.001760 Acc: 13.4531\n",
      " |~~ train@63040  Loss: 0.003406 Acc: 12.9531\n",
      " |~~ train@63104  Loss: 0.001877 Acc: 13.3906\n",
      " |~~ train@63168  Loss: 0.001754 Acc: 13.5312\n",
      " |~~ train@63232  Loss: 0.001656 Acc: 13.5469\n",
      " |~~ train@63296  Loss: 0.002046 Acc: 13.3438\n",
      " |~~ train@63360  Loss: 0.002494 Acc: 13.2188\n",
      " |~~ train@63424  Loss: 0.002443 Acc: 13.2500\n",
      " |~~ train@63488  Loss: 0.002213 Acc: 13.2031\n",
      " |~~ train@63552  Loss: 0.002097 Acc: 13.4062\n",
      " |~~ train@63616  Loss: 0.002449 Acc: 13.1719\n",
      " |~~ train@63680  Loss: 0.001965 Acc: 13.5156\n",
      " |~~ train@63744  Loss: 0.002060 Acc: 13.3438\n",
      " |~~ train@63808  Loss: 0.001947 Acc: 13.4062\n",
      " |~~ train@63872  Loss: 0.002448 Acc: 13.0938\n",
      " |~~ train@63936  Loss: 0.001909 Acc: 13.4531\n",
      " |~~ train@64000  Loss: 0.002456 Acc: 13.2656\n",
      " |~~ train@64064  Loss: 0.001568 Acc: 13.5625\n",
      " |~~ train@64128  Loss: 0.002081 Acc: 13.3750\n",
      " |~~ train@64192  Loss: 0.001844 Acc: 13.4844\n",
      " |~~ train@64256  Loss: 0.002478 Acc: 13.2344\n",
      " |~~ train@64320  Loss: 0.002104 Acc: 13.3906\n",
      " |~~ train@64384  Loss: 0.001896 Acc: 13.3594\n",
      " |~~ train@64448  Loss: 0.002312 Acc: 13.2656\n",
      " |~~ train@64512  Loss: 0.002012 Acc: 13.3125\n",
      " |~~ train@64576  Loss: 0.002195 Acc: 13.3438\n",
      " |~~ train@64640  Loss: 0.002322 Acc: 13.2188\n",
      " |~~ train@64704  Loss: 0.002005 Acc: 13.4062\n",
      " |~~ train@64768  Loss: 0.002531 Acc: 13.2344\n",
      " |~~ train@64832  Loss: 0.002389 Acc: 13.2500\n",
      " |~~ train@64896  Loss: 0.002366 Acc: 13.2188\n",
      " |~~ train@64960  Loss: 0.002409 Acc: 13.2344\n",
      " |~~ train@65024  Loss: 0.001983 Acc: 13.2969\n",
      " |~~ train@65088  Loss: 0.002040 Acc: 13.3438\n",
      " |~~ train@65152  Loss: 0.002970 Acc: 13.1406\n",
      " |~~ train@65216  Loss: 0.002176 Acc: 13.4062\n",
      " |~~ train@65280  Loss: 0.002096 Acc: 13.3125\n",
      " |~~ train@65344  Loss: 0.002285 Acc: 13.2656\n",
      " |~~ train@65408  Loss: 0.001772 Acc: 13.4062\n",
      " |~~ train@65472  Loss: 0.002622 Acc: 13.1875\n",
      " |~~ train@65536  Loss: 0.002270 Acc: 13.2969\n",
      " |~~ train@65600  Loss: 0.001917 Acc: 13.4844\n",
      " |~~ train@65664  Loss: 0.001704 Acc: 13.4844\n",
      " |~~ train@65728  Loss: 0.002259 Acc: 13.3438\n",
      " |~~ train@65792  Loss: 0.002222 Acc: 13.3906\n",
      " |~~ train@65856  Loss: 0.002231 Acc: 13.2812\n",
      " |~~ train@65920  Loss: 0.002317 Acc: 13.3281\n",
      " |~~ train@65984  Loss: 0.002114 Acc: 13.2812\n",
      " |~~ train@66048  Loss: 0.002480 Acc: 13.1562\n",
      " |~~ train@66112  Loss: 0.002098 Acc: 13.3438\n",
      " |~~ train@66176  Loss: 0.002073 Acc: 13.2656\n",
      " |~~ train@66240  Loss: 0.002520 Acc: 13.1406\n",
      " |~~ train@66304  Loss: 0.002049 Acc: 13.4062\n",
      " |~~ train@66368  Loss: 0.002688 Acc: 13.1250\n",
      " |~~ train@66432  Loss: 0.002244 Acc: 13.1875\n",
      " |~~ train@66496  Loss: 0.001679 Acc: 13.5781\n",
      " |~~ train@66560  Loss: 0.001980 Acc: 13.3750\n",
      " |~~ train@66624  Loss: 0.001650 Acc: 13.5156\n",
      " |~~ train@66688  Loss: 0.001979 Acc: 13.4219\n",
      " |~~ train@66752  Loss: 0.002279 Acc: 13.3125\n",
      " |~~ train@66816  Loss: 0.002041 Acc: 13.3750\n",
      " |~~ train@66880  Loss: 0.002296 Acc: 13.2969\n",
      " |~~ train@66944  Loss: 0.001865 Acc: 13.4531\n",
      " |~~ train@67008  Loss: 0.002095 Acc: 13.4219\n",
      " |~~ train@67072  Loss: 0.001704 Acc: 13.4219\n",
      " |~~ train@67136  Loss: 0.001903 Acc: 13.4062\n",
      " |~~ train@67200  Loss: 0.002026 Acc: 13.4062\n",
      " |~~ train@67264  Loss: 0.002141 Acc: 13.3438\n",
      " |~~ train@67328  Loss: 0.001702 Acc: 13.4375\n",
      " |~~ train@67392  Loss: 0.002227 Acc: 13.3125\n",
      " |~~ train@67456  Loss: 0.002137 Acc: 13.3594\n",
      " |~~ train@67520  Loss: 0.001683 Acc: 13.4844\n",
      " |~~ train@67584  Loss: 0.002230 Acc: 13.2656\n",
      " |~~ train@67648  Loss: 0.001998 Acc: 13.3594\n",
      " |~~ train@67712  Loss: 0.002435 Acc: 13.2656\n",
      " |~~ train@67776  Loss: 0.001702 Acc: 13.5312\n",
      " |~~ train@67840  Loss: 0.002267 Acc: 13.2188\n",
      " |~~ train@67904  Loss: 0.002312 Acc: 13.2500\n",
      " |~~ train@67968  Loss: 0.002321 Acc: 13.2188\n",
      " |~~ train@68032  Loss: 0.001887 Acc: 13.4062\n",
      " |~~ train@68096  Loss: 0.002439 Acc: 13.2031\n",
      " |~~ train@68160  Loss: 0.001839 Acc: 13.5156\n",
      " |~~ train@68224  Loss: 0.002689 Acc: 13.1562\n",
      " |~~ train@68288  Loss: 0.002053 Acc: 13.3281\n",
      " |~~ train@68352  Loss: 0.002318 Acc: 13.2656\n",
      " |~~ train@68416  Loss: 0.001779 Acc: 13.5000\n",
      " |~~ train@68480  Loss: 0.001903 Acc: 13.3750\n",
      " |~~ train@68544  Loss: 0.002210 Acc: 13.3438\n",
      " |~~ train@68608  Loss: 0.002469 Acc: 13.2031\n",
      " |~~ train@68672  Loss: 0.001929 Acc: 13.4219\n",
      " |~~ train@68736  Loss: 0.002231 Acc: 13.3906\n",
      " |~~ train@68800  Loss: 0.001926 Acc: 13.3750\n",
      " |~~ train@68864  Loss: 0.002462 Acc: 13.2188\n",
      " |~~ train@68928  Loss: 0.002182 Acc: 13.2500\n",
      " |~~ train@68992  Loss: 0.002113 Acc: 13.3281\n",
      " |~~ train@69056  Loss: 0.001820 Acc: 13.4688\n",
      " |~~ train@69120  Loss: 0.002302 Acc: 13.2812\n",
      " |~~ train@69184  Loss: 0.001913 Acc: 13.4531\n",
      " |~~ train@69248  Loss: 0.002288 Acc: 13.3281\n",
      " |~~ train@69312  Loss: 0.002323 Acc: 13.2656\n",
      " |~~ train@69376  Loss: 0.002042 Acc: 13.2812\n",
      " |~~ train@69440  Loss: 0.002557 Acc: 13.2031\n",
      " |~~ train@69504  Loss: 0.002141 Acc: 13.2656\n",
      " |~~ train@69568  Loss: 0.001727 Acc: 13.4844\n",
      " |~~ train@69632  Loss: 0.002377 Acc: 13.3125\n",
      " |~~ train@69696  Loss: 0.002506 Acc: 13.2344\n",
      " |~~ train@69760  Loss: 0.002313 Acc: 13.2656\n",
      " |~~ train@69824  Loss: 0.002362 Acc: 13.3125\n",
      " |~~ train@69888  Loss: 0.002546 Acc: 13.2812\n",
      " |~~ train@69952  Loss: 0.002454 Acc: 13.2188\n",
      " |~~ train@70016  Loss: 0.002274 Acc: 13.2656\n",
      " |~~ train@70080  Loss: 0.001945 Acc: 13.3125\n",
      " |~~ train@70144  Loss: 0.002916 Acc: 13.0625\n",
      " |~~ train@70208  Loss: 0.002095 Acc: 13.3750\n",
      " |~~ train@70272  Loss: 0.001933 Acc: 13.5781\n",
      " |~~ train@70336  Loss: 0.001545 Acc: 13.5469\n",
      " |~~ train@70400  Loss: 0.002105 Acc: 13.3906\n",
      " |~~ train@70464  Loss: 0.002414 Acc: 13.1094\n",
      " |~~ train@70528  Loss: 0.002403 Acc: 13.2500\n",
      " |~~ train@70592  Loss: 0.002249 Acc: 13.3125\n",
      " |~~ train@70656  Loss: 0.001549 Acc: 13.5938\n",
      " |~~ train@70720  Loss: 0.001779 Acc: 13.4688\n",
      " |~~ train@70784  Loss: 0.002279 Acc: 13.2812\n",
      " |~~ train@70848  Loss: 0.002378 Acc: 13.1875\n",
      " |~~ train@70912  Loss: 0.001731 Acc: 13.4688\n",
      " |~~ train@70976  Loss: 0.002039 Acc: 13.3594\n",
      " |~~ train@71040  Loss: 0.002028 Acc: 13.4219\n",
      " |~~ train@71104  Loss: 0.002705 Acc: 13.0781\n",
      " |~~ train@71168  Loss: 0.002228 Acc: 13.2344\n",
      " |~~ train@71232  Loss: 0.002094 Acc: 13.3750\n",
      " |~~ train@71296  Loss: 0.002515 Acc: 13.2188\n",
      " |~~ train@71360  Loss: 0.002272 Acc: 13.2500\n",
      " |~~ train@71424  Loss: 0.002397 Acc: 13.2656\n",
      " |~~ train@71488  Loss: 0.002189 Acc: 13.2969\n",
      " |~~ train@71552  Loss: 0.002271 Acc: 13.2500\n",
      " |~~ train@71616  Loss: 0.002507 Acc: 13.1562\n",
      " |~~ train@71680  Loss: 0.001857 Acc: 13.5000\n",
      " |~~ train@71744  Loss: 0.002268 Acc: 13.2188\n",
      " |~~ train@71808  Loss: 0.002079 Acc: 13.4219\n",
      " |~~ train@71872  Loss: 0.001911 Acc: 13.3906\n",
      " |~~ train@71936  Loss: 0.002072 Acc: 13.3750\n",
      " |~~ train@72000  Loss: 0.002254 Acc: 13.2031\n",
      " |~~ train@72064  Loss: 0.001779 Acc: 13.4531\n",
      " |~~ train@72128  Loss: 0.002177 Acc: 13.3281\n",
      " |~~ train@72192  Loss: 0.001636 Acc: 13.5156\n",
      " |~~ train@72256  Loss: 0.001803 Acc: 13.5469\n",
      " |~~ train@72320  Loss: 0.002048 Acc: 13.3594\n",
      " |~~ train@72384  Loss: 0.002157 Acc: 13.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@72448  Loss: 0.001908 Acc: 13.4219\n",
      " |~~ train@72512  Loss: 0.001943 Acc: 13.4375\n",
      " |~~ train@72576  Loss: 0.002440 Acc: 13.2188\n",
      " |~~ train@72640  Loss: 0.002339 Acc: 13.2500\n",
      " |~~ train@72704  Loss: 0.002415 Acc: 13.3438\n",
      " |~~ train@72768  Loss: 0.002277 Acc: 13.2969\n",
      " |~~ train@72832  Loss: 0.001847 Acc: 13.4219\n",
      " |~~ train@72896  Loss: 0.002329 Acc: 13.2344\n",
      " |~~ train@72960  Loss: 0.002124 Acc: 13.4062\n",
      " |~~ train@73024  Loss: 0.001886 Acc: 13.4219\n",
      " |~~ train@73088  Loss: 0.002307 Acc: 13.2656\n",
      " |~~ train@73152  Loss: 0.002212 Acc: 13.3438\n",
      " |~~ train@73216  Loss: 0.001832 Acc: 13.5156\n",
      " |~~ train@73280  Loss: 0.002113 Acc: 13.2500\n",
      " |~~ train@73344  Loss: 0.002308 Acc: 13.3125\n",
      " |~~ train@73408  Loss: 0.002253 Acc: 13.3125\n",
      " |~~ train@73472  Loss: 0.002543 Acc: 13.2344\n",
      " |~~ train@73536  Loss: 0.002741 Acc: 13.0625\n",
      " |~~ train@73600  Loss: 0.002048 Acc: 13.4531\n",
      " |~~ train@73664  Loss: 0.002706 Acc: 13.1250\n",
      " |~~ train@73728  Loss: 0.002591 Acc: 13.2500\n",
      " |~~ train@73792  Loss: 0.001880 Acc: 13.3125\n",
      " |~~ train@73856  Loss: 0.002110 Acc: 13.3594\n",
      " |~~ train@73920  Loss: 0.002298 Acc: 13.3438\n",
      " |~~ train@73984  Loss: 0.002302 Acc: 13.2500\n",
      " |~~ train@74048  Loss: 0.002356 Acc: 13.2969\n",
      " |~~ train@74112  Loss: 0.002013 Acc: 13.3750\n",
      " |~~ train@74176  Loss: 0.002538 Acc: 13.2344\n",
      " |~~ train@74240  Loss: 0.002304 Acc: 13.2812\n",
      " |~~ train@74304  Loss: 0.002648 Acc: 13.3594\n",
      " |~~ train@74368  Loss: 0.002237 Acc: 13.2344\n",
      " |~~ train@74432  Loss: 0.002005 Acc: 13.4219\n",
      " |~~ train@74496  Loss: 0.002474 Acc: 13.1562\n",
      " |~~ train@74560  Loss: 0.002169 Acc: 13.2500\n",
      " |~~ train@74624  Loss: 0.001656 Acc: 13.5000\n",
      " |~~ train@74688  Loss: 0.002240 Acc: 13.1875\n",
      " |~~ train@74752  Loss: 0.001861 Acc: 13.4688\n",
      " |~~ train@74816  Loss: 0.002041 Acc: 13.3594\n",
      " |~~ train@74880  Loss: 0.002439 Acc: 13.1719\n",
      " |~~ train@74944  Loss: 0.001882 Acc: 13.4219\n",
      " |~~ train@75008  Loss: 0.002041 Acc: 13.4219\n",
      " |~~ train@75072  Loss: 0.001744 Acc: 13.5312\n",
      " |~~ train@75136  Loss: 0.003105 Acc: 12.9844\n",
      " |~~ train@75200  Loss: 0.001556 Acc: 13.4844\n",
      " |~~ train@75264  Loss: 0.002256 Acc: 13.2344\n",
      " |~~ train@75328  Loss: 0.002061 Acc: 13.3906\n",
      " |~~ train@75392  Loss: 0.002511 Acc: 13.1094\n",
      " |~~ train@75456  Loss: 0.001776 Acc: 13.3906\n",
      " |~~ train@75520  Loss: 0.002165 Acc: 13.2969\n",
      " |~~ train@75584  Loss: 0.002753 Acc: 13.0625\n",
      " |~~ train@75648  Loss: 0.002176 Acc: 13.2656\n",
      " |~~ train@75712  Loss: 0.002031 Acc: 13.4062\n",
      " |~~ train@75776  Loss: 0.002509 Acc: 13.1875\n",
      " |~~ train@75840  Loss: 0.002246 Acc: 13.2656\n",
      " |~~ train@75904  Loss: 0.002217 Acc: 13.3281\n",
      " |~~ train@75968  Loss: 0.002153 Acc: 13.3438\n",
      " |~~ train@76032  Loss: 0.001824 Acc: 13.4062\n",
      " |~~ train@76096  Loss: 0.002275 Acc: 13.3125\n",
      " |~~ train@76160  Loss: 0.002464 Acc: 13.2188\n",
      " |~~ train@76224  Loss: 0.001815 Acc: 13.3906\n",
      " |~~ train@76288  Loss: 0.001929 Acc: 13.4688\n",
      " |~~ train@76352  Loss: 0.002007 Acc: 13.4062\n",
      " |~~ train@76416  Loss: 0.002433 Acc: 13.1719\n",
      " |~~ train@76480  Loss: 0.002155 Acc: 13.3906\n",
      " |~~ train@76544  Loss: 0.002130 Acc: 13.3125\n",
      " |~~ train@76608  Loss: 0.001905 Acc: 13.4375\n",
      " |~~ train@76672  Loss: 0.002569 Acc: 13.2656\n",
      " |~~ train@76736  Loss: 0.002182 Acc: 13.2812\n",
      " |~~ train@76800  Loss: 0.002722 Acc: 13.1406\n",
      " |~~ train@76864  Loss: 0.002218 Acc: 13.3438\n",
      " |~~ train@76928  Loss: 0.002269 Acc: 13.3750\n",
      " |~~ train@76992  Loss: 0.001833 Acc: 13.5000\n",
      " |~~ train@77056  Loss: 0.002147 Acc: 13.3281\n",
      " |~~ train@77120  Loss: 0.001895 Acc: 13.3438\n",
      " |~~ train@77184  Loss: 0.002025 Acc: 13.3281\n",
      " |~~ train@77248  Loss: 0.002603 Acc: 13.2656\n",
      " |~~ train@77312  Loss: 0.002730 Acc: 13.1562\n",
      " |~~ train@77376  Loss: 0.002637 Acc: 13.2031\n",
      " |~~ train@77440  Loss: 0.002188 Acc: 13.3750\n",
      " |~~ train@77504  Loss: 0.002376 Acc: 13.3125\n",
      " |~~ train@77568  Loss: 0.002688 Acc: 13.1562\n",
      " |~~ train@77632  Loss: 0.002212 Acc: 13.3125\n",
      " |~~ train@77696  Loss: 0.001948 Acc: 13.4375\n",
      " |~~ train@77760  Loss: 0.002225 Acc: 13.2812\n",
      " |~~ train@77824  Loss: 0.001979 Acc: 13.4531\n",
      " |~~ train@77888  Loss: 0.002006 Acc: 13.4062\n",
      " |~~ train@77952  Loss: 0.002289 Acc: 13.2344\n",
      " |~~ train@78016  Loss: 0.001842 Acc: 13.3750\n",
      " |~~ train@78080  Loss: 0.002890 Acc: 13.2812\n",
      " |~~ train@78144  Loss: 0.002314 Acc: 13.3750\n",
      " |~~ train@78208  Loss: 0.001765 Acc: 13.4219\n",
      " |~~ train@78272  Loss: 0.002245 Acc: 13.3125\n",
      " |~~ train@78336  Loss: 0.002295 Acc: 13.2656\n",
      " |~~ train@78400  Loss: 0.002134 Acc: 13.2812\n",
      " |~~ train@78464  Loss: 0.002356 Acc: 13.2344\n",
      " |~~ train@78484  Loss: 0.006452 Acc: 13.2500\n",
      "train  Loss: 0.002191 Acc: 13.3145\n",
      " |~~ val@64  Loss: 0.002274 Acc: 13.3281\n",
      " |~~ val@128  Loss: 0.002663 Acc: 13.1562\n",
      " |~~ val@192  Loss: 0.002440 Acc: 13.3281\n",
      " |~~ val@256  Loss: 0.002643 Acc: 13.2812\n",
      " |~~ val@320  Loss: 0.001914 Acc: 13.3906\n",
      " |~~ val@384  Loss: 0.003059 Acc: 13.1094\n",
      " |~~ val@448  Loss: 0.002310 Acc: 13.2969\n",
      " |~~ val@512  Loss: 0.002746 Acc: 13.2031\n",
      " |~~ val@576  Loss: 0.002196 Acc: 13.3438\n",
      " |~~ val@640  Loss: 0.002445 Acc: 13.3438\n",
      " |~~ val@704  Loss: 0.002744 Acc: 13.1406\n",
      " |~~ val@768  Loss: 0.002374 Acc: 13.2656\n",
      " |~~ val@832  Loss: 0.002412 Acc: 13.2031\n",
      " |~~ val@896  Loss: 0.002871 Acc: 13.1406\n",
      " |~~ val@960  Loss: 0.002973 Acc: 13.0000\n",
      " |~~ val@1024  Loss: 0.002204 Acc: 13.3594\n",
      " |~~ val@1088  Loss: 0.002293 Acc: 13.2812\n",
      " |~~ val@1152  Loss: 0.002864 Acc: 13.1875\n",
      " |~~ val@1216  Loss: 0.002167 Acc: 13.3750\n",
      " |~~ val@1280  Loss: 0.002485 Acc: 13.2656\n",
      " |~~ val@1344  Loss: 0.002867 Acc: 12.9688\n",
      " |~~ val@1408  Loss: 0.002233 Acc: 13.3594\n",
      " |~~ val@1472  Loss: 0.002276 Acc: 13.3594\n",
      " |~~ val@1536  Loss: 0.001678 Acc: 13.5781\n",
      " |~~ val@1600  Loss: 0.002369 Acc: 13.2656\n",
      " |~~ val@1664  Loss: 0.002584 Acc: 13.2812\n",
      " |~~ val@1728  Loss: 0.002025 Acc: 13.4062\n",
      " |~~ val@1792  Loss: 0.002345 Acc: 13.2656\n",
      " |~~ val@1856  Loss: 0.002623 Acc: 13.2031\n",
      " |~~ val@1920  Loss: 0.002187 Acc: 13.3125\n",
      " |~~ val@1984  Loss: 0.002303 Acc: 13.2969\n",
      " |~~ val@2048  Loss: 0.002456 Acc: 13.3750\n",
      " |~~ val@2112  Loss: 0.002287 Acc: 13.2969\n",
      " |~~ val@2176  Loss: 0.001837 Acc: 13.4844\n",
      " |~~ val@2240  Loss: 0.002192 Acc: 13.3594\n",
      " |~~ val@2304  Loss: 0.002422 Acc: 13.3125\n",
      " |~~ val@2368  Loss: 0.002117 Acc: 13.4688\n",
      " |~~ val@2432  Loss: 0.002787 Acc: 13.2031\n",
      " |~~ val@2496  Loss: 0.002294 Acc: 13.3125\n",
      " |~~ val@2560  Loss: 0.002658 Acc: 13.1562\n",
      " |~~ val@2624  Loss: 0.002840 Acc: 13.2344\n",
      " |~~ val@2688  Loss: 0.002303 Acc: 13.3438\n",
      " |~~ val@2752  Loss: 0.001930 Acc: 13.4219\n",
      " |~~ val@2816  Loss: 0.002412 Acc: 13.2656\n",
      " |~~ val@2880  Loss: 0.002265 Acc: 13.3594\n",
      " |~~ val@2944  Loss: 0.002168 Acc: 13.4219\n",
      " |~~ val@3008  Loss: 0.002414 Acc: 13.3438\n",
      " |~~ val@3072  Loss: 0.002157 Acc: 13.4062\n",
      " |~~ val@3136  Loss: 0.002519 Acc: 13.1719\n",
      " |~~ val@3200  Loss: 0.002792 Acc: 13.1562\n",
      " |~~ val@3264  Loss: 0.002537 Acc: 13.3438\n",
      " |~~ val@3328  Loss: 0.002312 Acc: 13.3125\n",
      " |~~ val@3392  Loss: 0.001689 Acc: 13.5312\n",
      " |~~ val@3456  Loss: 0.002233 Acc: 13.2969\n",
      " |~~ val@3520  Loss: 0.001801 Acc: 13.5000\n",
      " |~~ val@3584  Loss: 0.001829 Acc: 13.4531\n",
      " |~~ val@3648  Loss: 0.002719 Acc: 13.2188\n",
      " |~~ val@3712  Loss: 0.002156 Acc: 13.2656\n",
      " |~~ val@3776  Loss: 0.002582 Acc: 13.1094\n",
      " |~~ val@3840  Loss: 0.002685 Acc: 13.1250\n",
      " |~~ val@3904  Loss: 0.002008 Acc: 13.3594\n",
      " |~~ val@3968  Loss: 0.002940 Acc: 12.9688\n",
      " |~~ val@4032  Loss: 0.002257 Acc: 13.2812\n",
      " |~~ val@4096  Loss: 0.002802 Acc: 13.1406\n",
      " |~~ val@4160  Loss: 0.001923 Acc: 13.4688\n",
      " |~~ val@4224  Loss: 0.002155 Acc: 13.2812\n",
      " |~~ val@4288  Loss: 0.001864 Acc: 13.4375\n",
      " |~~ val@4352  Loss: 0.002408 Acc: 13.2969\n",
      " |~~ val@4416  Loss: 0.002252 Acc: 13.2500\n",
      " |~~ val@4480  Loss: 0.002142 Acc: 13.3438\n",
      " |~~ val@4544  Loss: 0.003002 Acc: 13.0625\n",
      " |~~ val@4608  Loss: 0.002494 Acc: 13.2656\n",
      " |~~ val@4672  Loss: 0.002570 Acc: 13.2031\n",
      " |~~ val@4736  Loss: 0.002130 Acc: 13.2812\n",
      " |~~ val@4800  Loss: 0.002213 Acc: 13.3281\n",
      " |~~ val@4864  Loss: 0.002347 Acc: 13.3594\n",
      " |~~ val@4928  Loss: 0.002225 Acc: 13.3281\n",
      " |~~ val@4992  Loss: 0.001888 Acc: 13.5156\n",
      " |~~ val@5056  Loss: 0.002056 Acc: 13.5000\n",
      " |~~ val@5120  Loss: 0.002604 Acc: 13.2031\n",
      " |~~ val@5184  Loss: 0.002592 Acc: 13.2500\n",
      " |~~ val@5248  Loss: 0.002854 Acc: 13.1719\n",
      " |~~ val@5312  Loss: 0.002442 Acc: 13.3281\n",
      " |~~ val@5376  Loss: 0.002520 Acc: 13.3125\n",
      " |~~ val@5440  Loss: 0.002221 Acc: 13.3594\n",
      " |~~ val@5504  Loss: 0.002510 Acc: 13.2656\n",
      " |~~ val@5568  Loss: 0.002251 Acc: 13.3906\n",
      " |~~ val@5632  Loss: 0.002547 Acc: 13.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@5696  Loss: 0.003106 Acc: 13.1719\n",
      " |~~ val@5760  Loss: 0.002747 Acc: 13.2344\n",
      " |~~ val@5824  Loss: 0.002005 Acc: 13.4531\n",
      " |~~ val@5888  Loss: 0.001930 Acc: 13.4375\n",
      " |~~ val@5952  Loss: 0.001978 Acc: 13.4062\n",
      " |~~ val@6016  Loss: 0.002089 Acc: 13.4219\n",
      " |~~ val@6080  Loss: 0.001622 Acc: 13.5156\n",
      " |~~ val@6144  Loss: 0.002347 Acc: 13.2656\n",
      " |~~ val@6208  Loss: 0.002313 Acc: 13.4062\n",
      " |~~ val@6272  Loss: 0.003334 Acc: 13.0469\n",
      " |~~ val@6336  Loss: 0.002538 Acc: 13.2344\n",
      " |~~ val@6400  Loss: 0.002067 Acc: 13.4531\n",
      " |~~ val@6464  Loss: 0.002099 Acc: 13.3125\n",
      " |~~ val@6528  Loss: 0.002806 Acc: 13.2969\n",
      " |~~ val@6592  Loss: 0.002372 Acc: 13.3125\n",
      " |~~ val@6656  Loss: 0.002348 Acc: 13.2188\n",
      " |~~ val@6720  Loss: 0.001868 Acc: 13.3750\n",
      " |~~ val@6784  Loss: 0.002330 Acc: 13.3281\n",
      " |~~ val@6848  Loss: 0.002513 Acc: 13.2500\n",
      " |~~ val@6912  Loss: 0.001982 Acc: 13.4375\n",
      " |~~ val@6976  Loss: 0.002287 Acc: 13.2656\n",
      " |~~ val@7040  Loss: 0.002886 Acc: 13.0938\n",
      " |~~ val@7104  Loss: 0.002529 Acc: 13.2969\n",
      " |~~ val@7168  Loss: 0.002644 Acc: 13.2344\n",
      " |~~ val@7232  Loss: 0.002257 Acc: 13.3906\n",
      " |~~ val@7296  Loss: 0.002325 Acc: 13.2500\n",
      " |~~ val@7360  Loss: 0.002745 Acc: 13.2500\n",
      " |~~ val@7424  Loss: 0.002446 Acc: 13.2812\n",
      " |~~ val@7488  Loss: 0.002617 Acc: 13.2656\n",
      " |~~ val@7552  Loss: 0.002022 Acc: 13.3594\n",
      " |~~ val@7616  Loss: 0.002869 Acc: 13.1406\n",
      " |~~ val@7680  Loss: 0.002333 Acc: 13.3125\n",
      " |~~ val@7744  Loss: 0.002499 Acc: 13.3750\n",
      " |~~ val@7808  Loss: 0.002389 Acc: 13.2812\n",
      " |~~ val@7872  Loss: 0.002390 Acc: 13.2656\n",
      " |~~ val@7936  Loss: 0.002348 Acc: 13.2812\n",
      " |~~ val@8000  Loss: 0.002497 Acc: 13.2031\n",
      " |~~ val@8064  Loss: 0.001984 Acc: 13.3438\n",
      " |~~ val@8128  Loss: 0.002476 Acc: 13.2344\n",
      " |~~ val@8192  Loss: 0.002715 Acc: 13.1250\n",
      " |~~ val@8256  Loss: 0.002587 Acc: 13.2188\n",
      " |~~ val@8320  Loss: 0.001883 Acc: 13.4219\n",
      " |~~ val@8384  Loss: 0.002575 Acc: 13.2031\n",
      " |~~ val@8448  Loss: 0.002289 Acc: 13.3750\n",
      " |~~ val@8512  Loss: 0.001894 Acc: 13.4688\n",
      " |~~ val@8576  Loss: 0.002033 Acc: 13.4844\n",
      " |~~ val@8640  Loss: 0.002353 Acc: 13.2031\n",
      " |~~ val@8704  Loss: 0.002225 Acc: 13.3906\n",
      " |~~ val@8768  Loss: 0.003062 Acc: 13.0312\n",
      " |~~ val@8832  Loss: 0.002346 Acc: 13.3594\n",
      " |~~ val@8896  Loss: 0.002717 Acc: 13.1562\n",
      " |~~ val@8960  Loss: 0.002404 Acc: 13.2188\n",
      " |~~ val@9024  Loss: 0.002562 Acc: 13.2344\n",
      " |~~ val@9088  Loss: 0.002009 Acc: 13.4375\n",
      " |~~ val@9152  Loss: 0.002085 Acc: 13.4062\n",
      " |~~ val@9216  Loss: 0.002103 Acc: 13.3906\n",
      " |~~ val@9280  Loss: 0.002238 Acc: 13.3594\n",
      " |~~ val@9344  Loss: 0.002797 Acc: 13.2031\n",
      " |~~ val@9408  Loss: 0.002031 Acc: 13.3906\n",
      " |~~ val@9472  Loss: 0.002137 Acc: 13.4844\n",
      " |~~ val@9536  Loss: 0.002134 Acc: 13.4375\n",
      " |~~ val@9600  Loss: 0.002841 Acc: 13.1562\n",
      " |~~ val@9664  Loss: 0.002384 Acc: 13.3750\n",
      " |~~ val@9728  Loss: 0.002163 Acc: 13.3125\n",
      " |~~ val@9792  Loss: 0.002138 Acc: 13.4062\n",
      " |~~ val@9856  Loss: 0.002236 Acc: 13.2812\n",
      " |~~ val@9920  Loss: 0.002382 Acc: 13.3125\n",
      " |~~ val@9984  Loss: 0.002319 Acc: 13.3750\n",
      " |~~ val@10048  Loss: 0.002120 Acc: 13.4375\n",
      " |~~ val@10112  Loss: 0.003075 Acc: 13.1719\n",
      " |~~ val@10176  Loss: 0.001789 Acc: 13.4219\n",
      " |~~ val@10240  Loss: 0.002385 Acc: 13.2500\n",
      " |~~ val@10304  Loss: 0.001841 Acc: 13.3906\n",
      " |~~ val@10368  Loss: 0.003304 Acc: 13.1406\n",
      " |~~ val@10432  Loss: 0.003200 Acc: 13.0469\n",
      " |~~ val@10496  Loss: 0.002803 Acc: 13.0938\n",
      " |~~ val@10560  Loss: 0.002876 Acc: 13.1250\n",
      " |~~ val@10624  Loss: 0.002509 Acc: 13.3750\n",
      " |~~ val@10688  Loss: 0.002353 Acc: 13.3594\n",
      " |~~ val@10752  Loss: 0.001956 Acc: 13.4062\n",
      " |~~ val@10816  Loss: 0.002196 Acc: 13.3438\n",
      " |~~ val@10880  Loss: 0.002219 Acc: 13.2812\n",
      " |~~ val@10944  Loss: 0.002610 Acc: 13.1875\n",
      " |~~ val@11008  Loss: 0.002706 Acc: 13.1406\n",
      " |~~ val@11072  Loss: 0.002329 Acc: 13.3594\n",
      " |~~ val@11136  Loss: 0.002010 Acc: 13.4219\n",
      " |~~ val@11200  Loss: 0.002844 Acc: 13.2188\n",
      " |~~ val@11264  Loss: 0.002419 Acc: 13.3281\n",
      " |~~ val@11328  Loss: 0.002886 Acc: 13.1094\n",
      " |~~ val@11392  Loss: 0.002623 Acc: 13.2188\n",
      " |~~ val@11456  Loss: 0.001931 Acc: 13.4688\n",
      " |~~ val@11520  Loss: 0.002646 Acc: 13.1875\n",
      " |~~ val@11584  Loss: 0.002707 Acc: 13.2344\n",
      " |~~ val@11648  Loss: 0.002244 Acc: 13.3906\n",
      " |~~ val@11712  Loss: 0.002714 Acc: 13.1875\n",
      " |~~ val@11776  Loss: 0.003266 Acc: 13.0938\n",
      " |~~ val@11840  Loss: 0.002606 Acc: 13.2031\n",
      " |~~ val@11904  Loss: 0.003071 Acc: 13.0781\n",
      " |~~ val@11968  Loss: 0.002303 Acc: 13.2656\n",
      " |~~ val@12032  Loss: 0.002673 Acc: 13.2344\n",
      " |~~ val@12096  Loss: 0.002818 Acc: 13.2500\n",
      " |~~ val@12160  Loss: 0.002547 Acc: 13.2656\n",
      " |~~ val@12224  Loss: 0.003400 Acc: 12.9219\n",
      " |~~ val@12288  Loss: 0.002470 Acc: 13.2812\n",
      " |~~ val@12352  Loss: 0.002172 Acc: 13.3438\n",
      " |~~ val@12416  Loss: 0.002544 Acc: 13.2656\n",
      " |~~ val@12480  Loss: 0.002030 Acc: 13.3906\n",
      " |~~ val@12544  Loss: 0.002396 Acc: 13.2500\n",
      " |~~ val@12608  Loss: 0.002429 Acc: 13.3281\n",
      " |~~ val@12672  Loss: 0.002410 Acc: 13.2812\n",
      " |~~ val@12736  Loss: 0.001692 Acc: 13.5469\n",
      " |~~ val@12800  Loss: 0.002537 Acc: 13.2188\n",
      " |~~ val@12864  Loss: 0.002039 Acc: 13.3438\n",
      " |~~ val@12928  Loss: 0.002615 Acc: 13.2656\n",
      " |~~ val@12992  Loss: 0.002401 Acc: 13.2656\n",
      " |~~ val@13056  Loss: 0.002166 Acc: 13.3438\n",
      " |~~ val@13120  Loss: 0.002334 Acc: 13.3594\n",
      " |~~ val@13184  Loss: 0.002179 Acc: 13.4688\n",
      " |~~ val@13248  Loss: 0.002775 Acc: 13.2188\n",
      " |~~ val@13312  Loss: 0.003151 Acc: 13.0000\n",
      " |~~ val@13376  Loss: 0.002490 Acc: 13.2812\n",
      " |~~ val@13440  Loss: 0.002417 Acc: 13.3125\n",
      " |~~ val@13504  Loss: 0.003020 Acc: 13.0312\n",
      " |~~ val@13568  Loss: 0.002323 Acc: 13.3281\n",
      " |~~ val@13632  Loss: 0.002286 Acc: 13.2812\n",
      " |~~ val@13696  Loss: 0.002284 Acc: 13.3125\n",
      " |~~ val@13760  Loss: 0.001954 Acc: 13.4844\n",
      " |~~ val@13824  Loss: 0.002402 Acc: 13.3125\n",
      " |~~ val@13888  Loss: 0.002727 Acc: 13.1406\n",
      " |~~ val@13952  Loss: 0.002273 Acc: 13.3281\n",
      " |~~ val@14016  Loss: 0.002528 Acc: 13.1562\n",
      " |~~ val@14080  Loss: 0.002756 Acc: 13.1406\n",
      " |~~ val@14144  Loss: 0.002621 Acc: 13.1875\n",
      " |~~ val@14208  Loss: 0.002404 Acc: 13.1719\n",
      " |~~ val@14272  Loss: 0.002262 Acc: 13.2656\n",
      " |~~ val@14336  Loss: 0.001795 Acc: 13.4062\n",
      " |~~ val@14400  Loss: 0.001887 Acc: 13.4688\n",
      " |~~ val@14464  Loss: 0.002335 Acc: 13.2969\n",
      " |~~ val@14528  Loss: 0.002622 Acc: 13.2500\n",
      " |~~ val@14592  Loss: 0.002827 Acc: 13.1875\n",
      " |~~ val@14656  Loss: 0.002478 Acc: 13.3281\n",
      " |~~ val@14720  Loss: 0.002891 Acc: 13.1875\n",
      " |~~ val@14784  Loss: 0.002656 Acc: 13.2031\n",
      " |~~ val@14848  Loss: 0.002552 Acc: 12.9688\n",
      " |~~ val@14912  Loss: 0.003484 Acc: 12.9219\n",
      " |~~ val@14976  Loss: 0.002273 Acc: 13.2812\n",
      " |~~ val@15040  Loss: 0.002354 Acc: 13.2188\n",
      " |~~ val@15104  Loss: 0.002325 Acc: 13.3594\n",
      " |~~ val@15168  Loss: 0.002283 Acc: 13.2500\n",
      " |~~ val@15232  Loss: 0.002582 Acc: 13.2031\n",
      " |~~ val@15296  Loss: 0.003133 Acc: 13.0312\n",
      " |~~ val@15360  Loss: 0.002438 Acc: 13.3125\n",
      " |~~ val@15424  Loss: 0.002813 Acc: 13.1719\n",
      " |~~ val@15488  Loss: 0.002349 Acc: 13.2969\n",
      " |~~ val@15552  Loss: 0.001789 Acc: 13.4688\n",
      " |~~ val@15616  Loss: 0.002446 Acc: 13.2656\n",
      " |~~ val@15680  Loss: 0.002315 Acc: 13.3125\n",
      " |~~ val@15744  Loss: 0.002048 Acc: 13.3594\n",
      " |~~ val@15808  Loss: 0.002302 Acc: 13.4062\n",
      " |~~ val@15872  Loss: 0.002833 Acc: 13.1250\n",
      " |~~ val@15936  Loss: 0.002516 Acc: 13.2344\n",
      " |~~ val@16000  Loss: 0.002881 Acc: 13.1250\n",
      " |~~ val@16064  Loss: 0.002986 Acc: 13.0156\n",
      " |~~ val@16128  Loss: 0.002631 Acc: 13.0625\n",
      " |~~ val@16192  Loss: 0.002024 Acc: 13.3750\n",
      " |~~ val@16256  Loss: 0.002264 Acc: 13.3125\n",
      " |~~ val@16320  Loss: 0.002601 Acc: 13.2500\n",
      " |~~ val@16384  Loss: 0.002376 Acc: 13.2656\n",
      " |~~ val@16448  Loss: 0.001776 Acc: 13.5000\n",
      " |~~ val@16512  Loss: 0.002449 Acc: 13.3750\n",
      " |~~ val@16576  Loss: 0.002459 Acc: 13.2656\n",
      " |~~ val@16640  Loss: 0.002300 Acc: 13.3125\n",
      " |~~ val@16704  Loss: 0.002433 Acc: 13.3281\n",
      " |~~ val@16768  Loss: 0.001802 Acc: 13.4219\n",
      " |~~ val@16832  Loss: 0.001805 Acc: 13.4844\n",
      " |~~ val@16896  Loss: 0.003044 Acc: 13.0781\n",
      " |~~ val@16960  Loss: 0.002547 Acc: 13.3281\n",
      " |~~ val@17024  Loss: 0.002286 Acc: 13.3125\n",
      " |~~ val@17088  Loss: 0.002535 Acc: 13.2500\n",
      " |~~ val@17152  Loss: 0.002278 Acc: 13.2969\n",
      " |~~ val@17216  Loss: 0.002814 Acc: 13.1406\n",
      " |~~ val@17280  Loss: 0.002751 Acc: 13.1562\n",
      " |~~ val@17344  Loss: 0.002089 Acc: 13.3438\n",
      " |~~ val@17408  Loss: 0.001574 Acc: 13.5625\n",
      " |~~ val@17472  Loss: 0.002003 Acc: 13.4375\n",
      " |~~ val@17536  Loss: 0.002405 Acc: 13.3438\n",
      " |~~ val@17600  Loss: 0.002315 Acc: 13.2031\n",
      " |~~ val@17664  Loss: 0.002233 Acc: 13.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@17728  Loss: 0.002912 Acc: 13.2344\n",
      " |~~ val@17792  Loss: 0.002561 Acc: 13.2188\n",
      " |~~ val@17856  Loss: 0.002504 Acc: 13.2812\n",
      " |~~ val@17920  Loss: 0.002230 Acc: 13.2656\n",
      " |~~ val@17984  Loss: 0.002220 Acc: 13.2656\n",
      " |~~ val@18048  Loss: 0.001945 Acc: 13.4219\n",
      " |~~ val@18112  Loss: 0.002131 Acc: 13.3438\n",
      " |~~ val@18176  Loss: 0.002381 Acc: 13.2344\n",
      " |~~ val@18240  Loss: 0.002195 Acc: 13.3438\n",
      " |~~ val@18304  Loss: 0.001890 Acc: 13.4844\n",
      " |~~ val@18368  Loss: 0.003101 Acc: 13.1094\n",
      " |~~ val@18432  Loss: 0.002389 Acc: 13.2969\n",
      " |~~ val@18496  Loss: 0.002513 Acc: 13.1406\n",
      " |~~ val@18560  Loss: 0.002188 Acc: 13.3906\n",
      " |~~ val@18624  Loss: 0.001801 Acc: 13.4531\n",
      " |~~ val@18688  Loss: 0.002480 Acc: 13.2812\n",
      " |~~ val@18752  Loss: 0.002312 Acc: 13.3750\n",
      " |~~ val@18816  Loss: 0.002832 Acc: 13.1562\n",
      " |~~ val@18880  Loss: 0.003238 Acc: 13.1406\n",
      " |~~ val@18944  Loss: 0.001994 Acc: 13.3906\n",
      " |~~ val@19008  Loss: 0.002238 Acc: 13.2500\n",
      " |~~ val@19072  Loss: 0.002272 Acc: 13.3906\n",
      " |~~ val@19136  Loss: 0.002415 Acc: 13.3438\n",
      " |~~ val@19200  Loss: 0.002180 Acc: 13.3594\n",
      " |~~ val@19264  Loss: 0.002356 Acc: 13.2656\n",
      " |~~ val@19328  Loss: 0.002264 Acc: 13.3125\n",
      " |~~ val@19392  Loss: 0.002362 Acc: 13.3438\n",
      " |~~ val@19456  Loss: 0.002368 Acc: 13.2500\n",
      " |~~ val@19520  Loss: 0.003059 Acc: 13.0938\n",
      " |~~ val@19584  Loss: 0.002699 Acc: 13.2031\n",
      " |~~ val@19648  Loss: 0.002202 Acc: 13.4844\n",
      " |~~ val@19712  Loss: 0.001732 Acc: 13.4688\n",
      " |~~ val@19776  Loss: 0.002383 Acc: 13.3438\n",
      " |~~ val@19840  Loss: 0.002625 Acc: 13.2188\n",
      " |~~ val@19904  Loss: 0.002580 Acc: 13.2031\n",
      " |~~ val@19968  Loss: 0.002566 Acc: 13.1562\n",
      " |~~ val@20032  Loss: 0.002695 Acc: 13.2656\n",
      " |~~ val@20096  Loss: 0.002250 Acc: 13.3906\n",
      " |~~ val@20160  Loss: 0.002151 Acc: 13.3750\n",
      " |~~ val@20224  Loss: 0.003011 Acc: 12.9688\n",
      " |~~ val@20288  Loss: 0.002138 Acc: 13.3281\n",
      " |~~ val@20352  Loss: 0.002585 Acc: 13.2500\n",
      " |~~ val@20416  Loss: 0.002583 Acc: 13.2656\n",
      " |~~ val@20480  Loss: 0.002280 Acc: 13.3125\n",
      " |~~ val@20544  Loss: 0.002582 Acc: 13.2031\n",
      " |~~ val@20608  Loss: 0.001957 Acc: 13.4062\n",
      " |~~ val@20672  Loss: 0.002429 Acc: 13.1875\n",
      " |~~ val@20736  Loss: 0.002914 Acc: 13.1250\n",
      " |~~ val@20800  Loss: 0.002515 Acc: 13.2500\n",
      " |~~ val@20864  Loss: 0.002453 Acc: 13.2344\n",
      " |~~ val@20928  Loss: 0.002299 Acc: 13.2188\n",
      " |~~ val@20992  Loss: 0.002463 Acc: 13.2812\n",
      " |~~ val@21056  Loss: 0.002420 Acc: 13.3906\n",
      " |~~ val@21120  Loss: 0.002702 Acc: 13.1562\n",
      " |~~ val@21184  Loss: 0.001933 Acc: 13.4688\n",
      " |~~ val@21248  Loss: 0.002463 Acc: 13.3281\n",
      " |~~ val@21312  Loss: 0.002439 Acc: 13.3438\n",
      " |~~ val@21376  Loss: 0.002447 Acc: 13.3281\n",
      " |~~ val@21440  Loss: 0.003341 Acc: 13.0156\n",
      " |~~ val@21504  Loss: 0.002107 Acc: 13.3906\n",
      " |~~ val@21568  Loss: 0.002503 Acc: 13.2656\n",
      " |~~ val@21632  Loss: 0.002385 Acc: 13.2500\n",
      " |~~ val@21696  Loss: 0.002167 Acc: 13.2344\n",
      " |~~ val@21760  Loss: 0.002073 Acc: 13.3906\n",
      " |~~ val@21824  Loss: 0.002327 Acc: 13.3750\n",
      " |~~ val@21888  Loss: 0.002523 Acc: 13.3438\n",
      " |~~ val@21952  Loss: 0.002083 Acc: 13.4688\n",
      " |~~ val@22016  Loss: 0.002330 Acc: 13.2812\n",
      " |~~ val@22080  Loss: 0.002260 Acc: 13.3750\n",
      " |~~ val@22144  Loss: 0.002982 Acc: 13.1094\n",
      " |~~ val@22208  Loss: 0.002050 Acc: 13.4219\n",
      " |~~ val@22272  Loss: 0.001949 Acc: 13.4688\n",
      " |~~ val@22336  Loss: 0.002452 Acc: 13.3125\n",
      " |~~ val@22400  Loss: 0.002086 Acc: 13.3281\n",
      " |~~ val@22424  Loss: 0.004635 Acc: 13.3750\n",
      "val  Loss: 0.002409 Acc: 13.2866\n",
      "Epoch 5/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.002405 Acc: 13.3281\n",
      " |~~ train@128  Loss: 0.002027 Acc: 13.3750\n",
      " |~~ train@192  Loss: 0.001747 Acc: 13.4688\n",
      " |~~ train@256  Loss: 0.002081 Acc: 13.2500\n",
      " |~~ train@320  Loss: 0.001753 Acc: 13.5000\n",
      " |~~ train@384  Loss: 0.002167 Acc: 13.3438\n",
      " |~~ train@448  Loss: 0.001976 Acc: 13.4375\n",
      " |~~ train@512  Loss: 0.002521 Acc: 13.2031\n",
      " |~~ train@576  Loss: 0.002376 Acc: 13.1562\n",
      " |~~ train@640  Loss: 0.001897 Acc: 13.3281\n",
      " |~~ train@704  Loss: 0.002523 Acc: 13.1562\n",
      " |~~ train@768  Loss: 0.002203 Acc: 13.2969\n",
      " |~~ train@832  Loss: 0.001905 Acc: 13.4844\n",
      " |~~ train@896  Loss: 0.001758 Acc: 13.3750\n",
      " |~~ train@960  Loss: 0.001557 Acc: 13.6094\n",
      " |~~ train@1024  Loss: 0.002451 Acc: 13.1719\n",
      " |~~ train@1088  Loss: 0.002246 Acc: 13.2969\n",
      " |~~ train@1152  Loss: 0.002488 Acc: 13.1719\n",
      " |~~ train@1216  Loss: 0.001888 Acc: 13.4844\n",
      " |~~ train@1280  Loss: 0.001817 Acc: 13.3438\n",
      " |~~ train@1344  Loss: 0.002072 Acc: 13.3594\n",
      " |~~ train@1408  Loss: 0.002043 Acc: 13.4375\n",
      " |~~ train@1472  Loss: 0.001580 Acc: 13.5781\n",
      " |~~ train@1536  Loss: 0.002005 Acc: 13.3906\n",
      " |~~ train@1600  Loss: 0.002455 Acc: 13.1719\n",
      " |~~ train@1664  Loss: 0.002393 Acc: 13.1250\n",
      " |~~ train@1728  Loss: 0.002373 Acc: 13.2812\n",
      " |~~ train@1792  Loss: 0.001894 Acc: 13.3906\n",
      " |~~ train@1856  Loss: 0.001968 Acc: 13.4531\n",
      " |~~ train@1920  Loss: 0.002429 Acc: 13.1875\n",
      " |~~ train@1984  Loss: 0.001974 Acc: 13.3281\n",
      " |~~ train@2048  Loss: 0.001758 Acc: 13.4062\n",
      " |~~ train@2112  Loss: 0.001919 Acc: 13.4062\n",
      " |~~ train@2176  Loss: 0.001564 Acc: 13.5156\n",
      " |~~ train@2240  Loss: 0.001481 Acc: 13.5312\n",
      " |~~ train@2304  Loss: 0.001862 Acc: 13.3594\n",
      " |~~ train@2368  Loss: 0.001571 Acc: 13.6250\n",
      " |~~ train@2432  Loss: 0.002240 Acc: 13.2656\n",
      " |~~ train@2496  Loss: 0.001735 Acc: 13.4062\n",
      " |~~ train@2560  Loss: 0.002503 Acc: 13.1719\n",
      " |~~ train@2624  Loss: 0.002449 Acc: 13.2500\n",
      " |~~ train@2688  Loss: 0.001708 Acc: 13.5156\n",
      " |~~ train@2752  Loss: 0.002091 Acc: 13.3906\n",
      " |~~ train@2816  Loss: 0.001810 Acc: 13.4688\n",
      " |~~ train@2880  Loss: 0.001381 Acc: 13.6406\n",
      " |~~ train@2944  Loss: 0.002279 Acc: 13.2812\n",
      " |~~ train@3008  Loss: 0.001608 Acc: 13.5000\n",
      " |~~ train@3072  Loss: 0.002582 Acc: 13.2188\n",
      " |~~ train@3136  Loss: 0.001895 Acc: 13.4688\n",
      " |~~ train@3200  Loss: 0.002172 Acc: 13.2656\n",
      " |~~ train@3264  Loss: 0.001748 Acc: 13.4688\n",
      " |~~ train@3328  Loss: 0.002297 Acc: 13.2812\n",
      " |~~ train@3392  Loss: 0.002437 Acc: 13.1562\n",
      " |~~ train@3456  Loss: 0.002687 Acc: 13.1719\n",
      " |~~ train@3520  Loss: 0.001949 Acc: 13.3906\n",
      " |~~ train@3584  Loss: 0.002345 Acc: 13.2656\n",
      " |~~ train@3648  Loss: 0.002144 Acc: 13.3125\n",
      " |~~ train@3712  Loss: 0.002256 Acc: 13.1406\n",
      " |~~ train@3776  Loss: 0.002236 Acc: 13.3281\n",
      " |~~ train@3840  Loss: 0.001762 Acc: 13.4375\n",
      " |~~ train@3904  Loss: 0.002056 Acc: 13.2344\n",
      " |~~ train@3968  Loss: 0.001987 Acc: 13.2656\n",
      " |~~ train@4032  Loss: 0.002327 Acc: 13.2031\n",
      " |~~ train@4096  Loss: 0.002552 Acc: 13.0625\n",
      " |~~ train@4160  Loss: 0.002270 Acc: 13.2344\n",
      " |~~ train@4224  Loss: 0.002180 Acc: 13.2500\n",
      " |~~ train@4288  Loss: 0.002435 Acc: 13.2031\n",
      " |~~ train@4352  Loss: 0.001761 Acc: 13.5156\n",
      " |~~ train@4416  Loss: 0.002416 Acc: 13.1875\n",
      " |~~ train@4480  Loss: 0.001937 Acc: 13.4062\n",
      " |~~ train@4544  Loss: 0.002340 Acc: 13.3281\n",
      " |~~ train@4608  Loss: 0.002282 Acc: 13.2188\n",
      " |~~ train@4672  Loss: 0.002219 Acc: 13.3125\n",
      " |~~ train@4736  Loss: 0.002076 Acc: 13.2812\n",
      " |~~ train@4800  Loss: 0.002180 Acc: 13.4375\n",
      " |~~ train@4864  Loss: 0.002342 Acc: 13.1875\n",
      " |~~ train@4928  Loss: 0.001811 Acc: 13.4531\n",
      " |~~ train@4992  Loss: 0.001857 Acc: 13.3906\n",
      " |~~ train@5056  Loss: 0.001807 Acc: 13.4219\n",
      " |~~ train@5120  Loss: 0.001973 Acc: 13.3750\n",
      " |~~ train@5184  Loss: 0.002335 Acc: 13.3438\n",
      " |~~ train@5248  Loss: 0.002268 Acc: 13.2969\n",
      " |~~ train@5312  Loss: 0.002197 Acc: 13.3906\n",
      " |~~ train@5376  Loss: 0.001739 Acc: 13.3438\n",
      " |~~ train@5440  Loss: 0.001765 Acc: 13.5000\n",
      " |~~ train@5504  Loss: 0.002041 Acc: 13.4062\n",
      " |~~ train@5568  Loss: 0.002321 Acc: 13.2188\n",
      " |~~ train@5632  Loss: 0.001811 Acc: 13.4531\n",
      " |~~ train@5696  Loss: 0.002309 Acc: 13.2656\n",
      " |~~ train@5760  Loss: 0.001701 Acc: 13.4688\n",
      " |~~ train@5824  Loss: 0.002241 Acc: 13.2500\n",
      " |~~ train@5888  Loss: 0.001902 Acc: 13.4219\n",
      " |~~ train@5952  Loss: 0.001786 Acc: 13.4375\n",
      " |~~ train@6016  Loss: 0.002446 Acc: 13.1719\n",
      " |~~ train@6080  Loss: 0.001952 Acc: 13.4531\n",
      " |~~ train@6144  Loss: 0.001907 Acc: 13.3438\n",
      " |~~ train@6208  Loss: 0.001954 Acc: 13.4062\n",
      " |~~ train@6272  Loss: 0.002907 Acc: 13.0781\n",
      " |~~ train@6336  Loss: 0.002355 Acc: 13.2812\n",
      " |~~ train@6400  Loss: 0.002167 Acc: 13.2656\n",
      " |~~ train@6464  Loss: 0.001801 Acc: 13.4688\n",
      " |~~ train@6528  Loss: 0.002091 Acc: 13.3594\n",
      " |~~ train@6592  Loss: 0.002518 Acc: 13.1250\n",
      " |~~ train@6656  Loss: 0.002227 Acc: 13.2500\n",
      " |~~ train@6720  Loss: 0.002485 Acc: 13.1719\n",
      " |~~ train@6784  Loss: 0.001789 Acc: 13.4375\n",
      " |~~ train@6848  Loss: 0.002560 Acc: 13.1406\n",
      " |~~ train@6912  Loss: 0.002728 Acc: 13.1406\n",
      " |~~ train@6976  Loss: 0.001888 Acc: 13.3281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@7040  Loss: 0.001994 Acc: 13.3125\n",
      " |~~ train@7104  Loss: 0.002081 Acc: 13.2656\n",
      " |~~ train@7168  Loss: 0.002461 Acc: 13.1875\n",
      " |~~ train@7232  Loss: 0.002258 Acc: 13.2344\n",
      " |~~ train@7296  Loss: 0.002187 Acc: 13.2656\n",
      " |~~ train@7360  Loss: 0.002413 Acc: 13.1406\n",
      " |~~ train@7424  Loss: 0.002062 Acc: 13.2969\n",
      " |~~ train@7488  Loss: 0.002138 Acc: 13.2188\n",
      " |~~ train@7552  Loss: 0.001683 Acc: 13.4688\n",
      " |~~ train@7616  Loss: 0.002030 Acc: 13.3438\n",
      " |~~ train@7680  Loss: 0.001862 Acc: 13.3906\n",
      " |~~ train@7744  Loss: 0.002303 Acc: 13.2500\n",
      " |~~ train@7808  Loss: 0.001601 Acc: 13.5156\n",
      " |~~ train@7872  Loss: 0.002116 Acc: 13.3750\n",
      " |~~ train@7936  Loss: 0.002312 Acc: 13.2656\n",
      " |~~ train@8000  Loss: 0.002522 Acc: 13.1094\n",
      " |~~ train@8064  Loss: 0.002109 Acc: 13.2500\n",
      " |~~ train@8128  Loss: 0.002237 Acc: 13.2656\n",
      " |~~ train@8192  Loss: 0.002204 Acc: 13.2969\n",
      " |~~ train@8256  Loss: 0.001713 Acc: 13.4844\n",
      " |~~ train@8320  Loss: 0.002019 Acc: 13.3906\n",
      " |~~ train@8384  Loss: 0.001889 Acc: 13.4219\n",
      " |~~ train@8448  Loss: 0.002103 Acc: 13.3906\n",
      " |~~ train@8512  Loss: 0.002222 Acc: 13.2344\n",
      " |~~ train@8576  Loss: 0.001973 Acc: 13.3594\n",
      " |~~ train@8640  Loss: 0.002124 Acc: 13.2656\n",
      " |~~ train@8704  Loss: 0.001803 Acc: 13.4844\n",
      " |~~ train@8768  Loss: 0.002384 Acc: 13.2500\n",
      " |~~ train@8832  Loss: 0.002425 Acc: 13.3125\n",
      " |~~ train@8896  Loss: 0.001849 Acc: 13.3750\n",
      " |~~ train@8960  Loss: 0.002283 Acc: 13.2812\n",
      " |~~ train@9024  Loss: 0.001986 Acc: 13.2969\n",
      " |~~ train@9088  Loss: 0.001715 Acc: 13.4219\n",
      " |~~ train@9152  Loss: 0.001885 Acc: 13.4531\n",
      " |~~ train@9216  Loss: 0.002277 Acc: 13.2656\n",
      " |~~ train@9280  Loss: 0.002233 Acc: 13.3281\n",
      " |~~ train@9344  Loss: 0.001939 Acc: 13.4062\n",
      " |~~ train@9408  Loss: 0.002124 Acc: 13.3281\n",
      " |~~ train@9472  Loss: 0.002300 Acc: 13.2500\n",
      " |~~ train@9536  Loss: 0.002029 Acc: 13.2812\n",
      " |~~ train@9600  Loss: 0.002432 Acc: 13.2344\n",
      " |~~ train@9664  Loss: 0.002394 Acc: 13.1875\n",
      " |~~ train@9728  Loss: 0.001889 Acc: 13.3906\n",
      " |~~ train@9792  Loss: 0.001819 Acc: 13.3906\n",
      " |~~ train@9856  Loss: 0.002092 Acc: 13.3750\n",
      " |~~ train@9920  Loss: 0.001774 Acc: 13.3594\n",
      " |~~ train@9984  Loss: 0.001976 Acc: 13.3906\n",
      " |~~ train@10048  Loss: 0.002133 Acc: 13.2500\n",
      " |~~ train@10112  Loss: 0.002104 Acc: 13.3594\n",
      " |~~ train@10176  Loss: 0.001774 Acc: 13.5156\n",
      " |~~ train@10240  Loss: 0.002367 Acc: 13.2031\n",
      " |~~ train@10304  Loss: 0.002115 Acc: 13.3438\n",
      " |~~ train@10368  Loss: 0.002090 Acc: 13.3438\n",
      " |~~ train@10432  Loss: 0.001904 Acc: 13.4219\n",
      " |~~ train@10496  Loss: 0.002392 Acc: 13.2812\n",
      " |~~ train@10560  Loss: 0.001830 Acc: 13.4219\n",
      " |~~ train@10624  Loss: 0.002003 Acc: 13.3594\n",
      " |~~ train@10688  Loss: 0.002341 Acc: 13.1719\n",
      " |~~ train@10752  Loss: 0.002203 Acc: 13.2812\n",
      " |~~ train@10816  Loss: 0.002502 Acc: 13.0938\n",
      " |~~ train@10880  Loss: 0.002025 Acc: 13.3750\n",
      " |~~ train@10944  Loss: 0.002138 Acc: 13.3438\n",
      " |~~ train@11008  Loss: 0.003220 Acc: 12.9844\n",
      " |~~ train@11072  Loss: 0.001724 Acc: 13.4688\n",
      " |~~ train@11136  Loss: 0.002131 Acc: 13.3125\n",
      " |~~ train@11200  Loss: 0.001488 Acc: 13.5938\n",
      " |~~ train@11264  Loss: 0.002909 Acc: 13.0938\n",
      " |~~ train@11328  Loss: 0.002445 Acc: 13.2656\n",
      " |~~ train@11392  Loss: 0.002185 Acc: 13.2969\n",
      " |~~ train@11456  Loss: 0.002283 Acc: 13.2500\n",
      " |~~ train@11520  Loss: 0.001791 Acc: 13.3906\n",
      " |~~ train@11584  Loss: 0.002623 Acc: 13.0781\n",
      " |~~ train@11648  Loss: 0.002003 Acc: 13.3125\n",
      " |~~ train@11712  Loss: 0.002290 Acc: 13.2812\n",
      " |~~ train@11776  Loss: 0.001900 Acc: 13.3594\n",
      " |~~ train@11840  Loss: 0.002204 Acc: 13.2188\n",
      " |~~ train@11904  Loss: 0.002100 Acc: 13.3750\n",
      " |~~ train@11968  Loss: 0.002421 Acc: 13.2656\n",
      " |~~ train@12032  Loss: 0.001711 Acc: 13.5000\n",
      " |~~ train@12096  Loss: 0.002421 Acc: 13.1094\n",
      " |~~ train@12160  Loss: 0.002022 Acc: 13.3281\n",
      " |~~ train@12224  Loss: 0.002178 Acc: 13.3281\n",
      " |~~ train@12288  Loss: 0.002477 Acc: 13.2344\n",
      " |~~ train@12352  Loss: 0.002059 Acc: 13.2812\n",
      " |~~ train@12416  Loss: 0.001767 Acc: 13.3594\n",
      " |~~ train@12480  Loss: 0.001991 Acc: 13.2812\n",
      " |~~ train@12544  Loss: 0.002064 Acc: 13.3438\n",
      " |~~ train@12608  Loss: 0.001615 Acc: 13.5469\n",
      " |~~ train@12672  Loss: 0.001953 Acc: 13.4219\n",
      " |~~ train@12736  Loss: 0.001500 Acc: 13.5625\n",
      " |~~ train@12800  Loss: 0.002503 Acc: 13.1719\n",
      " |~~ train@12864  Loss: 0.002443 Acc: 13.1406\n",
      " |~~ train@12928  Loss: 0.002044 Acc: 13.4375\n",
      " |~~ train@12992  Loss: 0.002212 Acc: 13.2656\n",
      " |~~ train@13056  Loss: 0.002236 Acc: 13.3438\n",
      " |~~ train@13120  Loss: 0.002425 Acc: 13.2969\n",
      " |~~ train@13184  Loss: 0.002178 Acc: 13.2969\n",
      " |~~ train@13248  Loss: 0.002700 Acc: 13.1719\n",
      " |~~ train@13312  Loss: 0.001859 Acc: 13.3906\n",
      " |~~ train@13376  Loss: 0.001646 Acc: 13.4219\n",
      " |~~ train@13440  Loss: 0.002318 Acc: 13.2188\n",
      " |~~ train@13504  Loss: 0.002191 Acc: 13.3750\n",
      " |~~ train@13568  Loss: 0.001883 Acc: 13.4531\n",
      " |~~ train@13632  Loss: 0.002116 Acc: 13.3438\n",
      " |~~ train@13696  Loss: 0.002195 Acc: 13.3281\n",
      " |~~ train@13760  Loss: 0.001829 Acc: 13.4531\n",
      " |~~ train@13824  Loss: 0.001878 Acc: 13.4062\n",
      " |~~ train@13888  Loss: 0.002414 Acc: 13.2812\n",
      " |~~ train@13952  Loss: 0.001868 Acc: 13.3438\n",
      " |~~ train@14016  Loss: 0.002054 Acc: 13.3594\n",
      " |~~ train@14080  Loss: 0.001894 Acc: 13.3906\n",
      " |~~ train@14144  Loss: 0.002119 Acc: 13.2656\n",
      " |~~ train@14208  Loss: 0.001799 Acc: 13.4062\n",
      " |~~ train@14272  Loss: 0.001926 Acc: 13.4688\n",
      " |~~ train@14336  Loss: 0.001980 Acc: 13.2500\n",
      " |~~ train@14400  Loss: 0.002511 Acc: 13.2344\n",
      " |~~ train@14464  Loss: 0.001463 Acc: 13.6094\n",
      " |~~ train@14528  Loss: 0.002477 Acc: 13.1875\n",
      " |~~ train@14592  Loss: 0.001802 Acc: 13.3906\n",
      " |~~ train@14656  Loss: 0.002073 Acc: 13.3281\n",
      " |~~ train@14720  Loss: 0.002006 Acc: 13.3438\n",
      " |~~ train@14784  Loss: 0.002700 Acc: 13.1562\n",
      " |~~ train@14848  Loss: 0.002104 Acc: 13.3281\n",
      " |~~ train@14912  Loss: 0.002094 Acc: 13.3438\n",
      " |~~ train@14976  Loss: 0.002138 Acc: 13.3594\n",
      " |~~ train@15040  Loss: 0.001650 Acc: 13.4844\n",
      " |~~ train@15104  Loss: 0.002423 Acc: 13.3438\n",
      " |~~ train@15168  Loss: 0.001851 Acc: 13.4375\n",
      " |~~ train@15232  Loss: 0.002008 Acc: 13.3594\n",
      " |~~ train@15296  Loss: 0.002211 Acc: 13.2500\n",
      " |~~ train@15360  Loss: 0.002551 Acc: 13.1719\n",
      " |~~ train@15424  Loss: 0.002234 Acc: 13.2812\n",
      " |~~ train@15488  Loss: 0.001745 Acc: 13.3906\n",
      " |~~ train@15552  Loss: 0.001811 Acc: 13.4375\n",
      " |~~ train@15616  Loss: 0.001948 Acc: 13.3906\n",
      " |~~ train@15680  Loss: 0.002054 Acc: 13.3125\n",
      " |~~ train@15744  Loss: 0.002035 Acc: 13.3750\n",
      " |~~ train@15808  Loss: 0.001872 Acc: 13.4062\n",
      " |~~ train@15872  Loss: 0.001863 Acc: 13.3906\n",
      " |~~ train@15936  Loss: 0.002344 Acc: 13.2969\n",
      " |~~ train@16000  Loss: 0.001787 Acc: 13.5000\n",
      " |~~ train@16064  Loss: 0.002314 Acc: 13.2500\n",
      " |~~ train@16128  Loss: 0.002027 Acc: 13.4062\n",
      " |~~ train@16192  Loss: 0.001962 Acc: 13.3438\n",
      " |~~ train@16256  Loss: 0.002363 Acc: 13.2500\n",
      " |~~ train@16320  Loss: 0.001672 Acc: 13.5781\n",
      " |~~ train@16384  Loss: 0.001990 Acc: 13.2344\n",
      " |~~ train@16448  Loss: 0.001955 Acc: 13.3906\n",
      " |~~ train@16512  Loss: 0.002488 Acc: 13.1719\n",
      " |~~ train@16576  Loss: 0.001804 Acc: 13.3750\n",
      " |~~ train@16640  Loss: 0.001728 Acc: 13.5000\n",
      " |~~ train@16704  Loss: 0.002089 Acc: 13.3438\n",
      " |~~ train@16768  Loss: 0.001716 Acc: 13.5938\n",
      " |~~ train@16832  Loss: 0.001975 Acc: 13.2656\n",
      " |~~ train@16896  Loss: 0.001685 Acc: 13.4531\n",
      " |~~ train@16960  Loss: 0.001977 Acc: 13.3594\n",
      " |~~ train@17024  Loss: 0.001957 Acc: 13.4688\n",
      " |~~ train@17088  Loss: 0.001665 Acc: 13.5312\n",
      " |~~ train@17152  Loss: 0.001914 Acc: 13.4688\n",
      " |~~ train@17216  Loss: 0.001985 Acc: 13.3438\n",
      " |~~ train@17280  Loss: 0.002351 Acc: 13.1094\n",
      " |~~ train@17344  Loss: 0.002411 Acc: 13.2031\n",
      " |~~ train@17408  Loss: 0.002430 Acc: 13.1406\n",
      " |~~ train@17472  Loss: 0.001771 Acc: 13.4531\n",
      " |~~ train@17536  Loss: 0.002361 Acc: 13.2500\n",
      " |~~ train@17600  Loss: 0.002831 Acc: 13.0312\n",
      " |~~ train@17664  Loss: 0.001940 Acc: 13.3750\n",
      " |~~ train@17728  Loss: 0.002274 Acc: 13.2969\n",
      " |~~ train@17792  Loss: 0.001841 Acc: 13.5000\n",
      " |~~ train@17856  Loss: 0.002111 Acc: 13.3594\n",
      " |~~ train@17920  Loss: 0.001642 Acc: 13.5469\n",
      " |~~ train@17984  Loss: 0.002038 Acc: 13.3438\n",
      " |~~ train@18048  Loss: 0.001901 Acc: 13.2812\n",
      " |~~ train@18112  Loss: 0.001860 Acc: 13.4062\n",
      " |~~ train@18176  Loss: 0.001970 Acc: 13.4219\n",
      " |~~ train@18240  Loss: 0.001937 Acc: 13.3594\n",
      " |~~ train@18304  Loss: 0.002044 Acc: 13.3906\n",
      " |~~ train@18368  Loss: 0.001957 Acc: 13.3594\n",
      " |~~ train@18432  Loss: 0.001844 Acc: 13.4219\n",
      " |~~ train@18496  Loss: 0.001510 Acc: 13.5938\n",
      " |~~ train@18560  Loss: 0.002034 Acc: 13.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@18624  Loss: 0.002037 Acc: 13.3281\n",
      " |~~ train@18688  Loss: 0.001797 Acc: 13.4531\n",
      " |~~ train@18752  Loss: 0.002294 Acc: 13.2031\n",
      " |~~ train@18816  Loss: 0.002295 Acc: 13.2344\n",
      " |~~ train@18880  Loss: 0.002358 Acc: 13.2969\n",
      " |~~ train@18944  Loss: 0.001927 Acc: 13.3438\n",
      " |~~ train@19008  Loss: 0.002267 Acc: 13.1719\n",
      " |~~ train@19072  Loss: 0.001794 Acc: 13.4531\n",
      " |~~ train@19136  Loss: 0.002395 Acc: 13.2344\n",
      " |~~ train@19200  Loss: 0.001359 Acc: 13.5781\n",
      " |~~ train@19264  Loss: 0.002563 Acc: 13.1562\n",
      " |~~ train@19328  Loss: 0.001866 Acc: 13.3594\n",
      " |~~ train@19392  Loss: 0.001884 Acc: 13.4219\n",
      " |~~ train@19456  Loss: 0.001851 Acc: 13.3281\n",
      " |~~ train@19520  Loss: 0.001871 Acc: 13.4062\n",
      " |~~ train@19584  Loss: 0.002394 Acc: 13.2344\n",
      " |~~ train@19648  Loss: 0.001607 Acc: 13.4219\n",
      " |~~ train@19712  Loss: 0.002354 Acc: 13.2188\n",
      " |~~ train@19776  Loss: 0.002114 Acc: 13.3281\n",
      " |~~ train@19840  Loss: 0.002280 Acc: 13.2188\n",
      " |~~ train@19904  Loss: 0.002039 Acc: 13.4219\n",
      " |~~ train@19968  Loss: 0.002202 Acc: 13.3125\n",
      " |~~ train@20032  Loss: 0.001778 Acc: 13.4531\n",
      " |~~ train@20096  Loss: 0.002345 Acc: 13.1250\n",
      " |~~ train@20160  Loss: 0.001983 Acc: 13.2500\n",
      " |~~ train@20224  Loss: 0.001960 Acc: 13.3906\n",
      " |~~ train@20288  Loss: 0.002174 Acc: 13.2656\n",
      " |~~ train@20352  Loss: 0.002460 Acc: 13.1719\n",
      " |~~ train@20416  Loss: 0.001759 Acc: 13.4531\n",
      " |~~ train@20480  Loss: 0.002596 Acc: 13.1562\n",
      " |~~ train@20544  Loss: 0.002348 Acc: 13.2188\n",
      " |~~ train@20608  Loss: 0.001812 Acc: 13.5156\n",
      " |~~ train@20672  Loss: 0.001901 Acc: 13.3438\n",
      " |~~ train@20736  Loss: 0.002486 Acc: 13.1562\n",
      " |~~ train@20800  Loss: 0.001560 Acc: 13.5156\n",
      " |~~ train@20864  Loss: 0.002678 Acc: 13.1094\n",
      " |~~ train@20928  Loss: 0.002358 Acc: 13.3438\n",
      " |~~ train@20992  Loss: 0.001683 Acc: 13.5156\n",
      " |~~ train@21056  Loss: 0.002155 Acc: 13.3438\n",
      " |~~ train@21120  Loss: 0.001903 Acc: 13.5000\n",
      " |~~ train@21184  Loss: 0.002095 Acc: 13.3594\n",
      " |~~ train@21248  Loss: 0.002051 Acc: 13.3594\n",
      " |~~ train@21312  Loss: 0.001873 Acc: 13.4375\n",
      " |~~ train@21376  Loss: 0.001949 Acc: 13.3281\n",
      " |~~ train@21440  Loss: 0.001576 Acc: 13.5000\n",
      " |~~ train@21504  Loss: 0.001588 Acc: 13.5312\n",
      " |~~ train@21568  Loss: 0.001972 Acc: 13.4062\n",
      " |~~ train@21632  Loss: 0.002465 Acc: 13.2031\n",
      " |~~ train@21696  Loss: 0.001975 Acc: 13.3594\n",
      " |~~ train@21760  Loss: 0.002114 Acc: 13.2969\n",
      " |~~ train@21824  Loss: 0.001921 Acc: 13.4219\n",
      " |~~ train@21888  Loss: 0.002601 Acc: 13.1406\n",
      " |~~ train@21952  Loss: 0.002025 Acc: 13.3125\n",
      " |~~ train@22016  Loss: 0.002030 Acc: 13.3281\n",
      " |~~ train@22080  Loss: 0.001731 Acc: 13.4531\n",
      " |~~ train@22144  Loss: 0.001876 Acc: 13.3906\n",
      " |~~ train@22208  Loss: 0.001704 Acc: 13.5312\n",
      " |~~ train@22272  Loss: 0.001703 Acc: 13.4531\n",
      " |~~ train@22336  Loss: 0.002033 Acc: 13.2969\n",
      " |~~ train@22400  Loss: 0.001707 Acc: 13.4219\n",
      " |~~ train@22464  Loss: 0.002167 Acc: 13.2812\n",
      " |~~ train@22528  Loss: 0.002290 Acc: 13.2344\n",
      " |~~ train@22592  Loss: 0.002018 Acc: 13.3438\n",
      " |~~ train@22656  Loss: 0.001779 Acc: 13.4688\n",
      " |~~ train@22720  Loss: 0.001702 Acc: 13.3906\n",
      " |~~ train@22784  Loss: 0.002191 Acc: 13.2656\n",
      " |~~ train@22848  Loss: 0.002055 Acc: 13.2344\n",
      " |~~ train@22912  Loss: 0.001843 Acc: 13.4688\n",
      " |~~ train@22976  Loss: 0.002521 Acc: 13.1562\n",
      " |~~ train@23040  Loss: 0.001957 Acc: 13.3594\n",
      " |~~ train@23104  Loss: 0.001811 Acc: 13.4062\n",
      " |~~ train@23168  Loss: 0.001787 Acc: 13.3438\n",
      " |~~ train@23232  Loss: 0.002363 Acc: 13.3281\n",
      " |~~ train@23296  Loss: 0.001535 Acc: 13.5312\n",
      " |~~ train@23360  Loss: 0.002559 Acc: 13.2656\n",
      " |~~ train@23424  Loss: 0.001663 Acc: 13.5469\n",
      " |~~ train@23488  Loss: 0.001919 Acc: 13.3750\n",
      " |~~ train@23552  Loss: 0.002825 Acc: 13.0156\n",
      " |~~ train@23616  Loss: 0.001955 Acc: 13.2969\n",
      " |~~ train@23680  Loss: 0.002468 Acc: 13.1719\n",
      " |~~ train@23744  Loss: 0.002651 Acc: 13.1875\n",
      " |~~ train@23808  Loss: 0.002123 Acc: 13.3438\n",
      " |~~ train@23872  Loss: 0.002329 Acc: 13.2656\n",
      " |~~ train@23936  Loss: 0.002377 Acc: 13.2656\n",
      " |~~ train@24000  Loss: 0.001775 Acc: 13.4375\n",
      " |~~ train@24064  Loss: 0.002499 Acc: 13.2500\n",
      " |~~ train@24128  Loss: 0.002246 Acc: 13.2969\n",
      " |~~ train@24192  Loss: 0.001958 Acc: 13.3281\n",
      " |~~ train@24256  Loss: 0.002203 Acc: 13.2656\n",
      " |~~ train@24320  Loss: 0.002306 Acc: 13.3125\n",
      " |~~ train@24384  Loss: 0.002229 Acc: 13.3281\n",
      " |~~ train@24448  Loss: 0.002151 Acc: 13.1875\n",
      " |~~ train@24512  Loss: 0.002034 Acc: 13.3125\n",
      " |~~ train@24576  Loss: 0.002975 Acc: 13.0000\n",
      " |~~ train@24640  Loss: 0.002002 Acc: 13.3594\n",
      " |~~ train@24704  Loss: 0.002028 Acc: 13.4062\n",
      " |~~ train@24768  Loss: 0.001836 Acc: 13.3906\n",
      " |~~ train@24832  Loss: 0.001966 Acc: 13.4062\n",
      " |~~ train@24896  Loss: 0.002289 Acc: 13.2812\n",
      " |~~ train@24960  Loss: 0.002136 Acc: 13.2656\n",
      " |~~ train@25024  Loss: 0.002053 Acc: 13.2969\n",
      " |~~ train@25088  Loss: 0.001459 Acc: 13.5312\n",
      " |~~ train@25152  Loss: 0.002179 Acc: 13.3750\n",
      " |~~ train@25216  Loss: 0.002751 Acc: 13.2031\n",
      " |~~ train@25280  Loss: 0.001939 Acc: 13.4688\n",
      " |~~ train@25344  Loss: 0.002228 Acc: 13.3281\n",
      " |~~ train@25408  Loss: 0.002677 Acc: 13.1406\n",
      " |~~ train@25472  Loss: 0.001783 Acc: 13.3750\n",
      " |~~ train@25536  Loss: 0.002395 Acc: 13.2344\n",
      " |~~ train@25600  Loss: 0.001979 Acc: 13.5000\n",
      " |~~ train@25664  Loss: 0.001917 Acc: 13.3594\n",
      " |~~ train@25728  Loss: 0.002184 Acc: 13.2500\n",
      " |~~ train@25792  Loss: 0.001894 Acc: 13.4531\n",
      " |~~ train@25856  Loss: 0.001754 Acc: 13.4688\n",
      " |~~ train@25920  Loss: 0.002031 Acc: 13.4375\n",
      " |~~ train@25984  Loss: 0.001657 Acc: 13.4844\n",
      " |~~ train@26048  Loss: 0.002263 Acc: 13.3438\n",
      " |~~ train@26112  Loss: 0.001839 Acc: 13.4375\n",
      " |~~ train@26176  Loss: 0.002405 Acc: 13.3125\n",
      " |~~ train@26240  Loss: 0.002131 Acc: 13.3281\n",
      " |~~ train@26304  Loss: 0.002160 Acc: 13.3438\n",
      " |~~ train@26368  Loss: 0.001834 Acc: 13.4531\n",
      " |~~ train@26432  Loss: 0.002125 Acc: 13.2656\n",
      " |~~ train@26496  Loss: 0.001842 Acc: 13.3750\n",
      " |~~ train@26560  Loss: 0.001854 Acc: 13.4219\n",
      " |~~ train@26624  Loss: 0.001882 Acc: 13.4844\n",
      " |~~ train@26688  Loss: 0.001990 Acc: 13.4062\n",
      " |~~ train@26752  Loss: 0.001832 Acc: 13.3750\n",
      " |~~ train@26816  Loss: 0.002004 Acc: 13.2969\n",
      " |~~ train@26880  Loss: 0.002019 Acc: 13.3281\n",
      " |~~ train@26944  Loss: 0.002349 Acc: 13.2031\n",
      " |~~ train@27008  Loss: 0.001837 Acc: 13.4219\n",
      " |~~ train@27072  Loss: 0.001997 Acc: 13.3125\n",
      " |~~ train@27136  Loss: 0.001525 Acc: 13.4375\n",
      " |~~ train@27200  Loss: 0.002886 Acc: 13.0312\n",
      " |~~ train@27264  Loss: 0.002300 Acc: 13.2500\n",
      " |~~ train@27328  Loss: 0.001791 Acc: 13.4062\n",
      " |~~ train@27392  Loss: 0.002129 Acc: 13.3125\n",
      " |~~ train@27456  Loss: 0.001662 Acc: 13.5938\n",
      " |~~ train@27520  Loss: 0.002051 Acc: 13.3281\n",
      " |~~ train@27584  Loss: 0.002594 Acc: 13.0781\n",
      " |~~ train@27648  Loss: 0.002123 Acc: 13.2969\n",
      " |~~ train@27712  Loss: 0.001959 Acc: 13.3281\n",
      " |~~ train@27776  Loss: 0.002375 Acc: 13.2344\n",
      " |~~ train@27840  Loss: 0.001951 Acc: 13.3750\n",
      " |~~ train@27904  Loss: 0.002172 Acc: 13.3125\n",
      " |~~ train@27968  Loss: 0.001780 Acc: 13.3594\n",
      " |~~ train@28032  Loss: 0.002409 Acc: 13.1562\n",
      " |~~ train@28096  Loss: 0.001840 Acc: 13.3594\n",
      " |~~ train@28160  Loss: 0.002055 Acc: 13.3750\n",
      " |~~ train@28224  Loss: 0.001960 Acc: 13.4062\n",
      " |~~ train@28288  Loss: 0.002118 Acc: 13.3594\n",
      " |~~ train@28352  Loss: 0.002080 Acc: 13.3125\n",
      " |~~ train@28416  Loss: 0.001857 Acc: 13.3438\n",
      " |~~ train@28480  Loss: 0.001688 Acc: 13.4844\n",
      " |~~ train@28544  Loss: 0.001792 Acc: 13.3438\n",
      " |~~ train@28608  Loss: 0.001645 Acc: 13.4375\n",
      " |~~ train@28672  Loss: 0.001638 Acc: 13.5469\n",
      " |~~ train@28736  Loss: 0.002109 Acc: 13.3125\n",
      " |~~ train@28800  Loss: 0.001990 Acc: 13.3906\n",
      " |~~ train@28864  Loss: 0.002225 Acc: 13.3281\n",
      " |~~ train@28928  Loss: 0.002329 Acc: 13.3281\n",
      " |~~ train@28992  Loss: 0.001819 Acc: 13.4062\n",
      " |~~ train@29056  Loss: 0.001883 Acc: 13.3750\n",
      " |~~ train@29120  Loss: 0.002045 Acc: 13.3906\n",
      " |~~ train@29184  Loss: 0.001670 Acc: 13.5312\n",
      " |~~ train@29248  Loss: 0.001953 Acc: 13.2969\n",
      " |~~ train@29312  Loss: 0.002126 Acc: 13.2969\n",
      " |~~ train@29376  Loss: 0.002009 Acc: 13.3125\n",
      " |~~ train@29440  Loss: 0.001952 Acc: 13.3438\n",
      " |~~ train@29504  Loss: 0.002326 Acc: 13.2344\n",
      " |~~ train@29568  Loss: 0.002277 Acc: 13.2031\n",
      " |~~ train@29632  Loss: 0.001573 Acc: 13.4844\n",
      " |~~ train@29696  Loss: 0.001580 Acc: 13.4531\n",
      " |~~ train@29760  Loss: 0.001509 Acc: 13.6719\n",
      " |~~ train@29824  Loss: 0.001679 Acc: 13.5312\n",
      " |~~ train@29888  Loss: 0.002181 Acc: 13.2188\n",
      " |~~ train@29952  Loss: 0.001905 Acc: 13.4219\n",
      " |~~ train@30016  Loss: 0.001870 Acc: 13.4844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@30080  Loss: 0.002214 Acc: 13.1719\n",
      " |~~ train@30144  Loss: 0.002340 Acc: 13.2812\n",
      " |~~ train@30208  Loss: 0.002155 Acc: 13.2656\n",
      " |~~ train@30272  Loss: 0.002328 Acc: 13.2656\n",
      " |~~ train@30336  Loss: 0.001859 Acc: 13.4219\n",
      " |~~ train@30400  Loss: 0.002428 Acc: 13.2812\n",
      " |~~ train@30464  Loss: 0.002389 Acc: 13.2188\n",
      " |~~ train@30528  Loss: 0.001977 Acc: 13.3438\n",
      " |~~ train@30592  Loss: 0.002464 Acc: 13.1719\n",
      " |~~ train@30656  Loss: 0.002367 Acc: 13.2031\n",
      " |~~ train@30720  Loss: 0.002054 Acc: 13.3438\n",
      " |~~ train@30784  Loss: 0.001761 Acc: 13.4062\n",
      " |~~ train@30848  Loss: 0.002179 Acc: 13.2812\n",
      " |~~ train@30912  Loss: 0.001996 Acc: 13.3438\n",
      " |~~ train@30976  Loss: 0.002184 Acc: 13.2188\n",
      " |~~ train@31040  Loss: 0.001840 Acc: 13.3438\n",
      " |~~ train@31104  Loss: 0.001946 Acc: 13.3906\n",
      " |~~ train@31168  Loss: 0.001719 Acc: 13.4219\n",
      " |~~ train@31232  Loss: 0.001534 Acc: 13.4688\n",
      " |~~ train@31296  Loss: 0.002620 Acc: 13.1562\n",
      " |~~ train@31360  Loss: 0.002436 Acc: 13.0938\n",
      " |~~ train@31424  Loss: 0.001965 Acc: 13.3906\n",
      " |~~ train@31488  Loss: 0.002230 Acc: 13.2031\n",
      " |~~ train@31552  Loss: 0.001890 Acc: 13.3125\n",
      " |~~ train@31616  Loss: 0.002204 Acc: 13.2656\n",
      " |~~ train@31680  Loss: 0.001627 Acc: 13.5625\n",
      " |~~ train@31744  Loss: 0.002738 Acc: 13.1562\n",
      " |~~ train@31808  Loss: 0.001752 Acc: 13.4062\n",
      " |~~ train@31872  Loss: 0.001691 Acc: 13.4688\n",
      " |~~ train@31936  Loss: 0.002010 Acc: 13.3281\n",
      " |~~ train@32000  Loss: 0.002076 Acc: 13.4062\n",
      " |~~ train@32064  Loss: 0.002050 Acc: 13.2656\n",
      " |~~ train@32128  Loss: 0.001973 Acc: 13.4219\n",
      " |~~ train@32192  Loss: 0.001734 Acc: 13.4844\n",
      " |~~ train@32256  Loss: 0.002126 Acc: 13.3281\n",
      " |~~ train@32320  Loss: 0.002216 Acc: 13.3438\n",
      " |~~ train@32384  Loss: 0.002006 Acc: 13.3750\n",
      " |~~ train@32448  Loss: 0.002081 Acc: 13.3438\n",
      " |~~ train@32512  Loss: 0.002663 Acc: 13.0469\n",
      " |~~ train@32576  Loss: 0.001610 Acc: 13.4844\n",
      " |~~ train@32640  Loss: 0.002421 Acc: 13.2344\n",
      " |~~ train@32704  Loss: 0.001743 Acc: 13.4844\n",
      " |~~ train@32768  Loss: 0.001773 Acc: 13.5469\n",
      " |~~ train@32832  Loss: 0.002112 Acc: 13.2812\n",
      " |~~ train@32896  Loss: 0.002400 Acc: 13.2500\n",
      " |~~ train@32960  Loss: 0.001820 Acc: 13.4375\n",
      " |~~ train@33024  Loss: 0.002101 Acc: 13.3594\n",
      " |~~ train@33088  Loss: 0.001727 Acc: 13.4375\n",
      " |~~ train@33152  Loss: 0.002081 Acc: 13.3594\n",
      " |~~ train@33216  Loss: 0.001795 Acc: 13.4375\n",
      " |~~ train@33280  Loss: 0.001595 Acc: 13.5000\n",
      " |~~ train@33344  Loss: 0.001864 Acc: 13.3594\n",
      " |~~ train@33408  Loss: 0.001984 Acc: 13.5625\n",
      " |~~ train@33472  Loss: 0.001953 Acc: 13.2969\n",
      " |~~ train@33536  Loss: 0.001928 Acc: 13.4219\n",
      " |~~ train@33600  Loss: 0.001922 Acc: 13.4531\n",
      " |~~ train@33664  Loss: 0.001914 Acc: 13.4531\n",
      " |~~ train@33728  Loss: 0.002615 Acc: 13.2188\n",
      " |~~ train@33792  Loss: 0.001854 Acc: 13.3906\n",
      " |~~ train@33856  Loss: 0.002260 Acc: 13.3125\n",
      " |~~ train@33920  Loss: 0.001999 Acc: 13.2812\n",
      " |~~ train@33984  Loss: 0.002067 Acc: 13.3281\n",
      " |~~ train@34048  Loss: 0.001874 Acc: 13.4062\n",
      " |~~ train@34112  Loss: 0.002280 Acc: 13.3281\n",
      " |~~ train@34176  Loss: 0.001967 Acc: 13.4375\n",
      " |~~ train@34240  Loss: 0.001630 Acc: 13.5625\n",
      " |~~ train@34304  Loss: 0.002085 Acc: 13.3594\n",
      " |~~ train@34368  Loss: 0.002528 Acc: 13.1406\n",
      " |~~ train@34432  Loss: 0.002041 Acc: 13.3281\n",
      " |~~ train@34496  Loss: 0.001948 Acc: 13.3750\n",
      " |~~ train@34560  Loss: 0.001870 Acc: 13.3750\n",
      " |~~ train@34624  Loss: 0.002034 Acc: 13.2812\n",
      " |~~ train@34688  Loss: 0.002413 Acc: 13.2500\n",
      " |~~ train@34752  Loss: 0.002013 Acc: 13.3906\n",
      " |~~ train@34816  Loss: 0.002319 Acc: 13.2031\n",
      " |~~ train@34880  Loss: 0.002635 Acc: 13.1875\n",
      " |~~ train@34944  Loss: 0.001997 Acc: 13.4844\n",
      " |~~ train@35008  Loss: 0.002238 Acc: 13.2500\n",
      " |~~ train@35072  Loss: 0.001974 Acc: 13.3750\n",
      " |~~ train@35136  Loss: 0.001951 Acc: 13.4062\n",
      " |~~ train@35200  Loss: 0.001828 Acc: 13.3906\n",
      " |~~ train@35264  Loss: 0.002169 Acc: 13.2656\n",
      " |~~ train@35328  Loss: 0.001884 Acc: 13.4375\n",
      " |~~ train@35392  Loss: 0.002353 Acc: 13.1875\n",
      " |~~ train@35456  Loss: 0.002261 Acc: 13.3125\n",
      " |~~ train@35520  Loss: 0.001990 Acc: 13.3750\n",
      " |~~ train@35584  Loss: 0.001967 Acc: 13.3594\n",
      " |~~ train@35648  Loss: 0.002062 Acc: 13.3906\n",
      " |~~ train@35712  Loss: 0.002055 Acc: 13.3281\n",
      " |~~ train@35776  Loss: 0.002379 Acc: 13.2500\n",
      " |~~ train@35840  Loss: 0.002554 Acc: 13.2500\n",
      " |~~ train@35904  Loss: 0.002037 Acc: 13.2812\n",
      " |~~ train@35968  Loss: 0.001911 Acc: 13.4375\n",
      " |~~ train@36032  Loss: 0.002386 Acc: 13.1562\n",
      " |~~ train@36096  Loss: 0.001993 Acc: 13.2812\n",
      " |~~ train@36160  Loss: 0.002106 Acc: 13.2656\n",
      " |~~ train@36224  Loss: 0.002184 Acc: 13.2969\n",
      " |~~ train@36288  Loss: 0.002125 Acc: 13.3125\n",
      " |~~ train@36352  Loss: 0.002077 Acc: 13.3906\n",
      " |~~ train@36416  Loss: 0.002262 Acc: 13.2500\n",
      " |~~ train@36480  Loss: 0.002794 Acc: 13.2031\n",
      " |~~ train@36544  Loss: 0.001853 Acc: 13.4219\n",
      " |~~ train@36608  Loss: 0.002255 Acc: 13.2656\n",
      " |~~ train@36672  Loss: 0.001696 Acc: 13.4688\n",
      " |~~ train@36736  Loss: 0.001895 Acc: 13.3438\n",
      " |~~ train@36800  Loss: 0.001814 Acc: 13.5000\n",
      " |~~ train@36864  Loss: 0.002250 Acc: 13.2031\n",
      " |~~ train@36928  Loss: 0.001949 Acc: 13.3125\n",
      " |~~ train@36992  Loss: 0.002001 Acc: 13.3750\n",
      " |~~ train@37056  Loss: 0.001655 Acc: 13.5312\n",
      " |~~ train@37120  Loss: 0.002065 Acc: 13.2812\n",
      " |~~ train@37184  Loss: 0.002471 Acc: 13.1406\n",
      " |~~ train@37248  Loss: 0.002227 Acc: 13.2344\n",
      " |~~ train@37312  Loss: 0.002027 Acc: 13.3750\n",
      " |~~ train@37376  Loss: 0.002279 Acc: 13.2500\n",
      " |~~ train@37440  Loss: 0.002129 Acc: 13.3125\n",
      " |~~ train@37504  Loss: 0.002118 Acc: 13.3594\n",
      " |~~ train@37568  Loss: 0.002437 Acc: 13.1719\n",
      " |~~ train@37632  Loss: 0.002242 Acc: 13.2812\n",
      " |~~ train@37696  Loss: 0.001706 Acc: 13.4688\n",
      " |~~ train@37760  Loss: 0.002184 Acc: 13.4219\n",
      " |~~ train@37824  Loss: 0.002063 Acc: 13.4062\n",
      " |~~ train@37888  Loss: 0.002095 Acc: 13.3125\n",
      " |~~ train@37952  Loss: 0.002163 Acc: 13.3906\n",
      " |~~ train@38016  Loss: 0.001850 Acc: 13.4531\n",
      " |~~ train@38080  Loss: 0.001829 Acc: 13.3594\n",
      " |~~ train@38144  Loss: 0.002319 Acc: 13.2188\n",
      " |~~ train@38208  Loss: 0.001585 Acc: 13.5469\n",
      " |~~ train@38272  Loss: 0.002115 Acc: 13.3438\n",
      " |~~ train@38336  Loss: 0.002028 Acc: 13.3281\n",
      " |~~ train@38400  Loss: 0.002117 Acc: 13.3594\n",
      " |~~ train@38464  Loss: 0.002780 Acc: 13.2031\n",
      " |~~ train@38528  Loss: 0.002208 Acc: 13.3125\n",
      " |~~ train@38592  Loss: 0.001753 Acc: 13.4375\n",
      " |~~ train@38656  Loss: 0.002054 Acc: 13.4062\n",
      " |~~ train@38720  Loss: 0.002015 Acc: 13.3750\n",
      " |~~ train@38784  Loss: 0.002345 Acc: 13.3125\n",
      " |~~ train@38848  Loss: 0.002162 Acc: 13.3750\n",
      " |~~ train@38912  Loss: 0.001628 Acc: 13.4844\n",
      " |~~ train@38976  Loss: 0.001968 Acc: 13.3750\n",
      " |~~ train@39040  Loss: 0.002056 Acc: 13.3906\n",
      " |~~ train@39104  Loss: 0.002362 Acc: 13.1875\n",
      " |~~ train@39168  Loss: 0.001851 Acc: 13.3281\n",
      " |~~ train@39232  Loss: 0.001719 Acc: 13.4688\n",
      " |~~ train@39296  Loss: 0.001598 Acc: 13.4844\n",
      " |~~ train@39360  Loss: 0.002290 Acc: 13.2500\n",
      " |~~ train@39424  Loss: 0.001755 Acc: 13.5000\n",
      " |~~ train@39488  Loss: 0.001601 Acc: 13.4688\n",
      " |~~ train@39552  Loss: 0.001875 Acc: 13.4375\n",
      " |~~ train@39616  Loss: 0.001860 Acc: 13.4062\n",
      " |~~ train@39680  Loss: 0.001944 Acc: 13.3125\n",
      " |~~ train@39744  Loss: 0.001928 Acc: 13.3438\n",
      " |~~ train@39808  Loss: 0.002274 Acc: 13.2344\n",
      " |~~ train@39872  Loss: 0.002754 Acc: 13.0938\n",
      " |~~ train@39936  Loss: 0.002330 Acc: 13.2031\n",
      " |~~ train@40000  Loss: 0.002775 Acc: 13.1875\n",
      " |~~ train@40064  Loss: 0.002020 Acc: 13.3906\n",
      " |~~ train@40128  Loss: 0.001942 Acc: 13.3281\n",
      " |~~ train@40192  Loss: 0.001989 Acc: 13.3750\n",
      " |~~ train@40256  Loss: 0.002032 Acc: 13.2812\n",
      " |~~ train@40320  Loss: 0.002090 Acc: 13.3281\n",
      " |~~ train@40384  Loss: 0.001990 Acc: 13.2969\n",
      " |~~ train@40448  Loss: 0.001874 Acc: 13.4844\n",
      " |~~ train@40512  Loss: 0.001816 Acc: 13.4375\n",
      " |~~ train@40576  Loss: 0.002084 Acc: 13.3906\n",
      " |~~ train@40640  Loss: 0.002006 Acc: 13.3594\n",
      " |~~ train@40704  Loss: 0.001482 Acc: 13.5781\n",
      " |~~ train@40768  Loss: 0.002000 Acc: 13.4688\n",
      " |~~ train@40832  Loss: 0.002148 Acc: 13.2969\n",
      " |~~ train@40896  Loss: 0.002049 Acc: 13.3281\n",
      " |~~ train@40960  Loss: 0.002183 Acc: 13.2969\n",
      " |~~ train@41024  Loss: 0.002409 Acc: 13.2500\n",
      " |~~ train@41088  Loss: 0.002227 Acc: 13.4219\n",
      " |~~ train@41152  Loss: 0.002393 Acc: 13.1562\n",
      " |~~ train@41216  Loss: 0.002479 Acc: 13.2344\n",
      " |~~ train@41280  Loss: 0.001828 Acc: 13.3594\n",
      " |~~ train@41344  Loss: 0.001752 Acc: 13.4688\n",
      " |~~ train@41408  Loss: 0.002285 Acc: 13.2344\n",
      " |~~ train@41472  Loss: 0.002163 Acc: 13.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@41536  Loss: 0.002763 Acc: 13.0781\n",
      " |~~ train@41600  Loss: 0.001794 Acc: 13.4531\n",
      " |~~ train@41664  Loss: 0.001868 Acc: 13.2500\n",
      " |~~ train@41728  Loss: 0.002561 Acc: 13.0625\n",
      " |~~ train@41792  Loss: 0.001935 Acc: 13.3750\n",
      " |~~ train@41856  Loss: 0.002494 Acc: 13.1719\n",
      " |~~ train@41920  Loss: 0.002099 Acc: 13.3281\n",
      " |~~ train@41984  Loss: 0.001987 Acc: 13.4375\n",
      " |~~ train@42048  Loss: 0.002039 Acc: 13.3281\n",
      " |~~ train@42112  Loss: 0.001357 Acc: 13.5781\n",
      " |~~ train@42176  Loss: 0.002101 Acc: 13.2969\n",
      " |~~ train@42240  Loss: 0.001948 Acc: 13.3438\n",
      " |~~ train@42304  Loss: 0.001636 Acc: 13.5625\n",
      " |~~ train@42368  Loss: 0.001834 Acc: 13.3906\n",
      " |~~ train@42432  Loss: 0.001646 Acc: 13.4375\n",
      " |~~ train@42496  Loss: 0.002178 Acc: 13.3594\n",
      " |~~ train@42560  Loss: 0.001751 Acc: 13.4688\n",
      " |~~ train@42624  Loss: 0.001902 Acc: 13.4531\n",
      " |~~ train@42688  Loss: 0.001495 Acc: 13.5625\n",
      " |~~ train@42752  Loss: 0.002322 Acc: 13.2500\n",
      " |~~ train@42816  Loss: 0.002558 Acc: 13.2188\n",
      " |~~ train@42880  Loss: 0.002485 Acc: 13.1250\n",
      " |~~ train@42944  Loss: 0.001886 Acc: 13.4219\n",
      " |~~ train@43008  Loss: 0.001828 Acc: 13.4062\n",
      " |~~ train@43072  Loss: 0.001597 Acc: 13.5000\n",
      " |~~ train@43136  Loss: 0.001692 Acc: 13.4688\n",
      " |~~ train@43200  Loss: 0.002017 Acc: 13.3438\n",
      " |~~ train@43264  Loss: 0.002315 Acc: 13.2500\n",
      " |~~ train@43328  Loss: 0.002121 Acc: 13.2969\n",
      " |~~ train@43392  Loss: 0.001778 Acc: 13.4688\n",
      " |~~ train@43456  Loss: 0.001887 Acc: 13.3906\n",
      " |~~ train@43520  Loss: 0.001938 Acc: 13.4062\n",
      " |~~ train@43584  Loss: 0.001637 Acc: 13.5000\n",
      " |~~ train@43648  Loss: 0.002135 Acc: 13.2188\n",
      " |~~ train@43712  Loss: 0.001963 Acc: 13.4219\n",
      " |~~ train@43776  Loss: 0.002397 Acc: 13.1875\n",
      " |~~ train@43840  Loss: 0.002106 Acc: 13.3750\n",
      " |~~ train@43904  Loss: 0.002244 Acc: 13.2031\n",
      " |~~ train@43968  Loss: 0.002051 Acc: 13.4062\n",
      " |~~ train@44032  Loss: 0.002375 Acc: 13.1875\n",
      " |~~ train@44096  Loss: 0.002049 Acc: 13.3281\n",
      " |~~ train@44160  Loss: 0.002754 Acc: 13.0938\n",
      " |~~ train@44224  Loss: 0.001515 Acc: 13.5625\n",
      " |~~ train@44288  Loss: 0.002431 Acc: 13.1562\n",
      " |~~ train@44352  Loss: 0.001877 Acc: 13.4219\n",
      " |~~ train@44416  Loss: 0.001901 Acc: 13.3906\n",
      " |~~ train@44480  Loss: 0.001710 Acc: 13.4531\n",
      " |~~ train@44544  Loss: 0.001590 Acc: 13.5312\n",
      " |~~ train@44608  Loss: 0.002300 Acc: 13.2344\n",
      " |~~ train@44672  Loss: 0.001711 Acc: 13.4375\n",
      " |~~ train@44736  Loss: 0.002067 Acc: 13.3125\n",
      " |~~ train@44800  Loss: 0.002016 Acc: 13.3906\n",
      " |~~ train@44864  Loss: 0.002412 Acc: 13.1875\n",
      " |~~ train@44928  Loss: 0.001581 Acc: 13.5625\n",
      " |~~ train@44992  Loss: 0.002202 Acc: 13.3281\n",
      " |~~ train@45056  Loss: 0.001642 Acc: 13.4844\n",
      " |~~ train@45120  Loss: 0.002029 Acc: 13.3906\n",
      " |~~ train@45184  Loss: 0.002060 Acc: 13.3594\n",
      " |~~ train@45248  Loss: 0.001901 Acc: 13.4062\n",
      " |~~ train@45312  Loss: 0.002555 Acc: 13.0625\n",
      " |~~ train@45376  Loss: 0.002105 Acc: 13.2969\n",
      " |~~ train@45440  Loss: 0.003012 Acc: 13.0312\n",
      " |~~ train@45504  Loss: 0.001809 Acc: 13.3594\n",
      " |~~ train@45568  Loss: 0.001752 Acc: 13.4688\n",
      " |~~ train@45632  Loss: 0.002106 Acc: 13.3281\n",
      " |~~ train@45696  Loss: 0.002133 Acc: 13.3438\n",
      " |~~ train@45760  Loss: 0.002265 Acc: 13.3125\n",
      " |~~ train@45824  Loss: 0.002249 Acc: 13.3594\n",
      " |~~ train@45888  Loss: 0.001792 Acc: 13.4688\n",
      " |~~ train@45952  Loss: 0.001713 Acc: 13.4688\n",
      " |~~ train@46016  Loss: 0.002008 Acc: 13.4062\n",
      " |~~ train@46080  Loss: 0.002257 Acc: 13.3281\n",
      " |~~ train@46144  Loss: 0.002036 Acc: 13.3125\n",
      " |~~ train@46208  Loss: 0.002117 Acc: 13.2656\n",
      " |~~ train@46272  Loss: 0.002464 Acc: 13.2812\n",
      " |~~ train@46336  Loss: 0.002100 Acc: 13.3125\n",
      " |~~ train@46400  Loss: 0.002773 Acc: 13.0938\n",
      " |~~ train@46464  Loss: 0.001929 Acc: 13.3438\n",
      " |~~ train@46528  Loss: 0.002409 Acc: 13.1562\n",
      " |~~ train@46592  Loss: 0.001639 Acc: 13.5156\n",
      " |~~ train@46656  Loss: 0.002355 Acc: 13.2031\n",
      " |~~ train@46720  Loss: 0.002403 Acc: 13.2812\n",
      " |~~ train@46784  Loss: 0.001744 Acc: 13.4688\n",
      " |~~ train@46848  Loss: 0.001763 Acc: 13.4375\n",
      " |~~ train@46912  Loss: 0.002282 Acc: 13.2969\n",
      " |~~ train@46976  Loss: 0.002028 Acc: 13.3906\n",
      " |~~ train@47040  Loss: 0.001942 Acc: 13.3750\n",
      " |~~ train@47104  Loss: 0.002170 Acc: 13.3125\n",
      " |~~ train@47168  Loss: 0.001724 Acc: 13.3906\n",
      " |~~ train@47232  Loss: 0.002048 Acc: 13.3125\n",
      " |~~ train@47296  Loss: 0.001793 Acc: 13.4062\n",
      " |~~ train@47360  Loss: 0.002011 Acc: 13.3906\n",
      " |~~ train@47424  Loss: 0.001616 Acc: 13.5000\n",
      " |~~ train@47488  Loss: 0.001802 Acc: 13.5156\n",
      " |~~ train@47552  Loss: 0.001897 Acc: 13.3438\n",
      " |~~ train@47616  Loss: 0.002089 Acc: 13.3281\n",
      " |~~ train@47680  Loss: 0.001910 Acc: 13.5312\n",
      " |~~ train@47744  Loss: 0.002683 Acc: 13.0625\n",
      " |~~ train@47808  Loss: 0.002023 Acc: 13.3125\n",
      " |~~ train@47872  Loss: 0.001812 Acc: 13.4062\n",
      " |~~ train@47936  Loss: 0.002086 Acc: 13.3281\n",
      " |~~ train@48000  Loss: 0.001797 Acc: 13.3750\n",
      " |~~ train@48064  Loss: 0.002055 Acc: 13.4375\n",
      " |~~ train@48128  Loss: 0.002231 Acc: 13.2344\n",
      " |~~ train@48192  Loss: 0.002155 Acc: 13.2188\n",
      " |~~ train@48256  Loss: 0.001927 Acc: 13.3906\n",
      " |~~ train@48320  Loss: 0.002243 Acc: 13.2500\n",
      " |~~ train@48384  Loss: 0.001733 Acc: 13.5156\n",
      " |~~ train@48448  Loss: 0.001666 Acc: 13.4688\n",
      " |~~ train@48512  Loss: 0.001940 Acc: 13.3438\n",
      " |~~ train@48576  Loss: 0.001377 Acc: 13.6406\n",
      " |~~ train@48640  Loss: 0.001630 Acc: 13.5625\n",
      " |~~ train@48704  Loss: 0.001798 Acc: 13.4062\n",
      " |~~ train@48768  Loss: 0.002408 Acc: 13.2812\n",
      " |~~ train@48832  Loss: 0.001687 Acc: 13.4531\n",
      " |~~ train@48896  Loss: 0.001941 Acc: 13.3438\n",
      " |~~ train@48960  Loss: 0.001939 Acc: 13.2656\n",
      " |~~ train@49024  Loss: 0.002065 Acc: 13.3438\n",
      " |~~ train@49088  Loss: 0.001920 Acc: 13.4062\n",
      " |~~ train@49152  Loss: 0.001594 Acc: 13.5469\n",
      " |~~ train@49216  Loss: 0.001953 Acc: 13.4531\n",
      " |~~ train@49280  Loss: 0.002264 Acc: 13.2656\n",
      " |~~ train@49344  Loss: 0.001902 Acc: 13.3594\n",
      " |~~ train@49408  Loss: 0.002364 Acc: 13.1719\n",
      " |~~ train@49472  Loss: 0.002234 Acc: 13.3125\n",
      " |~~ train@49536  Loss: 0.002003 Acc: 13.2812\n",
      " |~~ train@49600  Loss: 0.002256 Acc: 13.2500\n",
      " |~~ train@49664  Loss: 0.002475 Acc: 13.2188\n",
      " |~~ train@49728  Loss: 0.002386 Acc: 13.2812\n",
      " |~~ train@49792  Loss: 0.002109 Acc: 13.3438\n",
      " |~~ train@49856  Loss: 0.002069 Acc: 13.2969\n",
      " |~~ train@49920  Loss: 0.001890 Acc: 13.3594\n",
      " |~~ train@49984  Loss: 0.002220 Acc: 13.2812\n",
      " |~~ train@50048  Loss: 0.002443 Acc: 13.1875\n",
      " |~~ train@50112  Loss: 0.001861 Acc: 13.5312\n",
      " |~~ train@50176  Loss: 0.001740 Acc: 13.4688\n",
      " |~~ train@50240  Loss: 0.002370 Acc: 13.1719\n",
      " |~~ train@50304  Loss: 0.001346 Acc: 13.6250\n",
      " |~~ train@50368  Loss: 0.002333 Acc: 13.3750\n",
      " |~~ train@50432  Loss: 0.002510 Acc: 13.1406\n",
      " |~~ train@50496  Loss: 0.002123 Acc: 13.2500\n",
      " |~~ train@50560  Loss: 0.002579 Acc: 13.2188\n",
      " |~~ train@50624  Loss: 0.002114 Acc: 13.3594\n",
      " |~~ train@50688  Loss: 0.001849 Acc: 13.3438\n",
      " |~~ train@50752  Loss: 0.001815 Acc: 13.4219\n",
      " |~~ train@50816  Loss: 0.002560 Acc: 13.1250\n",
      " |~~ train@50880  Loss: 0.001840 Acc: 13.5312\n",
      " |~~ train@50944  Loss: 0.002402 Acc: 13.1094\n",
      " |~~ train@51008  Loss: 0.001710 Acc: 13.4062\n",
      " |~~ train@51072  Loss: 0.002116 Acc: 13.2656\n",
      " |~~ train@51136  Loss: 0.002269 Acc: 13.2812\n",
      " |~~ train@51200  Loss: 0.002001 Acc: 13.3906\n",
      " |~~ train@51264  Loss: 0.002555 Acc: 13.1094\n",
      " |~~ train@51328  Loss: 0.002281 Acc: 13.2812\n",
      " |~~ train@51392  Loss: 0.001864 Acc: 13.3594\n",
      " |~~ train@51456  Loss: 0.001789 Acc: 13.5312\n",
      " |~~ train@51520  Loss: 0.001892 Acc: 13.3750\n",
      " |~~ train@51584  Loss: 0.002030 Acc: 13.3906\n",
      " |~~ train@51648  Loss: 0.002845 Acc: 13.0938\n",
      " |~~ train@51712  Loss: 0.001819 Acc: 13.4531\n",
      " |~~ train@51776  Loss: 0.001945 Acc: 13.4375\n",
      " |~~ train@51840  Loss: 0.001735 Acc: 13.3594\n",
      " |~~ train@51904  Loss: 0.002199 Acc: 13.2656\n",
      " |~~ train@51968  Loss: 0.002460 Acc: 13.0938\n",
      " |~~ train@52032  Loss: 0.001824 Acc: 13.4531\n",
      " |~~ train@52096  Loss: 0.002155 Acc: 13.3750\n",
      " |~~ train@52160  Loss: 0.002284 Acc: 13.3125\n",
      " |~~ train@52224  Loss: 0.001961 Acc: 13.4062\n",
      " |~~ train@52288  Loss: 0.001773 Acc: 13.3438\n",
      " |~~ train@52352  Loss: 0.002023 Acc: 13.4062\n",
      " |~~ train@52416  Loss: 0.002118 Acc: 13.2031\n",
      " |~~ train@52480  Loss: 0.002639 Acc: 13.1094\n",
      " |~~ train@52544  Loss: 0.002086 Acc: 13.3594\n",
      " |~~ train@52608  Loss: 0.001566 Acc: 13.5156\n",
      " |~~ train@52672  Loss: 0.002431 Acc: 13.1250\n",
      " |~~ train@52736  Loss: 0.001632 Acc: 13.4844\n",
      " |~~ train@52800  Loss: 0.002195 Acc: 13.2656\n",
      " |~~ train@52864  Loss: 0.002111 Acc: 13.2812\n",
      " |~~ train@52928  Loss: 0.001861 Acc: 13.2969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@52992  Loss: 0.001965 Acc: 13.3438\n",
      " |~~ train@53056  Loss: 0.002600 Acc: 13.2344\n",
      " |~~ train@53120  Loss: 0.002363 Acc: 13.1875\n",
      " |~~ train@53184  Loss: 0.002116 Acc: 13.3438\n",
      " |~~ train@53248  Loss: 0.001895 Acc: 13.4062\n",
      " |~~ train@53312  Loss: 0.001857 Acc: 13.4375\n",
      " |~~ train@53376  Loss: 0.001987 Acc: 13.3906\n",
      " |~~ train@53440  Loss: 0.001946 Acc: 13.4531\n",
      " |~~ train@53504  Loss: 0.001802 Acc: 13.4844\n",
      " |~~ train@53568  Loss: 0.002408 Acc: 13.1875\n",
      " |~~ train@53632  Loss: 0.001621 Acc: 13.5000\n",
      " |~~ train@53696  Loss: 0.002041 Acc: 13.3438\n",
      " |~~ train@53760  Loss: 0.001992 Acc: 13.3125\n",
      " |~~ train@53824  Loss: 0.002162 Acc: 13.2656\n",
      " |~~ train@53888  Loss: 0.001660 Acc: 13.5000\n",
      " |~~ train@53952  Loss: 0.002204 Acc: 13.4062\n",
      " |~~ train@54016  Loss: 0.001979 Acc: 13.3750\n",
      " |~~ train@54080  Loss: 0.001912 Acc: 13.4219\n",
      " |~~ train@54144  Loss: 0.002524 Acc: 13.0781\n",
      " |~~ train@54208  Loss: 0.002150 Acc: 13.2188\n",
      " |~~ train@54272  Loss: 0.002492 Acc: 13.2969\n",
      " |~~ train@54336  Loss: 0.001987 Acc: 13.3906\n",
      " |~~ train@54400  Loss: 0.001749 Acc: 13.4688\n",
      " |~~ train@54464  Loss: 0.001813 Acc: 13.4531\n",
      " |~~ train@54528  Loss: 0.002168 Acc: 13.3281\n",
      " |~~ train@54592  Loss: 0.001723 Acc: 13.4844\n",
      " |~~ train@54656  Loss: 0.001961 Acc: 13.3594\n",
      " |~~ train@54720  Loss: 0.002013 Acc: 13.3906\n",
      " |~~ train@54784  Loss: 0.001629 Acc: 13.6562\n",
      " |~~ train@54848  Loss: 0.002061 Acc: 13.2500\n",
      " |~~ train@54912  Loss: 0.001908 Acc: 13.3750\n",
      " |~~ train@54976  Loss: 0.001895 Acc: 13.4219\n",
      " |~~ train@55040  Loss: 0.001946 Acc: 13.4688\n",
      " |~~ train@55104  Loss: 0.002174 Acc: 13.2500\n",
      " |~~ train@55168  Loss: 0.001749 Acc: 13.3906\n",
      " |~~ train@55232  Loss: 0.001855 Acc: 13.5000\n",
      " |~~ train@55296  Loss: 0.001750 Acc: 13.4531\n",
      " |~~ train@55360  Loss: 0.002178 Acc: 13.2344\n",
      " |~~ train@55424  Loss: 0.002347 Acc: 13.3125\n",
      " |~~ train@55488  Loss: 0.003138 Acc: 13.0000\n",
      " |~~ train@55552  Loss: 0.001857 Acc: 13.4531\n",
      " |~~ train@55616  Loss: 0.002147 Acc: 13.3281\n",
      " |~~ train@55680  Loss: 0.001852 Acc: 13.4219\n",
      " |~~ train@55744  Loss: 0.001600 Acc: 13.4688\n",
      " |~~ train@55808  Loss: 0.002049 Acc: 13.3125\n",
      " |~~ train@55872  Loss: 0.002287 Acc: 13.3281\n",
      " |~~ train@55936  Loss: 0.002583 Acc: 13.1562\n",
      " |~~ train@56000  Loss: 0.002149 Acc: 13.2656\n",
      " |~~ train@56064  Loss: 0.001784 Acc: 13.4688\n",
      " |~~ train@56128  Loss: 0.002065 Acc: 13.3125\n",
      " |~~ train@56192  Loss: 0.002251 Acc: 13.2500\n",
      " |~~ train@56256  Loss: 0.002611 Acc: 13.0938\n",
      " |~~ train@56320  Loss: 0.001780 Acc: 13.4375\n",
      " |~~ train@56384  Loss: 0.001976 Acc: 13.4062\n",
      " |~~ train@56448  Loss: 0.001948 Acc: 13.3281\n",
      " |~~ train@56512  Loss: 0.002171 Acc: 13.3125\n",
      " |~~ train@56576  Loss: 0.002198 Acc: 13.2812\n",
      " |~~ train@56640  Loss: 0.002179 Acc: 13.3281\n",
      " |~~ train@56704  Loss: 0.002254 Acc: 13.2969\n",
      " |~~ train@56768  Loss: 0.002644 Acc: 13.1562\n",
      " |~~ train@56832  Loss: 0.001887 Acc: 13.4844\n",
      " |~~ train@56896  Loss: 0.001883 Acc: 13.3750\n",
      " |~~ train@56960  Loss: 0.002214 Acc: 13.3594\n",
      " |~~ train@57024  Loss: 0.002742 Acc: 13.0625\n",
      " |~~ train@57088  Loss: 0.001509 Acc: 13.5469\n",
      " |~~ train@57152  Loss: 0.001977 Acc: 13.4375\n",
      " |~~ train@57216  Loss: 0.002324 Acc: 13.1250\n",
      " |~~ train@57280  Loss: 0.002059 Acc: 13.2812\n",
      " |~~ train@57344  Loss: 0.001699 Acc: 13.4688\n",
      " |~~ train@57408  Loss: 0.002105 Acc: 13.2969\n",
      " |~~ train@57472  Loss: 0.001918 Acc: 13.4375\n",
      " |~~ train@57536  Loss: 0.002308 Acc: 13.2188\n",
      " |~~ train@57600  Loss: 0.002464 Acc: 13.2344\n",
      " |~~ train@57664  Loss: 0.001767 Acc: 13.4844\n",
      " |~~ train@57728  Loss: 0.002080 Acc: 13.3594\n",
      " |~~ train@57792  Loss: 0.001657 Acc: 13.4844\n",
      " |~~ train@57856  Loss: 0.001818 Acc: 13.5156\n",
      " |~~ train@57920  Loss: 0.002115 Acc: 13.2656\n",
      " |~~ train@57984  Loss: 0.001712 Acc: 13.4531\n",
      " |~~ train@58048  Loss: 0.002321 Acc: 13.1719\n",
      " |~~ train@58112  Loss: 0.002040 Acc: 13.5000\n",
      " |~~ train@58176  Loss: 0.001740 Acc: 13.4531\n",
      " |~~ train@58240  Loss: 0.001632 Acc: 13.5156\n",
      " |~~ train@58304  Loss: 0.002390 Acc: 13.2031\n",
      " |~~ train@58368  Loss: 0.002166 Acc: 13.3281\n",
      " |~~ train@58432  Loss: 0.002289 Acc: 13.2656\n",
      " |~~ train@58496  Loss: 0.001956 Acc: 13.3125\n",
      " |~~ train@58560  Loss: 0.001867 Acc: 13.4062\n",
      " |~~ train@58624  Loss: 0.002016 Acc: 13.3750\n",
      " |~~ train@58688  Loss: 0.002311 Acc: 13.3125\n",
      " |~~ train@58752  Loss: 0.001857 Acc: 13.4062\n",
      " |~~ train@58816  Loss: 0.002140 Acc: 13.3594\n",
      " |~~ train@58880  Loss: 0.002533 Acc: 13.1719\n",
      " |~~ train@58944  Loss: 0.002107 Acc: 13.3438\n",
      " |~~ train@59008  Loss: 0.002177 Acc: 13.2812\n",
      " |~~ train@59072  Loss: 0.002152 Acc: 13.2500\n",
      " |~~ train@59136  Loss: 0.002390 Acc: 13.2344\n",
      " |~~ train@59200  Loss: 0.002242 Acc: 13.1250\n",
      " |~~ train@59264  Loss: 0.002253 Acc: 13.3438\n",
      " |~~ train@59328  Loss: 0.002136 Acc: 13.2188\n",
      " |~~ train@59392  Loss: 0.002319 Acc: 13.2344\n",
      " |~~ train@59456  Loss: 0.001935 Acc: 13.4531\n",
      " |~~ train@59520  Loss: 0.001993 Acc: 13.2969\n",
      " |~~ train@59584  Loss: 0.002566 Acc: 13.1094\n",
      " |~~ train@59648  Loss: 0.002615 Acc: 13.2188\n",
      " |~~ train@59712  Loss: 0.002060 Acc: 13.2344\n",
      " |~~ train@59776  Loss: 0.001837 Acc: 13.4688\n",
      " |~~ train@59840  Loss: 0.002107 Acc: 13.3281\n",
      " |~~ train@59904  Loss: 0.001817 Acc: 13.5625\n",
      " |~~ train@59968  Loss: 0.001968 Acc: 13.3438\n",
      " |~~ train@60032  Loss: 0.002129 Acc: 13.2812\n",
      " |~~ train@60096  Loss: 0.002233 Acc: 13.3125\n",
      " |~~ train@60160  Loss: 0.002442 Acc: 13.2969\n",
      " |~~ train@60224  Loss: 0.002740 Acc: 13.0781\n",
      " |~~ train@60288  Loss: 0.002115 Acc: 13.3594\n",
      " |~~ train@60352  Loss: 0.002026 Acc: 13.3438\n",
      " |~~ train@60416  Loss: 0.002023 Acc: 13.3594\n",
      " |~~ train@60480  Loss: 0.002198 Acc: 13.2969\n",
      " |~~ train@60544  Loss: 0.001702 Acc: 13.4219\n",
      " |~~ train@60608  Loss: 0.001770 Acc: 13.4531\n",
      " |~~ train@60672  Loss: 0.001888 Acc: 13.4219\n",
      " |~~ train@60736  Loss: 0.001859 Acc: 13.4062\n",
      " |~~ train@60800  Loss: 0.001977 Acc: 13.3281\n",
      " |~~ train@60864  Loss: 0.001646 Acc: 13.5156\n",
      " |~~ train@60928  Loss: 0.001855 Acc: 13.4375\n",
      " |~~ train@60992  Loss: 0.002655 Acc: 13.1406\n",
      " |~~ train@61056  Loss: 0.002165 Acc: 13.2812\n",
      " |~~ train@61120  Loss: 0.001911 Acc: 13.4219\n",
      " |~~ train@61184  Loss: 0.002328 Acc: 13.0938\n",
      " |~~ train@61248  Loss: 0.002257 Acc: 13.2656\n",
      " |~~ train@61312  Loss: 0.002411 Acc: 13.1875\n",
      " |~~ train@61376  Loss: 0.001987 Acc: 13.3906\n",
      " |~~ train@61440  Loss: 0.001950 Acc: 13.2812\n",
      " |~~ train@61504  Loss: 0.001705 Acc: 13.3594\n",
      " |~~ train@61568  Loss: 0.002490 Acc: 13.1875\n",
      " |~~ train@61632  Loss: 0.002325 Acc: 13.3125\n",
      " |~~ train@61696  Loss: 0.002307 Acc: 13.2812\n",
      " |~~ train@61760  Loss: 0.001416 Acc: 13.6094\n",
      " |~~ train@61824  Loss: 0.001597 Acc: 13.5156\n",
      " |~~ train@61888  Loss: 0.002105 Acc: 13.3438\n",
      " |~~ train@61952  Loss: 0.002320 Acc: 13.1719\n",
      " |~~ train@62016  Loss: 0.002192 Acc: 13.3281\n",
      " |~~ train@62080  Loss: 0.002325 Acc: 13.2500\n",
      " |~~ train@62144  Loss: 0.002168 Acc: 13.3125\n",
      " |~~ train@62208  Loss: 0.002367 Acc: 13.1875\n",
      " |~~ train@62272  Loss: 0.002021 Acc: 13.4844\n",
      " |~~ train@62336  Loss: 0.001887 Acc: 13.4062\n",
      " |~~ train@62400  Loss: 0.001793 Acc: 13.3281\n",
      " |~~ train@62464  Loss: 0.002091 Acc: 13.3906\n",
      " |~~ train@62528  Loss: 0.002095 Acc: 13.2656\n",
      " |~~ train@62592  Loss: 0.002399 Acc: 13.1719\n",
      " |~~ train@62656  Loss: 0.002266 Acc: 13.3281\n",
      " |~~ train@62720  Loss: 0.001745 Acc: 13.5469\n",
      " |~~ train@62784  Loss: 0.002049 Acc: 13.3281\n",
      " |~~ train@62848  Loss: 0.001897 Acc: 13.3750\n",
      " |~~ train@62912  Loss: 0.001860 Acc: 13.3594\n",
      " |~~ train@62976  Loss: 0.002176 Acc: 13.3594\n",
      " |~~ train@63040  Loss: 0.002176 Acc: 13.3281\n",
      " |~~ train@63104  Loss: 0.001675 Acc: 13.3906\n",
      " |~~ train@63168  Loss: 0.001646 Acc: 13.4844\n",
      " |~~ train@63232  Loss: 0.001648 Acc: 13.5469\n",
      " |~~ train@63296  Loss: 0.001995 Acc: 13.3281\n",
      " |~~ train@63360  Loss: 0.001948 Acc: 13.3750\n",
      " |~~ train@63424  Loss: 0.001968 Acc: 13.2656\n",
      " |~~ train@63488  Loss: 0.001612 Acc: 13.4375\n",
      " |~~ train@63552  Loss: 0.001655 Acc: 13.5781\n",
      " |~~ train@63616  Loss: 0.001916 Acc: 13.3438\n",
      " |~~ train@63680  Loss: 0.002046 Acc: 13.3594\n",
      " |~~ train@63744  Loss: 0.002154 Acc: 13.3125\n",
      " |~~ train@63808  Loss: 0.001853 Acc: 13.5156\n",
      " |~~ train@63872  Loss: 0.002350 Acc: 13.1250\n",
      " |~~ train@63936  Loss: 0.001775 Acc: 13.4531\n",
      " |~~ train@64000  Loss: 0.002076 Acc: 13.3125\n",
      " |~~ train@64064  Loss: 0.002568 Acc: 13.1875\n",
      " |~~ train@64128  Loss: 0.002328 Acc: 13.2500\n",
      " |~~ train@64192  Loss: 0.001903 Acc: 13.3281\n",
      " |~~ train@64256  Loss: 0.002623 Acc: 13.1094\n",
      " |~~ train@64320  Loss: 0.002045 Acc: 13.4375\n",
      " |~~ train@64384  Loss: 0.002520 Acc: 13.1406\n",
      " |~~ train@64448  Loss: 0.001969 Acc: 13.3906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@64512  Loss: 0.002132 Acc: 13.2656\n",
      " |~~ train@64576  Loss: 0.001667 Acc: 13.5469\n",
      " |~~ train@64640  Loss: 0.002243 Acc: 13.2031\n",
      " |~~ train@64704  Loss: 0.002043 Acc: 13.3281\n",
      " |~~ train@64768  Loss: 0.002319 Acc: 13.2188\n",
      " |~~ train@64832  Loss: 0.002244 Acc: 13.2656\n",
      " |~~ train@64896  Loss: 0.002244 Acc: 13.3125\n",
      " |~~ train@64960  Loss: 0.001734 Acc: 13.3906\n",
      " |~~ train@65024  Loss: 0.002149 Acc: 13.2656\n",
      " |~~ train@65088  Loss: 0.002470 Acc: 13.2344\n",
      " |~~ train@65152  Loss: 0.001816 Acc: 13.3594\n",
      " |~~ train@65216  Loss: 0.001898 Acc: 13.3750\n",
      " |~~ train@65280  Loss: 0.002117 Acc: 13.2188\n",
      " |~~ train@65344  Loss: 0.002718 Acc: 13.0625\n",
      " |~~ train@65408  Loss: 0.002099 Acc: 13.2500\n",
      " |~~ train@65472  Loss: 0.001813 Acc: 13.4375\n",
      " |~~ train@65536  Loss: 0.002771 Acc: 13.0000\n",
      " |~~ train@65600  Loss: 0.001833 Acc: 13.4062\n",
      " |~~ train@65664  Loss: 0.002232 Acc: 13.2500\n",
      " |~~ train@65728  Loss: 0.001953 Acc: 13.4062\n",
      " |~~ train@65792  Loss: 0.002735 Acc: 13.1250\n",
      " |~~ train@65856  Loss: 0.002226 Acc: 13.2500\n",
      " |~~ train@65920  Loss: 0.002461 Acc: 13.1875\n",
      " |~~ train@65984  Loss: 0.001580 Acc: 13.5312\n",
      " |~~ train@66048  Loss: 0.001948 Acc: 13.3906\n",
      " |~~ train@66112  Loss: 0.001767 Acc: 13.4375\n",
      " |~~ train@66176  Loss: 0.001923 Acc: 13.4375\n",
      " |~~ train@66240  Loss: 0.002104 Acc: 13.3750\n",
      " |~~ train@66304  Loss: 0.001983 Acc: 13.3281\n",
      " |~~ train@66368  Loss: 0.001648 Acc: 13.5625\n",
      " |~~ train@66432  Loss: 0.001835 Acc: 13.4062\n",
      " |~~ train@66496  Loss: 0.002267 Acc: 13.2656\n",
      " |~~ train@66560  Loss: 0.002011 Acc: 13.3594\n",
      " |~~ train@66624  Loss: 0.002297 Acc: 13.2969\n",
      " |~~ train@66688  Loss: 0.002014 Acc: 13.4219\n",
      " |~~ train@66752  Loss: 0.002035 Acc: 13.4062\n",
      " |~~ train@66816  Loss: 0.001447 Acc: 13.6719\n",
      " |~~ train@66880  Loss: 0.002211 Acc: 13.1875\n",
      " |~~ train@66944  Loss: 0.002724 Acc: 13.1250\n",
      " |~~ train@67008  Loss: 0.002094 Acc: 13.3594\n",
      " |~~ train@67072  Loss: 0.002188 Acc: 13.2656\n",
      " |~~ train@67136  Loss: 0.002512 Acc: 13.2656\n",
      " |~~ train@67200  Loss: 0.001939 Acc: 13.3750\n",
      " |~~ train@67264  Loss: 0.002324 Acc: 13.1562\n",
      " |~~ train@67328  Loss: 0.002399 Acc: 13.1406\n",
      " |~~ train@67392  Loss: 0.002126 Acc: 13.2656\n",
      " |~~ train@67456  Loss: 0.001802 Acc: 13.4531\n",
      " |~~ train@67520  Loss: 0.002034 Acc: 13.4688\n",
      " |~~ train@67584  Loss: 0.002141 Acc: 13.3281\n",
      " |~~ train@67648  Loss: 0.001612 Acc: 13.4375\n",
      " |~~ train@67712  Loss: 0.002271 Acc: 13.1719\n",
      " |~~ train@67776  Loss: 0.001605 Acc: 13.5000\n",
      " |~~ train@67840  Loss: 0.002012 Acc: 13.4219\n",
      " |~~ train@67904  Loss: 0.002412 Acc: 13.3594\n",
      " |~~ train@67968  Loss: 0.001858 Acc: 13.3906\n",
      " |~~ train@68032  Loss: 0.002129 Acc: 13.2969\n",
      " |~~ train@68096  Loss: 0.002188 Acc: 13.3281\n",
      " |~~ train@68160  Loss: 0.001808 Acc: 13.3750\n",
      " |~~ train@68224  Loss: 0.002028 Acc: 13.2969\n",
      " |~~ train@68288  Loss: 0.002484 Acc: 13.2500\n",
      " |~~ train@68352  Loss: 0.002026 Acc: 13.3438\n",
      " |~~ train@68416  Loss: 0.001728 Acc: 13.4375\n",
      " |~~ train@68480  Loss: 0.002137 Acc: 13.3438\n",
      " |~~ train@68544  Loss: 0.002043 Acc: 13.2656\n",
      " |~~ train@68608  Loss: 0.002553 Acc: 13.1719\n",
      " |~~ train@68672  Loss: 0.002104 Acc: 13.3594\n",
      " |~~ train@68736  Loss: 0.002009 Acc: 13.4375\n",
      " |~~ train@68800  Loss: 0.002529 Acc: 13.1094\n",
      " |~~ train@68864  Loss: 0.002399 Acc: 13.2500\n",
      " |~~ train@68928  Loss: 0.002011 Acc: 13.3125\n",
      " |~~ train@68992  Loss: 0.001695 Acc: 13.4219\n",
      " |~~ train@69056  Loss: 0.001629 Acc: 13.4375\n",
      " |~~ train@69120  Loss: 0.002104 Acc: 13.3438\n",
      " |~~ train@69184  Loss: 0.001668 Acc: 13.4844\n",
      " |~~ train@69248  Loss: 0.002004 Acc: 13.2812\n",
      " |~~ train@69312  Loss: 0.001976 Acc: 13.3594\n",
      " |~~ train@69376  Loss: 0.002054 Acc: 13.3594\n",
      " |~~ train@69440  Loss: 0.001886 Acc: 13.2969\n",
      " |~~ train@69504  Loss: 0.002094 Acc: 13.2344\n",
      " |~~ train@69568  Loss: 0.002588 Acc: 13.1406\n",
      " |~~ train@69632  Loss: 0.002532 Acc: 13.2188\n",
      " |~~ train@69696  Loss: 0.001992 Acc: 13.3594\n",
      " |~~ train@69760  Loss: 0.002180 Acc: 13.3125\n",
      " |~~ train@69824  Loss: 0.002036 Acc: 13.3125\n",
      " |~~ train@69888  Loss: 0.001767 Acc: 13.4062\n",
      " |~~ train@69952  Loss: 0.002106 Acc: 13.2344\n",
      " |~~ train@70016  Loss: 0.001927 Acc: 13.3906\n",
      " |~~ train@70080  Loss: 0.002346 Acc: 13.2344\n",
      " |~~ train@70144  Loss: 0.002485 Acc: 13.1562\n",
      " |~~ train@70208  Loss: 0.002216 Acc: 13.2344\n",
      " |~~ train@70272  Loss: 0.001700 Acc: 13.5156\n",
      " |~~ train@70336  Loss: 0.002175 Acc: 13.3281\n",
      " |~~ train@70400  Loss: 0.002218 Acc: 13.2344\n",
      " |~~ train@70464  Loss: 0.001548 Acc: 13.6406\n",
      " |~~ train@70528  Loss: 0.001990 Acc: 13.3906\n",
      " |~~ train@70592  Loss: 0.001800 Acc: 13.4375\n",
      " |~~ train@70656  Loss: 0.001875 Acc: 13.3281\n",
      " |~~ train@70720  Loss: 0.002081 Acc: 13.3438\n",
      " |~~ train@70784  Loss: 0.002084 Acc: 13.3594\n",
      " |~~ train@70848  Loss: 0.002191 Acc: 13.2500\n",
      " |~~ train@70912  Loss: 0.002389 Acc: 13.1719\n",
      " |~~ train@70976  Loss: 0.001902 Acc: 13.4062\n",
      " |~~ train@71040  Loss: 0.002066 Acc: 13.3750\n",
      " |~~ train@71104  Loss: 0.001771 Acc: 13.4531\n",
      " |~~ train@71168  Loss: 0.002561 Acc: 13.1562\n",
      " |~~ train@71232  Loss: 0.001814 Acc: 13.3906\n",
      " |~~ train@71296  Loss: 0.002414 Acc: 13.1562\n",
      " |~~ train@71360  Loss: 0.001559 Acc: 13.5312\n",
      " |~~ train@71424  Loss: 0.001837 Acc: 13.4375\n",
      " |~~ train@71488  Loss: 0.001700 Acc: 13.5312\n",
      " |~~ train@71552  Loss: 0.002304 Acc: 13.2031\n",
      " |~~ train@71616  Loss: 0.002221 Acc: 13.2500\n",
      " |~~ train@71680  Loss: 0.001752 Acc: 13.5625\n",
      " |~~ train@71744  Loss: 0.001638 Acc: 13.4688\n",
      " |~~ train@71808  Loss: 0.002071 Acc: 13.3281\n",
      " |~~ train@71872  Loss: 0.002336 Acc: 13.2969\n",
      " |~~ train@71936  Loss: 0.001766 Acc: 13.4844\n",
      " |~~ train@72000  Loss: 0.002029 Acc: 13.3281\n",
      " |~~ train@72064  Loss: 0.001484 Acc: 13.4531\n",
      " |~~ train@72128  Loss: 0.002500 Acc: 13.1406\n",
      " |~~ train@72192  Loss: 0.002053 Acc: 13.4375\n",
      " |~~ train@72256  Loss: 0.001597 Acc: 13.5000\n",
      " |~~ train@72320  Loss: 0.002104 Acc: 13.3594\n",
      " |~~ train@72384  Loss: 0.001712 Acc: 13.4219\n",
      " |~~ train@72448  Loss: 0.002469 Acc: 13.2500\n",
      " |~~ train@72512  Loss: 0.001892 Acc: 13.4688\n",
      " |~~ train@72576  Loss: 0.002123 Acc: 13.2969\n",
      " |~~ train@72640  Loss: 0.002121 Acc: 13.2969\n",
      " |~~ train@72704  Loss: 0.001727 Acc: 13.3594\n",
      " |~~ train@72768  Loss: 0.001722 Acc: 13.5312\n",
      " |~~ train@72832  Loss: 0.002065 Acc: 13.3438\n",
      " |~~ train@72896  Loss: 0.002084 Acc: 13.3281\n",
      " |~~ train@72960  Loss: 0.002127 Acc: 13.3125\n",
      " |~~ train@73024  Loss: 0.002087 Acc: 13.2500\n",
      " |~~ train@73088  Loss: 0.002047 Acc: 13.3906\n",
      " |~~ train@73152  Loss: 0.002387 Acc: 13.2188\n",
      " |~~ train@73216  Loss: 0.002096 Acc: 13.3906\n",
      " |~~ train@73280  Loss: 0.001866 Acc: 13.3906\n",
      " |~~ train@73344  Loss: 0.001864 Acc: 13.3281\n",
      " |~~ train@73408  Loss: 0.001803 Acc: 13.3906\n",
      " |~~ train@73472  Loss: 0.001700 Acc: 13.4062\n",
      " |~~ train@73536  Loss: 0.001897 Acc: 13.3594\n",
      " |~~ train@73600  Loss: 0.002491 Acc: 13.2031\n",
      " |~~ train@73664  Loss: 0.001807 Acc: 13.3906\n",
      " |~~ train@73728  Loss: 0.002072 Acc: 13.3594\n",
      " |~~ train@73792  Loss: 0.002090 Acc: 13.2500\n",
      " |~~ train@73856  Loss: 0.001497 Acc: 13.5469\n",
      " |~~ train@73920  Loss: 0.001486 Acc: 13.5781\n",
      " |~~ train@73984  Loss: 0.001744 Acc: 13.3594\n",
      " |~~ train@74048  Loss: 0.002350 Acc: 13.1250\n",
      " |~~ train@74112  Loss: 0.001928 Acc: 13.3594\n",
      " |~~ train@74176  Loss: 0.001948 Acc: 13.3438\n",
      " |~~ train@74240  Loss: 0.001801 Acc: 13.4062\n",
      " |~~ train@74304  Loss: 0.001932 Acc: 13.2656\n",
      " |~~ train@74368  Loss: 0.001516 Acc: 13.5312\n",
      " |~~ train@74432  Loss: 0.001850 Acc: 13.4062\n",
      " |~~ train@74496  Loss: 0.002327 Acc: 13.2656\n",
      " |~~ train@74560  Loss: 0.001738 Acc: 13.5156\n",
      " |~~ train@74624  Loss: 0.001818 Acc: 13.4219\n",
      " |~~ train@74688  Loss: 0.002003 Acc: 13.2656\n",
      " |~~ train@74752  Loss: 0.001692 Acc: 13.4375\n",
      " |~~ train@74816  Loss: 0.002133 Acc: 13.3750\n",
      " |~~ train@74880  Loss: 0.002026 Acc: 13.3281\n",
      " |~~ train@74944  Loss: 0.002599 Acc: 13.1562\n",
      " |~~ train@75008  Loss: 0.001980 Acc: 13.4531\n",
      " |~~ train@75072  Loss: 0.002153 Acc: 13.3438\n",
      " |~~ train@75136  Loss: 0.002012 Acc: 13.4375\n",
      " |~~ train@75200  Loss: 0.002045 Acc: 13.3594\n",
      " |~~ train@75264  Loss: 0.002443 Acc: 13.1562\n",
      " |~~ train@75328  Loss: 0.002019 Acc: 13.3906\n",
      " |~~ train@75392  Loss: 0.002085 Acc: 13.2969\n",
      " |~~ train@75456  Loss: 0.001858 Acc: 13.4844\n",
      " |~~ train@75520  Loss: 0.002256 Acc: 13.2969\n",
      " |~~ train@75584  Loss: 0.002515 Acc: 13.1406\n",
      " |~~ train@75648  Loss: 0.001604 Acc: 13.5000\n",
      " |~~ train@75712  Loss: 0.001967 Acc: 13.3906\n",
      " |~~ train@75776  Loss: 0.001667 Acc: 13.5156\n",
      " |~~ train@75840  Loss: 0.001632 Acc: 13.5469\n",
      " |~~ train@75904  Loss: 0.002163 Acc: 13.3906\n",
      " |~~ train@75968  Loss: 0.002310 Acc: 13.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@76032  Loss: 0.001971 Acc: 13.3906\n",
      " |~~ train@76096  Loss: 0.002165 Acc: 13.2656\n",
      " |~~ train@76160  Loss: 0.001991 Acc: 13.3750\n",
      " |~~ train@76224  Loss: 0.002235 Acc: 13.2969\n",
      " |~~ train@76288  Loss: 0.002116 Acc: 13.2969\n",
      " |~~ train@76352  Loss: 0.001917 Acc: 13.3750\n",
      " |~~ train@76416  Loss: 0.001877 Acc: 13.4688\n",
      " |~~ train@76480  Loss: 0.001847 Acc: 13.3750\n",
      " |~~ train@76544  Loss: 0.001858 Acc: 13.4688\n",
      " |~~ train@76608  Loss: 0.001970 Acc: 13.4219\n",
      " |~~ train@76672  Loss: 0.002047 Acc: 13.2969\n",
      " |~~ train@76736  Loss: 0.001668 Acc: 13.4688\n",
      " |~~ train@76800  Loss: 0.002408 Acc: 13.2500\n",
      " |~~ train@76864  Loss: 0.002204 Acc: 13.2969\n",
      " |~~ train@76928  Loss: 0.001849 Acc: 13.4062\n",
      " |~~ train@76992  Loss: 0.002075 Acc: 13.3594\n",
      " |~~ train@77056  Loss: 0.001950 Acc: 13.4531\n",
      " |~~ train@77120  Loss: 0.001971 Acc: 13.3438\n",
      " |~~ train@77184  Loss: 0.002162 Acc: 13.3281\n",
      " |~~ train@77248  Loss: 0.001650 Acc: 13.5000\n",
      " |~~ train@77312  Loss: 0.001819 Acc: 13.4062\n",
      " |~~ train@77376  Loss: 0.001977 Acc: 13.3594\n",
      " |~~ train@77440  Loss: 0.002386 Acc: 13.2031\n",
      " |~~ train@77504  Loss: 0.002151 Acc: 13.1875\n",
      " |~~ train@77568  Loss: 0.001568 Acc: 13.4844\n",
      " |~~ train@77632  Loss: 0.001911 Acc: 13.3594\n",
      " |~~ train@77696  Loss: 0.002208 Acc: 13.2656\n",
      " |~~ train@77760  Loss: 0.002414 Acc: 13.1562\n",
      " |~~ train@77824  Loss: 0.002167 Acc: 13.2500\n",
      " |~~ train@77888  Loss: 0.002517 Acc: 13.2344\n",
      " |~~ train@77952  Loss: 0.001702 Acc: 13.5156\n",
      " |~~ train@78016  Loss: 0.002062 Acc: 13.2812\n",
      " |~~ train@78080  Loss: 0.001978 Acc: 13.3750\n",
      " |~~ train@78144  Loss: 0.002046 Acc: 13.3594\n",
      " |~~ train@78208  Loss: 0.002099 Acc: 13.4062\n",
      " |~~ train@78272  Loss: 0.002260 Acc: 13.2344\n",
      " |~~ train@78336  Loss: 0.001905 Acc: 13.3281\n",
      " |~~ train@78400  Loss: 0.002260 Acc: 13.1719\n",
      " |~~ train@78464  Loss: 0.002258 Acc: 13.2812\n",
      " |~~ train@78484  Loss: 0.006113 Acc: 13.2000\n",
      "train  Loss: 0.002063 Acc: 13.3395\n",
      " |~~ val@64  Loss: 0.002508 Acc: 13.1406\n",
      " |~~ val@128  Loss: 0.002440 Acc: 13.2500\n",
      " |~~ val@192  Loss: 0.002500 Acc: 13.3125\n",
      " |~~ val@256  Loss: 0.002048 Acc: 13.3281\n",
      " |~~ val@320  Loss: 0.001666 Acc: 13.5000\n",
      " |~~ val@384  Loss: 0.002702 Acc: 13.2188\n",
      " |~~ val@448  Loss: 0.002358 Acc: 13.3594\n",
      " |~~ val@512  Loss: 0.002851 Acc: 13.1875\n",
      " |~~ val@576  Loss: 0.002312 Acc: 13.3438\n",
      " |~~ val@640  Loss: 0.002235 Acc: 13.2656\n",
      " |~~ val@704  Loss: 0.002361 Acc: 13.2812\n",
      " |~~ val@768  Loss: 0.002343 Acc: 13.3594\n",
      " |~~ val@832  Loss: 0.002640 Acc: 13.1250\n",
      " |~~ val@896  Loss: 0.002295 Acc: 13.3594\n",
      " |~~ val@960  Loss: 0.002242 Acc: 13.3906\n",
      " |~~ val@1024  Loss: 0.002132 Acc: 13.3594\n",
      " |~~ val@1088  Loss: 0.002042 Acc: 13.3594\n",
      " |~~ val@1152  Loss: 0.002471 Acc: 13.2812\n",
      " |~~ val@1216  Loss: 0.001938 Acc: 13.4219\n",
      " |~~ val@1280  Loss: 0.002701 Acc: 13.1562\n",
      " |~~ val@1344  Loss: 0.001930 Acc: 13.3438\n",
      " |~~ val@1408  Loss: 0.002596 Acc: 13.2969\n",
      " |~~ val@1472  Loss: 0.002271 Acc: 13.2344\n",
      " |~~ val@1536  Loss: 0.002330 Acc: 13.3125\n",
      " |~~ val@1600  Loss: 0.002651 Acc: 13.1719\n",
      " |~~ val@1664  Loss: 0.002664 Acc: 13.2188\n",
      " |~~ val@1728  Loss: 0.002353 Acc: 13.2188\n",
      " |~~ val@1792  Loss: 0.002396 Acc: 13.3281\n",
      " |~~ val@1856  Loss: 0.002363 Acc: 13.3438\n",
      " |~~ val@1920  Loss: 0.002559 Acc: 13.2031\n",
      " |~~ val@1984  Loss: 0.002140 Acc: 13.3438\n",
      " |~~ val@2048  Loss: 0.002389 Acc: 13.2188\n",
      " |~~ val@2112  Loss: 0.002337 Acc: 13.2500\n",
      " |~~ val@2176  Loss: 0.001865 Acc: 13.3594\n",
      " |~~ val@2240  Loss: 0.002598 Acc: 13.2812\n",
      " |~~ val@2304  Loss: 0.002492 Acc: 13.2344\n",
      " |~~ val@2368  Loss: 0.002051 Acc: 13.3750\n",
      " |~~ val@2432  Loss: 0.002376 Acc: 13.2656\n",
      " |~~ val@2496  Loss: 0.002431 Acc: 13.2500\n",
      " |~~ val@2560  Loss: 0.002649 Acc: 13.2188\n",
      " |~~ val@2624  Loss: 0.002164 Acc: 13.3750\n",
      " |~~ val@2688  Loss: 0.002632 Acc: 13.1094\n",
      " |~~ val@2752  Loss: 0.002780 Acc: 13.1719\n",
      " |~~ val@2816  Loss: 0.002066 Acc: 13.3594\n",
      " |~~ val@2880  Loss: 0.002349 Acc: 13.2500\n",
      " |~~ val@2944  Loss: 0.001944 Acc: 13.3750\n",
      " |~~ val@3008  Loss: 0.001985 Acc: 13.4219\n",
      " |~~ val@3072  Loss: 0.002659 Acc: 13.1875\n",
      " |~~ val@3136  Loss: 0.002562 Acc: 13.1250\n",
      " |~~ val@3200  Loss: 0.002149 Acc: 13.3438\n",
      " |~~ val@3264  Loss: 0.002012 Acc: 13.3906\n",
      " |~~ val@3328  Loss: 0.001869 Acc: 13.4531\n",
      " |~~ val@3392  Loss: 0.002536 Acc: 13.1719\n",
      " |~~ val@3456  Loss: 0.002766 Acc: 13.1250\n",
      " |~~ val@3520  Loss: 0.002548 Acc: 13.2969\n",
      " |~~ val@3584  Loss: 0.002049 Acc: 13.3750\n",
      " |~~ val@3648  Loss: 0.002432 Acc: 13.2344\n",
      " |~~ val@3712  Loss: 0.002238 Acc: 13.3281\n",
      " |~~ val@3776  Loss: 0.002623 Acc: 13.2031\n",
      " |~~ val@3840  Loss: 0.002195 Acc: 13.3438\n",
      " |~~ val@3904  Loss: 0.002072 Acc: 13.3906\n",
      " |~~ val@3968  Loss: 0.002988 Acc: 13.0781\n",
      " |~~ val@4032  Loss: 0.002702 Acc: 13.1250\n",
      " |~~ val@4096  Loss: 0.001890 Acc: 13.4531\n",
      " |~~ val@4160  Loss: 0.002428 Acc: 13.3281\n",
      " |~~ val@4224  Loss: 0.002385 Acc: 13.2812\n",
      " |~~ val@4288  Loss: 0.002696 Acc: 13.2031\n",
      " |~~ val@4352  Loss: 0.002389 Acc: 13.3438\n",
      " |~~ val@4416  Loss: 0.002726 Acc: 13.1094\n",
      " |~~ val@4480  Loss: 0.002244 Acc: 13.4219\n",
      " |~~ val@4544  Loss: 0.002085 Acc: 13.4219\n",
      " |~~ val@4608  Loss: 0.002297 Acc: 13.2656\n",
      " |~~ val@4672  Loss: 0.002422 Acc: 13.2656\n",
      " |~~ val@4736  Loss: 0.002700 Acc: 13.2031\n",
      " |~~ val@4800  Loss: 0.001721 Acc: 13.5469\n",
      " |~~ val@4864  Loss: 0.002214 Acc: 13.3750\n",
      " |~~ val@4928  Loss: 0.001684 Acc: 13.4688\n",
      " |~~ val@4992  Loss: 0.002526 Acc: 13.1406\n",
      " |~~ val@5056  Loss: 0.002671 Acc: 13.1875\n",
      " |~~ val@5120  Loss: 0.002262 Acc: 13.3594\n",
      " |~~ val@5184  Loss: 0.002110 Acc: 13.3594\n",
      " |~~ val@5248  Loss: 0.002367 Acc: 13.2188\n",
      " |~~ val@5312  Loss: 0.002245 Acc: 13.2656\n",
      " |~~ val@5376  Loss: 0.002448 Acc: 13.1719\n",
      " |~~ val@5440  Loss: 0.002318 Acc: 13.2031\n",
      " |~~ val@5504  Loss: 0.001921 Acc: 13.4219\n",
      " |~~ val@5568  Loss: 0.002519 Acc: 13.2812\n",
      " |~~ val@5632  Loss: 0.001828 Acc: 13.4375\n",
      " |~~ val@5696  Loss: 0.002128 Acc: 13.4219\n",
      " |~~ val@5760  Loss: 0.002534 Acc: 13.1875\n",
      " |~~ val@5824  Loss: 0.001977 Acc: 13.4375\n",
      " |~~ val@5888  Loss: 0.002399 Acc: 13.2344\n",
      " |~~ val@5952  Loss: 0.002817 Acc: 13.1562\n",
      " |~~ val@6016  Loss: 0.001747 Acc: 13.3438\n",
      " |~~ val@6080  Loss: 0.002342 Acc: 13.2812\n",
      " |~~ val@6144  Loss: 0.002853 Acc: 13.0625\n",
      " |~~ val@6208  Loss: 0.002987 Acc: 13.1094\n",
      " |~~ val@6272  Loss: 0.002263 Acc: 13.3125\n",
      " |~~ val@6336  Loss: 0.001984 Acc: 13.3750\n",
      " |~~ val@6400  Loss: 0.002627 Acc: 13.1719\n",
      " |~~ val@6464  Loss: 0.003153 Acc: 13.0312\n",
      " |~~ val@6528  Loss: 0.002014 Acc: 13.3750\n",
      " |~~ val@6592  Loss: 0.002205 Acc: 13.3906\n",
      " |~~ val@6656  Loss: 0.002806 Acc: 13.1562\n",
      " |~~ val@6720  Loss: 0.003099 Acc: 13.1094\n",
      " |~~ val@6784  Loss: 0.002071 Acc: 13.3750\n",
      " |~~ val@6848  Loss: 0.002379 Acc: 13.2344\n",
      " |~~ val@6912  Loss: 0.002105 Acc: 13.4062\n",
      " |~~ val@6976  Loss: 0.002270 Acc: 13.2188\n",
      " |~~ val@7040  Loss: 0.002052 Acc: 13.4062\n",
      " |~~ val@7104  Loss: 0.001923 Acc: 13.5000\n",
      " |~~ val@7168  Loss: 0.002647 Acc: 13.1875\n",
      " |~~ val@7232  Loss: 0.002124 Acc: 13.3906\n",
      " |~~ val@7296  Loss: 0.002037 Acc: 13.3438\n",
      " |~~ val@7360  Loss: 0.002108 Acc: 13.2812\n",
      " |~~ val@7424  Loss: 0.003177 Acc: 12.9688\n",
      " |~~ val@7488  Loss: 0.001790 Acc: 13.5312\n",
      " |~~ val@7552  Loss: 0.002501 Acc: 13.2500\n",
      " |~~ val@7616  Loss: 0.002146 Acc: 13.3125\n",
      " |~~ val@7680  Loss: 0.002138 Acc: 13.2500\n",
      " |~~ val@7744  Loss: 0.002700 Acc: 13.2188\n",
      " |~~ val@7808  Loss: 0.002364 Acc: 13.2500\n",
      " |~~ val@7872  Loss: 0.002663 Acc: 13.1719\n",
      " |~~ val@7936  Loss: 0.002737 Acc: 13.1719\n",
      " |~~ val@8000  Loss: 0.002385 Acc: 13.2812\n",
      " |~~ val@8064  Loss: 0.002146 Acc: 13.3281\n",
      " |~~ val@8128  Loss: 0.002376 Acc: 13.3125\n",
      " |~~ val@8192  Loss: 0.002399 Acc: 13.3281\n",
      " |~~ val@8256  Loss: 0.001751 Acc: 13.5312\n",
      " |~~ val@8320  Loss: 0.001793 Acc: 13.5156\n",
      " |~~ val@8384  Loss: 0.002183 Acc: 13.3281\n",
      " |~~ val@8448  Loss: 0.002371 Acc: 13.2344\n",
      " |~~ val@8512  Loss: 0.002550 Acc: 13.2812\n",
      " |~~ val@8576  Loss: 0.002114 Acc: 13.3438\n",
      " |~~ val@8640  Loss: 0.002059 Acc: 13.4062\n",
      " |~~ val@8704  Loss: 0.002308 Acc: 13.2500\n",
      " |~~ val@8768  Loss: 0.002492 Acc: 13.2812\n",
      " |~~ val@8832  Loss: 0.002324 Acc: 13.2344\n",
      " |~~ val@8896  Loss: 0.002837 Acc: 13.1406\n",
      " |~~ val@8960  Loss: 0.003543 Acc: 13.0625\n",
      " |~~ val@9024  Loss: 0.002419 Acc: 13.1875\n",
      " |~~ val@9088  Loss: 0.001972 Acc: 13.4531\n",
      " |~~ val@9152  Loss: 0.002216 Acc: 13.2812\n",
      " |~~ val@9216  Loss: 0.002463 Acc: 13.1875\n",
      " |~~ val@9280  Loss: 0.002151 Acc: 13.3125\n",
      " |~~ val@9344  Loss: 0.002588 Acc: 13.2344\n",
      " |~~ val@9408  Loss: 0.002420 Acc: 13.3125\n",
      " |~~ val@9472  Loss: 0.002477 Acc: 13.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@9536  Loss: 0.001921 Acc: 13.3906\n",
      " |~~ val@9600  Loss: 0.002821 Acc: 13.2500\n",
      " |~~ val@9664  Loss: 0.002850 Acc: 13.0781\n",
      " |~~ val@9728  Loss: 0.001909 Acc: 13.4688\n",
      " |~~ val@9792  Loss: 0.001932 Acc: 13.3594\n",
      " |~~ val@9856  Loss: 0.002158 Acc: 13.2812\n",
      " |~~ val@9920  Loss: 0.002259 Acc: 13.3438\n",
      " |~~ val@9984  Loss: 0.001773 Acc: 13.3594\n",
      " |~~ val@10048  Loss: 0.003266 Acc: 13.1406\n",
      " |~~ val@10112  Loss: 0.002113 Acc: 13.4062\n",
      " |~~ val@10176  Loss: 0.002430 Acc: 13.2344\n",
      " |~~ val@10240  Loss: 0.001873 Acc: 13.3281\n",
      " |~~ val@10304  Loss: 0.002436 Acc: 13.2812\n",
      " |~~ val@10368  Loss: 0.001903 Acc: 13.4844\n",
      " |~~ val@10432  Loss: 0.002092 Acc: 13.3750\n",
      " |~~ val@10496  Loss: 0.002696 Acc: 13.2031\n",
      " |~~ val@10560  Loss: 0.002222 Acc: 13.3906\n",
      " |~~ val@10624  Loss: 0.002532 Acc: 13.2812\n",
      " |~~ val@10688  Loss: 0.002425 Acc: 13.3125\n",
      " |~~ val@10752  Loss: 0.002245 Acc: 13.3438\n",
      " |~~ val@10816  Loss: 0.002553 Acc: 13.1250\n",
      " |~~ val@10880  Loss: 0.002557 Acc: 13.1875\n",
      " |~~ val@10944  Loss: 0.002185 Acc: 13.3438\n",
      " |~~ val@11008  Loss: 0.002213 Acc: 13.2344\n",
      " |~~ val@11072  Loss: 0.002029 Acc: 13.3438\n",
      " |~~ val@11136  Loss: 0.002176 Acc: 13.3594\n",
      " |~~ val@11200  Loss: 0.002263 Acc: 13.3750\n",
      " |~~ val@11264  Loss: 0.002143 Acc: 13.3438\n",
      " |~~ val@11328  Loss: 0.002769 Acc: 13.2188\n",
      " |~~ val@11392  Loss: 0.001959 Acc: 13.3750\n",
      " |~~ val@11456  Loss: 0.001958 Acc: 13.3438\n",
      " |~~ val@11520  Loss: 0.002268 Acc: 13.2812\n",
      " |~~ val@11584  Loss: 0.002364 Acc: 13.2812\n",
      " |~~ val@11648  Loss: 0.002863 Acc: 13.1250\n",
      " |~~ val@11712  Loss: 0.001974 Acc: 13.3750\n",
      " |~~ val@11776  Loss: 0.002455 Acc: 13.2656\n",
      " |~~ val@11840  Loss: 0.002155 Acc: 13.3750\n",
      " |~~ val@11904  Loss: 0.002622 Acc: 13.2188\n",
      " |~~ val@11968  Loss: 0.002735 Acc: 13.1250\n",
      " |~~ val@12032  Loss: 0.002042 Acc: 13.2969\n",
      " |~~ val@12096  Loss: 0.001800 Acc: 13.5156\n",
      " |~~ val@12160  Loss: 0.002269 Acc: 13.3906\n",
      " |~~ val@12224  Loss: 0.002801 Acc: 13.2188\n",
      " |~~ val@12288  Loss: 0.002871 Acc: 13.1719\n",
      " |~~ val@12352  Loss: 0.002220 Acc: 13.3438\n",
      " |~~ val@12416  Loss: 0.002588 Acc: 13.2031\n",
      " |~~ val@12480  Loss: 0.002492 Acc: 13.1562\n",
      " |~~ val@12544  Loss: 0.002733 Acc: 13.2344\n",
      " |~~ val@12608  Loss: 0.002580 Acc: 13.2969\n",
      " |~~ val@12672  Loss: 0.002057 Acc: 13.3594\n",
      " |~~ val@12736  Loss: 0.002432 Acc: 13.2656\n",
      " |~~ val@12800  Loss: 0.002065 Acc: 13.4062\n",
      " |~~ val@12864  Loss: 0.002567 Acc: 13.1562\n",
      " |~~ val@12928  Loss: 0.002797 Acc: 13.0469\n",
      " |~~ val@12992  Loss: 0.002087 Acc: 13.3281\n",
      " |~~ val@13056  Loss: 0.002146 Acc: 13.4062\n",
      " |~~ val@13120  Loss: 0.002460 Acc: 13.2500\n",
      " |~~ val@13184  Loss: 0.002588 Acc: 13.2188\n",
      " |~~ val@13248  Loss: 0.001776 Acc: 13.4531\n",
      " |~~ val@13312  Loss: 0.001925 Acc: 13.4844\n",
      " |~~ val@13376  Loss: 0.002107 Acc: 13.4375\n",
      " |~~ val@13440  Loss: 0.002585 Acc: 13.2344\n",
      " |~~ val@13504  Loss: 0.002497 Acc: 13.2812\n",
      " |~~ val@13568  Loss: 0.002265 Acc: 13.4531\n",
      " |~~ val@13632  Loss: 0.001935 Acc: 13.3438\n",
      " |~~ val@13696  Loss: 0.002747 Acc: 13.2188\n",
      " |~~ val@13760  Loss: 0.002632 Acc: 13.2500\n",
      " |~~ val@13824  Loss: 0.002342 Acc: 13.2344\n",
      " |~~ val@13888  Loss: 0.002376 Acc: 13.3281\n",
      " |~~ val@13952  Loss: 0.002193 Acc: 13.2344\n",
      " |~~ val@14016  Loss: 0.002592 Acc: 13.2031\n",
      " |~~ val@14080  Loss: 0.002293 Acc: 13.3750\n",
      " |~~ val@14144  Loss: 0.002559 Acc: 13.1406\n",
      " |~~ val@14208  Loss: 0.002400 Acc: 13.1719\n",
      " |~~ val@14272  Loss: 0.002113 Acc: 13.4062\n",
      " |~~ val@14336  Loss: 0.002485 Acc: 13.2344\n",
      " |~~ val@14400  Loss: 0.001850 Acc: 13.5000\n",
      " |~~ val@14464  Loss: 0.002593 Acc: 13.2812\n",
      " |~~ val@14528  Loss: 0.002504 Acc: 13.2344\n",
      " |~~ val@14592  Loss: 0.002336 Acc: 13.2969\n",
      " |~~ val@14656  Loss: 0.001824 Acc: 13.4062\n",
      " |~~ val@14720  Loss: 0.002158 Acc: 13.2188\n",
      " |~~ val@14784  Loss: 0.002048 Acc: 13.4531\n",
      " |~~ val@14848  Loss: 0.002676 Acc: 13.2344\n",
      " |~~ val@14912  Loss: 0.002431 Acc: 13.2969\n",
      " |~~ val@14976  Loss: 0.001967 Acc: 13.3438\n",
      " |~~ val@15040  Loss: 0.002316 Acc: 13.2969\n",
      " |~~ val@15104  Loss: 0.002756 Acc: 13.1094\n",
      " |~~ val@15168  Loss: 0.002919 Acc: 13.2188\n",
      " |~~ val@15232  Loss: 0.002193 Acc: 13.4531\n",
      " |~~ val@15296  Loss: 0.002420 Acc: 13.3281\n",
      " |~~ val@15360  Loss: 0.002619 Acc: 13.2344\n",
      " |~~ val@15424  Loss: 0.002204 Acc: 13.2344\n",
      " |~~ val@15488  Loss: 0.002733 Acc: 13.0938\n",
      " |~~ val@15552  Loss: 0.002845 Acc: 13.2656\n",
      " |~~ val@15616  Loss: 0.002674 Acc: 13.2188\n",
      " |~~ val@15680  Loss: 0.003274 Acc: 12.8906\n",
      " |~~ val@15744  Loss: 0.002312 Acc: 13.2656\n",
      " |~~ val@15808  Loss: 0.002785 Acc: 13.0938\n",
      " |~~ val@15872  Loss: 0.002427 Acc: 13.3125\n",
      " |~~ val@15936  Loss: 0.002324 Acc: 13.3906\n",
      " |~~ val@16000  Loss: 0.002484 Acc: 13.2031\n",
      " |~~ val@16064  Loss: 0.002634 Acc: 13.1875\n",
      " |~~ val@16128  Loss: 0.001919 Acc: 13.4062\n",
      " |~~ val@16192  Loss: 0.002060 Acc: 13.3438\n",
      " |~~ val@16256  Loss: 0.002320 Acc: 13.2500\n",
      " |~~ val@16320  Loss: 0.001930 Acc: 13.4844\n",
      " |~~ val@16384  Loss: 0.002122 Acc: 13.3125\n",
      " |~~ val@16448  Loss: 0.002253 Acc: 13.2969\n",
      " |~~ val@16512  Loss: 0.002493 Acc: 13.2031\n",
      " |~~ val@16576  Loss: 0.002415 Acc: 13.2656\n",
      " |~~ val@16640  Loss: 0.002436 Acc: 13.2500\n",
      " |~~ val@16704  Loss: 0.002062 Acc: 13.4375\n",
      " |~~ val@16768  Loss: 0.002494 Acc: 13.3438\n",
      " |~~ val@16832  Loss: 0.002529 Acc: 13.2031\n",
      " |~~ val@16896  Loss: 0.002524 Acc: 13.2031\n",
      " |~~ val@16960  Loss: 0.002069 Acc: 13.3594\n",
      " |~~ val@17024  Loss: 0.002388 Acc: 13.2812\n",
      " |~~ val@17088  Loss: 0.002164 Acc: 13.4062\n",
      " |~~ val@17152  Loss: 0.001966 Acc: 13.2969\n",
      " |~~ val@17216  Loss: 0.002444 Acc: 13.3594\n",
      " |~~ val@17280  Loss: 0.002427 Acc: 13.2500\n",
      " |~~ val@17344  Loss: 0.002752 Acc: 13.0938\n",
      " |~~ val@17408  Loss: 0.002381 Acc: 13.3594\n",
      " |~~ val@17472  Loss: 0.002566 Acc: 13.2500\n",
      " |~~ val@17536  Loss: 0.001877 Acc: 13.4219\n",
      " |~~ val@17600  Loss: 0.002608 Acc: 13.2188\n",
      " |~~ val@17664  Loss: 0.002710 Acc: 13.0938\n",
      " |~~ val@17728  Loss: 0.002825 Acc: 13.1719\n",
      " |~~ val@17792  Loss: 0.001883 Acc: 13.4219\n",
      " |~~ val@17856  Loss: 0.002684 Acc: 13.2344\n",
      " |~~ val@17920  Loss: 0.001900 Acc: 13.4062\n",
      " |~~ val@17984  Loss: 0.002498 Acc: 13.2344\n",
      " |~~ val@18048  Loss: 0.001863 Acc: 13.5000\n",
      " |~~ val@18112  Loss: 0.003037 Acc: 13.0625\n",
      " |~~ val@18176  Loss: 0.002574 Acc: 13.1719\n",
      " |~~ val@18240  Loss: 0.002602 Acc: 13.2500\n",
      " |~~ val@18304  Loss: 0.002184 Acc: 13.2188\n",
      " |~~ val@18368  Loss: 0.002822 Acc: 13.1094\n",
      " |~~ val@18432  Loss: 0.002663 Acc: 13.2656\n",
      " |~~ val@18496  Loss: 0.002620 Acc: 13.2656\n",
      " |~~ val@18560  Loss: 0.002472 Acc: 13.2500\n",
      " |~~ val@18624  Loss: 0.002255 Acc: 13.4375\n",
      " |~~ val@18688  Loss: 0.001966 Acc: 13.3906\n",
      " |~~ val@18752  Loss: 0.002824 Acc: 13.1094\n",
      " |~~ val@18816  Loss: 0.002314 Acc: 13.2188\n",
      " |~~ val@18880  Loss: 0.002153 Acc: 13.4531\n",
      " |~~ val@18944  Loss: 0.002329 Acc: 13.3281\n",
      " |~~ val@19008  Loss: 0.002095 Acc: 13.3281\n",
      " |~~ val@19072  Loss: 0.002368 Acc: 13.3438\n",
      " |~~ val@19136  Loss: 0.002003 Acc: 13.4062\n",
      " |~~ val@19200  Loss: 0.002777 Acc: 13.2344\n",
      " |~~ val@19264  Loss: 0.001957 Acc: 13.3750\n",
      " |~~ val@19328  Loss: 0.002533 Acc: 13.3594\n",
      " |~~ val@19392  Loss: 0.002812 Acc: 13.1406\n",
      " |~~ val@19456  Loss: 0.002744 Acc: 13.1875\n",
      " |~~ val@19520  Loss: 0.002246 Acc: 13.2969\n",
      " |~~ val@19584  Loss: 0.002283 Acc: 13.4062\n",
      " |~~ val@19648  Loss: 0.002037 Acc: 13.3594\n",
      " |~~ val@19712  Loss: 0.002022 Acc: 13.4062\n",
      " |~~ val@19776  Loss: 0.002614 Acc: 13.2656\n",
      " |~~ val@19840  Loss: 0.002214 Acc: 13.3125\n",
      " |~~ val@19904  Loss: 0.002032 Acc: 13.3281\n",
      " |~~ val@19968  Loss: 0.002878 Acc: 13.1562\n",
      " |~~ val@20032  Loss: 0.002080 Acc: 13.2656\n",
      " |~~ val@20096  Loss: 0.002076 Acc: 13.3906\n",
      " |~~ val@20160  Loss: 0.002283 Acc: 13.2656\n",
      " |~~ val@20224  Loss: 0.002457 Acc: 13.1562\n",
      " |~~ val@20288  Loss: 0.002433 Acc: 13.3438\n",
      " |~~ val@20352  Loss: 0.002895 Acc: 13.0000\n",
      " |~~ val@20416  Loss: 0.002507 Acc: 13.2188\n",
      " |~~ val@20480  Loss: 0.002406 Acc: 13.2031\n",
      " |~~ val@20544  Loss: 0.002088 Acc: 13.4062\n",
      " |~~ val@20608  Loss: 0.002465 Acc: 13.3281\n",
      " |~~ val@20672  Loss: 0.002791 Acc: 13.1562\n",
      " |~~ val@20736  Loss: 0.002399 Acc: 13.2656\n",
      " |~~ val@20800  Loss: 0.002379 Acc: 13.2812\n",
      " |~~ val@20864  Loss: 0.002595 Acc: 13.1875\n",
      " |~~ val@20928  Loss: 0.002227 Acc: 13.3906\n",
      " |~~ val@20992  Loss: 0.002706 Acc: 13.2188\n",
      " |~~ val@21056  Loss: 0.002247 Acc: 13.2500\n",
      " |~~ val@21120  Loss: 0.002093 Acc: 13.3281\n",
      " |~~ val@21184  Loss: 0.002542 Acc: 13.2344\n",
      " |~~ val@21248  Loss: 0.002702 Acc: 13.2188\n",
      " |~~ val@21312  Loss: 0.002126 Acc: 13.3750\n",
      " |~~ val@21376  Loss: 0.002011 Acc: 13.3906\n",
      " |~~ val@21440  Loss: 0.001993 Acc: 13.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@21504  Loss: 0.002937 Acc: 13.0156\n",
      " |~~ val@21568  Loss: 0.002207 Acc: 13.3438\n",
      " |~~ val@21632  Loss: 0.002365 Acc: 13.2812\n",
      " |~~ val@21696  Loss: 0.002912 Acc: 13.1094\n",
      " |~~ val@21760  Loss: 0.002498 Acc: 13.1875\n",
      " |~~ val@21824  Loss: 0.002525 Acc: 13.2344\n",
      " |~~ val@21888  Loss: 0.002753 Acc: 13.0625\n",
      " |~~ val@21952  Loss: 0.002628 Acc: 13.1562\n",
      " |~~ val@22016  Loss: 0.002081 Acc: 13.3906\n",
      " |~~ val@22080  Loss: 0.002504 Acc: 13.2344\n",
      " |~~ val@22144  Loss: 0.002315 Acc: 13.3750\n",
      " |~~ val@22208  Loss: 0.002309 Acc: 13.4062\n",
      " |~~ val@22272  Loss: 0.002481 Acc: 13.2969\n",
      " |~~ val@22336  Loss: 0.002668 Acc: 13.1562\n",
      " |~~ val@22400  Loss: 0.001946 Acc: 13.5000\n",
      " |~~ val@22424  Loss: 0.005836 Acc: 13.4167\n",
      "val  Loss: 0.002367 Acc: 13.2841\n",
      "Epoch 6/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.002138 Acc: 13.2344\n",
      " |~~ train@128  Loss: 0.002291 Acc: 13.2656\n",
      " |~~ train@192  Loss: 0.001870 Acc: 13.4688\n",
      " |~~ train@256  Loss: 0.001922 Acc: 13.3594\n",
      " |~~ train@320  Loss: 0.002083 Acc: 13.3125\n",
      " |~~ train@384  Loss: 0.001645 Acc: 13.4688\n",
      " |~~ train@448  Loss: 0.001893 Acc: 13.4062\n",
      " |~~ train@512  Loss: 0.002759 Acc: 13.0625\n",
      " |~~ train@576  Loss: 0.001819 Acc: 13.4375\n",
      " |~~ train@640  Loss: 0.001960 Acc: 13.4531\n",
      " |~~ train@704  Loss: 0.001908 Acc: 13.3594\n",
      " |~~ train@768  Loss: 0.001875 Acc: 13.4375\n",
      " |~~ train@832  Loss: 0.002084 Acc: 13.2812\n",
      " |~~ train@896  Loss: 0.002165 Acc: 13.4062\n",
      " |~~ train@960  Loss: 0.002359 Acc: 13.1719\n",
      " |~~ train@1024  Loss: 0.002078 Acc: 13.2344\n",
      " |~~ train@1088  Loss: 0.002243 Acc: 13.2812\n",
      " |~~ train@1152  Loss: 0.002183 Acc: 13.3281\n",
      " |~~ train@1216  Loss: 0.001722 Acc: 13.3750\n",
      " |~~ train@1280  Loss: 0.002409 Acc: 13.2969\n",
      " |~~ train@1344  Loss: 0.002088 Acc: 13.3281\n",
      " |~~ train@1408  Loss: 0.001849 Acc: 13.4844\n",
      " |~~ train@1472  Loss: 0.001859 Acc: 13.4375\n",
      " |~~ train@1536  Loss: 0.001737 Acc: 13.5000\n",
      " |~~ train@1600  Loss: 0.001904 Acc: 13.4531\n",
      " |~~ train@1664  Loss: 0.001841 Acc: 13.4375\n",
      " |~~ train@1728  Loss: 0.001306 Acc: 13.5938\n",
      " |~~ train@1792  Loss: 0.002369 Acc: 13.2500\n",
      " |~~ train@1856  Loss: 0.002268 Acc: 13.1562\n",
      " |~~ train@1920  Loss: 0.002311 Acc: 13.2344\n",
      " |~~ train@1984  Loss: 0.001752 Acc: 13.5781\n",
      " |~~ train@2048  Loss: 0.002154 Acc: 13.2656\n",
      " |~~ train@2112  Loss: 0.002206 Acc: 13.2969\n",
      " |~~ train@2176  Loss: 0.002020 Acc: 13.3125\n",
      " |~~ train@2240  Loss: 0.002218 Acc: 13.2812\n",
      " |~~ train@2304  Loss: 0.002371 Acc: 13.2969\n",
      " |~~ train@2368  Loss: 0.001747 Acc: 13.3750\n",
      " |~~ train@2432  Loss: 0.002247 Acc: 13.2344\n",
      " |~~ train@2496  Loss: 0.002057 Acc: 13.4062\n",
      " |~~ train@2560  Loss: 0.002472 Acc: 13.2344\n",
      " |~~ train@2624  Loss: 0.002130 Acc: 13.2812\n",
      " |~~ train@2688  Loss: 0.001734 Acc: 13.4375\n",
      " |~~ train@2752  Loss: 0.002228 Acc: 13.2500\n",
      " |~~ train@2816  Loss: 0.001697 Acc: 13.5156\n",
      " |~~ train@2880  Loss: 0.002128 Acc: 13.4062\n",
      " |~~ train@2944  Loss: 0.001967 Acc: 13.3750\n",
      " |~~ train@3008  Loss: 0.001825 Acc: 13.3750\n",
      " |~~ train@3072  Loss: 0.001800 Acc: 13.4219\n",
      " |~~ train@3136  Loss: 0.002100 Acc: 13.3125\n",
      " |~~ train@3200  Loss: 0.002597 Acc: 13.1406\n",
      " |~~ train@3264  Loss: 0.002021 Acc: 13.3906\n",
      " |~~ train@3328  Loss: 0.002842 Acc: 13.0625\n",
      " |~~ train@3392  Loss: 0.002201 Acc: 13.4219\n",
      " |~~ train@3456  Loss: 0.002003 Acc: 13.3125\n",
      " |~~ train@3520  Loss: 0.001646 Acc: 13.4844\n",
      " |~~ train@3584  Loss: 0.001965 Acc: 13.2969\n",
      " |~~ train@3648  Loss: 0.001799 Acc: 13.4688\n",
      " |~~ train@3712  Loss: 0.002246 Acc: 13.2344\n",
      " |~~ train@3776  Loss: 0.001926 Acc: 13.3438\n",
      " |~~ train@3840  Loss: 0.002063 Acc: 13.2969\n",
      " |~~ train@3904  Loss: 0.002136 Acc: 13.2812\n",
      " |~~ train@3968  Loss: 0.001714 Acc: 13.4375\n",
      " |~~ train@4032  Loss: 0.002501 Acc: 13.2188\n",
      " |~~ train@4096  Loss: 0.001940 Acc: 13.3281\n",
      " |~~ train@4160  Loss: 0.002706 Acc: 13.0156\n",
      " |~~ train@4224  Loss: 0.001834 Acc: 13.4688\n",
      " |~~ train@4288  Loss: 0.001763 Acc: 13.3750\n",
      " |~~ train@4352  Loss: 0.002071 Acc: 13.3125\n",
      " |~~ train@4416  Loss: 0.001829 Acc: 13.3906\n",
      " |~~ train@4480  Loss: 0.002117 Acc: 13.3906\n",
      " |~~ train@4544  Loss: 0.001669 Acc: 13.4531\n",
      " |~~ train@4608  Loss: 0.001808 Acc: 13.5000\n",
      " |~~ train@4672  Loss: 0.002206 Acc: 13.3750\n",
      " |~~ train@4736  Loss: 0.002429 Acc: 13.2812\n",
      " |~~ train@4800  Loss: 0.001776 Acc: 13.4844\n",
      " |~~ train@4864  Loss: 0.002058 Acc: 13.3594\n",
      " |~~ train@4928  Loss: 0.002196 Acc: 13.2656\n",
      " |~~ train@4992  Loss: 0.001880 Acc: 13.3750\n",
      " |~~ train@5056  Loss: 0.002255 Acc: 13.2500\n",
      " |~~ train@5120  Loss: 0.002231 Acc: 13.2188\n",
      " |~~ train@5184  Loss: 0.001943 Acc: 13.3438\n",
      " |~~ train@5248  Loss: 0.001696 Acc: 13.5312\n",
      " |~~ train@5312  Loss: 0.002014 Acc: 13.3281\n",
      " |~~ train@5376  Loss: 0.002052 Acc: 13.3906\n",
      " |~~ train@5440  Loss: 0.002312 Acc: 13.3438\n",
      " |~~ train@5504  Loss: 0.002189 Acc: 13.2188\n",
      " |~~ train@5568  Loss: 0.002073 Acc: 13.3750\n",
      " |~~ train@5632  Loss: 0.001771 Acc: 13.4531\n",
      " |~~ train@5696  Loss: 0.002251 Acc: 13.2344\n",
      " |~~ train@5760  Loss: 0.002120 Acc: 13.3594\n",
      " |~~ train@5824  Loss: 0.002005 Acc: 13.4219\n",
      " |~~ train@5888  Loss: 0.002081 Acc: 13.3281\n",
      " |~~ train@5952  Loss: 0.001518 Acc: 13.5000\n",
      " |~~ train@6016  Loss: 0.002224 Acc: 13.3750\n",
      " |~~ train@6080  Loss: 0.001945 Acc: 13.2969\n",
      " |~~ train@6144  Loss: 0.002004 Acc: 13.3750\n",
      " |~~ train@6208  Loss: 0.001890 Acc: 13.3750\n",
      " |~~ train@6272  Loss: 0.001885 Acc: 13.3594\n",
      " |~~ train@6336  Loss: 0.002033 Acc: 13.3594\n",
      " |~~ train@6400  Loss: 0.001976 Acc: 13.3594\n",
      " |~~ train@6464  Loss: 0.001991 Acc: 13.3594\n",
      " |~~ train@6528  Loss: 0.002103 Acc: 13.2969\n",
      " |~~ train@6592  Loss: 0.002180 Acc: 13.2656\n",
      " |~~ train@6656  Loss: 0.002267 Acc: 13.2188\n",
      " |~~ train@6720  Loss: 0.002138 Acc: 13.2969\n",
      " |~~ train@6784  Loss: 0.001895 Acc: 13.3906\n",
      " |~~ train@6848  Loss: 0.002054 Acc: 13.2500\n",
      " |~~ train@6912  Loss: 0.001655 Acc: 13.4062\n",
      " |~~ train@6976  Loss: 0.001841 Acc: 13.4375\n",
      " |~~ train@7040  Loss: 0.001964 Acc: 13.3750\n",
      " |~~ train@7104  Loss: 0.002222 Acc: 13.2188\n",
      " |~~ train@7168  Loss: 0.002223 Acc: 13.2656\n",
      " |~~ train@7232  Loss: 0.001758 Acc: 13.4219\n",
      " |~~ train@7296  Loss: 0.002512 Acc: 13.1875\n",
      " |~~ train@7360  Loss: 0.001972 Acc: 13.2969\n",
      " |~~ train@7424  Loss: 0.001927 Acc: 13.3750\n",
      " |~~ train@7488  Loss: 0.002031 Acc: 13.3594\n",
      " |~~ train@7552  Loss: 0.001726 Acc: 13.5000\n",
      " |~~ train@7616  Loss: 0.001954 Acc: 13.5000\n",
      " |~~ train@7680  Loss: 0.001761 Acc: 13.5000\n",
      " |~~ train@7744  Loss: 0.002078 Acc: 13.3906\n",
      " |~~ train@7808  Loss: 0.001789 Acc: 13.4688\n",
      " |~~ train@7872  Loss: 0.001824 Acc: 13.4062\n",
      " |~~ train@7936  Loss: 0.002495 Acc: 13.1719\n",
      " |~~ train@8000  Loss: 0.001858 Acc: 13.3438\n",
      " |~~ train@8064  Loss: 0.002324 Acc: 13.2812\n",
      " |~~ train@8128  Loss: 0.002351 Acc: 13.2031\n",
      " |~~ train@8192  Loss: 0.002307 Acc: 13.2500\n",
      " |~~ train@8256  Loss: 0.001671 Acc: 13.4688\n",
      " |~~ train@8320  Loss: 0.002591 Acc: 13.1406\n",
      " |~~ train@8384  Loss: 0.002436 Acc: 13.2344\n",
      " |~~ train@8448  Loss: 0.001880 Acc: 13.3594\n",
      " |~~ train@8512  Loss: 0.002328 Acc: 13.3438\n",
      " |~~ train@8576  Loss: 0.001957 Acc: 13.3594\n",
      " |~~ train@8640  Loss: 0.001817 Acc: 13.4062\n",
      " |~~ train@8704  Loss: 0.001905 Acc: 13.4688\n",
      " |~~ train@8768  Loss: 0.001282 Acc: 13.5938\n",
      " |~~ train@8832  Loss: 0.001866 Acc: 13.3281\n",
      " |~~ train@8896  Loss: 0.001712 Acc: 13.4375\n",
      " |~~ train@8960  Loss: 0.002104 Acc: 13.3750\n",
      " |~~ train@9024  Loss: 0.001733 Acc: 13.4219\n",
      " |~~ train@9088  Loss: 0.002644 Acc: 13.1406\n",
      " |~~ train@9152  Loss: 0.002137 Acc: 13.3438\n",
      " |~~ train@9216  Loss: 0.002359 Acc: 13.2188\n",
      " |~~ train@9280  Loss: 0.002372 Acc: 13.1875\n",
      " |~~ train@9344  Loss: 0.001866 Acc: 13.4375\n",
      " |~~ train@9408  Loss: 0.002234 Acc: 13.2031\n",
      " |~~ train@9472  Loss: 0.001801 Acc: 13.4062\n",
      " |~~ train@9536  Loss: 0.001696 Acc: 13.4219\n",
      " |~~ train@9600  Loss: 0.002070 Acc: 13.2969\n",
      " |~~ train@9664  Loss: 0.002154 Acc: 13.2500\n",
      " |~~ train@9728  Loss: 0.001925 Acc: 13.4219\n",
      " |~~ train@9792  Loss: 0.002029 Acc: 13.2500\n",
      " |~~ train@9856  Loss: 0.002043 Acc: 13.3750\n",
      " |~~ train@9920  Loss: 0.001950 Acc: 13.4531\n",
      " |~~ train@9984  Loss: 0.002221 Acc: 13.3594\n",
      " |~~ train@10048  Loss: 0.002349 Acc: 13.1562\n",
      " |~~ train@10112  Loss: 0.002365 Acc: 13.1719\n",
      " |~~ train@10176  Loss: 0.001632 Acc: 13.5000\n",
      " |~~ train@10240  Loss: 0.002362 Acc: 13.2031\n",
      " |~~ train@10304  Loss: 0.001843 Acc: 13.4688\n",
      " |~~ train@10368  Loss: 0.002210 Acc: 13.2656\n",
      " |~~ train@10432  Loss: 0.001847 Acc: 13.4219\n",
      " |~~ train@10496  Loss: 0.002221 Acc: 13.2812\n",
      " |~~ train@10560  Loss: 0.002052 Acc: 13.3750\n",
      " |~~ train@10624  Loss: 0.001984 Acc: 13.3281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@10688  Loss: 0.002270 Acc: 13.1875\n",
      " |~~ train@10752  Loss: 0.002100 Acc: 13.3281\n",
      " |~~ train@10816  Loss: 0.002423 Acc: 13.1094\n",
      " |~~ train@10880  Loss: 0.001965 Acc: 13.3594\n",
      " |~~ train@10944  Loss: 0.001863 Acc: 13.4531\n",
      " |~~ train@11008  Loss: 0.001791 Acc: 13.4531\n",
      " |~~ train@11072  Loss: 0.002413 Acc: 13.2031\n",
      " |~~ train@11136  Loss: 0.002060 Acc: 13.4062\n",
      " |~~ train@11200  Loss: 0.001992 Acc: 13.3438\n",
      " |~~ train@11264  Loss: 0.002187 Acc: 13.3594\n",
      " |~~ train@11328  Loss: 0.002381 Acc: 13.2188\n",
      " |~~ train@11392  Loss: 0.002587 Acc: 13.2656\n",
      " |~~ train@11456  Loss: 0.002362 Acc: 13.2656\n",
      " |~~ train@11520  Loss: 0.002262 Acc: 13.2500\n",
      " |~~ train@11584  Loss: 0.001595 Acc: 13.4844\n",
      " |~~ train@11648  Loss: 0.002734 Acc: 13.1406\n",
      " |~~ train@11712  Loss: 0.001886 Acc: 13.4375\n",
      " |~~ train@11776  Loss: 0.002433 Acc: 13.3281\n",
      " |~~ train@11840  Loss: 0.002364 Acc: 13.2031\n",
      " |~~ train@11904  Loss: 0.002258 Acc: 13.2344\n",
      " |~~ train@11968  Loss: 0.001761 Acc: 13.4844\n",
      " |~~ train@12032  Loss: 0.001366 Acc: 13.6094\n",
      " |~~ train@12096  Loss: 0.002169 Acc: 13.3438\n",
      " |~~ train@12160  Loss: 0.002255 Acc: 13.2969\n",
      " |~~ train@12224  Loss: 0.002165 Acc: 13.2812\n",
      " |~~ train@12288  Loss: 0.002229 Acc: 13.1875\n",
      " |~~ train@12352  Loss: 0.002202 Acc: 13.2344\n",
      " |~~ train@12416  Loss: 0.001968 Acc: 13.4062\n",
      " |~~ train@12480  Loss: 0.001827 Acc: 13.4062\n",
      " |~~ train@12544  Loss: 0.001660 Acc: 13.5312\n",
      " |~~ train@12608  Loss: 0.001679 Acc: 13.4531\n",
      " |~~ train@12672  Loss: 0.002091 Acc: 13.3750\n",
      " |~~ train@12736  Loss: 0.002302 Acc: 13.1875\n",
      " |~~ train@12800  Loss: 0.001937 Acc: 13.3438\n",
      " |~~ train@12864  Loss: 0.001919 Acc: 13.4844\n",
      " |~~ train@12928  Loss: 0.002139 Acc: 13.3125\n",
      " |~~ train@12992  Loss: 0.001829 Acc: 13.3750\n",
      " |~~ train@13056  Loss: 0.002379 Acc: 13.2656\n",
      " |~~ train@13120  Loss: 0.001990 Acc: 13.2656\n",
      " |~~ train@13184  Loss: 0.001838 Acc: 13.4688\n",
      " |~~ train@13248  Loss: 0.002271 Acc: 13.3594\n",
      " |~~ train@13312  Loss: 0.001671 Acc: 13.4844\n",
      " |~~ train@13376  Loss: 0.001911 Acc: 13.2812\n",
      " |~~ train@13440  Loss: 0.002023 Acc: 13.3125\n",
      " |~~ train@13504  Loss: 0.001790 Acc: 13.5156\n",
      " |~~ train@13568  Loss: 0.001878 Acc: 13.3125\n",
      " |~~ train@13632  Loss: 0.001839 Acc: 13.3594\n",
      " |~~ train@13696  Loss: 0.001763 Acc: 13.4219\n",
      " |~~ train@13760  Loss: 0.001781 Acc: 13.5000\n",
      " |~~ train@13824  Loss: 0.002051 Acc: 13.3281\n",
      " |~~ train@13888  Loss: 0.002183 Acc: 13.2656\n",
      " |~~ train@13952  Loss: 0.001696 Acc: 13.5469\n",
      " |~~ train@14016  Loss: 0.001786 Acc: 13.3594\n",
      " |~~ train@14080  Loss: 0.001939 Acc: 13.3438\n",
      " |~~ train@14144  Loss: 0.002082 Acc: 13.3906\n",
      " |~~ train@14208  Loss: 0.001922 Acc: 13.3750\n",
      " |~~ train@14272  Loss: 0.002152 Acc: 13.2969\n",
      " |~~ train@14336  Loss: 0.002295 Acc: 13.3750\n",
      " |~~ train@14400  Loss: 0.001763 Acc: 13.4062\n",
      " |~~ train@14464  Loss: 0.002112 Acc: 13.3438\n",
      " |~~ train@14528  Loss: 0.001908 Acc: 13.4688\n",
      " |~~ train@14592  Loss: 0.001989 Acc: 13.3906\n",
      " |~~ train@14656  Loss: 0.001855 Acc: 13.3906\n",
      " |~~ train@14720  Loss: 0.002336 Acc: 13.2812\n",
      " |~~ train@14784  Loss: 0.002160 Acc: 13.2656\n",
      " |~~ train@14848  Loss: 0.002309 Acc: 13.2031\n",
      " |~~ train@14912  Loss: 0.001813 Acc: 13.4531\n",
      " |~~ train@14976  Loss: 0.002086 Acc: 13.3750\n",
      " |~~ train@15040  Loss: 0.002336 Acc: 13.2656\n",
      " |~~ train@15104  Loss: 0.002191 Acc: 13.2812\n",
      " |~~ train@15168  Loss: 0.002275 Acc: 13.2812\n",
      " |~~ train@15232  Loss: 0.002180 Acc: 13.3125\n",
      " |~~ train@15296  Loss: 0.002187 Acc: 13.3906\n",
      " |~~ train@15360  Loss: 0.002977 Acc: 12.9688\n",
      " |~~ train@15424  Loss: 0.002419 Acc: 13.1406\n",
      " |~~ train@15488  Loss: 0.001537 Acc: 13.6250\n",
      " |~~ train@15552  Loss: 0.001939 Acc: 13.4688\n",
      " |~~ train@15616  Loss: 0.001882 Acc: 13.3281\n",
      " |~~ train@15680  Loss: 0.002609 Acc: 13.1094\n",
      " |~~ train@15744  Loss: 0.002245 Acc: 13.3281\n",
      " |~~ train@15808  Loss: 0.002074 Acc: 13.3750\n",
      " |~~ train@15872  Loss: 0.002095 Acc: 13.3438\n",
      " |~~ train@15936  Loss: 0.001572 Acc: 13.5312\n",
      " |~~ train@16000  Loss: 0.002777 Acc: 13.1719\n",
      " |~~ train@16064  Loss: 0.001986 Acc: 13.3594\n",
      " |~~ train@16128  Loss: 0.001971 Acc: 13.3906\n",
      " |~~ train@16192  Loss: 0.002015 Acc: 13.3438\n",
      " |~~ train@16256  Loss: 0.001774 Acc: 13.4688\n",
      " |~~ train@16320  Loss: 0.001538 Acc: 13.5156\n",
      " |~~ train@16384  Loss: 0.001919 Acc: 13.3906\n",
      " |~~ train@16448  Loss: 0.002201 Acc: 13.2656\n",
      " |~~ train@16512  Loss: 0.002093 Acc: 13.2812\n",
      " |~~ train@16576  Loss: 0.001874 Acc: 13.4688\n",
      " |~~ train@16640  Loss: 0.002405 Acc: 13.2031\n",
      " |~~ train@16704  Loss: 0.001939 Acc: 13.4531\n",
      " |~~ train@16768  Loss: 0.001892 Acc: 13.3906\n",
      " |~~ train@16832  Loss: 0.001526 Acc: 13.5312\n",
      " |~~ train@16896  Loss: 0.002290 Acc: 13.2344\n",
      " |~~ train@16960  Loss: 0.002054 Acc: 13.2656\n",
      " |~~ train@17024  Loss: 0.001731 Acc: 13.5156\n",
      " |~~ train@17088  Loss: 0.002332 Acc: 13.2500\n",
      " |~~ train@17152  Loss: 0.001891 Acc: 13.3906\n",
      " |~~ train@17216  Loss: 0.001812 Acc: 13.4062\n",
      " |~~ train@17280  Loss: 0.001885 Acc: 13.3750\n",
      " |~~ train@17344  Loss: 0.001946 Acc: 13.3750\n",
      " |~~ train@17408  Loss: 0.002229 Acc: 13.2188\n",
      " |~~ train@17472  Loss: 0.002162 Acc: 13.3594\n",
      " |~~ train@17536  Loss: 0.001793 Acc: 13.4219\n",
      " |~~ train@17600  Loss: 0.001954 Acc: 13.3281\n",
      " |~~ train@17664  Loss: 0.002335 Acc: 13.1562\n",
      " |~~ train@17728  Loss: 0.001798 Acc: 13.4531\n",
      " |~~ train@17792  Loss: 0.002007 Acc: 13.3125\n",
      " |~~ train@17856  Loss: 0.001824 Acc: 13.5000\n",
      " |~~ train@17920  Loss: 0.001687 Acc: 13.5156\n",
      " |~~ train@17984  Loss: 0.001814 Acc: 13.4062\n",
      " |~~ train@18048  Loss: 0.002075 Acc: 13.2656\n",
      " |~~ train@18112  Loss: 0.002376 Acc: 13.2656\n",
      " |~~ train@18176  Loss: 0.002462 Acc: 13.1250\n",
      " |~~ train@18240  Loss: 0.002425 Acc: 13.1562\n",
      " |~~ train@18304  Loss: 0.002245 Acc: 13.2344\n",
      " |~~ train@18368  Loss: 0.002088 Acc: 13.4219\n",
      " |~~ train@18432  Loss: 0.001768 Acc: 13.5312\n",
      " |~~ train@18496  Loss: 0.002031 Acc: 13.2188\n",
      " |~~ train@18560  Loss: 0.001852 Acc: 13.2812\n",
      " |~~ train@18624  Loss: 0.002231 Acc: 13.3125\n",
      " |~~ train@18688  Loss: 0.002536 Acc: 13.1875\n",
      " |~~ train@18752  Loss: 0.002695 Acc: 13.0625\n",
      " |~~ train@18816  Loss: 0.002075 Acc: 13.2500\n",
      " |~~ train@18880  Loss: 0.002309 Acc: 13.2344\n",
      " |~~ train@18944  Loss: 0.001829 Acc: 13.3906\n",
      " |~~ train@19008  Loss: 0.002002 Acc: 13.3750\n",
      " |~~ train@19072  Loss: 0.001994 Acc: 13.3750\n",
      " |~~ train@19136  Loss: 0.002269 Acc: 13.3438\n",
      " |~~ train@19200  Loss: 0.001885 Acc: 13.4219\n",
      " |~~ train@19264  Loss: 0.001746 Acc: 13.4844\n",
      " |~~ train@19328  Loss: 0.001856 Acc: 13.3750\n",
      " |~~ train@19392  Loss: 0.001908 Acc: 13.3594\n",
      " |~~ train@19456  Loss: 0.002199 Acc: 13.2500\n",
      " |~~ train@19520  Loss: 0.001816 Acc: 13.4531\n",
      " |~~ train@19584  Loss: 0.002014 Acc: 13.3125\n",
      " |~~ train@19648  Loss: 0.002404 Acc: 13.2344\n",
      " |~~ train@19712  Loss: 0.002240 Acc: 13.1875\n",
      " |~~ train@19776  Loss: 0.002137 Acc: 13.2188\n",
      " |~~ train@19840  Loss: 0.002052 Acc: 13.3281\n",
      " |~~ train@19904  Loss: 0.002309 Acc: 13.2656\n",
      " |~~ train@19968  Loss: 0.001917 Acc: 13.4062\n",
      " |~~ train@20032  Loss: 0.001844 Acc: 13.4531\n",
      " |~~ train@20096  Loss: 0.001758 Acc: 13.2969\n",
      " |~~ train@20160  Loss: 0.002274 Acc: 13.2344\n",
      " |~~ train@20224  Loss: 0.002154 Acc: 13.3438\n",
      " |~~ train@20288  Loss: 0.001831 Acc: 13.4219\n",
      " |~~ train@20352  Loss: 0.002346 Acc: 13.2500\n",
      " |~~ train@20416  Loss: 0.002241 Acc: 13.2188\n",
      " |~~ train@20480  Loss: 0.002036 Acc: 13.2656\n",
      " |~~ train@20544  Loss: 0.002197 Acc: 13.2344\n",
      " |~~ train@20608  Loss: 0.002028 Acc: 13.3594\n",
      " |~~ train@20672  Loss: 0.002068 Acc: 13.2188\n",
      " |~~ train@20736  Loss: 0.001859 Acc: 13.3906\n",
      " |~~ train@20800  Loss: 0.002382 Acc: 13.2188\n",
      " |~~ train@20864  Loss: 0.002485 Acc: 13.2031\n",
      " |~~ train@20928  Loss: 0.001981 Acc: 13.3438\n",
      " |~~ train@20992  Loss: 0.002020 Acc: 13.3750\n",
      " |~~ train@21056  Loss: 0.001733 Acc: 13.4219\n",
      " |~~ train@21120  Loss: 0.001939 Acc: 13.2812\n",
      " |~~ train@21184  Loss: 0.001533 Acc: 13.5938\n",
      " |~~ train@21248  Loss: 0.002073 Acc: 13.3125\n",
      " |~~ train@21312  Loss: 0.002204 Acc: 13.2500\n",
      " |~~ train@21376  Loss: 0.001941 Acc: 13.4531\n",
      " |~~ train@21440  Loss: 0.002313 Acc: 13.1875\n",
      " |~~ train@21504  Loss: 0.002845 Acc: 13.1719\n",
      " |~~ train@21568  Loss: 0.002570 Acc: 13.2344\n",
      " |~~ train@21632  Loss: 0.001986 Acc: 13.4531\n",
      " |~~ train@21696  Loss: 0.001926 Acc: 13.3750\n",
      " |~~ train@21760  Loss: 0.002325 Acc: 13.2188\n",
      " |~~ train@21824  Loss: 0.001458 Acc: 13.5469\n",
      " |~~ train@21888  Loss: 0.002107 Acc: 13.2500\n",
      " |~~ train@21952  Loss: 0.002300 Acc: 13.2500\n",
      " |~~ train@22016  Loss: 0.002362 Acc: 13.2969\n",
      " |~~ train@22080  Loss: 0.001867 Acc: 13.3438\n",
      " |~~ train@22144  Loss: 0.002263 Acc: 13.3594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@22208  Loss: 0.001876 Acc: 13.4219\n",
      " |~~ train@22272  Loss: 0.002526 Acc: 13.2344\n",
      " |~~ train@22336  Loss: 0.002016 Acc: 13.3750\n",
      " |~~ train@22400  Loss: 0.001735 Acc: 13.3750\n",
      " |~~ train@22464  Loss: 0.001438 Acc: 13.5625\n",
      " |~~ train@22528  Loss: 0.002270 Acc: 13.2500\n",
      " |~~ train@22592  Loss: 0.001649 Acc: 13.5000\n",
      " |~~ train@22656  Loss: 0.002526 Acc: 13.0781\n",
      " |~~ train@22720  Loss: 0.002053 Acc: 13.3125\n",
      " |~~ train@22784  Loss: 0.002188 Acc: 13.2812\n",
      " |~~ train@22848  Loss: 0.001676 Acc: 13.4844\n",
      " |~~ train@22912  Loss: 0.001662 Acc: 13.4844\n",
      " |~~ train@22976  Loss: 0.001891 Acc: 13.3906\n",
      " |~~ train@23040  Loss: 0.001730 Acc: 13.3906\n",
      " |~~ train@23104  Loss: 0.002083 Acc: 13.3594\n",
      " |~~ train@23168  Loss: 0.001926 Acc: 13.3594\n",
      " |~~ train@23232  Loss: 0.002339 Acc: 13.1875\n",
      " |~~ train@23296  Loss: 0.002417 Acc: 13.3125\n",
      " |~~ train@23360  Loss: 0.001467 Acc: 13.5625\n",
      " |~~ train@23424  Loss: 0.002089 Acc: 13.3438\n",
      " |~~ train@23488  Loss: 0.001428 Acc: 13.6250\n",
      " |~~ train@23552  Loss: 0.002630 Acc: 13.1875\n",
      " |~~ train@23616  Loss: 0.002208 Acc: 13.2500\n",
      " |~~ train@23680  Loss: 0.001983 Acc: 13.3438\n",
      " |~~ train@23744  Loss: 0.001475 Acc: 13.5938\n",
      " |~~ train@23808  Loss: 0.001729 Acc: 13.5312\n",
      " |~~ train@23872  Loss: 0.002304 Acc: 13.3125\n",
      " |~~ train@23936  Loss: 0.001665 Acc: 13.4531\n",
      " |~~ train@24000  Loss: 0.002063 Acc: 13.2656\n",
      " |~~ train@24064  Loss: 0.001466 Acc: 13.5469\n",
      " |~~ train@24128  Loss: 0.001704 Acc: 13.4531\n",
      " |~~ train@24192  Loss: 0.002438 Acc: 13.1094\n",
      " |~~ train@24256  Loss: 0.001794 Acc: 13.3750\n",
      " |~~ train@24320  Loss: 0.002145 Acc: 13.3594\n",
      " |~~ train@24384  Loss: 0.002310 Acc: 13.2188\n",
      " |~~ train@24448  Loss: 0.001665 Acc: 13.4844\n",
      " |~~ train@24512  Loss: 0.002463 Acc: 13.1719\n",
      " |~~ train@24576  Loss: 0.002251 Acc: 13.2656\n",
      " |~~ train@24640  Loss: 0.002090 Acc: 13.3594\n",
      " |~~ train@24704  Loss: 0.002297 Acc: 13.2344\n",
      " |~~ train@24768  Loss: 0.001828 Acc: 13.3594\n",
      " |~~ train@24832  Loss: 0.002051 Acc: 13.3906\n",
      " |~~ train@24896  Loss: 0.001822 Acc: 13.4531\n",
      " |~~ train@24960  Loss: 0.002155 Acc: 13.3750\n",
      " |~~ train@25024  Loss: 0.001695 Acc: 13.5000\n",
      " |~~ train@25088  Loss: 0.002515 Acc: 13.2656\n",
      " |~~ train@25152  Loss: 0.001458 Acc: 13.4844\n",
      " |~~ train@25216  Loss: 0.002164 Acc: 13.2812\n",
      " |~~ train@25280  Loss: 0.002315 Acc: 13.1094\n",
      " |~~ train@25344  Loss: 0.002032 Acc: 13.4688\n",
      " |~~ train@25408  Loss: 0.001916 Acc: 13.3750\n",
      " |~~ train@25472  Loss: 0.001764 Acc: 13.4844\n",
      " |~~ train@25536  Loss: 0.002463 Acc: 13.1875\n",
      " |~~ train@25600  Loss: 0.001827 Acc: 13.4688\n",
      " |~~ train@25664  Loss: 0.002101 Acc: 13.3125\n",
      " |~~ train@25728  Loss: 0.002261 Acc: 13.2344\n",
      " |~~ train@25792  Loss: 0.002065 Acc: 13.3438\n",
      " |~~ train@25856  Loss: 0.002168 Acc: 13.2188\n",
      " |~~ train@25920  Loss: 0.001407 Acc: 13.6250\n",
      " |~~ train@25984  Loss: 0.001971 Acc: 13.3750\n",
      " |~~ train@26048  Loss: 0.002362 Acc: 13.1875\n",
      " |~~ train@26112  Loss: 0.001802 Acc: 13.4688\n",
      " |~~ train@26176  Loss: 0.002004 Acc: 13.2969\n",
      " |~~ train@26240  Loss: 0.001994 Acc: 13.3906\n",
      " |~~ train@26304  Loss: 0.001950 Acc: 13.4219\n",
      " |~~ train@26368  Loss: 0.002109 Acc: 13.2188\n",
      " |~~ train@26432  Loss: 0.002083 Acc: 13.2969\n",
      " |~~ train@26496  Loss: 0.001710 Acc: 13.5625\n",
      " |~~ train@26560  Loss: 0.001620 Acc: 13.4531\n",
      " |~~ train@26624  Loss: 0.001986 Acc: 13.3438\n",
      " |~~ train@26688  Loss: 0.002108 Acc: 13.2812\n",
      " |~~ train@26752  Loss: 0.002111 Acc: 13.2812\n",
      " |~~ train@26816  Loss: 0.002429 Acc: 13.1875\n",
      " |~~ train@26880  Loss: 0.001886 Acc: 13.3594\n",
      " |~~ train@26944  Loss: 0.002339 Acc: 13.2500\n",
      " |~~ train@27008  Loss: 0.002076 Acc: 13.2969\n",
      " |~~ train@27072  Loss: 0.001881 Acc: 13.4531\n",
      " |~~ train@27136  Loss: 0.001838 Acc: 13.3594\n",
      " |~~ train@27200  Loss: 0.001855 Acc: 13.4062\n",
      " |~~ train@27264  Loss: 0.001856 Acc: 13.3438\n",
      " |~~ train@27328  Loss: 0.001821 Acc: 13.5000\n",
      " |~~ train@27392  Loss: 0.002057 Acc: 13.3281\n",
      " |~~ train@27456  Loss: 0.002338 Acc: 13.3125\n",
      " |~~ train@27520  Loss: 0.002026 Acc: 13.2656\n",
      " |~~ train@27584  Loss: 0.002213 Acc: 13.2656\n",
      " |~~ train@27648  Loss: 0.001902 Acc: 13.3281\n",
      " |~~ train@27712  Loss: 0.002096 Acc: 13.3125\n",
      " |~~ train@27776  Loss: 0.002384 Acc: 13.2656\n",
      " |~~ train@27840  Loss: 0.002658 Acc: 13.0781\n",
      " |~~ train@27904  Loss: 0.001628 Acc: 13.4531\n",
      " |~~ train@27968  Loss: 0.001977 Acc: 13.3281\n",
      " |~~ train@28032  Loss: 0.002071 Acc: 13.3438\n",
      " |~~ train@28096  Loss: 0.002366 Acc: 13.2656\n",
      " |~~ train@28160  Loss: 0.002178 Acc: 13.2656\n",
      " |~~ train@28224  Loss: 0.001743 Acc: 13.4062\n",
      " |~~ train@28288  Loss: 0.002325 Acc: 13.3438\n",
      " |~~ train@28352  Loss: 0.001739 Acc: 13.5000\n",
      " |~~ train@28416  Loss: 0.002319 Acc: 13.1562\n",
      " |~~ train@28480  Loss: 0.001995 Acc: 13.4062\n",
      " |~~ train@28544  Loss: 0.002113 Acc: 13.2500\n",
      " |~~ train@28608  Loss: 0.002151 Acc: 13.2969\n",
      " |~~ train@28672  Loss: 0.001876 Acc: 13.4062\n",
      " |~~ train@28736  Loss: 0.001945 Acc: 13.3438\n",
      " |~~ train@28800  Loss: 0.001847 Acc: 13.4219\n",
      " |~~ train@28864  Loss: 0.002320 Acc: 13.2812\n",
      " |~~ train@28928  Loss: 0.002079 Acc: 13.2188\n",
      " |~~ train@28992  Loss: 0.002170 Acc: 13.1250\n",
      " |~~ train@29056  Loss: 0.002071 Acc: 13.2812\n",
      " |~~ train@29120  Loss: 0.002181 Acc: 13.2188\n",
      " |~~ train@29184  Loss: 0.001816 Acc: 13.4219\n",
      " |~~ train@29248  Loss: 0.002602 Acc: 13.2031\n",
      " |~~ train@29312  Loss: 0.001923 Acc: 13.3906\n",
      " |~~ train@29376  Loss: 0.002387 Acc: 13.2812\n",
      " |~~ train@29440  Loss: 0.002448 Acc: 13.2812\n",
      " |~~ train@29504  Loss: 0.001690 Acc: 13.4375\n",
      " |~~ train@29568  Loss: 0.001915 Acc: 13.3438\n",
      " |~~ train@29632  Loss: 0.002316 Acc: 13.1562\n",
      " |~~ train@29696  Loss: 0.001909 Acc: 13.3906\n",
      " |~~ train@29760  Loss: 0.002411 Acc: 13.1719\n",
      " |~~ train@29824  Loss: 0.001779 Acc: 13.4219\n",
      " |~~ train@29888  Loss: 0.001488 Acc: 13.5781\n",
      " |~~ train@29952  Loss: 0.002113 Acc: 13.2969\n",
      " |~~ train@30016  Loss: 0.001574 Acc: 13.5469\n",
      " |~~ train@30080  Loss: 0.001825 Acc: 13.3906\n",
      " |~~ train@30144  Loss: 0.002285 Acc: 13.3125\n",
      " |~~ train@30208  Loss: 0.001876 Acc: 13.2969\n",
      " |~~ train@30272  Loss: 0.002175 Acc: 13.2656\n",
      " |~~ train@30336  Loss: 0.001528 Acc: 13.5781\n",
      " |~~ train@30400  Loss: 0.001958 Acc: 13.3594\n",
      " |~~ train@30464  Loss: 0.001859 Acc: 13.4062\n",
      " |~~ train@30528  Loss: 0.001861 Acc: 13.3750\n",
      " |~~ train@30592  Loss: 0.001519 Acc: 13.5469\n",
      " |~~ train@30656  Loss: 0.002352 Acc: 13.2500\n",
      " |~~ train@30720  Loss: 0.002186 Acc: 13.2500\n",
      " |~~ train@30784  Loss: 0.002580 Acc: 13.1250\n",
      " |~~ train@30848  Loss: 0.001637 Acc: 13.5156\n",
      " |~~ train@30912  Loss: 0.001831 Acc: 13.3750\n",
      " |~~ train@30976  Loss: 0.002133 Acc: 13.1719\n",
      " |~~ train@31040  Loss: 0.002147 Acc: 13.3438\n",
      " |~~ train@31104  Loss: 0.002049 Acc: 13.3750\n",
      " |~~ train@31168  Loss: 0.002033 Acc: 13.4062\n",
      " |~~ train@31232  Loss: 0.002441 Acc: 13.1875\n",
      " |~~ train@31296  Loss: 0.001652 Acc: 13.5938\n",
      " |~~ train@31360  Loss: 0.002073 Acc: 13.3125\n",
      " |~~ train@31424  Loss: 0.001657 Acc: 13.4844\n",
      " |~~ train@31488  Loss: 0.001941 Acc: 13.4688\n",
      " |~~ train@31552  Loss: 0.002199 Acc: 13.2812\n",
      " |~~ train@31616  Loss: 0.002083 Acc: 13.3438\n",
      " |~~ train@31680  Loss: 0.001877 Acc: 13.4688\n",
      " |~~ train@31744  Loss: 0.001743 Acc: 13.4688\n",
      " |~~ train@31808  Loss: 0.001694 Acc: 13.4531\n",
      " |~~ train@31872  Loss: 0.002754 Acc: 13.1875\n",
      " |~~ train@31936  Loss: 0.002135 Acc: 13.2812\n",
      " |~~ train@32000  Loss: 0.001999 Acc: 13.3125\n",
      " |~~ train@32064  Loss: 0.002071 Acc: 13.3594\n",
      " |~~ train@32128  Loss: 0.002181 Acc: 13.3750\n",
      " |~~ train@32192  Loss: 0.002067 Acc: 13.3281\n",
      " |~~ train@32256  Loss: 0.001622 Acc: 13.5000\n",
      " |~~ train@32320  Loss: 0.001946 Acc: 13.4219\n",
      " |~~ train@32384  Loss: 0.002010 Acc: 13.3906\n",
      " |~~ train@32448  Loss: 0.001782 Acc: 13.4375\n",
      " |~~ train@32512  Loss: 0.002048 Acc: 13.3750\n",
      " |~~ train@32576  Loss: 0.001886 Acc: 13.3594\n",
      " |~~ train@32640  Loss: 0.002031 Acc: 13.4219\n",
      " |~~ train@32704  Loss: 0.001605 Acc: 13.5781\n",
      " |~~ train@32768  Loss: 0.002313 Acc: 13.2344\n",
      " |~~ train@32832  Loss: 0.002478 Acc: 13.2031\n",
      " |~~ train@32896  Loss: 0.001722 Acc: 13.4062\n",
      " |~~ train@32960  Loss: 0.001618 Acc: 13.5000\n",
      " |~~ train@33024  Loss: 0.001727 Acc: 13.4688\n",
      " |~~ train@33088  Loss: 0.001813 Acc: 13.4219\n",
      " |~~ train@33152  Loss: 0.001986 Acc: 13.3281\n",
      " |~~ train@33216  Loss: 0.001658 Acc: 13.5000\n",
      " |~~ train@33280  Loss: 0.001971 Acc: 13.3906\n",
      " |~~ train@33344  Loss: 0.002149 Acc: 13.2812\n",
      " |~~ train@33408  Loss: 0.001701 Acc: 13.3906\n",
      " |~~ train@33472  Loss: 0.001687 Acc: 13.5312\n",
      " |~~ train@33536  Loss: 0.002364 Acc: 13.2188\n",
      " |~~ train@33600  Loss: 0.001686 Acc: 13.4219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@33664  Loss: 0.001920 Acc: 13.3594\n",
      " |~~ train@33728  Loss: 0.002194 Acc: 13.2500\n",
      " |~~ train@33792  Loss: 0.001755 Acc: 13.3281\n",
      " |~~ train@33856  Loss: 0.002291 Acc: 13.1875\n",
      " |~~ train@33920  Loss: 0.002006 Acc: 13.3438\n",
      " |~~ train@33984  Loss: 0.001785 Acc: 13.4844\n",
      " |~~ train@34048  Loss: 0.002442 Acc: 13.1875\n",
      " |~~ train@34112  Loss: 0.002182 Acc: 13.2969\n",
      " |~~ train@34176  Loss: 0.002490 Acc: 13.1875\n",
      " |~~ train@34240  Loss: 0.001910 Acc: 13.3438\n",
      " |~~ train@34304  Loss: 0.002313 Acc: 13.2500\n",
      " |~~ train@34368  Loss: 0.002278 Acc: 13.2344\n",
      " |~~ train@34432  Loss: 0.002132 Acc: 13.3125\n",
      " |~~ train@34496  Loss: 0.001995 Acc: 13.2500\n",
      " |~~ train@34560  Loss: 0.002465 Acc: 13.2031\n",
      " |~~ train@34624  Loss: 0.002062 Acc: 13.2500\n",
      " |~~ train@34688  Loss: 0.002617 Acc: 13.1875\n",
      " |~~ train@34752  Loss: 0.001697 Acc: 13.4531\n",
      " |~~ train@34816  Loss: 0.002214 Acc: 13.2188\n",
      " |~~ train@34880  Loss: 0.001666 Acc: 13.4531\n",
      " |~~ train@34944  Loss: 0.002036 Acc: 13.3125\n",
      " |~~ train@35008  Loss: 0.001965 Acc: 13.3125\n",
      " |~~ train@35072  Loss: 0.001921 Acc: 13.4062\n",
      " |~~ train@35136  Loss: 0.001807 Acc: 13.4688\n",
      " |~~ train@35200  Loss: 0.001996 Acc: 13.2969\n",
      " |~~ train@35264  Loss: 0.001899 Acc: 13.4375\n",
      " |~~ train@35328  Loss: 0.001939 Acc: 13.3750\n",
      " |~~ train@35392  Loss: 0.001636 Acc: 13.5312\n",
      " |~~ train@35456  Loss: 0.001686 Acc: 13.5156\n",
      " |~~ train@35520  Loss: 0.002327 Acc: 13.2344\n",
      " |~~ train@35584  Loss: 0.002490 Acc: 13.0469\n",
      " |~~ train@35648  Loss: 0.002202 Acc: 13.2969\n",
      " |~~ train@35712  Loss: 0.002170 Acc: 13.2812\n",
      " |~~ train@35776  Loss: 0.001814 Acc: 13.3594\n",
      " |~~ train@35840  Loss: 0.002077 Acc: 13.2344\n",
      " |~~ train@35904  Loss: 0.002963 Acc: 13.0312\n",
      " |~~ train@35968  Loss: 0.001773 Acc: 13.4062\n",
      " |~~ train@36032  Loss: 0.001776 Acc: 13.4219\n",
      " |~~ train@36096  Loss: 0.002305 Acc: 13.2812\n",
      " |~~ train@36160  Loss: 0.002507 Acc: 13.1719\n",
      " |~~ train@36224  Loss: 0.001692 Acc: 13.4375\n",
      " |~~ train@36288  Loss: 0.002103 Acc: 13.3594\n",
      " |~~ train@36352  Loss: 0.002057 Acc: 13.4062\n",
      " |~~ train@36416  Loss: 0.001915 Acc: 13.3594\n",
      " |~~ train@36480  Loss: 0.001759 Acc: 13.4688\n",
      " |~~ train@36544  Loss: 0.002009 Acc: 13.3594\n",
      " |~~ train@36608  Loss: 0.001907 Acc: 13.3750\n",
      " |~~ train@36672  Loss: 0.002415 Acc: 13.2188\n",
      " |~~ train@36736  Loss: 0.001724 Acc: 13.4688\n",
      " |~~ train@36800  Loss: 0.002168 Acc: 13.2500\n",
      " |~~ train@36864  Loss: 0.002137 Acc: 13.3281\n",
      " |~~ train@36928  Loss: 0.001809 Acc: 13.4219\n",
      " |~~ train@36992  Loss: 0.001965 Acc: 13.3906\n",
      " |~~ train@37056  Loss: 0.001946 Acc: 13.3438\n",
      " |~~ train@37120  Loss: 0.001935 Acc: 13.3906\n",
      " |~~ train@37184  Loss: 0.001875 Acc: 13.5156\n",
      " |~~ train@37248  Loss: 0.002268 Acc: 13.2500\n",
      " |~~ train@37312  Loss: 0.001699 Acc: 13.4844\n",
      " |~~ train@37376  Loss: 0.001719 Acc: 13.4219\n",
      " |~~ train@37440  Loss: 0.002111 Acc: 13.3281\n",
      " |~~ train@37504  Loss: 0.002061 Acc: 13.3438\n",
      " |~~ train@37568  Loss: 0.001792 Acc: 13.3281\n",
      " |~~ train@37632  Loss: 0.002263 Acc: 13.3594\n",
      " |~~ train@37696  Loss: 0.001884 Acc: 13.3906\n",
      " |~~ train@37760  Loss: 0.001864 Acc: 13.3750\n",
      " |~~ train@37824  Loss: 0.002249 Acc: 13.3594\n",
      " |~~ train@37888  Loss: 0.001658 Acc: 13.4531\n",
      " |~~ train@37952  Loss: 0.002341 Acc: 13.2812\n",
      " |~~ train@38016  Loss: 0.002296 Acc: 13.3594\n",
      " |~~ train@38080  Loss: 0.001893 Acc: 13.4531\n",
      " |~~ train@38144  Loss: 0.002354 Acc: 13.2812\n",
      " |~~ train@38208  Loss: 0.002215 Acc: 13.1562\n",
      " |~~ train@38272  Loss: 0.001718 Acc: 13.4688\n",
      " |~~ train@38336  Loss: 0.002605 Acc: 13.0781\n",
      " |~~ train@38400  Loss: 0.001975 Acc: 13.4219\n",
      " |~~ train@38464  Loss: 0.002039 Acc: 13.2969\n",
      " |~~ train@38528  Loss: 0.002149 Acc: 13.2500\n",
      " |~~ train@38592  Loss: 0.001890 Acc: 13.3750\n",
      " |~~ train@38656  Loss: 0.002045 Acc: 13.3906\n",
      " |~~ train@38720  Loss: 0.001749 Acc: 13.4375\n",
      " |~~ train@38784  Loss: 0.001972 Acc: 13.4062\n",
      " |~~ train@38848  Loss: 0.002039 Acc: 13.2188\n",
      " |~~ train@38912  Loss: 0.002144 Acc: 13.2500\n",
      " |~~ train@38976  Loss: 0.001856 Acc: 13.4844\n",
      " |~~ train@39040  Loss: 0.002161 Acc: 13.2812\n",
      " |~~ train@39104  Loss: 0.001970 Acc: 13.2656\n",
      " |~~ train@39168  Loss: 0.002151 Acc: 13.2812\n",
      " |~~ train@39232  Loss: 0.001570 Acc: 13.5000\n",
      " |~~ train@39296  Loss: 0.002410 Acc: 13.2188\n",
      " |~~ train@39360  Loss: 0.002170 Acc: 13.3125\n",
      " |~~ train@39424  Loss: 0.001739 Acc: 13.4688\n",
      " |~~ train@39488  Loss: 0.002025 Acc: 13.2969\n",
      " |~~ train@39552  Loss: 0.001542 Acc: 13.4844\n",
      " |~~ train@39616  Loss: 0.001845 Acc: 13.3438\n",
      " |~~ train@39680  Loss: 0.002121 Acc: 13.2812\n",
      " |~~ train@39744  Loss: 0.001944 Acc: 13.3438\n",
      " |~~ train@39808  Loss: 0.001904 Acc: 13.5000\n",
      " |~~ train@39872  Loss: 0.001968 Acc: 13.3125\n",
      " |~~ train@39936  Loss: 0.002337 Acc: 13.2031\n",
      " |~~ train@40000  Loss: 0.002503 Acc: 13.1406\n",
      " |~~ train@40064  Loss: 0.002249 Acc: 13.2500\n",
      " |~~ train@40128  Loss: 0.001752 Acc: 13.5625\n",
      " |~~ train@40192  Loss: 0.001620 Acc: 13.4375\n",
      " |~~ train@40256  Loss: 0.001908 Acc: 13.3281\n",
      " |~~ train@40320  Loss: 0.001640 Acc: 13.5000\n",
      " |~~ train@40384  Loss: 0.002049 Acc: 13.3438\n",
      " |~~ train@40448  Loss: 0.002077 Acc: 13.3906\n",
      " |~~ train@40512  Loss: 0.001725 Acc: 13.4062\n",
      " |~~ train@40576  Loss: 0.002088 Acc: 13.3438\n",
      " |~~ train@40640  Loss: 0.001466 Acc: 13.5781\n",
      " |~~ train@40704  Loss: 0.001624 Acc: 13.5156\n",
      " |~~ train@40768  Loss: 0.001748 Acc: 13.4375\n",
      " |~~ train@40832  Loss: 0.002061 Acc: 13.3281\n",
      " |~~ train@40896  Loss: 0.002285 Acc: 13.1406\n",
      " |~~ train@40960  Loss: 0.002023 Acc: 13.3594\n",
      " |~~ train@41024  Loss: 0.002206 Acc: 13.1719\n",
      " |~~ train@41088  Loss: 0.001944 Acc: 13.3750\n",
      " |~~ train@41152  Loss: 0.002259 Acc: 13.2656\n",
      " |~~ train@41216  Loss: 0.002277 Acc: 13.1875\n",
      " |~~ train@41280  Loss: 0.002251 Acc: 13.1719\n",
      " |~~ train@41344  Loss: 0.001835 Acc: 13.4688\n",
      " |~~ train@41408  Loss: 0.001989 Acc: 13.3906\n",
      " |~~ train@41472  Loss: 0.001983 Acc: 13.3281\n",
      " |~~ train@41536  Loss: 0.001645 Acc: 13.4219\n",
      " |~~ train@41600  Loss: 0.001814 Acc: 13.3594\n",
      " |~~ train@41664  Loss: 0.002614 Acc: 13.1406\n",
      " |~~ train@41728  Loss: 0.002520 Acc: 13.1406\n",
      " |~~ train@41792  Loss: 0.002073 Acc: 13.2344\n",
      " |~~ train@41856  Loss: 0.002394 Acc: 13.2812\n",
      " |~~ train@41920  Loss: 0.002169 Acc: 13.2656\n",
      " |~~ train@41984  Loss: 0.001927 Acc: 13.4062\n",
      " |~~ train@42048  Loss: 0.002163 Acc: 13.3906\n",
      " |~~ train@42112  Loss: 0.002056 Acc: 13.3438\n",
      " |~~ train@42176  Loss: 0.002295 Acc: 13.3125\n",
      " |~~ train@42240  Loss: 0.001983 Acc: 13.3594\n",
      " |~~ train@42304  Loss: 0.001783 Acc: 13.4062\n",
      " |~~ train@42368  Loss: 0.002749 Acc: 13.0781\n",
      " |~~ train@42432  Loss: 0.002345 Acc: 13.2500\n",
      " |~~ train@42496  Loss: 0.002420 Acc: 13.2344\n",
      " |~~ train@42560  Loss: 0.002171 Acc: 13.2344\n",
      " |~~ train@42624  Loss: 0.001470 Acc: 13.5000\n",
      " |~~ train@42688  Loss: 0.002236 Acc: 13.2656\n",
      " |~~ train@42752  Loss: 0.002454 Acc: 13.2188\n",
      " |~~ train@42816  Loss: 0.001613 Acc: 13.4375\n",
      " |~~ train@42880  Loss: 0.002253 Acc: 13.2031\n",
      " |~~ train@42944  Loss: 0.001506 Acc: 13.5469\n",
      " |~~ train@43008  Loss: 0.002093 Acc: 13.1562\n",
      " |~~ train@43072  Loss: 0.002343 Acc: 13.2344\n",
      " |~~ train@43136  Loss: 0.001988 Acc: 13.2656\n",
      " |~~ train@43200  Loss: 0.002625 Acc: 13.0469\n",
      " |~~ train@43264  Loss: 0.002022 Acc: 13.3281\n",
      " |~~ train@43328  Loss: 0.001894 Acc: 13.3125\n",
      " |~~ train@43392  Loss: 0.002172 Acc: 13.3750\n",
      " |~~ train@43456  Loss: 0.001868 Acc: 13.4219\n",
      " |~~ train@43520  Loss: 0.002299 Acc: 13.2188\n",
      " |~~ train@43584  Loss: 0.002703 Acc: 13.0625\n",
      " |~~ train@43648  Loss: 0.001962 Acc: 13.3438\n",
      " |~~ train@43712  Loss: 0.002350 Acc: 13.1719\n",
      " |~~ train@43776  Loss: 0.002025 Acc: 13.4062\n",
      " |~~ train@43840  Loss: 0.002089 Acc: 13.4062\n",
      " |~~ train@43904  Loss: 0.001909 Acc: 13.3438\n",
      " |~~ train@43968  Loss: 0.002541 Acc: 13.1094\n",
      " |~~ train@44032  Loss: 0.001969 Acc: 13.3906\n",
      " |~~ train@44096  Loss: 0.001900 Acc: 13.4062\n",
      " |~~ train@44160  Loss: 0.001981 Acc: 13.4062\n",
      " |~~ train@44224  Loss: 0.002263 Acc: 13.2969\n",
      " |~~ train@44288  Loss: 0.002089 Acc: 13.2656\n",
      " |~~ train@44352  Loss: 0.002478 Acc: 13.1562\n",
      " |~~ train@44416  Loss: 0.001929 Acc: 13.4062\n",
      " |~~ train@44480  Loss: 0.002482 Acc: 13.1250\n",
      " |~~ train@44544  Loss: 0.002499 Acc: 13.2500\n",
      " |~~ train@44608  Loss: 0.001918 Acc: 13.4844\n",
      " |~~ train@44672  Loss: 0.002221 Acc: 13.2500\n",
      " |~~ train@44736  Loss: 0.001906 Acc: 13.3906\n",
      " |~~ train@44800  Loss: 0.002166 Acc: 13.3438\n",
      " |~~ train@44864  Loss: 0.001689 Acc: 13.5156\n",
      " |~~ train@44928  Loss: 0.001622 Acc: 13.5469\n",
      " |~~ train@44992  Loss: 0.002309 Acc: 13.2500\n",
      " |~~ train@45056  Loss: 0.001748 Acc: 13.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@45120  Loss: 0.001545 Acc: 13.5469\n",
      " |~~ train@45184  Loss: 0.002105 Acc: 13.3438\n",
      " |~~ train@45248  Loss: 0.001570 Acc: 13.5625\n",
      " |~~ train@45312  Loss: 0.001978 Acc: 13.3438\n",
      " |~~ train@45376  Loss: 0.002091 Acc: 13.3281\n",
      " |~~ train@45440  Loss: 0.002242 Acc: 13.2656\n",
      " |~~ train@45504  Loss: 0.001942 Acc: 13.3281\n",
      " |~~ train@45568  Loss: 0.002181 Acc: 13.2188\n",
      " |~~ train@45632  Loss: 0.002011 Acc: 13.3594\n",
      " |~~ train@45696  Loss: 0.002153 Acc: 13.2812\n",
      " |~~ train@45760  Loss: 0.002303 Acc: 13.2812\n",
      " |~~ train@45824  Loss: 0.002331 Acc: 13.3281\n",
      " |~~ train@45888  Loss: 0.002361 Acc: 13.2656\n",
      " |~~ train@45952  Loss: 0.001946 Acc: 13.3281\n",
      " |~~ train@46016  Loss: 0.001844 Acc: 13.4531\n",
      " |~~ train@46080  Loss: 0.001894 Acc: 13.3750\n",
      " |~~ train@46144  Loss: 0.002156 Acc: 13.1875\n",
      " |~~ train@46208  Loss: 0.002006 Acc: 13.3594\n",
      " |~~ train@46272  Loss: 0.001857 Acc: 13.3906\n",
      " |~~ train@46336  Loss: 0.002158 Acc: 13.2969\n",
      " |~~ train@46400  Loss: 0.002077 Acc: 13.3438\n",
      " |~~ train@46464  Loss: 0.001924 Acc: 13.4375\n",
      " |~~ train@46528  Loss: 0.002120 Acc: 13.3438\n",
      " |~~ train@46592  Loss: 0.002261 Acc: 13.2812\n",
      " |~~ train@46656  Loss: 0.002201 Acc: 13.2812\n",
      " |~~ train@46720  Loss: 0.002005 Acc: 13.3906\n",
      " |~~ train@46784  Loss: 0.002054 Acc: 13.4062\n",
      " |~~ train@46848  Loss: 0.002307 Acc: 13.2656\n",
      " |~~ train@46912  Loss: 0.001951 Acc: 13.4844\n",
      " |~~ train@46976  Loss: 0.002058 Acc: 13.3906\n",
      " |~~ train@47040  Loss: 0.002013 Acc: 13.3281\n",
      " |~~ train@47104  Loss: 0.002429 Acc: 13.2031\n",
      " |~~ train@47168  Loss: 0.001828 Acc: 13.4062\n",
      " |~~ train@47232  Loss: 0.001758 Acc: 13.4375\n",
      " |~~ train@47296  Loss: 0.002108 Acc: 13.2812\n",
      " |~~ train@47360  Loss: 0.001705 Acc: 13.5156\n",
      " |~~ train@47424  Loss: 0.002280 Acc: 13.2969\n",
      " |~~ train@47488  Loss: 0.002038 Acc: 13.3594\n",
      " |~~ train@47552  Loss: 0.002042 Acc: 13.3594\n",
      " |~~ train@47616  Loss: 0.001885 Acc: 13.4531\n",
      " |~~ train@47680  Loss: 0.001949 Acc: 13.4375\n",
      " |~~ train@47744  Loss: 0.002346 Acc: 13.1719\n",
      " |~~ train@47808  Loss: 0.001372 Acc: 13.5938\n",
      " |~~ train@47872  Loss: 0.001967 Acc: 13.3438\n",
      " |~~ train@47936  Loss: 0.002095 Acc: 13.2812\n",
      " |~~ train@48000  Loss: 0.001855 Acc: 13.4531\n",
      " |~~ train@48064  Loss: 0.002256 Acc: 13.2812\n",
      " |~~ train@48128  Loss: 0.001933 Acc: 13.3750\n",
      " |~~ train@48192  Loss: 0.002017 Acc: 13.2812\n",
      " |~~ train@48256  Loss: 0.002169 Acc: 13.2344\n",
      " |~~ train@48320  Loss: 0.001920 Acc: 13.3906\n",
      " |~~ train@48384  Loss: 0.001906 Acc: 13.4688\n",
      " |~~ train@48448  Loss: 0.001848 Acc: 13.3750\n",
      " |~~ train@48512  Loss: 0.001901 Acc: 13.4062\n",
      " |~~ train@48576  Loss: 0.002313 Acc: 13.1719\n",
      " |~~ train@48640  Loss: 0.002112 Acc: 13.3281\n",
      " |~~ train@48704  Loss: 0.001921 Acc: 13.4062\n",
      " |~~ train@48768  Loss: 0.001966 Acc: 13.3750\n",
      " |~~ train@48832  Loss: 0.002072 Acc: 13.3594\n",
      " |~~ train@48896  Loss: 0.001939 Acc: 13.3750\n",
      " |~~ train@48960  Loss: 0.001813 Acc: 13.4844\n",
      " |~~ train@49024  Loss: 0.002261 Acc: 13.2969\n",
      " |~~ train@49088  Loss: 0.002025 Acc: 13.2031\n",
      " |~~ train@49152  Loss: 0.001711 Acc: 13.5000\n",
      " |~~ train@49216  Loss: 0.002101 Acc: 13.3438\n",
      " |~~ train@49280  Loss: 0.002344 Acc: 13.2031\n",
      " |~~ train@49344  Loss: 0.001928 Acc: 13.3750\n",
      " |~~ train@49408  Loss: 0.001837 Acc: 13.4219\n",
      " |~~ train@49472  Loss: 0.002039 Acc: 13.2344\n",
      " |~~ train@49536  Loss: 0.001774 Acc: 13.4375\n",
      " |~~ train@49600  Loss: 0.002156 Acc: 13.2812\n",
      " |~~ train@49664  Loss: 0.002522 Acc: 13.0938\n",
      " |~~ train@49728  Loss: 0.002190 Acc: 13.2969\n",
      " |~~ train@49792  Loss: 0.002119 Acc: 13.2969\n",
      " |~~ train@49856  Loss: 0.002024 Acc: 13.3594\n",
      " |~~ train@49920  Loss: 0.002099 Acc: 13.3906\n",
      " |~~ train@49984  Loss: 0.002128 Acc: 13.2188\n",
      " |~~ train@50048  Loss: 0.002432 Acc: 13.0938\n",
      " |~~ train@50112  Loss: 0.002625 Acc: 13.1250\n",
      " |~~ train@50176  Loss: 0.001746 Acc: 13.4375\n",
      " |~~ train@50240  Loss: 0.002039 Acc: 13.2969\n",
      " |~~ train@50304  Loss: 0.001841 Acc: 13.5000\n",
      " |~~ train@50368  Loss: 0.001711 Acc: 13.4531\n",
      " |~~ train@50432  Loss: 0.002040 Acc: 13.2969\n",
      " |~~ train@50496  Loss: 0.001731 Acc: 13.5469\n",
      " |~~ train@50560  Loss: 0.002335 Acc: 13.2500\n",
      " |~~ train@50624  Loss: 0.002245 Acc: 13.3281\n",
      " |~~ train@50688  Loss: 0.002433 Acc: 13.2656\n",
      " |~~ train@50752  Loss: 0.002299 Acc: 13.2812\n",
      " |~~ train@50816  Loss: 0.002301 Acc: 13.2344\n",
      " |~~ train@50880  Loss: 0.001689 Acc: 13.4219\n",
      " |~~ train@50944  Loss: 0.001820 Acc: 13.4375\n",
      " |~~ train@51008  Loss: 0.001553 Acc: 13.6094\n",
      " |~~ train@51072  Loss: 0.001985 Acc: 13.3438\n",
      " |~~ train@51136  Loss: 0.001935 Acc: 13.4688\n",
      " |~~ train@51200  Loss: 0.001737 Acc: 13.4844\n",
      " |~~ train@51264  Loss: 0.001875 Acc: 13.3594\n",
      " |~~ train@51328  Loss: 0.002064 Acc: 13.2656\n",
      " |~~ train@51392  Loss: 0.002017 Acc: 13.3594\n",
      " |~~ train@51456  Loss: 0.002061 Acc: 13.3281\n",
      " |~~ train@51520  Loss: 0.001756 Acc: 13.4688\n",
      " |~~ train@51584  Loss: 0.001948 Acc: 13.4375\n",
      " |~~ train@51648  Loss: 0.002143 Acc: 13.2656\n",
      " |~~ train@51712  Loss: 0.001995 Acc: 13.2969\n",
      " |~~ train@51776  Loss: 0.001945 Acc: 13.3594\n",
      " |~~ train@51840  Loss: 0.001837 Acc: 13.5000\n",
      " |~~ train@51904  Loss: 0.001901 Acc: 13.4062\n",
      " |~~ train@51968  Loss: 0.002364 Acc: 13.3594\n",
      " |~~ train@52032  Loss: 0.001968 Acc: 13.4062\n",
      " |~~ train@52096  Loss: 0.001792 Acc: 13.4375\n",
      " |~~ train@52160  Loss: 0.002466 Acc: 13.2031\n",
      " |~~ train@52224  Loss: 0.002271 Acc: 13.2344\n",
      " |~~ train@52288  Loss: 0.002490 Acc: 13.1250\n",
      " |~~ train@52352  Loss: 0.002063 Acc: 13.2500\n",
      " |~~ train@52416  Loss: 0.001815 Acc: 13.4531\n",
      " |~~ train@52480  Loss: 0.001732 Acc: 13.4375\n",
      " |~~ train@52544  Loss: 0.001736 Acc: 13.5625\n",
      " |~~ train@52608  Loss: 0.002381 Acc: 13.1875\n",
      " |~~ train@52672  Loss: 0.001861 Acc: 13.4531\n",
      " |~~ train@52736  Loss: 0.002297 Acc: 13.2969\n",
      " |~~ train@52800  Loss: 0.002396 Acc: 13.2344\n",
      " |~~ train@52864  Loss: 0.001786 Acc: 13.4062\n",
      " |~~ train@52928  Loss: 0.002265 Acc: 13.3125\n",
      " |~~ train@52992  Loss: 0.001964 Acc: 13.3750\n",
      " |~~ train@53056  Loss: 0.002092 Acc: 13.3594\n",
      " |~~ train@53120  Loss: 0.002205 Acc: 13.2812\n",
      " |~~ train@53184  Loss: 0.001821 Acc: 13.4219\n",
      " |~~ train@53248  Loss: 0.002138 Acc: 13.3281\n",
      " |~~ train@53312  Loss: 0.001963 Acc: 13.3281\n",
      " |~~ train@53376  Loss: 0.002160 Acc: 13.2812\n",
      " |~~ train@53440  Loss: 0.002265 Acc: 13.2656\n",
      " |~~ train@53504  Loss: 0.002413 Acc: 13.2500\n",
      " |~~ train@53568  Loss: 0.001694 Acc: 13.4688\n",
      " |~~ train@53632  Loss: 0.002169 Acc: 13.2812\n",
      " |~~ train@53696  Loss: 0.002205 Acc: 13.2031\n",
      " |~~ train@53760  Loss: 0.002054 Acc: 13.3438\n",
      " |~~ train@53824  Loss: 0.001995 Acc: 13.3906\n",
      " |~~ train@53888  Loss: 0.001809 Acc: 13.5469\n",
      " |~~ train@53952  Loss: 0.001576 Acc: 13.4844\n",
      " |~~ train@54016  Loss: 0.002095 Acc: 13.3594\n",
      " |~~ train@54080  Loss: 0.002290 Acc: 13.2344\n",
      " |~~ train@54144  Loss: 0.001624 Acc: 13.4375\n",
      " |~~ train@54208  Loss: 0.002112 Acc: 13.2812\n",
      " |~~ train@54272  Loss: 0.002341 Acc: 13.2656\n",
      " |~~ train@54336  Loss: 0.002109 Acc: 13.2656\n",
      " |~~ train@54400  Loss: 0.002012 Acc: 13.2812\n",
      " |~~ train@54464  Loss: 0.002277 Acc: 13.3594\n",
      " |~~ train@54528  Loss: 0.001727 Acc: 13.5312\n",
      " |~~ train@54592  Loss: 0.002185 Acc: 13.2812\n",
      " |~~ train@54656  Loss: 0.002568 Acc: 13.1562\n",
      " |~~ train@54720  Loss: 0.001813 Acc: 13.4531\n",
      " |~~ train@54784  Loss: 0.001861 Acc: 13.3750\n",
      " |~~ train@54848  Loss: 0.001824 Acc: 13.3594\n",
      " |~~ train@54912  Loss: 0.002003 Acc: 13.2656\n",
      " |~~ train@54976  Loss: 0.002096 Acc: 13.2969\n",
      " |~~ train@55040  Loss: 0.001810 Acc: 13.4219\n",
      " |~~ train@55104  Loss: 0.002039 Acc: 13.3281\n",
      " |~~ train@55168  Loss: 0.002018 Acc: 13.3906\n",
      " |~~ train@55232  Loss: 0.001483 Acc: 13.5781\n",
      " |~~ train@55296  Loss: 0.002224 Acc: 13.1875\n",
      " |~~ train@55360  Loss: 0.002272 Acc: 13.2812\n",
      " |~~ train@55424  Loss: 0.001794 Acc: 13.4375\n",
      " |~~ train@55488  Loss: 0.002130 Acc: 13.3594\n",
      " |~~ train@55552  Loss: 0.002358 Acc: 13.3281\n",
      " |~~ train@55616  Loss: 0.001942 Acc: 13.3594\n",
      " |~~ train@55680  Loss: 0.001912 Acc: 13.3594\n",
      " |~~ train@55744  Loss: 0.001876 Acc: 13.3594\n",
      " |~~ train@55808  Loss: 0.001895 Acc: 13.3594\n",
      " |~~ train@55872  Loss: 0.002635 Acc: 13.2344\n",
      " |~~ train@55936  Loss: 0.001954 Acc: 13.3125\n",
      " |~~ train@56000  Loss: 0.002153 Acc: 13.3438\n",
      " |~~ train@56064  Loss: 0.002923 Acc: 12.9688\n",
      " |~~ train@56128  Loss: 0.001481 Acc: 13.5469\n",
      " |~~ train@56192  Loss: 0.002049 Acc: 13.3125\n",
      " |~~ train@56256  Loss: 0.001620 Acc: 13.4844\n",
      " |~~ train@56320  Loss: 0.002277 Acc: 13.3438\n",
      " |~~ train@56384  Loss: 0.001974 Acc: 13.3750\n",
      " |~~ train@56448  Loss: 0.001846 Acc: 13.4375\n",
      " |~~ train@56512  Loss: 0.002060 Acc: 13.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@56576  Loss: 0.001796 Acc: 13.4531\n",
      " |~~ train@56640  Loss: 0.002104 Acc: 13.4219\n",
      " |~~ train@56704  Loss: 0.001761 Acc: 13.3594\n",
      " |~~ train@56768  Loss: 0.002179 Acc: 13.2812\n",
      " |~~ train@56832  Loss: 0.001920 Acc: 13.4062\n",
      " |~~ train@56896  Loss: 0.001751 Acc: 13.4688\n",
      " |~~ train@56960  Loss: 0.002117 Acc: 13.3750\n",
      " |~~ train@57024  Loss: 0.001479 Acc: 13.5469\n",
      " |~~ train@57088  Loss: 0.002254 Acc: 13.3750\n",
      " |~~ train@57152  Loss: 0.001888 Acc: 13.3594\n",
      " |~~ train@57216  Loss: 0.001944 Acc: 13.3594\n",
      " |~~ train@57280  Loss: 0.002122 Acc: 13.2500\n",
      " |~~ train@57344  Loss: 0.001953 Acc: 13.3438\n",
      " |~~ train@57408  Loss: 0.001572 Acc: 13.4531\n",
      " |~~ train@57472  Loss: 0.002116 Acc: 13.3438\n",
      " |~~ train@57536  Loss: 0.001910 Acc: 13.4375\n",
      " |~~ train@57600  Loss: 0.002068 Acc: 13.2812\n",
      " |~~ train@57664  Loss: 0.002225 Acc: 13.2188\n",
      " |~~ train@57728  Loss: 0.002115 Acc: 13.2969\n",
      " |~~ train@57792  Loss: 0.001894 Acc: 13.4219\n",
      " |~~ train@57856  Loss: 0.001719 Acc: 13.5781\n",
      " |~~ train@57920  Loss: 0.002528 Acc: 13.1250\n",
      " |~~ train@57984  Loss: 0.002856 Acc: 13.2188\n",
      " |~~ train@58048  Loss: 0.002063 Acc: 13.4062\n",
      " |~~ train@58112  Loss: 0.002008 Acc: 13.3594\n",
      " |~~ train@58176  Loss: 0.002500 Acc: 13.0938\n",
      " |~~ train@58240  Loss: 0.001655 Acc: 13.5156\n",
      " |~~ train@58304  Loss: 0.001935 Acc: 13.4844\n",
      " |~~ train@58368  Loss: 0.001910 Acc: 13.3906\n",
      " |~~ train@58432  Loss: 0.001754 Acc: 13.4688\n",
      " |~~ train@58496  Loss: 0.001873 Acc: 13.2969\n",
      " |~~ train@58560  Loss: 0.001933 Acc: 13.3906\n",
      " |~~ train@58624  Loss: 0.002452 Acc: 13.1562\n",
      " |~~ train@58688  Loss: 0.001616 Acc: 13.5469\n",
      " |~~ train@58752  Loss: 0.002484 Acc: 13.1562\n",
      " |~~ train@58816  Loss: 0.001920 Acc: 13.3594\n",
      " |~~ train@58880  Loss: 0.001916 Acc: 13.3906\n",
      " |~~ train@58944  Loss: 0.002076 Acc: 13.3125\n",
      " |~~ train@59008  Loss: 0.001676 Acc: 13.4531\n",
      " |~~ train@59072  Loss: 0.002171 Acc: 13.3281\n",
      " |~~ train@59136  Loss: 0.001710 Acc: 13.4531\n",
      " |~~ train@59200  Loss: 0.001780 Acc: 13.5000\n",
      " |~~ train@59264  Loss: 0.002135 Acc: 13.3594\n",
      " |~~ train@59328  Loss: 0.002193 Acc: 13.2656\n",
      " |~~ train@59392  Loss: 0.002003 Acc: 13.3438\n",
      " |~~ train@59456  Loss: 0.002354 Acc: 13.0781\n",
      " |~~ train@59520  Loss: 0.001673 Acc: 13.4531\n",
      " |~~ train@59584  Loss: 0.001960 Acc: 13.3438\n",
      " |~~ train@59648  Loss: 0.002004 Acc: 13.4062\n",
      " |~~ train@59712  Loss: 0.001700 Acc: 13.5469\n",
      " |~~ train@59776  Loss: 0.001457 Acc: 13.5469\n",
      " |~~ train@59840  Loss: 0.001904 Acc: 13.3906\n",
      " |~~ train@59904  Loss: 0.002002 Acc: 13.3594\n",
      " |~~ train@59968  Loss: 0.001881 Acc: 13.4531\n",
      " |~~ train@60032  Loss: 0.002115 Acc: 13.2656\n",
      " |~~ train@60096  Loss: 0.001923 Acc: 13.3438\n",
      " |~~ train@60160  Loss: 0.001732 Acc: 13.5000\n",
      " |~~ train@60224  Loss: 0.002154 Acc: 13.2344\n",
      " |~~ train@60288  Loss: 0.002059 Acc: 13.3281\n",
      " |~~ train@60352  Loss: 0.001887 Acc: 13.4375\n",
      " |~~ train@60416  Loss: 0.002127 Acc: 13.2969\n",
      " |~~ train@60480  Loss: 0.002565 Acc: 13.1875\n",
      " |~~ train@60544  Loss: 0.001577 Acc: 13.5000\n",
      " |~~ train@60608  Loss: 0.002256 Acc: 13.2969\n",
      " |~~ train@60672  Loss: 0.002213 Acc: 13.2656\n",
      " |~~ train@60736  Loss: 0.001824 Acc: 13.4844\n",
      " |~~ train@60800  Loss: 0.001892 Acc: 13.3750\n",
      " |~~ train@60864  Loss: 0.001943 Acc: 13.5000\n",
      " |~~ train@60928  Loss: 0.002355 Acc: 13.2969\n",
      " |~~ train@60992  Loss: 0.001768 Acc: 13.3750\n",
      " |~~ train@61056  Loss: 0.001681 Acc: 13.4375\n",
      " |~~ train@61120  Loss: 0.002042 Acc: 13.3594\n",
      " |~~ train@61184  Loss: 0.001855 Acc: 13.2969\n",
      " |~~ train@61248  Loss: 0.001688 Acc: 13.5469\n",
      " |~~ train@61312  Loss: 0.002145 Acc: 13.3594\n",
      " |~~ train@61376  Loss: 0.001897 Acc: 13.5000\n",
      " |~~ train@61440  Loss: 0.002045 Acc: 13.2969\n",
      " |~~ train@61504  Loss: 0.001700 Acc: 13.4688\n",
      " |~~ train@61568  Loss: 0.002208 Acc: 13.3125\n",
      " |~~ train@61632  Loss: 0.002141 Acc: 13.3438\n",
      " |~~ train@61696  Loss: 0.001994 Acc: 13.3125\n",
      " |~~ train@61760  Loss: 0.001810 Acc: 13.4844\n",
      " |~~ train@61824  Loss: 0.002389 Acc: 13.0312\n",
      " |~~ train@61888  Loss: 0.002500 Acc: 13.1094\n",
      " |~~ train@61952  Loss: 0.002633 Acc: 13.2188\n",
      " |~~ train@62016  Loss: 0.001853 Acc: 13.4375\n",
      " |~~ train@62080  Loss: 0.001768 Acc: 13.4062\n",
      " |~~ train@62144  Loss: 0.001830 Acc: 13.4688\n",
      " |~~ train@62208  Loss: 0.002118 Acc: 13.3594\n",
      " |~~ train@62272  Loss: 0.002692 Acc: 13.0781\n",
      " |~~ train@62336  Loss: 0.001760 Acc: 13.4688\n",
      " |~~ train@62400  Loss: 0.001761 Acc: 13.5469\n",
      " |~~ train@62464  Loss: 0.001892 Acc: 13.4531\n",
      " |~~ train@62528  Loss: 0.001417 Acc: 13.6250\n",
      " |~~ train@62592  Loss: 0.002128 Acc: 13.2500\n",
      " |~~ train@62656  Loss: 0.002028 Acc: 13.4688\n",
      " |~~ train@62720  Loss: 0.002472 Acc: 13.2188\n",
      " |~~ train@62784  Loss: 0.002030 Acc: 13.3594\n",
      " |~~ train@62848  Loss: 0.002389 Acc: 13.2500\n",
      " |~~ train@62912  Loss: 0.002006 Acc: 13.4062\n",
      " |~~ train@62976  Loss: 0.001946 Acc: 13.3906\n",
      " |~~ train@63040  Loss: 0.001905 Acc: 13.4688\n",
      " |~~ train@63104  Loss: 0.001892 Acc: 13.4219\n",
      " |~~ train@63168  Loss: 0.002097 Acc: 13.3594\n",
      " |~~ train@63232  Loss: 0.002159 Acc: 13.2812\n",
      " |~~ train@63296  Loss: 0.002047 Acc: 13.4219\n",
      " |~~ train@63360  Loss: 0.001904 Acc: 13.3438\n",
      " |~~ train@63424  Loss: 0.002131 Acc: 13.2500\n",
      " |~~ train@63488  Loss: 0.002444 Acc: 13.1250\n",
      " |~~ train@63552  Loss: 0.001704 Acc: 13.4844\n",
      " |~~ train@63616  Loss: 0.002068 Acc: 13.3281\n",
      " |~~ train@63680  Loss: 0.002049 Acc: 13.4062\n",
      " |~~ train@63744  Loss: 0.001360 Acc: 13.5156\n",
      " |~~ train@63808  Loss: 0.001609 Acc: 13.5781\n",
      " |~~ train@63872  Loss: 0.001760 Acc: 13.3906\n",
      " |~~ train@63936  Loss: 0.002109 Acc: 13.2812\n",
      " |~~ train@64000  Loss: 0.002380 Acc: 13.2188\n",
      " |~~ train@64064  Loss: 0.001850 Acc: 13.4375\n",
      " |~~ train@64128  Loss: 0.002799 Acc: 13.0312\n",
      " |~~ train@64192  Loss: 0.002279 Acc: 13.2344\n",
      " |~~ train@64256  Loss: 0.002295 Acc: 13.2969\n",
      " |~~ train@64320  Loss: 0.001914 Acc: 13.4375\n",
      " |~~ train@64384  Loss: 0.002083 Acc: 13.3281\n",
      " |~~ train@64448  Loss: 0.002021 Acc: 13.3750\n",
      " |~~ train@64512  Loss: 0.001698 Acc: 13.4531\n",
      " |~~ train@64576  Loss: 0.002177 Acc: 13.3125\n",
      " |~~ train@64640  Loss: 0.002652 Acc: 13.1875\n",
      " |~~ train@64704  Loss: 0.001771 Acc: 13.4062\n",
      " |~~ train@64768  Loss: 0.001518 Acc: 13.4375\n",
      " |~~ train@64832  Loss: 0.001649 Acc: 13.5312\n",
      " |~~ train@64896  Loss: 0.002467 Acc: 13.0938\n",
      " |~~ train@64960  Loss: 0.002072 Acc: 13.2969\n",
      " |~~ train@65024  Loss: 0.002292 Acc: 13.2344\n",
      " |~~ train@65088  Loss: 0.002256 Acc: 13.2500\n",
      " |~~ train@65152  Loss: 0.001763 Acc: 13.4062\n",
      " |~~ train@65216  Loss: 0.001805 Acc: 13.4219\n",
      " |~~ train@65280  Loss: 0.001644 Acc: 13.5000\n",
      " |~~ train@65344  Loss: 0.002139 Acc: 13.2500\n",
      " |~~ train@65408  Loss: 0.001938 Acc: 13.4531\n",
      " |~~ train@65472  Loss: 0.001887 Acc: 13.3438\n",
      " |~~ train@65536  Loss: 0.001820 Acc: 13.4688\n",
      " |~~ train@65600  Loss: 0.001807 Acc: 13.4062\n",
      " |~~ train@65664  Loss: 0.002207 Acc: 13.2812\n",
      " |~~ train@65728  Loss: 0.002352 Acc: 13.2188\n",
      " |~~ train@65792  Loss: 0.002480 Acc: 13.2188\n",
      " |~~ train@65856  Loss: 0.001935 Acc: 13.3281\n",
      " |~~ train@65920  Loss: 0.001644 Acc: 13.4688\n",
      " |~~ train@65984  Loss: 0.001905 Acc: 13.3438\n",
      " |~~ train@66048  Loss: 0.001983 Acc: 13.3594\n",
      " |~~ train@66112  Loss: 0.001893 Acc: 13.3281\n",
      " |~~ train@66176  Loss: 0.002176 Acc: 13.2812\n",
      " |~~ train@66240  Loss: 0.002579 Acc: 13.1250\n",
      " |~~ train@66304  Loss: 0.001841 Acc: 13.4062\n",
      " |~~ train@66368  Loss: 0.001871 Acc: 13.3750\n",
      " |~~ train@66432  Loss: 0.001968 Acc: 13.3906\n",
      " |~~ train@66496  Loss: 0.002147 Acc: 13.2031\n",
      " |~~ train@66560  Loss: 0.002056 Acc: 13.2969\n",
      " |~~ train@66624  Loss: 0.001679 Acc: 13.5000\n",
      " |~~ train@66688  Loss: 0.002438 Acc: 13.2969\n",
      " |~~ train@66752  Loss: 0.001429 Acc: 13.6406\n",
      " |~~ train@66816  Loss: 0.001618 Acc: 13.5938\n",
      " |~~ train@66880  Loss: 0.002048 Acc: 13.3125\n",
      " |~~ train@66944  Loss: 0.002252 Acc: 13.2969\n",
      " |~~ train@67008  Loss: 0.001993 Acc: 13.3125\n",
      " |~~ train@67072  Loss: 0.002109 Acc: 13.2969\n",
      " |~~ train@67136  Loss: 0.001838 Acc: 13.3594\n",
      " |~~ train@67200  Loss: 0.002235 Acc: 13.2969\n",
      " |~~ train@67264  Loss: 0.002054 Acc: 13.3438\n",
      " |~~ train@67328  Loss: 0.002662 Acc: 13.0938\n",
      " |~~ train@67392  Loss: 0.001959 Acc: 13.3438\n",
      " |~~ train@67456  Loss: 0.002237 Acc: 13.2500\n",
      " |~~ train@67520  Loss: 0.001619 Acc: 13.4531\n",
      " |~~ train@67584  Loss: 0.002202 Acc: 13.2188\n",
      " |~~ train@67648  Loss: 0.002021 Acc: 13.4062\n",
      " |~~ train@67712  Loss: 0.001892 Acc: 13.3281\n",
      " |~~ train@67776  Loss: 0.002227 Acc: 13.2969\n",
      " |~~ train@67840  Loss: 0.001880 Acc: 13.3594\n",
      " |~~ train@67904  Loss: 0.001667 Acc: 13.4531\n",
      " |~~ train@67968  Loss: 0.001608 Acc: 13.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@68032  Loss: 0.001991 Acc: 13.3125\n",
      " |~~ train@68096  Loss: 0.001884 Acc: 13.2656\n",
      " |~~ train@68160  Loss: 0.001975 Acc: 13.3750\n",
      " |~~ train@68224  Loss: 0.002605 Acc: 13.2188\n",
      " |~~ train@68288  Loss: 0.001695 Acc: 13.5469\n",
      " |~~ train@68352  Loss: 0.002081 Acc: 13.3906\n",
      " |~~ train@68416  Loss: 0.001663 Acc: 13.4688\n",
      " |~~ train@68480  Loss: 0.002363 Acc: 13.2812\n",
      " |~~ train@68544  Loss: 0.002094 Acc: 13.3281\n",
      " |~~ train@68608  Loss: 0.001839 Acc: 13.4688\n",
      " |~~ train@68672  Loss: 0.001421 Acc: 13.6094\n",
      " |~~ train@68736  Loss: 0.002256 Acc: 13.1875\n",
      " |~~ train@68800  Loss: 0.001730 Acc: 13.5000\n",
      " |~~ train@68864  Loss: 0.002428 Acc: 13.1250\n",
      " |~~ train@68928  Loss: 0.001812 Acc: 13.4531\n",
      " |~~ train@68992  Loss: 0.001925 Acc: 13.3906\n",
      " |~~ train@69056  Loss: 0.001795 Acc: 13.5000\n",
      " |~~ train@69120  Loss: 0.002124 Acc: 13.3281\n",
      " |~~ train@69184  Loss: 0.001942 Acc: 13.3125\n",
      " |~~ train@69248  Loss: 0.002228 Acc: 13.3125\n",
      " |~~ train@69312  Loss: 0.002369 Acc: 13.3125\n",
      " |~~ train@69376  Loss: 0.002110 Acc: 13.3281\n",
      " |~~ train@69440  Loss: 0.001658 Acc: 13.5469\n",
      " |~~ train@69504  Loss: 0.002087 Acc: 13.2969\n",
      " |~~ train@69568  Loss: 0.002145 Acc: 13.3438\n",
      " |~~ train@69632  Loss: 0.001887 Acc: 13.4688\n",
      " |~~ train@69696  Loss: 0.001969 Acc: 13.3750\n",
      " |~~ train@69760  Loss: 0.001738 Acc: 13.4531\n",
      " |~~ train@69824  Loss: 0.001619 Acc: 13.5781\n",
      " |~~ train@69888  Loss: 0.002003 Acc: 13.3750\n",
      " |~~ train@69952  Loss: 0.001942 Acc: 13.4375\n",
      " |~~ train@70016  Loss: 0.001713 Acc: 13.4688\n",
      " |~~ train@70080  Loss: 0.002271 Acc: 13.2500\n",
      " |~~ train@70144  Loss: 0.002427 Acc: 13.2344\n",
      " |~~ train@70208  Loss: 0.001528 Acc: 13.5000\n",
      " |~~ train@70272  Loss: 0.001620 Acc: 13.4531\n",
      " |~~ train@70336  Loss: 0.001954 Acc: 13.4531\n",
      " |~~ train@70400  Loss: 0.001703 Acc: 13.4688\n",
      " |~~ train@70464  Loss: 0.002278 Acc: 13.2656\n",
      " |~~ train@70528  Loss: 0.002011 Acc: 13.2500\n",
      " |~~ train@70592  Loss: 0.002214 Acc: 13.1250\n",
      " |~~ train@70656  Loss: 0.002342 Acc: 13.2344\n",
      " |~~ train@70720  Loss: 0.002505 Acc: 13.1719\n",
      " |~~ train@70784  Loss: 0.001811 Acc: 13.4688\n",
      " |~~ train@70848  Loss: 0.001746 Acc: 13.3750\n",
      " |~~ train@70912  Loss: 0.002395 Acc: 13.1562\n",
      " |~~ train@70976  Loss: 0.002026 Acc: 13.3594\n",
      " |~~ train@71040  Loss: 0.001751 Acc: 13.4375\n",
      " |~~ train@71104  Loss: 0.001927 Acc: 13.4219\n",
      " |~~ train@71168  Loss: 0.001603 Acc: 13.5938\n",
      " |~~ train@71232  Loss: 0.001999 Acc: 13.3281\n",
      " |~~ train@71296  Loss: 0.001457 Acc: 13.5938\n",
      " |~~ train@71360  Loss: 0.002193 Acc: 13.2344\n",
      " |~~ train@71424  Loss: 0.001486 Acc: 13.5156\n",
      " |~~ train@71488  Loss: 0.001770 Acc: 13.4375\n",
      " |~~ train@71552  Loss: 0.001944 Acc: 13.3750\n",
      " |~~ train@71616  Loss: 0.001827 Acc: 13.3906\n",
      " |~~ train@71680  Loss: 0.001716 Acc: 13.4688\n",
      " |~~ train@71744  Loss: 0.001846 Acc: 13.4062\n",
      " |~~ train@71808  Loss: 0.002059 Acc: 13.3438\n",
      " |~~ train@71872  Loss: 0.002017 Acc: 13.3594\n",
      " |~~ train@71936  Loss: 0.001913 Acc: 13.3594\n",
      " |~~ train@72000  Loss: 0.001977 Acc: 13.3281\n",
      " |~~ train@72064  Loss: 0.001941 Acc: 13.3594\n",
      " |~~ train@72128  Loss: 0.002165 Acc: 13.2969\n",
      " |~~ train@72192  Loss: 0.002076 Acc: 13.3125\n",
      " |~~ train@72256  Loss: 0.001826 Acc: 13.4844\n",
      " |~~ train@72320  Loss: 0.001711 Acc: 13.5000\n",
      " |~~ train@72384  Loss: 0.001794 Acc: 13.4531\n",
      " |~~ train@72448  Loss: 0.002324 Acc: 13.2344\n",
      " |~~ train@72512  Loss: 0.001954 Acc: 13.4375\n",
      " |~~ train@72576  Loss: 0.001958 Acc: 13.4375\n",
      " |~~ train@72640  Loss: 0.002182 Acc: 13.2500\n",
      " |~~ train@72704  Loss: 0.001714 Acc: 13.4531\n",
      " |~~ train@72768  Loss: 0.001875 Acc: 13.4375\n",
      " |~~ train@72832  Loss: 0.001754 Acc: 13.4062\n",
      " |~~ train@72896  Loss: 0.002797 Acc: 13.0000\n",
      " |~~ train@72960  Loss: 0.002259 Acc: 13.2969\n",
      " |~~ train@73024  Loss: 0.002321 Acc: 13.1250\n",
      " |~~ train@73088  Loss: 0.001441 Acc: 13.5156\n",
      " |~~ train@73152  Loss: 0.001888 Acc: 13.4531\n",
      " |~~ train@73216  Loss: 0.001833 Acc: 13.3594\n",
      " |~~ train@73280  Loss: 0.001883 Acc: 13.4219\n",
      " |~~ train@73344  Loss: 0.001965 Acc: 13.3594\n",
      " |~~ train@73408  Loss: 0.002150 Acc: 13.3281\n",
      " |~~ train@73472  Loss: 0.001718 Acc: 13.5156\n",
      " |~~ train@73536  Loss: 0.002504 Acc: 13.0781\n",
      " |~~ train@73600  Loss: 0.002152 Acc: 13.3125\n",
      " |~~ train@73664  Loss: 0.002205 Acc: 13.2500\n",
      " |~~ train@73728  Loss: 0.002079 Acc: 13.3438\n",
      " |~~ train@73792  Loss: 0.002575 Acc: 13.1094\n",
      " |~~ train@73856  Loss: 0.002180 Acc: 13.3125\n",
      " |~~ train@73920  Loss: 0.001949 Acc: 13.3906\n",
      " |~~ train@73984  Loss: 0.001889 Acc: 13.3906\n",
      " |~~ train@74048  Loss: 0.001638 Acc: 13.5625\n",
      " |~~ train@74112  Loss: 0.001968 Acc: 13.3281\n",
      " |~~ train@74176  Loss: 0.002045 Acc: 13.2656\n",
      " |~~ train@74240  Loss: 0.002122 Acc: 13.3594\n",
      " |~~ train@74304  Loss: 0.002290 Acc: 13.2031\n",
      " |~~ train@74368  Loss: 0.001773 Acc: 13.4688\n",
      " |~~ train@74432  Loss: 0.001945 Acc: 13.4219\n",
      " |~~ train@74496  Loss: 0.001793 Acc: 13.4062\n",
      " |~~ train@74560  Loss: 0.001956 Acc: 13.4062\n",
      " |~~ train@74624  Loss: 0.001557 Acc: 13.4844\n",
      " |~~ train@74688  Loss: 0.002226 Acc: 13.4062\n",
      " |~~ train@74752  Loss: 0.002122 Acc: 13.3125\n",
      " |~~ train@74816  Loss: 0.001635 Acc: 13.5000\n",
      " |~~ train@74880  Loss: 0.001506 Acc: 13.5625\n",
      " |~~ train@74944  Loss: 0.002002 Acc: 13.3594\n",
      " |~~ train@75008  Loss: 0.001800 Acc: 13.4688\n",
      " |~~ train@75072  Loss: 0.001755 Acc: 13.4375\n",
      " |~~ train@75136  Loss: 0.001990 Acc: 13.3438\n",
      " |~~ train@75200  Loss: 0.002355 Acc: 13.2656\n",
      " |~~ train@75264  Loss: 0.002368 Acc: 13.2344\n",
      " |~~ train@75328  Loss: 0.001940 Acc: 13.4062\n",
      " |~~ train@75392  Loss: 0.001951 Acc: 13.3281\n",
      " |~~ train@75456  Loss: 0.002218 Acc: 13.2500\n",
      " |~~ train@75520  Loss: 0.002325 Acc: 13.2500\n",
      " |~~ train@75584  Loss: 0.002055 Acc: 13.3281\n",
      " |~~ train@75648  Loss: 0.001977 Acc: 13.3281\n",
      " |~~ train@75712  Loss: 0.001789 Acc: 13.4375\n",
      " |~~ train@75776  Loss: 0.002162 Acc: 13.3438\n",
      " |~~ train@75840  Loss: 0.002062 Acc: 13.2656\n",
      " |~~ train@75904  Loss: 0.001707 Acc: 13.4688\n",
      " |~~ train@75968  Loss: 0.001719 Acc: 13.4844\n",
      " |~~ train@76032  Loss: 0.001753 Acc: 13.4531\n",
      " |~~ train@76096  Loss: 0.002320 Acc: 13.2031\n",
      " |~~ train@76160  Loss: 0.002066 Acc: 13.2656\n",
      " |~~ train@76224  Loss: 0.002455 Acc: 13.1250\n",
      " |~~ train@76288  Loss: 0.001823 Acc: 13.4844\n",
      " |~~ train@76352  Loss: 0.002074 Acc: 13.3438\n",
      " |~~ train@76416  Loss: 0.001902 Acc: 13.3750\n",
      " |~~ train@76480  Loss: 0.001859 Acc: 13.4062\n",
      " |~~ train@76544  Loss: 0.002425 Acc: 13.1250\n",
      " |~~ train@76608  Loss: 0.001681 Acc: 13.5156\n",
      " |~~ train@76672  Loss: 0.001800 Acc: 13.2500\n",
      " |~~ train@76736  Loss: 0.002182 Acc: 13.3281\n",
      " |~~ train@76800  Loss: 0.001798 Acc: 13.4375\n",
      " |~~ train@76864  Loss: 0.002207 Acc: 13.3281\n",
      " |~~ train@76928  Loss: 0.001970 Acc: 13.3906\n",
      " |~~ train@76992  Loss: 0.002081 Acc: 13.2969\n",
      " |~~ train@77056  Loss: 0.002569 Acc: 13.1406\n",
      " |~~ train@77120  Loss: 0.002038 Acc: 13.2969\n",
      " |~~ train@77184  Loss: 0.002345 Acc: 13.2656\n",
      " |~~ train@77248  Loss: 0.001862 Acc: 13.3750\n",
      " |~~ train@77312  Loss: 0.002343 Acc: 13.3125\n",
      " |~~ train@77376  Loss: 0.002221 Acc: 13.2969\n",
      " |~~ train@77440  Loss: 0.002056 Acc: 13.4219\n",
      " |~~ train@77504  Loss: 0.001615 Acc: 13.5625\n",
      " |~~ train@77568  Loss: 0.001853 Acc: 13.3594\n",
      " |~~ train@77632  Loss: 0.001961 Acc: 13.3281\n",
      " |~~ train@77696  Loss: 0.002456 Acc: 13.2656\n",
      " |~~ train@77760  Loss: 0.001795 Acc: 13.4844\n",
      " |~~ train@77824  Loss: 0.002403 Acc: 13.1406\n",
      " |~~ train@77888  Loss: 0.001920 Acc: 13.4688\n",
      " |~~ train@77952  Loss: 0.002200 Acc: 13.1719\n",
      " |~~ train@78016  Loss: 0.001852 Acc: 13.5000\n",
      " |~~ train@78080  Loss: 0.001379 Acc: 13.5938\n",
      " |~~ train@78144  Loss: 0.002142 Acc: 13.3281\n",
      " |~~ train@78208  Loss: 0.002313 Acc: 13.2344\n",
      " |~~ train@78272  Loss: 0.002060 Acc: 13.4219\n",
      " |~~ train@78336  Loss: 0.001882 Acc: 13.4219\n",
      " |~~ train@78400  Loss: 0.002063 Acc: 13.3906\n",
      " |~~ train@78464  Loss: 0.002081 Acc: 13.2656\n",
      " |~~ train@78484  Loss: 0.004632 Acc: 13.4000\n",
      "train  Loss: 0.002030 Acc: 13.3468\n",
      " |~~ val@64  Loss: 0.002445 Acc: 13.2656\n",
      " |~~ val@128  Loss: 0.002737 Acc: 13.2344\n",
      " |~~ val@192  Loss: 0.002849 Acc: 13.1250\n",
      " |~~ val@256  Loss: 0.002053 Acc: 13.3906\n",
      " |~~ val@320  Loss: 0.002685 Acc: 13.1250\n",
      " |~~ val@384  Loss: 0.002137 Acc: 13.3125\n",
      " |~~ val@448  Loss: 0.002135 Acc: 13.4062\n",
      " |~~ val@512  Loss: 0.002603 Acc: 13.1250\n",
      " |~~ val@576  Loss: 0.002420 Acc: 13.3281\n",
      " |~~ val@640  Loss: 0.002795 Acc: 13.0938\n",
      " |~~ val@704  Loss: 0.002834 Acc: 13.0938\n",
      " |~~ val@768  Loss: 0.001904 Acc: 13.5000\n",
      " |~~ val@832  Loss: 0.001677 Acc: 13.4844\n",
      " |~~ val@896  Loss: 0.002842 Acc: 13.0781\n",
      " |~~ val@960  Loss: 0.002310 Acc: 13.2656\n",
      " |~~ val@1024  Loss: 0.002197 Acc: 13.4219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@1088  Loss: 0.002962 Acc: 13.1719\n",
      " |~~ val@1152  Loss: 0.001589 Acc: 13.5312\n",
      " |~~ val@1216  Loss: 0.002459 Acc: 13.2344\n",
      " |~~ val@1280  Loss: 0.002131 Acc: 13.3906\n",
      " |~~ val@1344  Loss: 0.002180 Acc: 13.2812\n",
      " |~~ val@1408  Loss: 0.002360 Acc: 13.2969\n",
      " |~~ val@1472  Loss: 0.002933 Acc: 13.1562\n",
      " |~~ val@1536  Loss: 0.002475 Acc: 13.2344\n",
      " |~~ val@1600  Loss: 0.001715 Acc: 13.5469\n",
      " |~~ val@1664  Loss: 0.002252 Acc: 13.3750\n",
      " |~~ val@1728  Loss: 0.002955 Acc: 13.1719\n",
      " |~~ val@1792  Loss: 0.002463 Acc: 13.3125\n",
      " |~~ val@1856  Loss: 0.002972 Acc: 13.0938\n",
      " |~~ val@1920  Loss: 0.003004 Acc: 13.0625\n",
      " |~~ val@1984  Loss: 0.002978 Acc: 13.1719\n",
      " |~~ val@2048  Loss: 0.002464 Acc: 13.2656\n",
      " |~~ val@2112  Loss: 0.002802 Acc: 13.0469\n",
      " |~~ val@2176  Loss: 0.002272 Acc: 13.3438\n",
      " |~~ val@2240  Loss: 0.002865 Acc: 13.2656\n",
      " |~~ val@2304  Loss: 0.002749 Acc: 13.1094\n",
      " |~~ val@2368  Loss: 0.002493 Acc: 13.1875\n",
      " |~~ val@2432  Loss: 0.001944 Acc: 13.4531\n",
      " |~~ val@2496  Loss: 0.002047 Acc: 13.3594\n",
      " |~~ val@2560  Loss: 0.003007 Acc: 13.0000\n",
      " |~~ val@2624  Loss: 0.002395 Acc: 13.2812\n",
      " |~~ val@2688  Loss: 0.002214 Acc: 13.2500\n",
      " |~~ val@2752  Loss: 0.002412 Acc: 13.2656\n",
      " |~~ val@2816  Loss: 0.002246 Acc: 13.2812\n",
      " |~~ val@2880  Loss: 0.001643 Acc: 13.4219\n",
      " |~~ val@2944  Loss: 0.002533 Acc: 13.2812\n",
      " |~~ val@3008  Loss: 0.002393 Acc: 13.1875\n",
      " |~~ val@3072  Loss: 0.002935 Acc: 13.2344\n",
      " |~~ val@3136  Loss: 0.002253 Acc: 13.2500\n",
      " |~~ val@3200  Loss: 0.002200 Acc: 13.3125\n",
      " |~~ val@3264  Loss: 0.002259 Acc: 13.3906\n",
      " |~~ val@3328  Loss: 0.002122 Acc: 13.3438\n",
      " |~~ val@3392  Loss: 0.002248 Acc: 13.3750\n",
      " |~~ val@3456  Loss: 0.002135 Acc: 13.4844\n",
      " |~~ val@3520  Loss: 0.002359 Acc: 13.2344\n",
      " |~~ val@3584  Loss: 0.002089 Acc: 13.5000\n",
      " |~~ val@3648  Loss: 0.001694 Acc: 13.6094\n",
      " |~~ val@3712  Loss: 0.002637 Acc: 13.2031\n",
      " |~~ val@3776  Loss: 0.002140 Acc: 13.3594\n",
      " |~~ val@3840  Loss: 0.002566 Acc: 13.2188\n",
      " |~~ val@3904  Loss: 0.002693 Acc: 13.1406\n",
      " |~~ val@3968  Loss: 0.002177 Acc: 13.3438\n",
      " |~~ val@4032  Loss: 0.001916 Acc: 13.3906\n",
      " |~~ val@4096  Loss: 0.002190 Acc: 13.3125\n",
      " |~~ val@4160  Loss: 0.002714 Acc: 13.2188\n",
      " |~~ val@4224  Loss: 0.002299 Acc: 13.3125\n",
      " |~~ val@4288  Loss: 0.002252 Acc: 13.3438\n",
      " |~~ val@4352  Loss: 0.002482 Acc: 13.2969\n",
      " |~~ val@4416  Loss: 0.002796 Acc: 13.1562\n",
      " |~~ val@4480  Loss: 0.002362 Acc: 13.2656\n",
      " |~~ val@4544  Loss: 0.002164 Acc: 13.4062\n",
      " |~~ val@4608  Loss: 0.002592 Acc: 13.0781\n",
      " |~~ val@4672  Loss: 0.002268 Acc: 13.2969\n",
      " |~~ val@4736  Loss: 0.002606 Acc: 13.2344\n",
      " |~~ val@4800  Loss: 0.002197 Acc: 13.3125\n",
      " |~~ val@4864  Loss: 0.002400 Acc: 13.3594\n",
      " |~~ val@4928  Loss: 0.002709 Acc: 13.1719\n",
      " |~~ val@4992  Loss: 0.002231 Acc: 13.3438\n",
      " |~~ val@5056  Loss: 0.002256 Acc: 13.4219\n",
      " |~~ val@5120  Loss: 0.002565 Acc: 13.2656\n",
      " |~~ val@5184  Loss: 0.002769 Acc: 13.2188\n",
      " |~~ val@5248  Loss: 0.003068 Acc: 13.0938\n",
      " |~~ val@5312  Loss: 0.002428 Acc: 13.2344\n",
      " |~~ val@5376  Loss: 0.002676 Acc: 13.1094\n",
      " |~~ val@5440  Loss: 0.002405 Acc: 13.2656\n",
      " |~~ val@5504  Loss: 0.001855 Acc: 13.4219\n",
      " |~~ val@5568  Loss: 0.002483 Acc: 13.1719\n",
      " |~~ val@5632  Loss: 0.002425 Acc: 13.2812\n",
      " |~~ val@5696  Loss: 0.002156 Acc: 13.4219\n",
      " |~~ val@5760  Loss: 0.002016 Acc: 13.3594\n",
      " |~~ val@5824  Loss: 0.002180 Acc: 13.3281\n",
      " |~~ val@5888  Loss: 0.003198 Acc: 13.0312\n",
      " |~~ val@5952  Loss: 0.002627 Acc: 13.2031\n",
      " |~~ val@6016  Loss: 0.002365 Acc: 13.2500\n",
      " |~~ val@6080  Loss: 0.002247 Acc: 13.2500\n",
      " |~~ val@6144  Loss: 0.001929 Acc: 13.4531\n",
      " |~~ val@6208  Loss: 0.002205 Acc: 13.4219\n",
      " |~~ val@6272  Loss: 0.002176 Acc: 13.2812\n",
      " |~~ val@6336  Loss: 0.001984 Acc: 13.3906\n",
      " |~~ val@6400  Loss: 0.002629 Acc: 13.2031\n",
      " |~~ val@6464  Loss: 0.001998 Acc: 13.3438\n",
      " |~~ val@6528  Loss: 0.002073 Acc: 13.2656\n",
      " |~~ val@6592  Loss: 0.003079 Acc: 13.0938\n",
      " |~~ val@6656  Loss: 0.002513 Acc: 13.1094\n",
      " |~~ val@6720  Loss: 0.002297 Acc: 13.3750\n",
      " |~~ val@6784  Loss: 0.001947 Acc: 13.4375\n",
      " |~~ val@6848  Loss: 0.002742 Acc: 13.1875\n",
      " |~~ val@6912  Loss: 0.002643 Acc: 13.1875\n",
      " |~~ val@6976  Loss: 0.001904 Acc: 13.3281\n",
      " |~~ val@7040  Loss: 0.002340 Acc: 13.2969\n",
      " |~~ val@7104  Loss: 0.003288 Acc: 13.0312\n",
      " |~~ val@7168  Loss: 0.002671 Acc: 13.0781\n",
      " |~~ val@7232  Loss: 0.002250 Acc: 13.3281\n",
      " |~~ val@7296  Loss: 0.002013 Acc: 13.4062\n",
      " |~~ val@7360  Loss: 0.002113 Acc: 13.4062\n",
      " |~~ val@7424  Loss: 0.002140 Acc: 13.3906\n",
      " |~~ val@7488  Loss: 0.002554 Acc: 13.2344\n",
      " |~~ val@7552  Loss: 0.002497 Acc: 13.3281\n",
      " |~~ val@7616  Loss: 0.002860 Acc: 13.1719\n",
      " |~~ val@7680  Loss: 0.001577 Acc: 13.6094\n",
      " |~~ val@7744  Loss: 0.002352 Acc: 13.2969\n",
      " |~~ val@7808  Loss: 0.002339 Acc: 13.2344\n",
      " |~~ val@7872  Loss: 0.002098 Acc: 13.3281\n",
      " |~~ val@7936  Loss: 0.002697 Acc: 13.1406\n",
      " |~~ val@8000  Loss: 0.002522 Acc: 13.2031\n",
      " |~~ val@8064  Loss: 0.002769 Acc: 13.0781\n",
      " |~~ val@8128  Loss: 0.002590 Acc: 13.2500\n",
      " |~~ val@8192  Loss: 0.002340 Acc: 13.1875\n",
      " |~~ val@8256  Loss: 0.002640 Acc: 13.3125\n",
      " |~~ val@8320  Loss: 0.001965 Acc: 13.4219\n",
      " |~~ val@8384  Loss: 0.002451 Acc: 13.3750\n",
      " |~~ val@8448  Loss: 0.002138 Acc: 13.3125\n",
      " |~~ val@8512  Loss: 0.002400 Acc: 13.2656\n",
      " |~~ val@8576  Loss: 0.002016 Acc: 13.4844\n",
      " |~~ val@8640  Loss: 0.002503 Acc: 13.2344\n",
      " |~~ val@8704  Loss: 0.002447 Acc: 13.1875\n",
      " |~~ val@8768  Loss: 0.002463 Acc: 13.2188\n",
      " |~~ val@8832  Loss: 0.002820 Acc: 13.1875\n",
      " |~~ val@8896  Loss: 0.002267 Acc: 13.3438\n",
      " |~~ val@8960  Loss: 0.002942 Acc: 13.0312\n",
      " |~~ val@9024  Loss: 0.002793 Acc: 13.1562\n",
      " |~~ val@9088  Loss: 0.002161 Acc: 13.3750\n",
      " |~~ val@9152  Loss: 0.002324 Acc: 13.2500\n",
      " |~~ val@9216  Loss: 0.002212 Acc: 13.3906\n",
      " |~~ val@9280  Loss: 0.002603 Acc: 13.2031\n",
      " |~~ val@9344  Loss: 0.002069 Acc: 13.4062\n",
      " |~~ val@9408  Loss: 0.002501 Acc: 13.3125\n",
      " |~~ val@9472  Loss: 0.002604 Acc: 13.1250\n",
      " |~~ val@9536  Loss: 0.002158 Acc: 13.4062\n",
      " |~~ val@9600  Loss: 0.002062 Acc: 13.3906\n",
      " |~~ val@9664  Loss: 0.002876 Acc: 13.0625\n",
      " |~~ val@9728  Loss: 0.002560 Acc: 13.1875\n",
      " |~~ val@9792  Loss: 0.002226 Acc: 13.2812\n",
      " |~~ val@9856  Loss: 0.002352 Acc: 13.2812\n",
      " |~~ val@9920  Loss: 0.002669 Acc: 13.2344\n",
      " |~~ val@9984  Loss: 0.002409 Acc: 13.2031\n",
      " |~~ val@10048  Loss: 0.002160 Acc: 13.3594\n",
      " |~~ val@10112  Loss: 0.001895 Acc: 13.4531\n",
      " |~~ val@10176  Loss: 0.002086 Acc: 13.4219\n",
      " |~~ val@10240  Loss: 0.002503 Acc: 13.2812\n",
      " |~~ val@10304  Loss: 0.002416 Acc: 13.2969\n",
      " |~~ val@10368  Loss: 0.003150 Acc: 12.9531\n",
      " |~~ val@10432  Loss: 0.002126 Acc: 13.3438\n",
      " |~~ val@10496  Loss: 0.002047 Acc: 13.2500\n",
      " |~~ val@10560  Loss: 0.002369 Acc: 13.2969\n",
      " |~~ val@10624  Loss: 0.002320 Acc: 13.2969\n",
      " |~~ val@10688  Loss: 0.002250 Acc: 13.2500\n",
      " |~~ val@10752  Loss: 0.002614 Acc: 13.2812\n",
      " |~~ val@10816  Loss: 0.003085 Acc: 12.9375\n",
      " |~~ val@10880  Loss: 0.002551 Acc: 13.1875\n",
      " |~~ val@10944  Loss: 0.002262 Acc: 13.3438\n",
      " |~~ val@11008  Loss: 0.002053 Acc: 13.3594\n",
      " |~~ val@11072  Loss: 0.001885 Acc: 13.5469\n",
      " |~~ val@11136  Loss: 0.002259 Acc: 13.2812\n",
      " |~~ val@11200  Loss: 0.002058 Acc: 13.3906\n",
      " |~~ val@11264  Loss: 0.002341 Acc: 13.2969\n",
      " |~~ val@11328  Loss: 0.002117 Acc: 13.3594\n",
      " |~~ val@11392  Loss: 0.002639 Acc: 13.2031\n",
      " |~~ val@11456  Loss: 0.002648 Acc: 13.1875\n",
      " |~~ val@11520  Loss: 0.002276 Acc: 13.2812\n",
      " |~~ val@11584  Loss: 0.002166 Acc: 13.4062\n",
      " |~~ val@11648  Loss: 0.002295 Acc: 13.3125\n",
      " |~~ val@11712  Loss: 0.002084 Acc: 13.2969\n",
      " |~~ val@11776  Loss: 0.002003 Acc: 13.3906\n",
      " |~~ val@11840  Loss: 0.002038 Acc: 13.3906\n",
      " |~~ val@11904  Loss: 0.002396 Acc: 13.3438\n",
      " |~~ val@11968  Loss: 0.002022 Acc: 13.5312\n",
      " |~~ val@12032  Loss: 0.001952 Acc: 13.3906\n",
      " |~~ val@12096  Loss: 0.002147 Acc: 13.4844\n",
      " |~~ val@12160  Loss: 0.002497 Acc: 13.2344\n",
      " |~~ val@12224  Loss: 0.001977 Acc: 13.4688\n",
      " |~~ val@12288  Loss: 0.002566 Acc: 13.2969\n",
      " |~~ val@12352  Loss: 0.002806 Acc: 13.2188\n",
      " |~~ val@12416  Loss: 0.002468 Acc: 13.2812\n",
      " |~~ val@12480  Loss: 0.002291 Acc: 13.3125\n",
      " |~~ val@12544  Loss: 0.002495 Acc: 13.2656\n",
      " |~~ val@12608  Loss: 0.002604 Acc: 13.2188\n",
      " |~~ val@12672  Loss: 0.002332 Acc: 13.2812\n",
      " |~~ val@12736  Loss: 0.002442 Acc: 13.2344\n",
      " |~~ val@12800  Loss: 0.002399 Acc: 13.1406\n",
      " |~~ val@12864  Loss: 0.002592 Acc: 13.1406\n",
      " |~~ val@12928  Loss: 0.002958 Acc: 13.1719\n",
      " |~~ val@12992  Loss: 0.002554 Acc: 13.1875\n",
      " |~~ val@13056  Loss: 0.002281 Acc: 13.2500\n",
      " |~~ val@13120  Loss: 0.002773 Acc: 13.1406\n",
      " |~~ val@13184  Loss: 0.002407 Acc: 13.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@13248  Loss: 0.001844 Acc: 13.4375\n",
      " |~~ val@13312  Loss: 0.001951 Acc: 13.4219\n",
      " |~~ val@13376  Loss: 0.002525 Acc: 13.3438\n",
      " |~~ val@13440  Loss: 0.002096 Acc: 13.4375\n",
      " |~~ val@13504  Loss: 0.002322 Acc: 13.2656\n",
      " |~~ val@13568  Loss: 0.002180 Acc: 13.2656\n",
      " |~~ val@13632  Loss: 0.002314 Acc: 13.2344\n",
      " |~~ val@13696  Loss: 0.002035 Acc: 13.3281\n",
      " |~~ val@13760  Loss: 0.002266 Acc: 13.3281\n",
      " |~~ val@13824  Loss: 0.002596 Acc: 13.1719\n",
      " |~~ val@13888  Loss: 0.001830 Acc: 13.5000\n",
      " |~~ val@13952  Loss: 0.002346 Acc: 13.3281\n",
      " |~~ val@14016  Loss: 0.002557 Acc: 13.3125\n",
      " |~~ val@14080  Loss: 0.002166 Acc: 13.3281\n",
      " |~~ val@14144  Loss: 0.002440 Acc: 13.1250\n",
      " |~~ val@14208  Loss: 0.002654 Acc: 13.0938\n",
      " |~~ val@14272  Loss: 0.002733 Acc: 13.1719\n",
      " |~~ val@14336  Loss: 0.002655 Acc: 13.1406\n",
      " |~~ val@14400  Loss: 0.002168 Acc: 13.4062\n",
      " |~~ val@14464  Loss: 0.002185 Acc: 13.3906\n",
      " |~~ val@14528  Loss: 0.002059 Acc: 13.3125\n",
      " |~~ val@14592  Loss: 0.001803 Acc: 13.4375\n",
      " |~~ val@14656  Loss: 0.001965 Acc: 13.4375\n",
      " |~~ val@14720  Loss: 0.002640 Acc: 13.0781\n",
      " |~~ val@14784  Loss: 0.002285 Acc: 13.2969\n",
      " |~~ val@14848  Loss: 0.002498 Acc: 13.2969\n",
      " |~~ val@14912  Loss: 0.002198 Acc: 13.4062\n",
      " |~~ val@14976  Loss: 0.002807 Acc: 13.1250\n",
      " |~~ val@15040  Loss: 0.001812 Acc: 13.4844\n",
      " |~~ val@15104  Loss: 0.002488 Acc: 13.2656\n",
      " |~~ val@15168  Loss: 0.002478 Acc: 13.2031\n",
      " |~~ val@15232  Loss: 0.002397 Acc: 13.3125\n",
      " |~~ val@15296  Loss: 0.002493 Acc: 13.2344\n",
      " |~~ val@15360  Loss: 0.002473 Acc: 13.1875\n",
      " |~~ val@15424  Loss: 0.002525 Acc: 13.1250\n",
      " |~~ val@15488  Loss: 0.002245 Acc: 13.3906\n",
      " |~~ val@15552  Loss: 0.002273 Acc: 13.3125\n",
      " |~~ val@15616  Loss: 0.003295 Acc: 12.9844\n",
      " |~~ val@15680  Loss: 0.002104 Acc: 13.4062\n",
      " |~~ val@15744  Loss: 0.002182 Acc: 13.3438\n",
      " |~~ val@15808  Loss: 0.002180 Acc: 13.3594\n",
      " |~~ val@15872  Loss: 0.002680 Acc: 13.0938\n",
      " |~~ val@15936  Loss: 0.002348 Acc: 13.2188\n",
      " |~~ val@16000  Loss: 0.001829 Acc: 13.5000\n",
      " |~~ val@16064  Loss: 0.002274 Acc: 13.3906\n",
      " |~~ val@16128  Loss: 0.002359 Acc: 13.3281\n",
      " |~~ val@16192  Loss: 0.002542 Acc: 13.2500\n",
      " |~~ val@16256  Loss: 0.002154 Acc: 13.3594\n",
      " |~~ val@16320  Loss: 0.002361 Acc: 13.2969\n",
      " |~~ val@16384  Loss: 0.002335 Acc: 13.3125\n",
      " |~~ val@16448  Loss: 0.001557 Acc: 13.5781\n",
      " |~~ val@16512  Loss: 0.002246 Acc: 13.3125\n",
      " |~~ val@16576  Loss: 0.002486 Acc: 13.2031\n",
      " |~~ val@16640  Loss: 0.002031 Acc: 13.3594\n",
      " |~~ val@16704  Loss: 0.002418 Acc: 13.2500\n",
      " |~~ val@16768  Loss: 0.002028 Acc: 13.3594\n",
      " |~~ val@16832  Loss: 0.002783 Acc: 13.2031\n",
      " |~~ val@16896  Loss: 0.001619 Acc: 13.5625\n",
      " |~~ val@16960  Loss: 0.002415 Acc: 13.2812\n",
      " |~~ val@17024  Loss: 0.001986 Acc: 13.3281\n",
      " |~~ val@17088  Loss: 0.003020 Acc: 13.1719\n",
      " |~~ val@17152  Loss: 0.002084 Acc: 13.3125\n",
      " |~~ val@17216  Loss: 0.002387 Acc: 13.1875\n",
      " |~~ val@17280  Loss: 0.002414 Acc: 13.1875\n",
      " |~~ val@17344  Loss: 0.002077 Acc: 13.3125\n",
      " |~~ val@17408  Loss: 0.002379 Acc: 13.1875\n",
      " |~~ val@17472  Loss: 0.001938 Acc: 13.3906\n",
      " |~~ val@17536  Loss: 0.001970 Acc: 13.4375\n",
      " |~~ val@17600  Loss: 0.002216 Acc: 13.4375\n",
      " |~~ val@17664  Loss: 0.002364 Acc: 13.2344\n",
      " |~~ val@17728  Loss: 0.002292 Acc: 13.4375\n",
      " |~~ val@17792  Loss: 0.001826 Acc: 13.3594\n",
      " |~~ val@17856  Loss: 0.002625 Acc: 13.1875\n",
      " |~~ val@17920  Loss: 0.002388 Acc: 13.2188\n",
      " |~~ val@17984  Loss: 0.002865 Acc: 13.1406\n",
      " |~~ val@18048  Loss: 0.002279 Acc: 13.3281\n",
      " |~~ val@18112  Loss: 0.002107 Acc: 13.3125\n",
      " |~~ val@18176  Loss: 0.002904 Acc: 13.2188\n",
      " |~~ val@18240  Loss: 0.002246 Acc: 13.2812\n",
      " |~~ val@18304  Loss: 0.002523 Acc: 13.1094\n",
      " |~~ val@18368  Loss: 0.002293 Acc: 13.2969\n",
      " |~~ val@18432  Loss: 0.002801 Acc: 13.0625\n",
      " |~~ val@18496  Loss: 0.002560 Acc: 13.2656\n",
      " |~~ val@18560  Loss: 0.002302 Acc: 13.2500\n",
      " |~~ val@18624  Loss: 0.002308 Acc: 13.3125\n",
      " |~~ val@18688  Loss: 0.002325 Acc: 13.2500\n",
      " |~~ val@18752  Loss: 0.002063 Acc: 13.3906\n",
      " |~~ val@18816  Loss: 0.002657 Acc: 13.1719\n",
      " |~~ val@18880  Loss: 0.001975 Acc: 13.4531\n",
      " |~~ val@18944  Loss: 0.002950 Acc: 13.1875\n",
      " |~~ val@19008  Loss: 0.002416 Acc: 13.1719\n",
      " |~~ val@19072  Loss: 0.001553 Acc: 13.5938\n",
      " |~~ val@19136  Loss: 0.001936 Acc: 13.4062\n",
      " |~~ val@19200  Loss: 0.002260 Acc: 13.3281\n",
      " |~~ val@19264  Loss: 0.001993 Acc: 13.4844\n",
      " |~~ val@19328  Loss: 0.002300 Acc: 13.3281\n",
      " |~~ val@19392  Loss: 0.002742 Acc: 13.1562\n",
      " |~~ val@19456  Loss: 0.002396 Acc: 13.1406\n",
      " |~~ val@19520  Loss: 0.002792 Acc: 13.1250\n",
      " |~~ val@19584  Loss: 0.002326 Acc: 13.3125\n",
      " |~~ val@19648  Loss: 0.002081 Acc: 13.4062\n",
      " |~~ val@19712  Loss: 0.002554 Acc: 13.2656\n",
      " |~~ val@19776  Loss: 0.002661 Acc: 13.1875\n",
      " |~~ val@19840  Loss: 0.001995 Acc: 13.2969\n",
      " |~~ val@19904  Loss: 0.002034 Acc: 13.4375\n",
      " |~~ val@19968  Loss: 0.002235 Acc: 13.2812\n",
      " |~~ val@20032  Loss: 0.002708 Acc: 13.2812\n",
      " |~~ val@20096  Loss: 0.002801 Acc: 13.0625\n",
      " |~~ val@20160  Loss: 0.002703 Acc: 13.1875\n",
      " |~~ val@20224  Loss: 0.002796 Acc: 13.2656\n",
      " |~~ val@20288  Loss: 0.003136 Acc: 13.1094\n",
      " |~~ val@20352  Loss: 0.002239 Acc: 13.2969\n",
      " |~~ val@20416  Loss: 0.002685 Acc: 13.0781\n",
      " |~~ val@20480  Loss: 0.001942 Acc: 13.3906\n",
      " |~~ val@20544  Loss: 0.002387 Acc: 13.2031\n",
      " |~~ val@20608  Loss: 0.002544 Acc: 13.1719\n",
      " |~~ val@20672  Loss: 0.002433 Acc: 13.2344\n",
      " |~~ val@20736  Loss: 0.002138 Acc: 13.3125\n",
      " |~~ val@20800  Loss: 0.003097 Acc: 12.9688\n",
      " |~~ val@20864  Loss: 0.001757 Acc: 13.4062\n",
      " |~~ val@20928  Loss: 0.003294 Acc: 13.0469\n",
      " |~~ val@20992  Loss: 0.002236 Acc: 13.3281\n",
      " |~~ val@21056  Loss: 0.002020 Acc: 13.3750\n",
      " |~~ val@21120  Loss: 0.002321 Acc: 13.2500\n",
      " |~~ val@21184  Loss: 0.001603 Acc: 13.5781\n",
      " |~~ val@21248  Loss: 0.002603 Acc: 13.1094\n",
      " |~~ val@21312  Loss: 0.002836 Acc: 13.1719\n",
      " |~~ val@21376  Loss: 0.001678 Acc: 13.4688\n",
      " |~~ val@21440  Loss: 0.001935 Acc: 13.3281\n",
      " |~~ val@21504  Loss: 0.002221 Acc: 13.4062\n",
      " |~~ val@21568  Loss: 0.002320 Acc: 13.2656\n",
      " |~~ val@21632  Loss: 0.002851 Acc: 13.2344\n",
      " |~~ val@21696  Loss: 0.002584 Acc: 13.1562\n",
      " |~~ val@21760  Loss: 0.002568 Acc: 13.2031\n",
      " |~~ val@21824  Loss: 0.002929 Acc: 13.1562\n",
      " |~~ val@21888  Loss: 0.002429 Acc: 13.2031\n",
      " |~~ val@21952  Loss: 0.002208 Acc: 13.2656\n",
      " |~~ val@22016  Loss: 0.002979 Acc: 13.0000\n",
      " |~~ val@22080  Loss: 0.002780 Acc: 13.2656\n",
      " |~~ val@22144  Loss: 0.002292 Acc: 13.2656\n",
      " |~~ val@22208  Loss: 0.002627 Acc: 13.2031\n",
      " |~~ val@22272  Loss: 0.002063 Acc: 13.4062\n",
      " |~~ val@22336  Loss: 0.002272 Acc: 13.2969\n",
      " |~~ val@22400  Loss: 0.002443 Acc: 13.3125\n",
      " |~~ val@22424  Loss: 0.004974 Acc: 13.3750\n",
      "val  Loss: 0.002376 Acc: 13.2796\n",
      "Epoch 7/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.002222 Acc: 13.2812\n",
      " |~~ train@128  Loss: 0.002009 Acc: 13.3281\n",
      " |~~ train@192  Loss: 0.002173 Acc: 13.2344\n",
      " |~~ train@256  Loss: 0.001802 Acc: 13.4844\n",
      " |~~ train@320  Loss: 0.002004 Acc: 13.3281\n",
      " |~~ train@384  Loss: 0.001969 Acc: 13.3281\n",
      " |~~ train@448  Loss: 0.002211 Acc: 13.1875\n",
      " |~~ train@512  Loss: 0.002045 Acc: 13.3750\n",
      " |~~ train@576  Loss: 0.002052 Acc: 13.3594\n",
      " |~~ train@640  Loss: 0.001865 Acc: 13.3750\n",
      " |~~ train@704  Loss: 0.002284 Acc: 13.2812\n",
      " |~~ train@768  Loss: 0.001567 Acc: 13.4844\n",
      " |~~ train@832  Loss: 0.002354 Acc: 13.1562\n",
      " |~~ train@896  Loss: 0.002170 Acc: 13.2656\n",
      " |~~ train@960  Loss: 0.001975 Acc: 13.3281\n",
      " |~~ train@1024  Loss: 0.002006 Acc: 13.3594\n",
      " |~~ train@1088  Loss: 0.001974 Acc: 13.4531\n",
      " |~~ train@1152  Loss: 0.001953 Acc: 13.4062\n",
      " |~~ train@1216  Loss: 0.002446 Acc: 13.2500\n",
      " |~~ train@1280  Loss: 0.001806 Acc: 13.3906\n",
      " |~~ train@1344  Loss: 0.002234 Acc: 13.2656\n",
      " |~~ train@1408  Loss: 0.001661 Acc: 13.4688\n",
      " |~~ train@1472  Loss: 0.001724 Acc: 13.5312\n",
      " |~~ train@1536  Loss: 0.002497 Acc: 13.2812\n",
      " |~~ train@1600  Loss: 0.002018 Acc: 13.2812\n",
      " |~~ train@1664  Loss: 0.001597 Acc: 13.4844\n",
      " |~~ train@1728  Loss: 0.002166 Acc: 13.2969\n",
      " |~~ train@1792  Loss: 0.002872 Acc: 13.0312\n",
      " |~~ train@1856  Loss: 0.001735 Acc: 13.5156\n",
      " |~~ train@1920  Loss: 0.001965 Acc: 13.2656\n",
      " |~~ train@1984  Loss: 0.002324 Acc: 13.2188\n",
      " |~~ train@2048  Loss: 0.002305 Acc: 13.2500\n",
      " |~~ train@2112  Loss: 0.002068 Acc: 13.3438\n",
      " |~~ train@2176  Loss: 0.001925 Acc: 13.4219\n",
      " |~~ train@2240  Loss: 0.002030 Acc: 13.4688\n",
      " |~~ train@2304  Loss: 0.001809 Acc: 13.4062\n",
      " |~~ train@2368  Loss: 0.001924 Acc: 13.3750\n",
      " |~~ train@2432  Loss: 0.002347 Acc: 13.2656\n",
      " |~~ train@2496  Loss: 0.001723 Acc: 13.5000\n",
      " |~~ train@2560  Loss: 0.001926 Acc: 13.3594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@2624  Loss: 0.002185 Acc: 13.2812\n",
      " |~~ train@2688  Loss: 0.001978 Acc: 13.2812\n",
      " |~~ train@2752  Loss: 0.002299 Acc: 13.1094\n",
      " |~~ train@2816  Loss: 0.002016 Acc: 13.3906\n",
      " |~~ train@2880  Loss: 0.001841 Acc: 13.4062\n",
      " |~~ train@2944  Loss: 0.001790 Acc: 13.4219\n",
      " |~~ train@3008  Loss: 0.001674 Acc: 13.3750\n",
      " |~~ train@3072  Loss: 0.001822 Acc: 13.4062\n",
      " |~~ train@3136  Loss: 0.001832 Acc: 13.3125\n",
      " |~~ train@3200  Loss: 0.001822 Acc: 13.3438\n",
      " |~~ train@3264  Loss: 0.002568 Acc: 13.1562\n",
      " |~~ train@3328  Loss: 0.001987 Acc: 13.3281\n",
      " |~~ train@3392  Loss: 0.002156 Acc: 13.3594\n",
      " |~~ train@3456  Loss: 0.001827 Acc: 13.4844\n",
      " |~~ train@3520  Loss: 0.002517 Acc: 13.2500\n",
      " |~~ train@3584  Loss: 0.001533 Acc: 13.5781\n",
      " |~~ train@3648  Loss: 0.002114 Acc: 13.2812\n",
      " |~~ train@3712  Loss: 0.002118 Acc: 13.2031\n",
      " |~~ train@3776  Loss: 0.001929 Acc: 13.3594\n",
      " |~~ train@3840  Loss: 0.002520 Acc: 13.1406\n",
      " |~~ train@3904  Loss: 0.002450 Acc: 13.2031\n",
      " |~~ train@3968  Loss: 0.001986 Acc: 13.3594\n",
      " |~~ train@4032  Loss: 0.001897 Acc: 13.4062\n",
      " |~~ train@4096  Loss: 0.002042 Acc: 13.4219\n",
      " |~~ train@4160  Loss: 0.002254 Acc: 13.3281\n",
      " |~~ train@4224  Loss: 0.001752 Acc: 13.5000\n",
      " |~~ train@4288  Loss: 0.001686 Acc: 13.4844\n",
      " |~~ train@4352  Loss: 0.001891 Acc: 13.3594\n",
      " |~~ train@4416  Loss: 0.001918 Acc: 13.3906\n",
      " |~~ train@4480  Loss: 0.002016 Acc: 13.2500\n",
      " |~~ train@4544  Loss: 0.002230 Acc: 13.2656\n",
      " |~~ train@4608  Loss: 0.002230 Acc: 13.2812\n",
      " |~~ train@4672  Loss: 0.001630 Acc: 13.5156\n",
      " |~~ train@4736  Loss: 0.002055 Acc: 13.2656\n",
      " |~~ train@4800  Loss: 0.001893 Acc: 13.3438\n",
      " |~~ train@4864  Loss: 0.003011 Acc: 13.0938\n",
      " |~~ train@4928  Loss: 0.002369 Acc: 13.2812\n",
      " |~~ train@4992  Loss: 0.002056 Acc: 13.2031\n",
      " |~~ train@5056  Loss: 0.001609 Acc: 13.5000\n",
      " |~~ train@5120  Loss: 0.002047 Acc: 13.4062\n",
      " |~~ train@5184  Loss: 0.002059 Acc: 13.3125\n",
      " |~~ train@5248  Loss: 0.002086 Acc: 13.2812\n",
      " |~~ train@5312  Loss: 0.001863 Acc: 13.3750\n",
      " |~~ train@5376  Loss: 0.002178 Acc: 13.2344\n",
      " |~~ train@5440  Loss: 0.001929 Acc: 13.4531\n",
      " |~~ train@5504  Loss: 0.001791 Acc: 13.4531\n",
      " |~~ train@5568  Loss: 0.002250 Acc: 13.1094\n",
      " |~~ train@5632  Loss: 0.002066 Acc: 13.3125\n",
      " |~~ train@5696  Loss: 0.002216 Acc: 13.2812\n",
      " |~~ train@5760  Loss: 0.001991 Acc: 13.4062\n",
      " |~~ train@5824  Loss: 0.002047 Acc: 13.3906\n",
      " |~~ train@5888  Loss: 0.002189 Acc: 13.3438\n",
      " |~~ train@5952  Loss: 0.002016 Acc: 13.4219\n",
      " |~~ train@6016  Loss: 0.002436 Acc: 13.1875\n",
      " |~~ train@6080  Loss: 0.002357 Acc: 13.2500\n",
      " |~~ train@6144  Loss: 0.001947 Acc: 13.3750\n",
      " |~~ train@6208  Loss: 0.002614 Acc: 13.0781\n",
      " |~~ train@6272  Loss: 0.001882 Acc: 13.4375\n",
      " |~~ train@6336  Loss: 0.001976 Acc: 13.3594\n",
      " |~~ train@6400  Loss: 0.001611 Acc: 13.5000\n",
      " |~~ train@6464  Loss: 0.002420 Acc: 13.1875\n",
      " |~~ train@6528  Loss: 0.001700 Acc: 13.3906\n",
      " |~~ train@6592  Loss: 0.001678 Acc: 13.4219\n",
      " |~~ train@6656  Loss: 0.001778 Acc: 13.4219\n",
      " |~~ train@6720  Loss: 0.001980 Acc: 13.3906\n",
      " |~~ train@6784  Loss: 0.002400 Acc: 13.1875\n",
      " |~~ train@6848  Loss: 0.002019 Acc: 13.4375\n",
      " |~~ train@6912  Loss: 0.001596 Acc: 13.5156\n",
      " |~~ train@6976  Loss: 0.001743 Acc: 13.4062\n",
      " |~~ train@7040  Loss: 0.002184 Acc: 13.3750\n",
      " |~~ train@7104  Loss: 0.001889 Acc: 13.4219\n",
      " |~~ train@7168  Loss: 0.001875 Acc: 13.3594\n",
      " |~~ train@7232  Loss: 0.002106 Acc: 13.3438\n",
      " |~~ train@7296  Loss: 0.001798 Acc: 13.3906\n",
      " |~~ train@7360  Loss: 0.001967 Acc: 13.3594\n",
      " |~~ train@7424  Loss: 0.001800 Acc: 13.4062\n",
      " |~~ train@7488  Loss: 0.001778 Acc: 13.3750\n",
      " |~~ train@7552  Loss: 0.002022 Acc: 13.3594\n",
      " |~~ train@7616  Loss: 0.001797 Acc: 13.4062\n",
      " |~~ train@7680  Loss: 0.002634 Acc: 13.0625\n",
      " |~~ train@7744  Loss: 0.002346 Acc: 13.2500\n",
      " |~~ train@7808  Loss: 0.001878 Acc: 13.4531\n",
      " |~~ train@7872  Loss: 0.001964 Acc: 13.3438\n",
      " |~~ train@7936  Loss: 0.002153 Acc: 13.2812\n",
      " |~~ train@8000  Loss: 0.001832 Acc: 13.4219\n",
      " |~~ train@8064  Loss: 0.001850 Acc: 13.5000\n",
      " |~~ train@8128  Loss: 0.001986 Acc: 13.3125\n",
      " |~~ train@8192  Loss: 0.002510 Acc: 13.1719\n",
      " |~~ train@8256  Loss: 0.001929 Acc: 13.4219\n",
      " |~~ train@8320  Loss: 0.001976 Acc: 13.3750\n",
      " |~~ train@8384  Loss: 0.002061 Acc: 13.3438\n",
      " |~~ train@8448  Loss: 0.002154 Acc: 13.2188\n",
      " |~~ train@8512  Loss: 0.002298 Acc: 13.2344\n",
      " |~~ train@8576  Loss: 0.002405 Acc: 13.1875\n",
      " |~~ train@8640  Loss: 0.002317 Acc: 13.2812\n",
      " |~~ train@8704  Loss: 0.001634 Acc: 13.4375\n",
      " |~~ train@8768  Loss: 0.001651 Acc: 13.4688\n",
      " |~~ train@8832  Loss: 0.001700 Acc: 13.4219\n",
      " |~~ train@8896  Loss: 0.002173 Acc: 13.2188\n",
      " |~~ train@8960  Loss: 0.001959 Acc: 13.2969\n",
      " |~~ train@9024  Loss: 0.001577 Acc: 13.5469\n",
      " |~~ train@9088  Loss: 0.001684 Acc: 13.4375\n",
      " |~~ train@9152  Loss: 0.002095 Acc: 13.2969\n",
      " |~~ train@9216  Loss: 0.001875 Acc: 13.4688\n",
      " |~~ train@9280  Loss: 0.001836 Acc: 13.3906\n",
      " |~~ train@9344  Loss: 0.002238 Acc: 13.2812\n",
      " |~~ train@9408  Loss: 0.002230 Acc: 13.2656\n",
      " |~~ train@9472  Loss: 0.001899 Acc: 13.4062\n",
      " |~~ train@9536  Loss: 0.001859 Acc: 13.3281\n",
      " |~~ train@9600  Loss: 0.002410 Acc: 13.0781\n",
      " |~~ train@9664  Loss: 0.002306 Acc: 13.1250\n",
      " |~~ train@9728  Loss: 0.001680 Acc: 13.5625\n",
      " |~~ train@9792  Loss: 0.001689 Acc: 13.3906\n",
      " |~~ train@9856  Loss: 0.002486 Acc: 13.0938\n",
      " |~~ train@9920  Loss: 0.002040 Acc: 13.3594\n",
      " |~~ train@9984  Loss: 0.002058 Acc: 13.2656\n",
      " |~~ train@10048  Loss: 0.001571 Acc: 13.4688\n",
      " |~~ train@10112  Loss: 0.001719 Acc: 13.4531\n",
      " |~~ train@10176  Loss: 0.002310 Acc: 13.2188\n",
      " |~~ train@10240  Loss: 0.001950 Acc: 13.5000\n",
      " |~~ train@10304  Loss: 0.001772 Acc: 13.4375\n",
      " |~~ train@10368  Loss: 0.001834 Acc: 13.3906\n",
      " |~~ train@10432  Loss: 0.002094 Acc: 13.2969\n",
      " |~~ train@10496  Loss: 0.001978 Acc: 13.3750\n",
      " |~~ train@10560  Loss: 0.001700 Acc: 13.4688\n",
      " |~~ train@10624  Loss: 0.001900 Acc: 13.3594\n",
      " |~~ train@10688  Loss: 0.001478 Acc: 13.5469\n",
      " |~~ train@10752  Loss: 0.001827 Acc: 13.5156\n",
      " |~~ train@10816  Loss: 0.002391 Acc: 13.2031\n",
      " |~~ train@10880  Loss: 0.001678 Acc: 13.5156\n",
      " |~~ train@10944  Loss: 0.002420 Acc: 13.1406\n",
      " |~~ train@11008  Loss: 0.001492 Acc: 13.5781\n",
      " |~~ train@11072  Loss: 0.002081 Acc: 13.2031\n",
      " |~~ train@11136  Loss: 0.001930 Acc: 13.4062\n",
      " |~~ train@11200  Loss: 0.002296 Acc: 13.1719\n",
      " |~~ train@11264  Loss: 0.002061 Acc: 13.3438\n",
      " |~~ train@11328  Loss: 0.002001 Acc: 13.3438\n",
      " |~~ train@11392  Loss: 0.002601 Acc: 13.1406\n",
      " |~~ train@11456  Loss: 0.001735 Acc: 13.3906\n",
      " |~~ train@11520  Loss: 0.001790 Acc: 13.4062\n",
      " |~~ train@11584  Loss: 0.001902 Acc: 13.3750\n",
      " |~~ train@11648  Loss: 0.001710 Acc: 13.4688\n",
      " |~~ train@11712  Loss: 0.002624 Acc: 13.1250\n",
      " |~~ train@11776  Loss: 0.002084 Acc: 13.2812\n",
      " |~~ train@11840  Loss: 0.001762 Acc: 13.4219\n",
      " |~~ train@11904  Loss: 0.001678 Acc: 13.5000\n",
      " |~~ train@11968  Loss: 0.001954 Acc: 13.4219\n",
      " |~~ train@12032  Loss: 0.001906 Acc: 13.4219\n",
      " |~~ train@12096  Loss: 0.001937 Acc: 13.3281\n",
      " |~~ train@12160  Loss: 0.002233 Acc: 13.2656\n",
      " |~~ train@12224  Loss: 0.002135 Acc: 13.3750\n",
      " |~~ train@12288  Loss: 0.001914 Acc: 13.4531\n",
      " |~~ train@12352  Loss: 0.001879 Acc: 13.3438\n",
      " |~~ train@12416  Loss: 0.002379 Acc: 13.2188\n",
      " |~~ train@12480  Loss: 0.001783 Acc: 13.3281\n",
      " |~~ train@12544  Loss: 0.001902 Acc: 13.4375\n",
      " |~~ train@12608  Loss: 0.001911 Acc: 13.3594\n",
      " |~~ train@12672  Loss: 0.001939 Acc: 13.3750\n",
      " |~~ train@12736  Loss: 0.002043 Acc: 13.3750\n",
      " |~~ train@12800  Loss: 0.001644 Acc: 13.4844\n",
      " |~~ train@12864  Loss: 0.001826 Acc: 13.3750\n",
      " |~~ train@12928  Loss: 0.002078 Acc: 13.4062\n",
      " |~~ train@12992  Loss: 0.001524 Acc: 13.5625\n",
      " |~~ train@13056  Loss: 0.002156 Acc: 13.2812\n",
      " |~~ train@13120  Loss: 0.002442 Acc: 13.1719\n",
      " |~~ train@13184  Loss: 0.002098 Acc: 13.3906\n",
      " |~~ train@13248  Loss: 0.002030 Acc: 13.3281\n",
      " |~~ train@13312  Loss: 0.002131 Acc: 13.2969\n",
      " |~~ train@13376  Loss: 0.001756 Acc: 13.4375\n",
      " |~~ train@13440  Loss: 0.002463 Acc: 13.3125\n",
      " |~~ train@13504  Loss: 0.001851 Acc: 13.3750\n",
      " |~~ train@13568  Loss: 0.001901 Acc: 13.3281\n",
      " |~~ train@13632  Loss: 0.001704 Acc: 13.5312\n",
      " |~~ train@13696  Loss: 0.002024 Acc: 13.4375\n",
      " |~~ train@13760  Loss: 0.001638 Acc: 13.4062\n",
      " |~~ train@13824  Loss: 0.001794 Acc: 13.4688\n",
      " |~~ train@13888  Loss: 0.001778 Acc: 13.4062\n",
      " |~~ train@13952  Loss: 0.001903 Acc: 13.3281\n",
      " |~~ train@14016  Loss: 0.002213 Acc: 13.2188\n",
      " |~~ train@14080  Loss: 0.002313 Acc: 13.2500\n",
      " |~~ train@14144  Loss: 0.002400 Acc: 13.1250\n",
      " |~~ train@14208  Loss: 0.001742 Acc: 13.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@14272  Loss: 0.002094 Acc: 13.3438\n",
      " |~~ train@14336  Loss: 0.002181 Acc: 13.3281\n",
      " |~~ train@14400  Loss: 0.001916 Acc: 13.3750\n",
      " |~~ train@14464  Loss: 0.002036 Acc: 13.3281\n",
      " |~~ train@14528  Loss: 0.002099 Acc: 13.2812\n",
      " |~~ train@14592  Loss: 0.001626 Acc: 13.4844\n",
      " |~~ train@14656  Loss: 0.001748 Acc: 13.4375\n",
      " |~~ train@14720  Loss: 0.002052 Acc: 13.3125\n",
      " |~~ train@14784  Loss: 0.001725 Acc: 13.4375\n",
      " |~~ train@14848  Loss: 0.001490 Acc: 13.4844\n",
      " |~~ train@14912  Loss: 0.001558 Acc: 13.6250\n",
      " |~~ train@14976  Loss: 0.002324 Acc: 13.2031\n",
      " |~~ train@15040  Loss: 0.002295 Acc: 13.3438\n",
      " |~~ train@15104  Loss: 0.001435 Acc: 13.6250\n",
      " |~~ train@15168  Loss: 0.002042 Acc: 13.3281\n",
      " |~~ train@15232  Loss: 0.001737 Acc: 13.3906\n",
      " |~~ train@15296  Loss: 0.002637 Acc: 13.0781\n",
      " |~~ train@15360  Loss: 0.002007 Acc: 13.2812\n",
      " |~~ train@15424  Loss: 0.001933 Acc: 13.3594\n",
      " |~~ train@15488  Loss: 0.001879 Acc: 13.3594\n",
      " |~~ train@15552  Loss: 0.002490 Acc: 13.1250\n",
      " |~~ train@15616  Loss: 0.001886 Acc: 13.3125\n",
      " |~~ train@15680  Loss: 0.001916 Acc: 13.3750\n",
      " |~~ train@15744  Loss: 0.002088 Acc: 13.2812\n",
      " |~~ train@15808  Loss: 0.001850 Acc: 13.4375\n",
      " |~~ train@15872  Loss: 0.002071 Acc: 13.2656\n",
      " |~~ train@15936  Loss: 0.001814 Acc: 13.4219\n",
      " |~~ train@16000  Loss: 0.001770 Acc: 13.3438\n",
      " |~~ train@16064  Loss: 0.002177 Acc: 13.2969\n",
      " |~~ train@16128  Loss: 0.002189 Acc: 13.3281\n",
      " |~~ train@16192  Loss: 0.002085 Acc: 13.2812\n",
      " |~~ train@16256  Loss: 0.002391 Acc: 13.2969\n",
      " |~~ train@16320  Loss: 0.002185 Acc: 13.3438\n",
      " |~~ train@16384  Loss: 0.001932 Acc: 13.3750\n",
      " |~~ train@16448  Loss: 0.001484 Acc: 13.5625\n",
      " |~~ train@16512  Loss: 0.002232 Acc: 13.3125\n",
      " |~~ train@16576  Loss: 0.002454 Acc: 13.2188\n",
      " |~~ train@16640  Loss: 0.002210 Acc: 13.2656\n",
      " |~~ train@16704  Loss: 0.002066 Acc: 13.2656\n",
      " |~~ train@16768  Loss: 0.001931 Acc: 13.5156\n",
      " |~~ train@16832  Loss: 0.002372 Acc: 13.2500\n",
      " |~~ train@16896  Loss: 0.001817 Acc: 13.2969\n",
      " |~~ train@16960  Loss: 0.001624 Acc: 13.4375\n",
      " |~~ train@17024  Loss: 0.002412 Acc: 13.2656\n",
      " |~~ train@17088  Loss: 0.002275 Acc: 13.1250\n",
      " |~~ train@17152  Loss: 0.001563 Acc: 13.4688\n",
      " |~~ train@17216  Loss: 0.001576 Acc: 13.4688\n",
      " |~~ train@17280  Loss: 0.001928 Acc: 13.4375\n",
      " |~~ train@17344  Loss: 0.001844 Acc: 13.4375\n",
      " |~~ train@17408  Loss: 0.001946 Acc: 13.3750\n",
      " |~~ train@17472  Loss: 0.001670 Acc: 13.4844\n",
      " |~~ train@17536  Loss: 0.002109 Acc: 13.2812\n",
      " |~~ train@17600  Loss: 0.001695 Acc: 13.4688\n",
      " |~~ train@17664  Loss: 0.002408 Acc: 13.2031\n",
      " |~~ train@17728  Loss: 0.002052 Acc: 13.4219\n",
      " |~~ train@17792  Loss: 0.002190 Acc: 13.3125\n",
      " |~~ train@17856  Loss: 0.002375 Acc: 13.2344\n",
      " |~~ train@17920  Loss: 0.002122 Acc: 13.2969\n",
      " |~~ train@17984  Loss: 0.001781 Acc: 13.3906\n",
      " |~~ train@18048  Loss: 0.001925 Acc: 13.3750\n",
      " |~~ train@18112  Loss: 0.002002 Acc: 13.2812\n",
      " |~~ train@18176  Loss: 0.001873 Acc: 13.3906\n",
      " |~~ train@18240  Loss: 0.002155 Acc: 13.2969\n",
      " |~~ train@18304  Loss: 0.002269 Acc: 13.2031\n",
      " |~~ train@18368  Loss: 0.002441 Acc: 13.2656\n",
      " |~~ train@18432  Loss: 0.001839 Acc: 13.3906\n",
      " |~~ train@18496  Loss: 0.002278 Acc: 13.3125\n",
      " |~~ train@18560  Loss: 0.001608 Acc: 13.5625\n",
      " |~~ train@18624  Loss: 0.001529 Acc: 13.5156\n",
      " |~~ train@18688  Loss: 0.001831 Acc: 13.3281\n",
      " |~~ train@18752  Loss: 0.002076 Acc: 13.2812\n",
      " |~~ train@18816  Loss: 0.001888 Acc: 13.3906\n",
      " |~~ train@18880  Loss: 0.001705 Acc: 13.4219\n",
      " |~~ train@18944  Loss: 0.001873 Acc: 13.4375\n",
      " |~~ train@19008  Loss: 0.001941 Acc: 13.3750\n",
      " |~~ train@19072  Loss: 0.002045 Acc: 13.3594\n",
      " |~~ train@19136  Loss: 0.002372 Acc: 13.3125\n",
      " |~~ train@19200  Loss: 0.001787 Acc: 13.4062\n",
      " |~~ train@19264  Loss: 0.001799 Acc: 13.3594\n",
      " |~~ train@19328  Loss: 0.002456 Acc: 13.2344\n",
      " |~~ train@19392  Loss: 0.001978 Acc: 13.4219\n",
      " |~~ train@19456  Loss: 0.001749 Acc: 13.5000\n",
      " |~~ train@19520  Loss: 0.001909 Acc: 13.3750\n",
      " |~~ train@19584  Loss: 0.001768 Acc: 13.3281\n",
      " |~~ train@19648  Loss: 0.002357 Acc: 13.2500\n",
      " |~~ train@19712  Loss: 0.002054 Acc: 13.2969\n",
      " |~~ train@19776  Loss: 0.001989 Acc: 13.3125\n",
      " |~~ train@19840  Loss: 0.001848 Acc: 13.5156\n",
      " |~~ train@19904  Loss: 0.002674 Acc: 13.1250\n",
      " |~~ train@19968  Loss: 0.002274 Acc: 13.1719\n",
      " |~~ train@20032  Loss: 0.001974 Acc: 13.3438\n",
      " |~~ train@20096  Loss: 0.001843 Acc: 13.4375\n",
      " |~~ train@20160  Loss: 0.002174 Acc: 13.2812\n",
      " |~~ train@20224  Loss: 0.001821 Acc: 13.3906\n",
      " |~~ train@20288  Loss: 0.002128 Acc: 13.3438\n",
      " |~~ train@20352  Loss: 0.002068 Acc: 13.3750\n",
      " |~~ train@20416  Loss: 0.002550 Acc: 13.2188\n",
      " |~~ train@20480  Loss: 0.001740 Acc: 13.5156\n",
      " |~~ train@20544  Loss: 0.002596 Acc: 13.1875\n",
      " |~~ train@20608  Loss: 0.001608 Acc: 13.4844\n",
      " |~~ train@20672  Loss: 0.001989 Acc: 13.3750\n",
      " |~~ train@20736  Loss: 0.001883 Acc: 13.3594\n",
      " |~~ train@20800  Loss: 0.002406 Acc: 13.2344\n",
      " |~~ train@20864  Loss: 0.002061 Acc: 13.3906\n",
      " |~~ train@20928  Loss: 0.002037 Acc: 13.2969\n",
      " |~~ train@20992  Loss: 0.001867 Acc: 13.4375\n",
      " |~~ train@21056  Loss: 0.001373 Acc: 13.5625\n",
      " |~~ train@21120  Loss: 0.001794 Acc: 13.4219\n",
      " |~~ train@21184  Loss: 0.002344 Acc: 13.2188\n",
      " |~~ train@21248  Loss: 0.002556 Acc: 13.2500\n",
      " |~~ train@21312  Loss: 0.001998 Acc: 13.3750\n",
      " |~~ train@21376  Loss: 0.002240 Acc: 13.1875\n",
      " |~~ train@21440  Loss: 0.001788 Acc: 13.5000\n",
      " |~~ train@21504  Loss: 0.001905 Acc: 13.4375\n",
      " |~~ train@21568  Loss: 0.002375 Acc: 13.2188\n",
      " |~~ train@21632  Loss: 0.001801 Acc: 13.5469\n",
      " |~~ train@21696  Loss: 0.002246 Acc: 13.3125\n",
      " |~~ train@21760  Loss: 0.002024 Acc: 13.3906\n",
      " |~~ train@21824  Loss: 0.002081 Acc: 13.3594\n",
      " |~~ train@21888  Loss: 0.001866 Acc: 13.4688\n",
      " |~~ train@21952  Loss: 0.002144 Acc: 13.3125\n",
      " |~~ train@22016  Loss: 0.001942 Acc: 13.4062\n",
      " |~~ train@22080  Loss: 0.002185 Acc: 13.3438\n",
      " |~~ train@22144  Loss: 0.001889 Acc: 13.3594\n",
      " |~~ train@22208  Loss: 0.001624 Acc: 13.5469\n",
      " |~~ train@22272  Loss: 0.001563 Acc: 13.5469\n",
      " |~~ train@22336  Loss: 0.002695 Acc: 13.0469\n",
      " |~~ train@22400  Loss: 0.001941 Acc: 13.2969\n",
      " |~~ train@22464  Loss: 0.001994 Acc: 13.3750\n",
      " |~~ train@22528  Loss: 0.001564 Acc: 13.4688\n",
      " |~~ train@22592  Loss: 0.002067 Acc: 13.3906\n",
      " |~~ train@22656  Loss: 0.002132 Acc: 13.2656\n",
      " |~~ train@22720  Loss: 0.001806 Acc: 13.4219\n",
      " |~~ train@22784  Loss: 0.002404 Acc: 13.2500\n",
      " |~~ train@22848  Loss: 0.002212 Acc: 13.3281\n",
      " |~~ train@22912  Loss: 0.001853 Acc: 13.4062\n",
      " |~~ train@22976  Loss: 0.002173 Acc: 13.2969\n",
      " |~~ train@23040  Loss: 0.002202 Acc: 13.3125\n",
      " |~~ train@23104  Loss: 0.002089 Acc: 13.3281\n",
      " |~~ train@23168  Loss: 0.002298 Acc: 13.2656\n",
      " |~~ train@23232  Loss: 0.002120 Acc: 13.3125\n",
      " |~~ train@23296  Loss: 0.002114 Acc: 13.2812\n",
      " |~~ train@23360  Loss: 0.001638 Acc: 13.4844\n",
      " |~~ train@23424  Loss: 0.001989 Acc: 13.3594\n",
      " |~~ train@23488  Loss: 0.001940 Acc: 13.3438\n",
      " |~~ train@23552  Loss: 0.001969 Acc: 13.3281\n",
      " |~~ train@23616  Loss: 0.002054 Acc: 13.2812\n",
      " |~~ train@23680  Loss: 0.001476 Acc: 13.5000\n",
      " |~~ train@23744  Loss: 0.001708 Acc: 13.4688\n",
      " |~~ train@23808  Loss: 0.001827 Acc: 13.3438\n",
      " |~~ train@23872  Loss: 0.002077 Acc: 13.3906\n",
      " |~~ train@23936  Loss: 0.001866 Acc: 13.3125\n",
      " |~~ train@24000  Loss: 0.001526 Acc: 13.5312\n",
      " |~~ train@24064  Loss: 0.002072 Acc: 13.3125\n",
      " |~~ train@24128  Loss: 0.002078 Acc: 13.3438\n",
      " |~~ train@24192  Loss: 0.001726 Acc: 13.4062\n",
      " |~~ train@24256  Loss: 0.001804 Acc: 13.3281\n",
      " |~~ train@24320  Loss: 0.002020 Acc: 13.3438\n",
      " |~~ train@24384  Loss: 0.002342 Acc: 13.3125\n",
      " |~~ train@24448  Loss: 0.002108 Acc: 13.3125\n",
      " |~~ train@24512  Loss: 0.002033 Acc: 13.3281\n",
      " |~~ train@24576  Loss: 0.002361 Acc: 13.2656\n",
      " |~~ train@24640  Loss: 0.002064 Acc: 13.3281\n",
      " |~~ train@24704  Loss: 0.002002 Acc: 13.3281\n",
      " |~~ train@24768  Loss: 0.001867 Acc: 13.3750\n",
      " |~~ train@24832  Loss: 0.002429 Acc: 13.2812\n",
      " |~~ train@24896  Loss: 0.002074 Acc: 13.3281\n",
      " |~~ train@24960  Loss: 0.002323 Acc: 13.1875\n",
      " |~~ train@25024  Loss: 0.002111 Acc: 13.3125\n",
      " |~~ train@25088  Loss: 0.001779 Acc: 13.4531\n",
      " |~~ train@25152  Loss: 0.001712 Acc: 13.3594\n",
      " |~~ train@25216  Loss: 0.001591 Acc: 13.4688\n",
      " |~~ train@25280  Loss: 0.002222 Acc: 13.3281\n",
      " |~~ train@25344  Loss: 0.001961 Acc: 13.3438\n",
      " |~~ train@25408  Loss: 0.002381 Acc: 13.3281\n",
      " |~~ train@25472  Loss: 0.002592 Acc: 13.2188\n",
      " |~~ train@25536  Loss: 0.002004 Acc: 13.3906\n",
      " |~~ train@25600  Loss: 0.002092 Acc: 13.4062\n",
      " |~~ train@25664  Loss: 0.002138 Acc: 13.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@25728  Loss: 0.001994 Acc: 13.3750\n",
      " |~~ train@25792  Loss: 0.001864 Acc: 13.4531\n",
      " |~~ train@25856  Loss: 0.001827 Acc: 13.4375\n",
      " |~~ train@25920  Loss: 0.002276 Acc: 13.2969\n",
      " |~~ train@25984  Loss: 0.001787 Acc: 13.4219\n",
      " |~~ train@26048  Loss: 0.001973 Acc: 13.4219\n",
      " |~~ train@26112  Loss: 0.002233 Acc: 13.3125\n",
      " |~~ train@26176  Loss: 0.002183 Acc: 13.3281\n",
      " |~~ train@26240  Loss: 0.002602 Acc: 13.1094\n",
      " |~~ train@26304  Loss: 0.002183 Acc: 13.2969\n",
      " |~~ train@26368  Loss: 0.002284 Acc: 13.1875\n",
      " |~~ train@26432  Loss: 0.002097 Acc: 13.2969\n",
      " |~~ train@26496  Loss: 0.001930 Acc: 13.3438\n",
      " |~~ train@26560  Loss: 0.002303 Acc: 13.2656\n",
      " |~~ train@26624  Loss: 0.002180 Acc: 13.2031\n",
      " |~~ train@26688  Loss: 0.002367 Acc: 13.2500\n",
      " |~~ train@26752  Loss: 0.002289 Acc: 13.2500\n",
      " |~~ train@26816  Loss: 0.002181 Acc: 13.2656\n",
      " |~~ train@26880  Loss: 0.001953 Acc: 13.3438\n",
      " |~~ train@26944  Loss: 0.002151 Acc: 13.2656\n",
      " |~~ train@27008  Loss: 0.001735 Acc: 13.5156\n",
      " |~~ train@27072  Loss: 0.001735 Acc: 13.4219\n",
      " |~~ train@27136  Loss: 0.001634 Acc: 13.5156\n",
      " |~~ train@27200  Loss: 0.002033 Acc: 13.3281\n",
      " |~~ train@27264  Loss: 0.002100 Acc: 13.3125\n",
      " |~~ train@27328  Loss: 0.002310 Acc: 13.2500\n",
      " |~~ train@27392  Loss: 0.001808 Acc: 13.4531\n",
      " |~~ train@27456  Loss: 0.002180 Acc: 13.3125\n",
      " |~~ train@27520  Loss: 0.002077 Acc: 13.2500\n",
      " |~~ train@27584  Loss: 0.002133 Acc: 13.3281\n",
      " |~~ train@27648  Loss: 0.001476 Acc: 13.4531\n",
      " |~~ train@27712  Loss: 0.002254 Acc: 13.1562\n",
      " |~~ train@27776  Loss: 0.001694 Acc: 13.4688\n",
      " |~~ train@27840  Loss: 0.002259 Acc: 13.2500\n",
      " |~~ train@27904  Loss: 0.002054 Acc: 13.3750\n",
      " |~~ train@27968  Loss: 0.001738 Acc: 13.4062\n",
      " |~~ train@28032  Loss: 0.001821 Acc: 13.5000\n",
      " |~~ train@28096  Loss: 0.001790 Acc: 13.4375\n",
      " |~~ train@28160  Loss: 0.001873 Acc: 13.4219\n",
      " |~~ train@28224  Loss: 0.001937 Acc: 13.2656\n",
      " |~~ train@28288  Loss: 0.001746 Acc: 13.4688\n",
      " |~~ train@28352  Loss: 0.001979 Acc: 13.4531\n",
      " |~~ train@28416  Loss: 0.001785 Acc: 13.4219\n",
      " |~~ train@28480  Loss: 0.002163 Acc: 13.2656\n",
      " |~~ train@28544  Loss: 0.001889 Acc: 13.4219\n",
      " |~~ train@28608  Loss: 0.002039 Acc: 13.2656\n",
      " |~~ train@28672  Loss: 0.001871 Acc: 13.4062\n",
      " |~~ train@28736  Loss: 0.002029 Acc: 13.3906\n",
      " |~~ train@28800  Loss: 0.001818 Acc: 13.3906\n",
      " |~~ train@28864  Loss: 0.001824 Acc: 13.4531\n",
      " |~~ train@28928  Loss: 0.001835 Acc: 13.5000\n",
      " |~~ train@28992  Loss: 0.002409 Acc: 13.2500\n",
      " |~~ train@29056  Loss: 0.002011 Acc: 13.2969\n",
      " |~~ train@29120  Loss: 0.001953 Acc: 13.3906\n",
      " |~~ train@29184  Loss: 0.002078 Acc: 13.3750\n",
      " |~~ train@29248  Loss: 0.002083 Acc: 13.2969\n",
      " |~~ train@29312  Loss: 0.002032 Acc: 13.2656\n",
      " |~~ train@29376  Loss: 0.001657 Acc: 13.5312\n",
      " |~~ train@29440  Loss: 0.001797 Acc: 13.5000\n",
      " |~~ train@29504  Loss: 0.002062 Acc: 13.3438\n",
      " |~~ train@29568  Loss: 0.001968 Acc: 13.3438\n",
      " |~~ train@29632  Loss: 0.002093 Acc: 13.3438\n",
      " |~~ train@29696  Loss: 0.002133 Acc: 13.3906\n",
      " |~~ train@29760  Loss: 0.002230 Acc: 13.2969\n",
      " |~~ train@29824  Loss: 0.001924 Acc: 13.4219\n",
      " |~~ train@29888  Loss: 0.001993 Acc: 13.2969\n",
      " |~~ train@29952  Loss: 0.002203 Acc: 13.2969\n",
      " |~~ train@30016  Loss: 0.001720 Acc: 13.4219\n",
      " |~~ train@30080  Loss: 0.002185 Acc: 13.3281\n",
      " |~~ train@30144  Loss: 0.002142 Acc: 13.2188\n",
      " |~~ train@30208  Loss: 0.001697 Acc: 13.5469\n",
      " |~~ train@30272  Loss: 0.002637 Acc: 13.1094\n",
      " |~~ train@30336  Loss: 0.002169 Acc: 13.2656\n",
      " |~~ train@30400  Loss: 0.002025 Acc: 13.3125\n",
      " |~~ train@30464  Loss: 0.002114 Acc: 13.2344\n",
      " |~~ train@30528  Loss: 0.001700 Acc: 13.4844\n",
      " |~~ train@30592  Loss: 0.002059 Acc: 13.2969\n",
      " |~~ train@30656  Loss: 0.002094 Acc: 13.3438\n",
      " |~~ train@30720  Loss: 0.001549 Acc: 13.5312\n",
      " |~~ train@30784  Loss: 0.002253 Acc: 13.2812\n",
      " |~~ train@30848  Loss: 0.001616 Acc: 13.5156\n",
      " |~~ train@30912  Loss: 0.001960 Acc: 13.3125\n",
      " |~~ train@30976  Loss: 0.001603 Acc: 13.5469\n",
      " |~~ train@31040  Loss: 0.002311 Acc: 13.2031\n",
      " |~~ train@31104  Loss: 0.001894 Acc: 13.3594\n",
      " |~~ train@31168  Loss: 0.002438 Acc: 13.2188\n",
      " |~~ train@31232  Loss: 0.002236 Acc: 13.3125\n",
      " |~~ train@31296  Loss: 0.001895 Acc: 13.4375\n",
      " |~~ train@31360  Loss: 0.001510 Acc: 13.6094\n",
      " |~~ train@31424  Loss: 0.001816 Acc: 13.4375\n",
      " |~~ train@31488  Loss: 0.001958 Acc: 13.3750\n",
      " |~~ train@31552  Loss: 0.002059 Acc: 13.2969\n",
      " |~~ train@31616  Loss: 0.002266 Acc: 13.2344\n",
      " |~~ train@31680  Loss: 0.002252 Acc: 13.3125\n",
      " |~~ train@31744  Loss: 0.001848 Acc: 13.5000\n",
      " |~~ train@31808  Loss: 0.002073 Acc: 13.2969\n",
      " |~~ train@31872  Loss: 0.001855 Acc: 13.4062\n",
      " |~~ train@31936  Loss: 0.002721 Acc: 13.1094\n",
      " |~~ train@32000  Loss: 0.001628 Acc: 13.4844\n",
      " |~~ train@32064  Loss: 0.002038 Acc: 13.3594\n",
      " |~~ train@32128  Loss: 0.001946 Acc: 13.5000\n",
      " |~~ train@32192  Loss: 0.002389 Acc: 13.1562\n",
      " |~~ train@32256  Loss: 0.001970 Acc: 13.3438\n",
      " |~~ train@32320  Loss: 0.002194 Acc: 13.1562\n",
      " |~~ train@32384  Loss: 0.001796 Acc: 13.4531\n",
      " |~~ train@32448  Loss: 0.001718 Acc: 13.4688\n",
      " |~~ train@32512  Loss: 0.002305 Acc: 13.2344\n",
      " |~~ train@32576  Loss: 0.002143 Acc: 13.3125\n",
      " |~~ train@32640  Loss: 0.002193 Acc: 13.2188\n",
      " |~~ train@32704  Loss: 0.001965 Acc: 13.3906\n",
      " |~~ train@32768  Loss: 0.002069 Acc: 13.2500\n",
      " |~~ train@32832  Loss: 0.002117 Acc: 13.2500\n",
      " |~~ train@32896  Loss: 0.002038 Acc: 13.3438\n",
      " |~~ train@32960  Loss: 0.002091 Acc: 13.3594\n",
      " |~~ train@33024  Loss: 0.001653 Acc: 13.4844\n",
      " |~~ train@33088  Loss: 0.002297 Acc: 13.3125\n",
      " |~~ train@33152  Loss: 0.002125 Acc: 13.2656\n",
      " |~~ train@33216  Loss: 0.001977 Acc: 13.3438\n",
      " |~~ train@33280  Loss: 0.002112 Acc: 13.3750\n",
      " |~~ train@33344  Loss: 0.001834 Acc: 13.3750\n",
      " |~~ train@33408  Loss: 0.002371 Acc: 13.2344\n",
      " |~~ train@33472  Loss: 0.001984 Acc: 13.4375\n",
      " |~~ train@33536  Loss: 0.001634 Acc: 13.5469\n",
      " |~~ train@33600  Loss: 0.002011 Acc: 13.4219\n",
      " |~~ train@33664  Loss: 0.002254 Acc: 13.1719\n",
      " |~~ train@33728  Loss: 0.001751 Acc: 13.4219\n",
      " |~~ train@33792  Loss: 0.001939 Acc: 13.3594\n",
      " |~~ train@33856  Loss: 0.001682 Acc: 13.4375\n",
      " |~~ train@33920  Loss: 0.001535 Acc: 13.5156\n",
      " |~~ train@33984  Loss: 0.002429 Acc: 13.1719\n",
      " |~~ train@34048  Loss: 0.001528 Acc: 13.5312\n",
      " |~~ train@34112  Loss: 0.002117 Acc: 13.3125\n",
      " |~~ train@34176  Loss: 0.002075 Acc: 13.2656\n",
      " |~~ train@34240  Loss: 0.002440 Acc: 13.1406\n",
      " |~~ train@34304  Loss: 0.001793 Acc: 13.3594\n",
      " |~~ train@34368  Loss: 0.002188 Acc: 13.1406\n",
      " |~~ train@34432  Loss: 0.001954 Acc: 13.4844\n",
      " |~~ train@34496  Loss: 0.002734 Acc: 13.2344\n",
      " |~~ train@34560  Loss: 0.001956 Acc: 13.3906\n",
      " |~~ train@34624  Loss: 0.001974 Acc: 13.3438\n",
      " |~~ train@34688  Loss: 0.002119 Acc: 13.3438\n",
      " |~~ train@34752  Loss: 0.002584 Acc: 13.2031\n",
      " |~~ train@34816  Loss: 0.002031 Acc: 13.3906\n",
      " |~~ train@34880  Loss: 0.002169 Acc: 13.2969\n",
      " |~~ train@34944  Loss: 0.001833 Acc: 13.4688\n",
      " |~~ train@35008  Loss: 0.002020 Acc: 13.4219\n",
      " |~~ train@35072  Loss: 0.002131 Acc: 13.3281\n",
      " |~~ train@35136  Loss: 0.001985 Acc: 13.4844\n",
      " |~~ train@35200  Loss: 0.001842 Acc: 13.5000\n",
      " |~~ train@35264  Loss: 0.002003 Acc: 13.3438\n",
      " |~~ train@35328  Loss: 0.002170 Acc: 13.2812\n",
      " |~~ train@35392  Loss: 0.001604 Acc: 13.5000\n",
      " |~~ train@35456  Loss: 0.001839 Acc: 13.4219\n",
      " |~~ train@35520  Loss: 0.001775 Acc: 13.3750\n",
      " |~~ train@35584  Loss: 0.001809 Acc: 13.4375\n",
      " |~~ train@35648  Loss: 0.001311 Acc: 13.5625\n",
      " |~~ train@35712  Loss: 0.002117 Acc: 13.3438\n",
      " |~~ train@35776  Loss: 0.001870 Acc: 13.4219\n",
      " |~~ train@35840  Loss: 0.001960 Acc: 13.3125\n",
      " |~~ train@35904  Loss: 0.002098 Acc: 13.3438\n",
      " |~~ train@35968  Loss: 0.001546 Acc: 13.5312\n",
      " |~~ train@36032  Loss: 0.001586 Acc: 13.5469\n",
      " |~~ train@36096  Loss: 0.001770 Acc: 13.5312\n",
      " |~~ train@36160  Loss: 0.001944 Acc: 13.3906\n",
      " |~~ train@36224  Loss: 0.002091 Acc: 13.2969\n",
      " |~~ train@36288  Loss: 0.001964 Acc: 13.3594\n",
      " |~~ train@36352  Loss: 0.001832 Acc: 13.4844\n",
      " |~~ train@36416  Loss: 0.001559 Acc: 13.5312\n",
      " |~~ train@36480  Loss: 0.001850 Acc: 13.2969\n",
      " |~~ train@36544  Loss: 0.002482 Acc: 13.1250\n",
      " |~~ train@36608  Loss: 0.002062 Acc: 13.3438\n",
      " |~~ train@36672  Loss: 0.001963 Acc: 13.4375\n",
      " |~~ train@36736  Loss: 0.001745 Acc: 13.4531\n",
      " |~~ train@36800  Loss: 0.002483 Acc: 13.2656\n",
      " |~~ train@36864  Loss: 0.002009 Acc: 13.3906\n",
      " |~~ train@36928  Loss: 0.001597 Acc: 13.5625\n",
      " |~~ train@36992  Loss: 0.002025 Acc: 13.2812\n",
      " |~~ train@37056  Loss: 0.002293 Acc: 13.2188\n",
      " |~~ train@37120  Loss: 0.002053 Acc: 13.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@37184  Loss: 0.001812 Acc: 13.3594\n",
      " |~~ train@37248  Loss: 0.002247 Acc: 13.2969\n",
      " |~~ train@37312  Loss: 0.002258 Acc: 13.2500\n",
      " |~~ train@37376  Loss: 0.002190 Acc: 13.2656\n",
      " |~~ train@37440  Loss: 0.001826 Acc: 13.4062\n",
      " |~~ train@37504  Loss: 0.002737 Acc: 13.1562\n",
      " |~~ train@37568  Loss: 0.001721 Acc: 13.4375\n",
      " |~~ train@37632  Loss: 0.002279 Acc: 13.2812\n",
      " |~~ train@37696  Loss: 0.001668 Acc: 13.4688\n",
      " |~~ train@37760  Loss: 0.001771 Acc: 13.3906\n",
      " |~~ train@37824  Loss: 0.002179 Acc: 13.3594\n",
      " |~~ train@37888  Loss: 0.001955 Acc: 13.3750\n",
      " |~~ train@37952  Loss: 0.002339 Acc: 13.2031\n",
      " |~~ train@38016  Loss: 0.001865 Acc: 13.4062\n",
      " |~~ train@38080  Loss: 0.001780 Acc: 13.5156\n",
      " |~~ train@38144  Loss: 0.002070 Acc: 13.3125\n",
      " |~~ train@38208  Loss: 0.002212 Acc: 13.2656\n",
      " |~~ train@38272  Loss: 0.002067 Acc: 13.2188\n",
      " |~~ train@38336  Loss: 0.001620 Acc: 13.4844\n",
      " |~~ train@38400  Loss: 0.001771 Acc: 13.4844\n",
      " |~~ train@38464  Loss: 0.002178 Acc: 13.2656\n",
      " |~~ train@38528  Loss: 0.002071 Acc: 13.3438\n",
      " |~~ train@38592  Loss: 0.001966 Acc: 13.4062\n",
      " |~~ train@38656  Loss: 0.002102 Acc: 13.2656\n",
      " |~~ train@38720  Loss: 0.002122 Acc: 13.3750\n",
      " |~~ train@38784  Loss: 0.001939 Acc: 13.3750\n",
      " |~~ train@38848  Loss: 0.001853 Acc: 13.3750\n",
      " |~~ train@38912  Loss: 0.001996 Acc: 13.2656\n",
      " |~~ train@38976  Loss: 0.002075 Acc: 13.3438\n",
      " |~~ train@39040  Loss: 0.001506 Acc: 13.5469\n",
      " |~~ train@39104  Loss: 0.002369 Acc: 13.1719\n",
      " |~~ train@39168  Loss: 0.002015 Acc: 13.2969\n",
      " |~~ train@39232  Loss: 0.001923 Acc: 13.3438\n",
      " |~~ train@39296  Loss: 0.002011 Acc: 13.3906\n",
      " |~~ train@39360  Loss: 0.001720 Acc: 13.4219\n",
      " |~~ train@39424  Loss: 0.001398 Acc: 13.5469\n",
      " |~~ train@39488  Loss: 0.002190 Acc: 13.2969\n",
      " |~~ train@39552  Loss: 0.002324 Acc: 13.2656\n",
      " |~~ train@39616  Loss: 0.002209 Acc: 13.2500\n",
      " |~~ train@39680  Loss: 0.001964 Acc: 13.2031\n",
      " |~~ train@39744  Loss: 0.001541 Acc: 13.5312\n",
      " |~~ train@39808  Loss: 0.001934 Acc: 13.3750\n",
      " |~~ train@39872  Loss: 0.001813 Acc: 13.4531\n",
      " |~~ train@39936  Loss: 0.002243 Acc: 13.2656\n",
      " |~~ train@40000  Loss: 0.001679 Acc: 13.4531\n",
      " |~~ train@40064  Loss: 0.001935 Acc: 13.3906\n",
      " |~~ train@40128  Loss: 0.001835 Acc: 13.4844\n",
      " |~~ train@40192  Loss: 0.001863 Acc: 13.3438\n",
      " |~~ train@40256  Loss: 0.001920 Acc: 13.4062\n",
      " |~~ train@40320  Loss: 0.002135 Acc: 13.2031\n",
      " |~~ train@40384  Loss: 0.001830 Acc: 13.3594\n",
      " |~~ train@40448  Loss: 0.001914 Acc: 13.3750\n",
      " |~~ train@40512  Loss: 0.001916 Acc: 13.3438\n",
      " |~~ train@40576  Loss: 0.002564 Acc: 13.0312\n",
      " |~~ train@40640  Loss: 0.002164 Acc: 13.2812\n",
      " |~~ train@40704  Loss: 0.002060 Acc: 13.2969\n",
      " |~~ train@40768  Loss: 0.002176 Acc: 13.2969\n",
      " |~~ train@40832  Loss: 0.002384 Acc: 13.1875\n",
      " |~~ train@40896  Loss: 0.001960 Acc: 13.4219\n",
      " |~~ train@40960  Loss: 0.001905 Acc: 13.4531\n",
      " |~~ train@41024  Loss: 0.001782 Acc: 13.3750\n",
      " |~~ train@41088  Loss: 0.001542 Acc: 13.4844\n",
      " |~~ train@41152  Loss: 0.002338 Acc: 13.2656\n",
      " |~~ train@41216  Loss: 0.001904 Acc: 13.2969\n",
      " |~~ train@41280  Loss: 0.002239 Acc: 13.2656\n",
      " |~~ train@41344  Loss: 0.002815 Acc: 13.0938\n",
      " |~~ train@41408  Loss: 0.001764 Acc: 13.4375\n",
      " |~~ train@41472  Loss: 0.002268 Acc: 13.3125\n",
      " |~~ train@41536  Loss: 0.002160 Acc: 13.2969\n",
      " |~~ train@41600  Loss: 0.002653 Acc: 13.0469\n",
      " |~~ train@41664  Loss: 0.002191 Acc: 13.2812\n",
      " |~~ train@41728  Loss: 0.001980 Acc: 13.3750\n",
      " |~~ train@41792  Loss: 0.002101 Acc: 13.2188\n",
      " |~~ train@41856  Loss: 0.001510 Acc: 13.5312\n",
      " |~~ train@41920  Loss: 0.002205 Acc: 13.2812\n",
      " |~~ train@41984  Loss: 0.001609 Acc: 13.4531\n",
      " |~~ train@42048  Loss: 0.002714 Acc: 13.0781\n",
      " |~~ train@42112  Loss: 0.001799 Acc: 13.4375\n",
      " |~~ train@42176  Loss: 0.001842 Acc: 13.4375\n",
      " |~~ train@42240  Loss: 0.002118 Acc: 13.3281\n",
      " |~~ train@42304  Loss: 0.001966 Acc: 13.4219\n",
      " |~~ train@42368  Loss: 0.002087 Acc: 13.3594\n",
      " |~~ train@42432  Loss: 0.001797 Acc: 13.3750\n",
      " |~~ train@42496  Loss: 0.002049 Acc: 13.3438\n",
      " |~~ train@42560  Loss: 0.002102 Acc: 13.3594\n",
      " |~~ train@42624  Loss: 0.001670 Acc: 13.3906\n",
      " |~~ train@42688  Loss: 0.001642 Acc: 13.4531\n",
      " |~~ train@42752  Loss: 0.002070 Acc: 13.3906\n",
      " |~~ train@42816  Loss: 0.001888 Acc: 13.4219\n",
      " |~~ train@42880  Loss: 0.002163 Acc: 13.2656\n",
      " |~~ train@42944  Loss: 0.001986 Acc: 13.3438\n",
      " |~~ train@43008  Loss: 0.002018 Acc: 13.3438\n",
      " |~~ train@43072  Loss: 0.001937 Acc: 13.3125\n",
      " |~~ train@43136  Loss: 0.001849 Acc: 13.4219\n",
      " |~~ train@43200  Loss: 0.002340 Acc: 13.3438\n",
      " |~~ train@43264  Loss: 0.002010 Acc: 13.3281\n",
      " |~~ train@43328  Loss: 0.001716 Acc: 13.4688\n",
      " |~~ train@43392  Loss: 0.002300 Acc: 13.1875\n",
      " |~~ train@43456  Loss: 0.002065 Acc: 13.3281\n",
      " |~~ train@43520  Loss: 0.002094 Acc: 13.3125\n",
      " |~~ train@43584  Loss: 0.002022 Acc: 13.3594\n",
      " |~~ train@43648  Loss: 0.001541 Acc: 13.5469\n",
      " |~~ train@43712  Loss: 0.002507 Acc: 13.1719\n",
      " |~~ train@43776  Loss: 0.001863 Acc: 13.4219\n",
      " |~~ train@43840  Loss: 0.001711 Acc: 13.3906\n",
      " |~~ train@43904  Loss: 0.002123 Acc: 13.2344\n",
      " |~~ train@43968  Loss: 0.002073 Acc: 13.3438\n",
      " |~~ train@44032  Loss: 0.001666 Acc: 13.4531\n",
      " |~~ train@44096  Loss: 0.001551 Acc: 13.4219\n",
      " |~~ train@44160  Loss: 0.001502 Acc: 13.4688\n",
      " |~~ train@44224  Loss: 0.001568 Acc: 13.5312\n",
      " |~~ train@44288  Loss: 0.002210 Acc: 13.2969\n",
      " |~~ train@44352  Loss: 0.002285 Acc: 13.1250\n",
      " |~~ train@44416  Loss: 0.002152 Acc: 13.2812\n",
      " |~~ train@44480  Loss: 0.002029 Acc: 13.2812\n",
      " |~~ train@44544  Loss: 0.002319 Acc: 13.2500\n",
      " |~~ train@44608  Loss: 0.001546 Acc: 13.4375\n",
      " |~~ train@44672  Loss: 0.001796 Acc: 13.4375\n",
      " |~~ train@44736  Loss: 0.001700 Acc: 13.5781\n",
      " |~~ train@44800  Loss: 0.002071 Acc: 13.2344\n",
      " |~~ train@44864  Loss: 0.001794 Acc: 13.5000\n",
      " |~~ train@44928  Loss: 0.002292 Acc: 13.2500\n",
      " |~~ train@44992  Loss: 0.001980 Acc: 13.4062\n",
      " |~~ train@45056  Loss: 0.001445 Acc: 13.6094\n",
      " |~~ train@45120  Loss: 0.002130 Acc: 13.3281\n",
      " |~~ train@45184  Loss: 0.002229 Acc: 13.2188\n",
      " |~~ train@45248  Loss: 0.001662 Acc: 13.4219\n",
      " |~~ train@45312  Loss: 0.001866 Acc: 13.4688\n",
      " |~~ train@45376  Loss: 0.002201 Acc: 13.2969\n",
      " |~~ train@45440  Loss: 0.002047 Acc: 13.3438\n",
      " |~~ train@45504  Loss: 0.001833 Acc: 13.4062\n",
      " |~~ train@45568  Loss: 0.002384 Acc: 13.1875\n",
      " |~~ train@45632  Loss: 0.002494 Acc: 13.2031\n",
      " |~~ train@45696  Loss: 0.002582 Acc: 13.1719\n",
      " |~~ train@45760  Loss: 0.002287 Acc: 13.1875\n",
      " |~~ train@45824  Loss: 0.001742 Acc: 13.4375\n",
      " |~~ train@45888  Loss: 0.001949 Acc: 13.4062\n",
      " |~~ train@45952  Loss: 0.002684 Acc: 13.1094\n",
      " |~~ train@46016  Loss: 0.001605 Acc: 13.5000\n",
      " |~~ train@46080  Loss: 0.002336 Acc: 13.3125\n",
      " |~~ train@46144  Loss: 0.002023 Acc: 13.4062\n",
      " |~~ train@46208  Loss: 0.001814 Acc: 13.3906\n",
      " |~~ train@46272  Loss: 0.001921 Acc: 13.4688\n",
      " |~~ train@46336  Loss: 0.001867 Acc: 13.2656\n",
      " |~~ train@46400  Loss: 0.001860 Acc: 13.4062\n",
      " |~~ train@46464  Loss: 0.002343 Acc: 13.2031\n",
      " |~~ train@46528  Loss: 0.002290 Acc: 13.3594\n",
      " |~~ train@46592  Loss: 0.001700 Acc: 13.4844\n",
      " |~~ train@46656  Loss: 0.002443 Acc: 13.2188\n",
      " |~~ train@46720  Loss: 0.001538 Acc: 13.5469\n",
      " |~~ train@46784  Loss: 0.001856 Acc: 13.2969\n",
      " |~~ train@46848  Loss: 0.001993 Acc: 13.4219\n",
      " |~~ train@46912  Loss: 0.001257 Acc: 13.6406\n",
      " |~~ train@46976  Loss: 0.001741 Acc: 13.4375\n",
      " |~~ train@47040  Loss: 0.001647 Acc: 13.4219\n",
      " |~~ train@47104  Loss: 0.002106 Acc: 13.2656\n",
      " |~~ train@47168  Loss: 0.002171 Acc: 13.3281\n",
      " |~~ train@47232  Loss: 0.001863 Acc: 13.5156\n",
      " |~~ train@47296  Loss: 0.001949 Acc: 13.3750\n",
      " |~~ train@47360  Loss: 0.001862 Acc: 13.3906\n",
      " |~~ train@47424  Loss: 0.001967 Acc: 13.4062\n",
      " |~~ train@47488  Loss: 0.002115 Acc: 13.2969\n",
      " |~~ train@47552  Loss: 0.002296 Acc: 13.2500\n",
      " |~~ train@47616  Loss: 0.002017 Acc: 13.3594\n",
      " |~~ train@47680  Loss: 0.001669 Acc: 13.4219\n",
      " |~~ train@47744  Loss: 0.001919 Acc: 13.4219\n",
      " |~~ train@47808  Loss: 0.002108 Acc: 13.4219\n",
      " |~~ train@47872  Loss: 0.002106 Acc: 13.2969\n",
      " |~~ train@47936  Loss: 0.001838 Acc: 13.4375\n",
      " |~~ train@48000  Loss: 0.001357 Acc: 13.6719\n",
      " |~~ train@48064  Loss: 0.002022 Acc: 13.3281\n",
      " |~~ train@48128  Loss: 0.002226 Acc: 13.1250\n",
      " |~~ train@48192  Loss: 0.002343 Acc: 13.2656\n",
      " |~~ train@48256  Loss: 0.001769 Acc: 13.4375\n",
      " |~~ train@48320  Loss: 0.002805 Acc: 13.0156\n",
      " |~~ train@48384  Loss: 0.002008 Acc: 13.3438\n",
      " |~~ train@48448  Loss: 0.002316 Acc: 13.2812\n",
      " |~~ train@48512  Loss: 0.002089 Acc: 13.3594\n",
      " |~~ train@48576  Loss: 0.001452 Acc: 13.5469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@48640  Loss: 0.001824 Acc: 13.4062\n",
      " |~~ train@48704  Loss: 0.001828 Acc: 13.4531\n",
      " |~~ train@48768  Loss: 0.002251 Acc: 13.2344\n",
      " |~~ train@48832  Loss: 0.002504 Acc: 13.3125\n",
      " |~~ train@48896  Loss: 0.002392 Acc: 13.2656\n",
      " |~~ train@48960  Loss: 0.002150 Acc: 13.3125\n",
      " |~~ train@49024  Loss: 0.002073 Acc: 13.4062\n",
      " |~~ train@49088  Loss: 0.002116 Acc: 13.3281\n",
      " |~~ train@49152  Loss: 0.001944 Acc: 13.3281\n",
      " |~~ train@49216  Loss: 0.001713 Acc: 13.3594\n",
      " |~~ train@49280  Loss: 0.002012 Acc: 13.2812\n",
      " |~~ train@49344  Loss: 0.002233 Acc: 13.2500\n",
      " |~~ train@49408  Loss: 0.002317 Acc: 13.1719\n",
      " |~~ train@49472  Loss: 0.001934 Acc: 13.4219\n",
      " |~~ train@49536  Loss: 0.002287 Acc: 13.3750\n",
      " |~~ train@49600  Loss: 0.002112 Acc: 13.3906\n",
      " |~~ train@49664  Loss: 0.002393 Acc: 13.2500\n",
      " |~~ train@49728  Loss: 0.001776 Acc: 13.4531\n",
      " |~~ train@49792  Loss: 0.002675 Acc: 13.0781\n",
      " |~~ train@49856  Loss: 0.002104 Acc: 13.2656\n",
      " |~~ train@49920  Loss: 0.002313 Acc: 13.2500\n",
      " |~~ train@49984  Loss: 0.001920 Acc: 13.3594\n",
      " |~~ train@50048  Loss: 0.001992 Acc: 13.3594\n",
      " |~~ train@50112  Loss: 0.001954 Acc: 13.3594\n",
      " |~~ train@50176  Loss: 0.002052 Acc: 13.3125\n",
      " |~~ train@50240  Loss: 0.001997 Acc: 13.3594\n",
      " |~~ train@50304  Loss: 0.002340 Acc: 13.2031\n",
      " |~~ train@50368  Loss: 0.001744 Acc: 13.4219\n",
      " |~~ train@50432  Loss: 0.001781 Acc: 13.4375\n",
      " |~~ train@50496  Loss: 0.001926 Acc: 13.3750\n",
      " |~~ train@50560  Loss: 0.002199 Acc: 13.2812\n",
      " |~~ train@50624  Loss: 0.001526 Acc: 13.5000\n",
      " |~~ train@50688  Loss: 0.002177 Acc: 13.3594\n",
      " |~~ train@50752  Loss: 0.002162 Acc: 13.2812\n",
      " |~~ train@50816  Loss: 0.001758 Acc: 13.4062\n",
      " |~~ train@50880  Loss: 0.001550 Acc: 13.4062\n",
      " |~~ train@50944  Loss: 0.002384 Acc: 13.2031\n",
      " |~~ train@51008  Loss: 0.002855 Acc: 13.0781\n",
      " |~~ train@51072  Loss: 0.002039 Acc: 13.3594\n",
      " |~~ train@51136  Loss: 0.001831 Acc: 13.3906\n",
      " |~~ train@51200  Loss: 0.001689 Acc: 13.4219\n",
      " |~~ train@51264  Loss: 0.001832 Acc: 13.4219\n",
      " |~~ train@51328  Loss: 0.001950 Acc: 13.3438\n",
      " |~~ train@51392  Loss: 0.001875 Acc: 13.3438\n",
      " |~~ train@51456  Loss: 0.001541 Acc: 13.5312\n",
      " |~~ train@51520  Loss: 0.002016 Acc: 13.4375\n",
      " |~~ train@51584  Loss: 0.002602 Acc: 13.1094\n",
      " |~~ train@51648  Loss: 0.002182 Acc: 13.1562\n",
      " |~~ train@51712  Loss: 0.002446 Acc: 13.0781\n",
      " |~~ train@51776  Loss: 0.001759 Acc: 13.4531\n",
      " |~~ train@51840  Loss: 0.001834 Acc: 13.3594\n",
      " |~~ train@51904  Loss: 0.001742 Acc: 13.5000\n",
      " |~~ train@51968  Loss: 0.002199 Acc: 13.2656\n",
      " |~~ train@52032  Loss: 0.002126 Acc: 13.2656\n",
      " |~~ train@52096  Loss: 0.002023 Acc: 13.3438\n",
      " |~~ train@52160  Loss: 0.002064 Acc: 13.2812\n",
      " |~~ train@52224  Loss: 0.001778 Acc: 13.4219\n",
      " |~~ train@52288  Loss: 0.001982 Acc: 13.2812\n",
      " |~~ train@52352  Loss: 0.001817 Acc: 13.3438\n",
      " |~~ train@52416  Loss: 0.001785 Acc: 13.2500\n",
      " |~~ train@52480  Loss: 0.001615 Acc: 13.4688\n",
      " |~~ train@52544  Loss: 0.001574 Acc: 13.5312\n",
      " |~~ train@52608  Loss: 0.001918 Acc: 13.4375\n",
      " |~~ train@52672  Loss: 0.002456 Acc: 13.2812\n",
      " |~~ train@52736  Loss: 0.001715 Acc: 13.4062\n",
      " |~~ train@52800  Loss: 0.002552 Acc: 13.0938\n",
      " |~~ train@52864  Loss: 0.001648 Acc: 13.5000\n",
      " |~~ train@52928  Loss: 0.002187 Acc: 13.2969\n",
      " |~~ train@52992  Loss: 0.002758 Acc: 13.0469\n",
      " |~~ train@53056  Loss: 0.002030 Acc: 13.3594\n",
      " |~~ train@53120  Loss: 0.001893 Acc: 13.4062\n",
      " |~~ train@53184  Loss: 0.001913 Acc: 13.4375\n",
      " |~~ train@53248  Loss: 0.002466 Acc: 13.2188\n",
      " |~~ train@53312  Loss: 0.001993 Acc: 13.3125\n",
      " |~~ train@53376  Loss: 0.001917 Acc: 13.3750\n",
      " |~~ train@53440  Loss: 0.001988 Acc: 13.3438\n",
      " |~~ train@53504  Loss: 0.002658 Acc: 13.0469\n",
      " |~~ train@53568  Loss: 0.001734 Acc: 13.4688\n",
      " |~~ train@53632  Loss: 0.002049 Acc: 13.3438\n",
      " |~~ train@53696  Loss: 0.001704 Acc: 13.5000\n",
      " |~~ train@53760  Loss: 0.001892 Acc: 13.4375\n",
      " |~~ train@53824  Loss: 0.001803 Acc: 13.4688\n",
      " |~~ train@53888  Loss: 0.001780 Acc: 13.4219\n",
      " |~~ train@53952  Loss: 0.001636 Acc: 13.4844\n",
      " |~~ train@54016  Loss: 0.001926 Acc: 13.4062\n",
      " |~~ train@54080  Loss: 0.002307 Acc: 13.1406\n",
      " |~~ train@54144  Loss: 0.002136 Acc: 13.2812\n",
      " |~~ train@54208  Loss: 0.001886 Acc: 13.4062\n",
      " |~~ train@54272  Loss: 0.001851 Acc: 13.4219\n",
      " |~~ train@54336  Loss: 0.001828 Acc: 13.4844\n",
      " |~~ train@54400  Loss: 0.001504 Acc: 13.5938\n",
      " |~~ train@54464  Loss: 0.002193 Acc: 13.3125\n",
      " |~~ train@54528  Loss: 0.002411 Acc: 13.2500\n",
      " |~~ train@54592  Loss: 0.001951 Acc: 13.4219\n",
      " |~~ train@54656  Loss: 0.002077 Acc: 13.2812\n",
      " |~~ train@54720  Loss: 0.001637 Acc: 13.5156\n",
      " |~~ train@54784  Loss: 0.001868 Acc: 13.3750\n",
      " |~~ train@54848  Loss: 0.002230 Acc: 13.3594\n",
      " |~~ train@54912  Loss: 0.001981 Acc: 13.3750\n",
      " |~~ train@54976  Loss: 0.001853 Acc: 13.4219\n",
      " |~~ train@55040  Loss: 0.001934 Acc: 13.3281\n",
      " |~~ train@55104  Loss: 0.002477 Acc: 13.1562\n",
      " |~~ train@55168  Loss: 0.001859 Acc: 13.3906\n",
      " |~~ train@55232  Loss: 0.002455 Acc: 13.1875\n",
      " |~~ train@55296  Loss: 0.002365 Acc: 13.2188\n",
      " |~~ train@55360  Loss: 0.002036 Acc: 13.3281\n",
      " |~~ train@55424  Loss: 0.001818 Acc: 13.4688\n",
      " |~~ train@55488  Loss: 0.001996 Acc: 13.3906\n",
      " |~~ train@55552  Loss: 0.001890 Acc: 13.3438\n",
      " |~~ train@55616  Loss: 0.002227 Acc: 13.2344\n",
      " |~~ train@55680  Loss: 0.002003 Acc: 13.3438\n",
      " |~~ train@55744  Loss: 0.002097 Acc: 13.3906\n",
      " |~~ train@55808  Loss: 0.002083 Acc: 13.3125\n",
      " |~~ train@55872  Loss: 0.001864 Acc: 13.4219\n",
      " |~~ train@55936  Loss: 0.001622 Acc: 13.5312\n",
      " |~~ train@56000  Loss: 0.001682 Acc: 13.4531\n",
      " |~~ train@56064  Loss: 0.001965 Acc: 13.4062\n",
      " |~~ train@56128  Loss: 0.001811 Acc: 13.4844\n",
      " |~~ train@56192  Loss: 0.001953 Acc: 13.3906\n",
      " |~~ train@56256  Loss: 0.001964 Acc: 13.3438\n",
      " |~~ train@56320  Loss: 0.001725 Acc: 13.4219\n",
      " |~~ train@56384  Loss: 0.001704 Acc: 13.5469\n",
      " |~~ train@56448  Loss: 0.001831 Acc: 13.4219\n",
      " |~~ train@56512  Loss: 0.001713 Acc: 13.4531\n",
      " |~~ train@56576  Loss: 0.002186 Acc: 13.2344\n",
      " |~~ train@56640  Loss: 0.002887 Acc: 13.0156\n",
      " |~~ train@56704  Loss: 0.002474 Acc: 13.0625\n",
      " |~~ train@56768  Loss: 0.002335 Acc: 13.2344\n",
      " |~~ train@56832  Loss: 0.002466 Acc: 13.1562\n",
      " |~~ train@56896  Loss: 0.001987 Acc: 13.4062\n",
      " |~~ train@56960  Loss: 0.001938 Acc: 13.3906\n",
      " |~~ train@57024  Loss: 0.001914 Acc: 13.3906\n",
      " |~~ train@57088  Loss: 0.002130 Acc: 13.3594\n",
      " |~~ train@57152  Loss: 0.001750 Acc: 13.4531\n",
      " |~~ train@57216  Loss: 0.002041 Acc: 13.4219\n",
      " |~~ train@57280  Loss: 0.001959 Acc: 13.2969\n",
      " |~~ train@57344  Loss: 0.002267 Acc: 13.2500\n",
      " |~~ train@57408  Loss: 0.001888 Acc: 13.3906\n",
      " |~~ train@57472  Loss: 0.002037 Acc: 13.4375\n",
      " |~~ train@57536  Loss: 0.002423 Acc: 13.1562\n",
      " |~~ train@57600  Loss: 0.001776 Acc: 13.3750\n",
      " |~~ train@57664  Loss: 0.001633 Acc: 13.5469\n",
      " |~~ train@57728  Loss: 0.001726 Acc: 13.4219\n",
      " |~~ train@57792  Loss: 0.001913 Acc: 13.3125\n",
      " |~~ train@57856  Loss: 0.002149 Acc: 13.3438\n",
      " |~~ train@57920  Loss: 0.002478 Acc: 13.2500\n",
      " |~~ train@57984  Loss: 0.001812 Acc: 13.4219\n",
      " |~~ train@58048  Loss: 0.002021 Acc: 13.4219\n",
      " |~~ train@58112  Loss: 0.001861 Acc: 13.3281\n",
      " |~~ train@58176  Loss: 0.002048 Acc: 13.3594\n",
      " |~~ train@58240  Loss: 0.001799 Acc: 13.4375\n",
      " |~~ train@58304  Loss: 0.002160 Acc: 13.3125\n",
      " |~~ train@58368  Loss: 0.002200 Acc: 13.3125\n",
      " |~~ train@58432  Loss: 0.001790 Acc: 13.4531\n",
      " |~~ train@58496  Loss: 0.001834 Acc: 13.4062\n",
      " |~~ train@58560  Loss: 0.001969 Acc: 13.4062\n",
      " |~~ train@58624  Loss: 0.002011 Acc: 13.2812\n",
      " |~~ train@58688  Loss: 0.002327 Acc: 13.2188\n",
      " |~~ train@58752  Loss: 0.001964 Acc: 13.3750\n",
      " |~~ train@58816  Loss: 0.002410 Acc: 13.2500\n",
      " |~~ train@58880  Loss: 0.002375 Acc: 13.2344\n",
      " |~~ train@58944  Loss: 0.002113 Acc: 13.2812\n",
      " |~~ train@59008  Loss: 0.002067 Acc: 13.3750\n",
      " |~~ train@59072  Loss: 0.002142 Acc: 13.2656\n",
      " |~~ train@59136  Loss: 0.001707 Acc: 13.4844\n",
      " |~~ train@59200  Loss: 0.002370 Acc: 13.1875\n",
      " |~~ train@59264  Loss: 0.001649 Acc: 13.4531\n",
      " |~~ train@59328  Loss: 0.002069 Acc: 13.3281\n",
      " |~~ train@59392  Loss: 0.001707 Acc: 13.4531\n",
      " |~~ train@59456  Loss: 0.001860 Acc: 13.4375\n",
      " |~~ train@59520  Loss: 0.001624 Acc: 13.4844\n",
      " |~~ train@59584  Loss: 0.001596 Acc: 13.3438\n",
      " |~~ train@59648  Loss: 0.002112 Acc: 13.3281\n",
      " |~~ train@59712  Loss: 0.001853 Acc: 13.4062\n",
      " |~~ train@59776  Loss: 0.002322 Acc: 13.2031\n",
      " |~~ train@59840  Loss: 0.002202 Acc: 13.3125\n",
      " |~~ train@59904  Loss: 0.001752 Acc: 13.4375\n",
      " |~~ train@59968  Loss: 0.001693 Acc: 13.4375\n",
      " |~~ train@60032  Loss: 0.001887 Acc: 13.3750\n",
      " |~~ train@60096  Loss: 0.001533 Acc: 13.5156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@60160  Loss: 0.002117 Acc: 13.3125\n",
      " |~~ train@60224  Loss: 0.001974 Acc: 13.3125\n",
      " |~~ train@60288  Loss: 0.001841 Acc: 13.4219\n",
      " |~~ train@60352  Loss: 0.002112 Acc: 13.3750\n",
      " |~~ train@60416  Loss: 0.002284 Acc: 13.2656\n",
      " |~~ train@60480  Loss: 0.001399 Acc: 13.5938\n",
      " |~~ train@60544  Loss: 0.002243 Acc: 13.2812\n",
      " |~~ train@60608  Loss: 0.002340 Acc: 13.3281\n",
      " |~~ train@60672  Loss: 0.002447 Acc: 13.2031\n",
      " |~~ train@60736  Loss: 0.002092 Acc: 13.3438\n",
      " |~~ train@60800  Loss: 0.001625 Acc: 13.4688\n",
      " |~~ train@60864  Loss: 0.001703 Acc: 13.4844\n",
      " |~~ train@60928  Loss: 0.002041 Acc: 13.3906\n",
      " |~~ train@60992  Loss: 0.002104 Acc: 13.2656\n",
      " |~~ train@61056  Loss: 0.001712 Acc: 13.4844\n",
      " |~~ train@61120  Loss: 0.002040 Acc: 13.3438\n",
      " |~~ train@61184  Loss: 0.002205 Acc: 13.2500\n",
      " |~~ train@61248  Loss: 0.002164 Acc: 13.2656\n",
      " |~~ train@61312  Loss: 0.001834 Acc: 13.4219\n",
      " |~~ train@61376  Loss: 0.002444 Acc: 13.2500\n",
      " |~~ train@61440  Loss: 0.002162 Acc: 13.3281\n",
      " |~~ train@61504  Loss: 0.001715 Acc: 13.4219\n",
      " |~~ train@61568  Loss: 0.001865 Acc: 13.5000\n",
      " |~~ train@61632  Loss: 0.001577 Acc: 13.4844\n",
      " |~~ train@61696  Loss: 0.001414 Acc: 13.5469\n",
      " |~~ train@61760  Loss: 0.001936 Acc: 13.2969\n",
      " |~~ train@61824  Loss: 0.002386 Acc: 13.1875\n",
      " |~~ train@61888  Loss: 0.001651 Acc: 13.3594\n",
      " |~~ train@61952  Loss: 0.002173 Acc: 13.2969\n",
      " |~~ train@62016  Loss: 0.001722 Acc: 13.4844\n",
      " |~~ train@62080  Loss: 0.002036 Acc: 13.2969\n",
      " |~~ train@62144  Loss: 0.002169 Acc: 13.2656\n",
      " |~~ train@62208  Loss: 0.002031 Acc: 13.2656\n",
      " |~~ train@62272  Loss: 0.002011 Acc: 13.2812\n",
      " |~~ train@62336  Loss: 0.001821 Acc: 13.4531\n",
      " |~~ train@62400  Loss: 0.001953 Acc: 13.4062\n",
      " |~~ train@62464  Loss: 0.002332 Acc: 13.1875\n",
      " |~~ train@62528  Loss: 0.001942 Acc: 13.4688\n",
      " |~~ train@62592  Loss: 0.001712 Acc: 13.4688\n",
      " |~~ train@62656  Loss: 0.001852 Acc: 13.4219\n",
      " |~~ train@62720  Loss: 0.002171 Acc: 13.1875\n",
      " |~~ train@62784  Loss: 0.001899 Acc: 13.4844\n",
      " |~~ train@62848  Loss: 0.002266 Acc: 13.3125\n",
      " |~~ train@62912  Loss: 0.001865 Acc: 13.3906\n",
      " |~~ train@62976  Loss: 0.002070 Acc: 13.3750\n",
      " |~~ train@63040  Loss: 0.002114 Acc: 13.3750\n",
      " |~~ train@63104  Loss: 0.002199 Acc: 13.2656\n",
      " |~~ train@63168  Loss: 0.001875 Acc: 13.3906\n",
      " |~~ train@63232  Loss: 0.002089 Acc: 13.4062\n",
      " |~~ train@63296  Loss: 0.002320 Acc: 13.2031\n",
      " |~~ train@63360  Loss: 0.002359 Acc: 13.2188\n",
      " |~~ train@63424  Loss: 0.001992 Acc: 13.2812\n",
      " |~~ train@63488  Loss: 0.002167 Acc: 13.1719\n",
      " |~~ train@63552  Loss: 0.002025 Acc: 13.2656\n",
      " |~~ train@63616  Loss: 0.001821 Acc: 13.4688\n",
      " |~~ train@63680  Loss: 0.001964 Acc: 13.4062\n",
      " |~~ train@63744  Loss: 0.001693 Acc: 13.4844\n",
      " |~~ train@63808  Loss: 0.001725 Acc: 13.3438\n",
      " |~~ train@63872  Loss: 0.001994 Acc: 13.3906\n",
      " |~~ train@63936  Loss: 0.001917 Acc: 13.4219\n",
      " |~~ train@64000  Loss: 0.002201 Acc: 13.2812\n",
      " |~~ train@64064  Loss: 0.002487 Acc: 13.2812\n",
      " |~~ train@64128  Loss: 0.001452 Acc: 13.5156\n",
      " |~~ train@64192  Loss: 0.002670 Acc: 13.1875\n",
      " |~~ train@64256  Loss: 0.001663 Acc: 13.4844\n",
      " |~~ train@64320  Loss: 0.001758 Acc: 13.4062\n",
      " |~~ train@64384  Loss: 0.002111 Acc: 13.3281\n",
      " |~~ train@64448  Loss: 0.002368 Acc: 13.2031\n",
      " |~~ train@64512  Loss: 0.002018 Acc: 13.3281\n",
      " |~~ train@64576  Loss: 0.001976 Acc: 13.3281\n",
      " |~~ train@64640  Loss: 0.001745 Acc: 13.4375\n",
      " |~~ train@64704  Loss: 0.001436 Acc: 13.5625\n",
      " |~~ train@64768  Loss: 0.001907 Acc: 13.3594\n",
      " |~~ train@64832  Loss: 0.002485 Acc: 13.1719\n",
      " |~~ train@64896  Loss: 0.002132 Acc: 13.2500\n",
      " |~~ train@64960  Loss: 0.001524 Acc: 13.4844\n",
      " |~~ train@65024  Loss: 0.001721 Acc: 13.3594\n",
      " |~~ train@65088  Loss: 0.002255 Acc: 13.3281\n",
      " |~~ train@65152  Loss: 0.001898 Acc: 13.4062\n",
      " |~~ train@65216  Loss: 0.001773 Acc: 13.3594\n",
      " |~~ train@65280  Loss: 0.002157 Acc: 13.2344\n",
      " |~~ train@65344  Loss: 0.002101 Acc: 13.2969\n",
      " |~~ train@65408  Loss: 0.002194 Acc: 13.2500\n",
      " |~~ train@65472  Loss: 0.001746 Acc: 13.5000\n",
      " |~~ train@65536  Loss: 0.001738 Acc: 13.3906\n",
      " |~~ train@65600  Loss: 0.001942 Acc: 13.4531\n",
      " |~~ train@65664  Loss: 0.001897 Acc: 13.3906\n",
      " |~~ train@65728  Loss: 0.001899 Acc: 13.4375\n",
      " |~~ train@65792  Loss: 0.001766 Acc: 13.3594\n",
      " |~~ train@65856  Loss: 0.002262 Acc: 13.3438\n",
      " |~~ train@65920  Loss: 0.001594 Acc: 13.4219\n",
      " |~~ train@65984  Loss: 0.002775 Acc: 13.0000\n",
      " |~~ train@66048  Loss: 0.001824 Acc: 13.4219\n",
      " |~~ train@66112  Loss: 0.002413 Acc: 13.1406\n",
      " |~~ train@66176  Loss: 0.002122 Acc: 13.3594\n",
      " |~~ train@66240  Loss: 0.002216 Acc: 13.2188\n",
      " |~~ train@66304  Loss: 0.001642 Acc: 13.4688\n",
      " |~~ train@66368  Loss: 0.002262 Acc: 13.2344\n",
      " |~~ train@66432  Loss: 0.001824 Acc: 13.4375\n",
      " |~~ train@66496  Loss: 0.001780 Acc: 13.4375\n",
      " |~~ train@66560  Loss: 0.001566 Acc: 13.5625\n",
      " |~~ train@66624  Loss: 0.001728 Acc: 13.4062\n",
      " |~~ train@66688  Loss: 0.001966 Acc: 13.3594\n",
      " |~~ train@66752  Loss: 0.002249 Acc: 13.2500\n",
      " |~~ train@66816  Loss: 0.002137 Acc: 13.2656\n",
      " |~~ train@66880  Loss: 0.002424 Acc: 13.1875\n",
      " |~~ train@66944  Loss: 0.001886 Acc: 13.4219\n",
      " |~~ train@67008  Loss: 0.002257 Acc: 13.2344\n",
      " |~~ train@67072  Loss: 0.002174 Acc: 13.3125\n",
      " |~~ train@67136  Loss: 0.002356 Acc: 13.3125\n",
      " |~~ train@67200  Loss: 0.002069 Acc: 13.3125\n",
      " |~~ train@67264  Loss: 0.002068 Acc: 13.3750\n",
      " |~~ train@67328  Loss: 0.001700 Acc: 13.3906\n",
      " |~~ train@67392  Loss: 0.002033 Acc: 13.2969\n",
      " |~~ train@67456  Loss: 0.002011 Acc: 13.3906\n",
      " |~~ train@67520  Loss: 0.001657 Acc: 13.5000\n",
      " |~~ train@67584  Loss: 0.002339 Acc: 13.1406\n",
      " |~~ train@67648  Loss: 0.002138 Acc: 13.3750\n",
      " |~~ train@67712  Loss: 0.001492 Acc: 13.5000\n",
      " |~~ train@67776  Loss: 0.001850 Acc: 13.4375\n",
      " |~~ train@67840  Loss: 0.002652 Acc: 13.1875\n",
      " |~~ train@67904  Loss: 0.002169 Acc: 13.3750\n",
      " |~~ train@67968  Loss: 0.002473 Acc: 13.2500\n",
      " |~~ train@68032  Loss: 0.002090 Acc: 13.3438\n",
      " |~~ train@68096  Loss: 0.002280 Acc: 13.1719\n",
      " |~~ train@68160  Loss: 0.002161 Acc: 13.2500\n",
      " |~~ train@68224  Loss: 0.002246 Acc: 13.3281\n",
      " |~~ train@68288  Loss: 0.002123 Acc: 13.3281\n",
      " |~~ train@68352  Loss: 0.002597 Acc: 13.0625\n",
      " |~~ train@68416  Loss: 0.001639 Acc: 13.5312\n",
      " |~~ train@68480  Loss: 0.001995 Acc: 13.3594\n",
      " |~~ train@68544  Loss: 0.001634 Acc: 13.5781\n",
      " |~~ train@68608  Loss: 0.001500 Acc: 13.5625\n",
      " |~~ train@68672  Loss: 0.001710 Acc: 13.4219\n",
      " |~~ train@68736  Loss: 0.001976 Acc: 13.3594\n",
      " |~~ train@68800  Loss: 0.001638 Acc: 13.4219\n",
      " |~~ train@68864  Loss: 0.002299 Acc: 13.1250\n",
      " |~~ train@68928  Loss: 0.002137 Acc: 13.2812\n",
      " |~~ train@68992  Loss: 0.001903 Acc: 13.3906\n",
      " |~~ train@69056  Loss: 0.002512 Acc: 13.2969\n",
      " |~~ train@69120  Loss: 0.002399 Acc: 13.2188\n",
      " |~~ train@69184  Loss: 0.002253 Acc: 13.2500\n",
      " |~~ train@69248  Loss: 0.002191 Acc: 13.3438\n",
      " |~~ train@69312  Loss: 0.001881 Acc: 13.3438\n",
      " |~~ train@69376  Loss: 0.001791 Acc: 13.4375\n",
      " |~~ train@69440  Loss: 0.002016 Acc: 13.3750\n",
      " |~~ train@69504  Loss: 0.001896 Acc: 13.3906\n",
      " |~~ train@69568  Loss: 0.002055 Acc: 13.3594\n",
      " |~~ train@69632  Loss: 0.001777 Acc: 13.4531\n",
      " |~~ train@69696  Loss: 0.002261 Acc: 13.3281\n",
      " |~~ train@69760  Loss: 0.002362 Acc: 13.2031\n",
      " |~~ train@69824  Loss: 0.002374 Acc: 13.2031\n",
      " |~~ train@69888  Loss: 0.001904 Acc: 13.4375\n",
      " |~~ train@69952  Loss: 0.001828 Acc: 13.3906\n",
      " |~~ train@70016  Loss: 0.002390 Acc: 13.2344\n",
      " |~~ train@70080  Loss: 0.001972 Acc: 13.3750\n",
      " |~~ train@70144  Loss: 0.002389 Acc: 13.1875\n",
      " |~~ train@70208  Loss: 0.002008 Acc: 13.4062\n",
      " |~~ train@70272  Loss: 0.002090 Acc: 13.2344\n",
      " |~~ train@70336  Loss: 0.001576 Acc: 13.5000\n",
      " |~~ train@70400  Loss: 0.001949 Acc: 13.2656\n",
      " |~~ train@70464  Loss: 0.002280 Acc: 13.2188\n",
      " |~~ train@70528  Loss: 0.001547 Acc: 13.5469\n",
      " |~~ train@70592  Loss: 0.002055 Acc: 13.3594\n",
      " |~~ train@70656  Loss: 0.002295 Acc: 13.2031\n",
      " |~~ train@70720  Loss: 0.001673 Acc: 13.5156\n",
      " |~~ train@70784  Loss: 0.001548 Acc: 13.5938\n",
      " |~~ train@70848  Loss: 0.001539 Acc: 13.5625\n",
      " |~~ train@70912  Loss: 0.001797 Acc: 13.4062\n",
      " |~~ train@70976  Loss: 0.002922 Acc: 13.1406\n",
      " |~~ train@71040  Loss: 0.001909 Acc: 13.3438\n",
      " |~~ train@71104  Loss: 0.001824 Acc: 13.4844\n",
      " |~~ train@71168  Loss: 0.002288 Acc: 13.2812\n",
      " |~~ train@71232  Loss: 0.001787 Acc: 13.4375\n",
      " |~~ train@71296  Loss: 0.001602 Acc: 13.4688\n",
      " |~~ train@71360  Loss: 0.001981 Acc: 13.3594\n",
      " |~~ train@71424  Loss: 0.002211 Acc: 13.1719\n",
      " |~~ train@71488  Loss: 0.001597 Acc: 13.5312\n",
      " |~~ train@71552  Loss: 0.001900 Acc: 13.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@71616  Loss: 0.002087 Acc: 13.3281\n",
      " |~~ train@71680  Loss: 0.001845 Acc: 13.5000\n",
      " |~~ train@71744  Loss: 0.001763 Acc: 13.5000\n",
      " |~~ train@71808  Loss: 0.001995 Acc: 13.3594\n",
      " |~~ train@71872  Loss: 0.001914 Acc: 13.4219\n",
      " |~~ train@71936  Loss: 0.002050 Acc: 13.2969\n",
      " |~~ train@72000  Loss: 0.002337 Acc: 13.2812\n",
      " |~~ train@72064  Loss: 0.002137 Acc: 13.3125\n",
      " |~~ train@72128  Loss: 0.002026 Acc: 13.3750\n",
      " |~~ train@72192  Loss: 0.002389 Acc: 13.0938\n",
      " |~~ train@72256  Loss: 0.002278 Acc: 13.3281\n",
      " |~~ train@72320  Loss: 0.002058 Acc: 13.3906\n",
      " |~~ train@72384  Loss: 0.002322 Acc: 13.2656\n",
      " |~~ train@72448  Loss: 0.001972 Acc: 13.3125\n",
      " |~~ train@72512  Loss: 0.001864 Acc: 13.3594\n",
      " |~~ train@72576  Loss: 0.002263 Acc: 13.2188\n",
      " |~~ train@72640  Loss: 0.001967 Acc: 13.3750\n",
      " |~~ train@72704  Loss: 0.002127 Acc: 13.2344\n",
      " |~~ train@72768  Loss: 0.002113 Acc: 13.2969\n",
      " |~~ train@72832  Loss: 0.001647 Acc: 13.5156\n",
      " |~~ train@72896  Loss: 0.002004 Acc: 13.3281\n",
      " |~~ train@72960  Loss: 0.002037 Acc: 13.2969\n",
      " |~~ train@73024  Loss: 0.001718 Acc: 13.4375\n",
      " |~~ train@73088  Loss: 0.002171 Acc: 13.1875\n",
      " |~~ train@73152  Loss: 0.002139 Acc: 13.3125\n",
      " |~~ train@73216  Loss: 0.001904 Acc: 13.4531\n",
      " |~~ train@73280  Loss: 0.002002 Acc: 13.4062\n",
      " |~~ train@73344  Loss: 0.002182 Acc: 13.2344\n",
      " |~~ train@73408  Loss: 0.002265 Acc: 13.3125\n",
      " |~~ train@73472  Loss: 0.002642 Acc: 13.0781\n",
      " |~~ train@73536  Loss: 0.001639 Acc: 13.4844\n",
      " |~~ train@73600  Loss: 0.001774 Acc: 13.4688\n",
      " |~~ train@73664  Loss: 0.001737 Acc: 13.5156\n",
      " |~~ train@73728  Loss: 0.001821 Acc: 13.4531\n",
      " |~~ train@73792  Loss: 0.001850 Acc: 13.3125\n",
      " |~~ train@73856  Loss: 0.001987 Acc: 13.3750\n",
      " |~~ train@73920  Loss: 0.001875 Acc: 13.4219\n",
      " |~~ train@73984  Loss: 0.001786 Acc: 13.4219\n",
      " |~~ train@74048  Loss: 0.001967 Acc: 13.4219\n",
      " |~~ train@74112  Loss: 0.002170 Acc: 13.2812\n",
      " |~~ train@74176  Loss: 0.002125 Acc: 13.4844\n",
      " |~~ train@74240  Loss: 0.001744 Acc: 13.4375\n",
      " |~~ train@74304  Loss: 0.001956 Acc: 13.3906\n",
      " |~~ train@74368  Loss: 0.001628 Acc: 13.5000\n",
      " |~~ train@74432  Loss: 0.002195 Acc: 13.2500\n",
      " |~~ train@74496  Loss: 0.002191 Acc: 13.2344\n",
      " |~~ train@74560  Loss: 0.001761 Acc: 13.4844\n",
      " |~~ train@74624  Loss: 0.001506 Acc: 13.5312\n",
      " |~~ train@74688  Loss: 0.002470 Acc: 13.2188\n",
      " |~~ train@74752  Loss: 0.001866 Acc: 13.4219\n",
      " |~~ train@74816  Loss: 0.001907 Acc: 13.4844\n",
      " |~~ train@74880  Loss: 0.002203 Acc: 13.2500\n",
      " |~~ train@74944  Loss: 0.001991 Acc: 13.4062\n",
      " |~~ train@75008  Loss: 0.001497 Acc: 13.5469\n",
      " |~~ train@75072  Loss: 0.002209 Acc: 13.3281\n",
      " |~~ train@75136  Loss: 0.001806 Acc: 13.4219\n",
      " |~~ train@75200  Loss: 0.002207 Acc: 13.3125\n",
      " |~~ train@75264  Loss: 0.001755 Acc: 13.4531\n",
      " |~~ train@75328  Loss: 0.001466 Acc: 13.6094\n",
      " |~~ train@75392  Loss: 0.001569 Acc: 13.5781\n",
      " |~~ train@75456  Loss: 0.002068 Acc: 13.2500\n",
      " |~~ train@75520  Loss: 0.001517 Acc: 13.5469\n",
      " |~~ train@75584  Loss: 0.001940 Acc: 13.3906\n",
      " |~~ train@75648  Loss: 0.002425 Acc: 13.2500\n",
      " |~~ train@75712  Loss: 0.001704 Acc: 13.4844\n",
      " |~~ train@75776  Loss: 0.002006 Acc: 13.3594\n",
      " |~~ train@75840  Loss: 0.001582 Acc: 13.5781\n",
      " |~~ train@75904  Loss: 0.001943 Acc: 13.3906\n",
      " |~~ train@75968  Loss: 0.002434 Acc: 13.2812\n",
      " |~~ train@76032  Loss: 0.001693 Acc: 13.4375\n",
      " |~~ train@76096  Loss: 0.001642 Acc: 13.4844\n",
      " |~~ train@76160  Loss: 0.001692 Acc: 13.5156\n",
      " |~~ train@76224  Loss: 0.001831 Acc: 13.3750\n",
      " |~~ train@76288  Loss: 0.002370 Acc: 13.1562\n",
      " |~~ train@76352  Loss: 0.002162 Acc: 13.3438\n",
      " |~~ train@76416  Loss: 0.002285 Acc: 13.2031\n",
      " |~~ train@76480  Loss: 0.002356 Acc: 13.1562\n",
      " |~~ train@76544  Loss: 0.002101 Acc: 13.3125\n",
      " |~~ train@76608  Loss: 0.002026 Acc: 13.3438\n",
      " |~~ train@76672  Loss: 0.001581 Acc: 13.5156\n",
      " |~~ train@76736  Loss: 0.001904 Acc: 13.3594\n",
      " |~~ train@76800  Loss: 0.001987 Acc: 13.4062\n",
      " |~~ train@76864  Loss: 0.002186 Acc: 13.2656\n",
      " |~~ train@76928  Loss: 0.001529 Acc: 13.5156\n",
      " |~~ train@76992  Loss: 0.001916 Acc: 13.4375\n",
      " |~~ train@77056  Loss: 0.001877 Acc: 13.3438\n",
      " |~~ train@77120  Loss: 0.002489 Acc: 13.1875\n",
      " |~~ train@77184  Loss: 0.002122 Acc: 13.3594\n",
      " |~~ train@77248  Loss: 0.002278 Acc: 13.1719\n",
      " |~~ train@77312  Loss: 0.002207 Acc: 13.1719\n",
      " |~~ train@77376  Loss: 0.002033 Acc: 13.3281\n",
      " |~~ train@77440  Loss: 0.001793 Acc: 13.3906\n",
      " |~~ train@77504  Loss: 0.001702 Acc: 13.4219\n",
      " |~~ train@77568  Loss: 0.002171 Acc: 13.1875\n",
      " |~~ train@77632  Loss: 0.001903 Acc: 13.3594\n",
      " |~~ train@77696  Loss: 0.002129 Acc: 13.2500\n",
      " |~~ train@77760  Loss: 0.001758 Acc: 13.4375\n",
      " |~~ train@77824  Loss: 0.001904 Acc: 13.3594\n",
      " |~~ train@77888  Loss: 0.001853 Acc: 13.4844\n",
      " |~~ train@77952  Loss: 0.001640 Acc: 13.4219\n",
      " |~~ train@78016  Loss: 0.001610 Acc: 13.5469\n",
      " |~~ train@78080  Loss: 0.001932 Acc: 13.4062\n",
      " |~~ train@78144  Loss: 0.001632 Acc: 13.4219\n",
      " |~~ train@78208  Loss: 0.002200 Acc: 13.1875\n",
      " |~~ train@78272  Loss: 0.002035 Acc: 13.4062\n",
      " |~~ train@78336  Loss: 0.002016 Acc: 13.4219\n",
      " |~~ train@78400  Loss: 0.001585 Acc: 13.4688\n",
      " |~~ train@78464  Loss: 0.002078 Acc: 13.3125\n",
      " |~~ train@78484  Loss: 0.003801 Acc: 13.6500\n",
      "train  Loss: 0.002005 Acc: 13.3522\n",
      " |~~ val@64  Loss: 0.002627 Acc: 13.2188\n",
      " |~~ val@128  Loss: 0.002123 Acc: 13.3125\n",
      " |~~ val@192  Loss: 0.002753 Acc: 13.3125\n",
      " |~~ val@256  Loss: 0.002493 Acc: 13.1562\n",
      " |~~ val@320  Loss: 0.002901 Acc: 13.0625\n",
      " |~~ val@384  Loss: 0.003003 Acc: 13.1875\n",
      " |~~ val@448  Loss: 0.002437 Acc: 13.2656\n",
      " |~~ val@512  Loss: 0.002499 Acc: 13.3281\n",
      " |~~ val@576  Loss: 0.002013 Acc: 13.4062\n",
      " |~~ val@640  Loss: 0.002589 Acc: 13.1875\n",
      " |~~ val@704  Loss: 0.002787 Acc: 13.1719\n",
      " |~~ val@768  Loss: 0.002585 Acc: 13.2500\n",
      " |~~ val@832  Loss: 0.002591 Acc: 13.2500\n",
      " |~~ val@896  Loss: 0.002435 Acc: 13.2656\n",
      " |~~ val@960  Loss: 0.002285 Acc: 13.3438\n",
      " |~~ val@1024  Loss: 0.002422 Acc: 13.3125\n",
      " |~~ val@1088  Loss: 0.002199 Acc: 13.2812\n",
      " |~~ val@1152  Loss: 0.002548 Acc: 13.2344\n",
      " |~~ val@1216  Loss: 0.002172 Acc: 13.4531\n",
      " |~~ val@1280  Loss: 0.002151 Acc: 13.4062\n",
      " |~~ val@1344  Loss: 0.002265 Acc: 13.3438\n",
      " |~~ val@1408  Loss: 0.002561 Acc: 13.2344\n",
      " |~~ val@1472  Loss: 0.002460 Acc: 13.3438\n",
      " |~~ val@1536  Loss: 0.002425 Acc: 13.2969\n",
      " |~~ val@1600  Loss: 0.002836 Acc: 13.1250\n",
      " |~~ val@1664  Loss: 0.001879 Acc: 13.4531\n",
      " |~~ val@1728  Loss: 0.001876 Acc: 13.4688\n",
      " |~~ val@1792  Loss: 0.002469 Acc: 13.3281\n",
      " |~~ val@1856  Loss: 0.002709 Acc: 13.1562\n",
      " |~~ val@1920  Loss: 0.002640 Acc: 13.1875\n",
      " |~~ val@1984  Loss: 0.001985 Acc: 13.3906\n",
      " |~~ val@2048  Loss: 0.002090 Acc: 13.3750\n",
      " |~~ val@2112  Loss: 0.002223 Acc: 13.2969\n",
      " |~~ val@2176  Loss: 0.002133 Acc: 13.3594\n",
      " |~~ val@2240  Loss: 0.002488 Acc: 13.3281\n",
      " |~~ val@2304  Loss: 0.002185 Acc: 13.4062\n",
      " |~~ val@2368  Loss: 0.002615 Acc: 13.2344\n",
      " |~~ val@2432  Loss: 0.001974 Acc: 13.4688\n",
      " |~~ val@2496  Loss: 0.002308 Acc: 13.3281\n",
      " |~~ val@2560  Loss: 0.002444 Acc: 13.2969\n",
      " |~~ val@2624  Loss: 0.002619 Acc: 13.2188\n",
      " |~~ val@2688  Loss: 0.002616 Acc: 13.2344\n",
      " |~~ val@2752  Loss: 0.002632 Acc: 13.2188\n",
      " |~~ val@2816  Loss: 0.002273 Acc: 13.2969\n",
      " |~~ val@2880  Loss: 0.001600 Acc: 13.5312\n",
      " |~~ val@2944  Loss: 0.002390 Acc: 13.2656\n",
      " |~~ val@3008  Loss: 0.001968 Acc: 13.4219\n",
      " |~~ val@3072  Loss: 0.002232 Acc: 13.2500\n",
      " |~~ val@3136  Loss: 0.001797 Acc: 13.4844\n",
      " |~~ val@3200  Loss: 0.001925 Acc: 13.3438\n",
      " |~~ val@3264  Loss: 0.002926 Acc: 13.0938\n",
      " |~~ val@3328  Loss: 0.002127 Acc: 13.3438\n",
      " |~~ val@3392  Loss: 0.002707 Acc: 13.2344\n",
      " |~~ val@3456  Loss: 0.002236 Acc: 13.3750\n",
      " |~~ val@3520  Loss: 0.002132 Acc: 13.3594\n",
      " |~~ val@3584  Loss: 0.002715 Acc: 13.1094\n",
      " |~~ val@3648  Loss: 0.002362 Acc: 13.2656\n",
      " |~~ val@3712  Loss: 0.001771 Acc: 13.5156\n",
      " |~~ val@3776  Loss: 0.002492 Acc: 13.2500\n",
      " |~~ val@3840  Loss: 0.002716 Acc: 13.2031\n",
      " |~~ val@3904  Loss: 0.002320 Acc: 13.3438\n",
      " |~~ val@3968  Loss: 0.002140 Acc: 13.3594\n",
      " |~~ val@4032  Loss: 0.002402 Acc: 13.2031\n",
      " |~~ val@4096  Loss: 0.003299 Acc: 13.0000\n",
      " |~~ val@4160  Loss: 0.001990 Acc: 13.3906\n",
      " |~~ val@4224  Loss: 0.002434 Acc: 13.2656\n",
      " |~~ val@4288  Loss: 0.001905 Acc: 13.4219\n",
      " |~~ val@4352  Loss: 0.001782 Acc: 13.5469\n",
      " |~~ val@4416  Loss: 0.001990 Acc: 13.3438\n",
      " |~~ val@4480  Loss: 0.002781 Acc: 13.1562\n",
      " |~~ val@4544  Loss: 0.002566 Acc: 13.2500\n",
      " |~~ val@4608  Loss: 0.002511 Acc: 13.2656\n",
      " |~~ val@4672  Loss: 0.001851 Acc: 13.3906\n",
      " |~~ val@4736  Loss: 0.002232 Acc: 13.3438\n",
      " |~~ val@4800  Loss: 0.002328 Acc: 13.2031\n",
      " |~~ val@4864  Loss: 0.002446 Acc: 13.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@4928  Loss: 0.002084 Acc: 13.4062\n",
      " |~~ val@4992  Loss: 0.002525 Acc: 13.2500\n",
      " |~~ val@5056  Loss: 0.002229 Acc: 13.2500\n",
      " |~~ val@5120  Loss: 0.002159 Acc: 13.3750\n",
      " |~~ val@5184  Loss: 0.002438 Acc: 13.2969\n",
      " |~~ val@5248  Loss: 0.002789 Acc: 13.2656\n",
      " |~~ val@5312  Loss: 0.002544 Acc: 13.2812\n",
      " |~~ val@5376  Loss: 0.002134 Acc: 13.3906\n",
      " |~~ val@5440  Loss: 0.002197 Acc: 13.3438\n",
      " |~~ val@5504  Loss: 0.002306 Acc: 13.3594\n",
      " |~~ val@5568  Loss: 0.002680 Acc: 13.2656\n",
      " |~~ val@5632  Loss: 0.002351 Acc: 13.3906\n",
      " |~~ val@5696  Loss: 0.002744 Acc: 13.0938\n",
      " |~~ val@5760  Loss: 0.002442 Acc: 13.2344\n",
      " |~~ val@5824  Loss: 0.002345 Acc: 13.2656\n",
      " |~~ val@5888  Loss: 0.002202 Acc: 13.2656\n",
      " |~~ val@5952  Loss: 0.002793 Acc: 13.1875\n",
      " |~~ val@6016  Loss: 0.002106 Acc: 13.4062\n",
      " |~~ val@6080  Loss: 0.002786 Acc: 13.1562\n",
      " |~~ val@6144  Loss: 0.001843 Acc: 13.4688\n",
      " |~~ val@6208  Loss: 0.002137 Acc: 13.3906\n",
      " |~~ val@6272  Loss: 0.002358 Acc: 13.2656\n",
      " |~~ val@6336  Loss: 0.002504 Acc: 13.2031\n",
      " |~~ val@6400  Loss: 0.002211 Acc: 13.3438\n",
      " |~~ val@6464  Loss: 0.002428 Acc: 13.0938\n",
      " |~~ val@6528  Loss: 0.002280 Acc: 13.2656\n",
      " |~~ val@6592  Loss: 0.002498 Acc: 13.2344\n",
      " |~~ val@6656  Loss: 0.001800 Acc: 13.5000\n",
      " |~~ val@6720  Loss: 0.002160 Acc: 13.2656\n",
      " |~~ val@6784  Loss: 0.002456 Acc: 13.1719\n",
      " |~~ val@6848  Loss: 0.002397 Acc: 13.2656\n",
      " |~~ val@6912  Loss: 0.002044 Acc: 13.3750\n",
      " |~~ val@6976  Loss: 0.002374 Acc: 13.1875\n",
      " |~~ val@7040  Loss: 0.002432 Acc: 13.2344\n",
      " |~~ val@7104  Loss: 0.002500 Acc: 13.2656\n",
      " |~~ val@7168  Loss: 0.002095 Acc: 13.3906\n",
      " |~~ val@7232  Loss: 0.002367 Acc: 13.2969\n",
      " |~~ val@7296  Loss: 0.002081 Acc: 13.3281\n",
      " |~~ val@7360  Loss: 0.002328 Acc: 13.3438\n",
      " |~~ val@7424  Loss: 0.002188 Acc: 13.3438\n",
      " |~~ val@7488  Loss: 0.002381 Acc: 13.2500\n",
      " |~~ val@7552  Loss: 0.002734 Acc: 13.1250\n",
      " |~~ val@7616  Loss: 0.002917 Acc: 13.1250\n",
      " |~~ val@7680  Loss: 0.001896 Acc: 13.3594\n",
      " |~~ val@7744  Loss: 0.002450 Acc: 13.2656\n",
      " |~~ val@7808  Loss: 0.002215 Acc: 13.2812\n",
      " |~~ val@7872  Loss: 0.001873 Acc: 13.4531\n",
      " |~~ val@7936  Loss: 0.002574 Acc: 13.1562\n",
      " |~~ val@8000  Loss: 0.001834 Acc: 13.5000\n",
      " |~~ val@8064  Loss: 0.002684 Acc: 13.1406\n",
      " |~~ val@8128  Loss: 0.002645 Acc: 13.2031\n",
      " |~~ val@8192  Loss: 0.002498 Acc: 13.2031\n",
      " |~~ val@8256  Loss: 0.002360 Acc: 13.3281\n",
      " |~~ val@8320  Loss: 0.001537 Acc: 13.5156\n",
      " |~~ val@8384  Loss: 0.002238 Acc: 13.3125\n",
      " |~~ val@8448  Loss: 0.002812 Acc: 13.1562\n",
      " |~~ val@8512  Loss: 0.002247 Acc: 13.3906\n",
      " |~~ val@8576  Loss: 0.002474 Acc: 13.2969\n",
      " |~~ val@8640  Loss: 0.002084 Acc: 13.3281\n",
      " |~~ val@8704  Loss: 0.002875 Acc: 13.1250\n",
      " |~~ val@8768  Loss: 0.002386 Acc: 13.2812\n",
      " |~~ val@8832  Loss: 0.002153 Acc: 13.3594\n",
      " |~~ val@8896  Loss: 0.002164 Acc: 13.2656\n",
      " |~~ val@8960  Loss: 0.002219 Acc: 13.3594\n",
      " |~~ val@9024  Loss: 0.002440 Acc: 13.2656\n",
      " |~~ val@9088  Loss: 0.002112 Acc: 13.4375\n",
      " |~~ val@9152  Loss: 0.002228 Acc: 13.3438\n",
      " |~~ val@9216  Loss: 0.002128 Acc: 13.4375\n",
      " |~~ val@9280  Loss: 0.002447 Acc: 13.2344\n",
      " |~~ val@9344  Loss: 0.002087 Acc: 13.4062\n",
      " |~~ val@9408  Loss: 0.002637 Acc: 13.1719\n",
      " |~~ val@9472  Loss: 0.002027 Acc: 13.3906\n",
      " |~~ val@9536  Loss: 0.002082 Acc: 13.3438\n",
      " |~~ val@9600  Loss: 0.001966 Acc: 13.4688\n",
      " |~~ val@9664  Loss: 0.002516 Acc: 13.2344\n",
      " |~~ val@9728  Loss: 0.002676 Acc: 13.1562\n",
      " |~~ val@9792  Loss: 0.002501 Acc: 13.1719\n",
      " |~~ val@9856  Loss: 0.003239 Acc: 13.1094\n",
      " |~~ val@9920  Loss: 0.002740 Acc: 13.1719\n",
      " |~~ val@9984  Loss: 0.002276 Acc: 13.2812\n",
      " |~~ val@10048  Loss: 0.002731 Acc: 13.1562\n",
      " |~~ val@10112  Loss: 0.001787 Acc: 13.4375\n",
      " |~~ val@10176  Loss: 0.002127 Acc: 13.4219\n",
      " |~~ val@10240  Loss: 0.002218 Acc: 13.3750\n",
      " |~~ val@10304  Loss: 0.001960 Acc: 13.4219\n",
      " |~~ val@10368  Loss: 0.002155 Acc: 13.3438\n",
      " |~~ val@10432  Loss: 0.002715 Acc: 13.1562\n",
      " |~~ val@10496  Loss: 0.002286 Acc: 13.3438\n",
      " |~~ val@10560  Loss: 0.002239 Acc: 13.3594\n",
      " |~~ val@10624  Loss: 0.001926 Acc: 13.5312\n",
      " |~~ val@10688  Loss: 0.002231 Acc: 13.2344\n",
      " |~~ val@10752  Loss: 0.001987 Acc: 13.3594\n",
      " |~~ val@10816  Loss: 0.002289 Acc: 13.2969\n",
      " |~~ val@10880  Loss: 0.002363 Acc: 13.3438\n",
      " |~~ val@10944  Loss: 0.002313 Acc: 13.1875\n",
      " |~~ val@11008  Loss: 0.002821 Acc: 13.2344\n",
      " |~~ val@11072  Loss: 0.002919 Acc: 13.1875\n",
      " |~~ val@11136  Loss: 0.002323 Acc: 13.2344\n",
      " |~~ val@11200  Loss: 0.002520 Acc: 13.2500\n",
      " |~~ val@11264  Loss: 0.002186 Acc: 13.3438\n",
      " |~~ val@11328  Loss: 0.002584 Acc: 13.2031\n",
      " |~~ val@11392  Loss: 0.002912 Acc: 13.0469\n",
      " |~~ val@11456  Loss: 0.002771 Acc: 13.1250\n",
      " |~~ val@11520  Loss: 0.002199 Acc: 13.4062\n",
      " |~~ val@11584  Loss: 0.002659 Acc: 13.1406\n",
      " |~~ val@11648  Loss: 0.003097 Acc: 13.0781\n",
      " |~~ val@11712  Loss: 0.002566 Acc: 13.2031\n",
      " |~~ val@11776  Loss: 0.002629 Acc: 13.2188\n",
      " |~~ val@11840  Loss: 0.002625 Acc: 13.2344\n",
      " |~~ val@11904  Loss: 0.002021 Acc: 13.3281\n",
      " |~~ val@11968  Loss: 0.002258 Acc: 13.2812\n",
      " |~~ val@12032  Loss: 0.002604 Acc: 13.2500\n",
      " |~~ val@12096  Loss: 0.002089 Acc: 13.3750\n",
      " |~~ val@12160  Loss: 0.002545 Acc: 13.1875\n",
      " |~~ val@12224  Loss: 0.002435 Acc: 13.2500\n",
      " |~~ val@12288  Loss: 0.002342 Acc: 13.2344\n",
      " |~~ val@12352  Loss: 0.002446 Acc: 13.3281\n",
      " |~~ val@12416  Loss: 0.002715 Acc: 13.2031\n",
      " |~~ val@12480  Loss: 0.002349 Acc: 13.2656\n",
      " |~~ val@12544  Loss: 0.002239 Acc: 13.1719\n",
      " |~~ val@12608  Loss: 0.002158 Acc: 13.4375\n",
      " |~~ val@12672  Loss: 0.002210 Acc: 13.3125\n",
      " |~~ val@12736  Loss: 0.002517 Acc: 13.1406\n",
      " |~~ val@12800  Loss: 0.002590 Acc: 13.1719\n",
      " |~~ val@12864  Loss: 0.002392 Acc: 13.2812\n",
      " |~~ val@12928  Loss: 0.002419 Acc: 13.2812\n",
      " |~~ val@12992  Loss: 0.002372 Acc: 13.2969\n",
      " |~~ val@13056  Loss: 0.002134 Acc: 13.3750\n",
      " |~~ val@13120  Loss: 0.002541 Acc: 13.2031\n",
      " |~~ val@13184  Loss: 0.002771 Acc: 13.0938\n",
      " |~~ val@13248  Loss: 0.002558 Acc: 13.3281\n",
      " |~~ val@13312  Loss: 0.002829 Acc: 13.2031\n",
      " |~~ val@13376  Loss: 0.002337 Acc: 13.2656\n",
      " |~~ val@13440  Loss: 0.002190 Acc: 13.3750\n",
      " |~~ val@13504  Loss: 0.002858 Acc: 13.2188\n",
      " |~~ val@13568  Loss: 0.002306 Acc: 13.2656\n",
      " |~~ val@13632  Loss: 0.002985 Acc: 12.9844\n",
      " |~~ val@13696  Loss: 0.001899 Acc: 13.3906\n",
      " |~~ val@13760  Loss: 0.002649 Acc: 13.1250\n",
      " |~~ val@13824  Loss: 0.002342 Acc: 13.2656\n",
      " |~~ val@13888  Loss: 0.002558 Acc: 13.3125\n",
      " |~~ val@13952  Loss: 0.001815 Acc: 13.4531\n",
      " |~~ val@14016  Loss: 0.002356 Acc: 13.2656\n",
      " |~~ val@14080  Loss: 0.002148 Acc: 13.2969\n",
      " |~~ val@14144  Loss: 0.002151 Acc: 13.4688\n",
      " |~~ val@14208  Loss: 0.002574 Acc: 13.1719\n",
      " |~~ val@14272  Loss: 0.002748 Acc: 13.1406\n",
      " |~~ val@14336  Loss: 0.002281 Acc: 13.3125\n",
      " |~~ val@14400  Loss: 0.002010 Acc: 13.3281\n",
      " |~~ val@14464  Loss: 0.002360 Acc: 13.2656\n",
      " |~~ val@14528  Loss: 0.002341 Acc: 13.2344\n",
      " |~~ val@14592  Loss: 0.001852 Acc: 13.4219\n",
      " |~~ val@14656  Loss: 0.002049 Acc: 13.4062\n",
      " |~~ val@14720  Loss: 0.002426 Acc: 13.3438\n",
      " |~~ val@14784  Loss: 0.002581 Acc: 13.2188\n",
      " |~~ val@14848  Loss: 0.001970 Acc: 13.4219\n",
      " |~~ val@14912  Loss: 0.002654 Acc: 13.1562\n",
      " |~~ val@14976  Loss: 0.002183 Acc: 13.2969\n",
      " |~~ val@15040  Loss: 0.002772 Acc: 13.0938\n",
      " |~~ val@15104  Loss: 0.002006 Acc: 13.3906\n",
      " |~~ val@15168  Loss: 0.002079 Acc: 13.4844\n",
      " |~~ val@15232  Loss: 0.002616 Acc: 13.2188\n",
      " |~~ val@15296  Loss: 0.002896 Acc: 13.1250\n",
      " |~~ val@15360  Loss: 0.002308 Acc: 13.2969\n",
      " |~~ val@15424  Loss: 0.002782 Acc: 13.1562\n",
      " |~~ val@15488  Loss: 0.002266 Acc: 13.2969\n",
      " |~~ val@15552  Loss: 0.002410 Acc: 13.2812\n",
      " |~~ val@15616  Loss: 0.002001 Acc: 13.3281\n",
      " |~~ val@15680  Loss: 0.003003 Acc: 13.0781\n",
      " |~~ val@15744  Loss: 0.002397 Acc: 13.2969\n",
      " |~~ val@15808  Loss: 0.002760 Acc: 13.1875\n",
      " |~~ val@15872  Loss: 0.002106 Acc: 13.3750\n",
      " |~~ val@15936  Loss: 0.002491 Acc: 13.1875\n",
      " |~~ val@16000  Loss: 0.002544 Acc: 13.2500\n",
      " |~~ val@16064  Loss: 0.002160 Acc: 13.3906\n",
      " |~~ val@16128  Loss: 0.002644 Acc: 13.0938\n",
      " |~~ val@16192  Loss: 0.003125 Acc: 13.0938\n",
      " |~~ val@16256  Loss: 0.002493 Acc: 13.3438\n",
      " |~~ val@16320  Loss: 0.002491 Acc: 13.3125\n",
      " |~~ val@16384  Loss: 0.002271 Acc: 13.2656\n",
      " |~~ val@16448  Loss: 0.002163 Acc: 13.4219\n",
      " |~~ val@16512  Loss: 0.002512 Acc: 13.1562\n",
      " |~~ val@16576  Loss: 0.002448 Acc: 13.2344\n",
      " |~~ val@16640  Loss: 0.002653 Acc: 13.2656\n",
      " |~~ val@16704  Loss: 0.002694 Acc: 13.2188\n",
      " |~~ val@16768  Loss: 0.002640 Acc: 13.2656\n",
      " |~~ val@16832  Loss: 0.002228 Acc: 13.2188\n",
      " |~~ val@16896  Loss: 0.002182 Acc: 13.3438\n",
      " |~~ val@16960  Loss: 0.002707 Acc: 13.2031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@17024  Loss: 0.002504 Acc: 13.2188\n",
      " |~~ val@17088  Loss: 0.002160 Acc: 13.3906\n",
      " |~~ val@17152  Loss: 0.002357 Acc: 13.2500\n",
      " |~~ val@17216  Loss: 0.002064 Acc: 13.3750\n",
      " |~~ val@17280  Loss: 0.002349 Acc: 13.2969\n",
      " |~~ val@17344  Loss: 0.002269 Acc: 13.2812\n",
      " |~~ val@17408  Loss: 0.002417 Acc: 13.2344\n",
      " |~~ val@17472  Loss: 0.002221 Acc: 13.4062\n",
      " |~~ val@17536  Loss: 0.002496 Acc: 13.2188\n",
      " |~~ val@17600  Loss: 0.002299 Acc: 13.1875\n",
      " |~~ val@17664  Loss: 0.002047 Acc: 13.3594\n",
      " |~~ val@17728  Loss: 0.001948 Acc: 13.4375\n",
      " |~~ val@17792  Loss: 0.002371 Acc: 13.2031\n",
      " |~~ val@17856  Loss: 0.001747 Acc: 13.6250\n",
      " |~~ val@17920  Loss: 0.003791 Acc: 12.8594\n",
      " |~~ val@17984  Loss: 0.002523 Acc: 13.2812\n",
      " |~~ val@18048  Loss: 0.002331 Acc: 13.1562\n",
      " |~~ val@18112  Loss: 0.002074 Acc: 13.3438\n",
      " |~~ val@18176  Loss: 0.002814 Acc: 13.0938\n",
      " |~~ val@18240  Loss: 0.001895 Acc: 13.4531\n",
      " |~~ val@18304  Loss: 0.001666 Acc: 13.4688\n",
      " |~~ val@18368  Loss: 0.003100 Acc: 13.0469\n",
      " |~~ val@18432  Loss: 0.002037 Acc: 13.3594\n",
      " |~~ val@18496  Loss: 0.002476 Acc: 13.2656\n",
      " |~~ val@18560  Loss: 0.002295 Acc: 13.2969\n",
      " |~~ val@18624  Loss: 0.002720 Acc: 13.1406\n",
      " |~~ val@18688  Loss: 0.002579 Acc: 13.2812\n",
      " |~~ val@18752  Loss: 0.002630 Acc: 13.0625\n",
      " |~~ val@18816  Loss: 0.002483 Acc: 13.2031\n",
      " |~~ val@18880  Loss: 0.002264 Acc: 13.2969\n",
      " |~~ val@18944  Loss: 0.003039 Acc: 13.0938\n",
      " |~~ val@19008  Loss: 0.002773 Acc: 13.1250\n",
      " |~~ val@19072  Loss: 0.002282 Acc: 13.3594\n",
      " |~~ val@19136  Loss: 0.002483 Acc: 13.2344\n",
      " |~~ val@19200  Loss: 0.002115 Acc: 13.2812\n",
      " |~~ val@19264  Loss: 0.002065 Acc: 13.3594\n",
      " |~~ val@19328  Loss: 0.002018 Acc: 13.3750\n",
      " |~~ val@19392  Loss: 0.002527 Acc: 13.2344\n",
      " |~~ val@19456  Loss: 0.002444 Acc: 13.3594\n",
      " |~~ val@19520  Loss: 0.002116 Acc: 13.4062\n",
      " |~~ val@19584  Loss: 0.002013 Acc: 13.4219\n",
      " |~~ val@19648  Loss: 0.002041 Acc: 13.3750\n",
      " |~~ val@19712  Loss: 0.002362 Acc: 13.2031\n",
      " |~~ val@19776  Loss: 0.001867 Acc: 13.5000\n",
      " |~~ val@19840  Loss: 0.002567 Acc: 13.1875\n",
      " |~~ val@19904  Loss: 0.003281 Acc: 13.0000\n",
      " |~~ val@19968  Loss: 0.002217 Acc: 13.2188\n",
      " |~~ val@20032  Loss: 0.002256 Acc: 13.2812\n",
      " |~~ val@20096  Loss: 0.002174 Acc: 13.3750\n",
      " |~~ val@20160  Loss: 0.002880 Acc: 13.1562\n",
      " |~~ val@20224  Loss: 0.001806 Acc: 13.5469\n",
      " |~~ val@20288  Loss: 0.002395 Acc: 13.2969\n",
      " |~~ val@20352  Loss: 0.002105 Acc: 13.3594\n",
      " |~~ val@20416  Loss: 0.002364 Acc: 13.2969\n",
      " |~~ val@20480  Loss: 0.002968 Acc: 13.2344\n",
      " |~~ val@20544  Loss: 0.002345 Acc: 13.2812\n",
      " |~~ val@20608  Loss: 0.001932 Acc: 13.4531\n",
      " |~~ val@20672  Loss: 0.002035 Acc: 13.3906\n",
      " |~~ val@20736  Loss: 0.002308 Acc: 13.4219\n",
      " |~~ val@20800  Loss: 0.003137 Acc: 13.0625\n",
      " |~~ val@20864  Loss: 0.002085 Acc: 13.3750\n",
      " |~~ val@20928  Loss: 0.001904 Acc: 13.4375\n",
      " |~~ val@20992  Loss: 0.002030 Acc: 13.4375\n",
      " |~~ val@21056  Loss: 0.002305 Acc: 13.3281\n",
      " |~~ val@21120  Loss: 0.002842 Acc: 13.1094\n",
      " |~~ val@21184  Loss: 0.002376 Acc: 13.2969\n",
      " |~~ val@21248  Loss: 0.002445 Acc: 13.1875\n",
      " |~~ val@21312  Loss: 0.002130 Acc: 13.2812\n",
      " |~~ val@21376  Loss: 0.002605 Acc: 13.2188\n",
      " |~~ val@21440  Loss: 0.002562 Acc: 13.1875\n",
      " |~~ val@21504  Loss: 0.002080 Acc: 13.3125\n",
      " |~~ val@21568  Loss: 0.002466 Acc: 13.1250\n",
      " |~~ val@21632  Loss: 0.003106 Acc: 13.0781\n",
      " |~~ val@21696  Loss: 0.002582 Acc: 13.0469\n",
      " |~~ val@21760  Loss: 0.001961 Acc: 13.3906\n",
      " |~~ val@21824  Loss: 0.002532 Acc: 13.1562\n",
      " |~~ val@21888  Loss: 0.002187 Acc: 13.3125\n",
      " |~~ val@21952  Loss: 0.002047 Acc: 13.3750\n",
      " |~~ val@22016  Loss: 0.002527 Acc: 13.1875\n",
      " |~~ val@22080  Loss: 0.002483 Acc: 13.2031\n",
      " |~~ val@22144  Loss: 0.002016 Acc: 13.4531\n",
      " |~~ val@22208  Loss: 0.001755 Acc: 13.5000\n",
      " |~~ val@22272  Loss: 0.003037 Acc: 13.1094\n",
      " |~~ val@22336  Loss: 0.002262 Acc: 13.2031\n",
      " |~~ val@22400  Loss: 0.002521 Acc: 13.1875\n",
      " |~~ val@22424  Loss: 0.004424 Acc: 13.4583\n",
      "val  Loss: 0.002376 Acc: 13.2811\n",
      "Epoch 8/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.001622 Acc: 13.4062\n",
      " |~~ train@128  Loss: 0.001804 Acc: 13.4531\n",
      " |~~ train@192  Loss: 0.002050 Acc: 13.2812\n",
      " |~~ train@256  Loss: 0.002002 Acc: 13.2969\n",
      " |~~ train@320  Loss: 0.002096 Acc: 13.2969\n",
      " |~~ train@384  Loss: 0.002373 Acc: 13.2188\n",
      " |~~ train@448  Loss: 0.001677 Acc: 13.4375\n",
      " |~~ train@512  Loss: 0.001909 Acc: 13.3594\n",
      " |~~ train@576  Loss: 0.001350 Acc: 13.6406\n",
      " |~~ train@640  Loss: 0.002082 Acc: 13.2031\n",
      " |~~ train@704  Loss: 0.002087 Acc: 13.3125\n",
      " |~~ train@768  Loss: 0.001901 Acc: 13.4219\n",
      " |~~ train@832  Loss: 0.001873 Acc: 13.2812\n",
      " |~~ train@896  Loss: 0.001932 Acc: 13.3750\n",
      " |~~ train@960  Loss: 0.001964 Acc: 13.3594\n",
      " |~~ train@1024  Loss: 0.001821 Acc: 13.4219\n",
      " |~~ train@1088  Loss: 0.002400 Acc: 13.1875\n",
      " |~~ train@1152  Loss: 0.001934 Acc: 13.2969\n",
      " |~~ train@1216  Loss: 0.002416 Acc: 13.2188\n",
      " |~~ train@1280  Loss: 0.001827 Acc: 13.3281\n",
      " |~~ train@1344  Loss: 0.002246 Acc: 13.2344\n",
      " |~~ train@1408  Loss: 0.001787 Acc: 13.4531\n",
      " |~~ train@1472  Loss: 0.002299 Acc: 13.2188\n",
      " |~~ train@1536  Loss: 0.002733 Acc: 13.1562\n",
      " |~~ train@1600  Loss: 0.001799 Acc: 13.4375\n",
      " |~~ train@1664  Loss: 0.002156 Acc: 13.4062\n",
      " |~~ train@1728  Loss: 0.002322 Acc: 13.1562\n",
      " |~~ train@1792  Loss: 0.001710 Acc: 13.4062\n",
      " |~~ train@1856  Loss: 0.002040 Acc: 13.2969\n",
      " |~~ train@1920  Loss: 0.001742 Acc: 13.4531\n",
      " |~~ train@1984  Loss: 0.002113 Acc: 13.3125\n",
      " |~~ train@2048  Loss: 0.002226 Acc: 13.2500\n",
      " |~~ train@2112  Loss: 0.001794 Acc: 13.3906\n",
      " |~~ train@2176  Loss: 0.001840 Acc: 13.4531\n",
      " |~~ train@2240  Loss: 0.001756 Acc: 13.3438\n",
      " |~~ train@2304  Loss: 0.001403 Acc: 13.5469\n",
      " |~~ train@2368  Loss: 0.001911 Acc: 13.4062\n",
      " |~~ train@2432  Loss: 0.002420 Acc: 13.1875\n",
      " |~~ train@2496  Loss: 0.002081 Acc: 13.3125\n",
      " |~~ train@2560  Loss: 0.002351 Acc: 13.2969\n",
      " |~~ train@2624  Loss: 0.001894 Acc: 13.4062\n",
      " |~~ train@2688  Loss: 0.002402 Acc: 13.2344\n",
      " |~~ train@2752  Loss: 0.002073 Acc: 13.2812\n",
      " |~~ train@2816  Loss: 0.001592 Acc: 13.5000\n",
      " |~~ train@2880  Loss: 0.001519 Acc: 13.5781\n",
      " |~~ train@2944  Loss: 0.002009 Acc: 13.3750\n",
      " |~~ train@3008  Loss: 0.002509 Acc: 13.2188\n",
      " |~~ train@3072  Loss: 0.001676 Acc: 13.3750\n",
      " |~~ train@3136  Loss: 0.001713 Acc: 13.5000\n",
      " |~~ train@3200  Loss: 0.001833 Acc: 13.4062\n",
      " |~~ train@3264  Loss: 0.002207 Acc: 13.2656\n",
      " |~~ train@3328  Loss: 0.001751 Acc: 13.4844\n",
      " |~~ train@3392  Loss: 0.002671 Acc: 13.1250\n",
      " |~~ train@3456  Loss: 0.002245 Acc: 13.3906\n",
      " |~~ train@3520  Loss: 0.001530 Acc: 13.5156\n",
      " |~~ train@3584  Loss: 0.001974 Acc: 13.3906\n",
      " |~~ train@3648  Loss: 0.002325 Acc: 13.1875\n",
      " |~~ train@3712  Loss: 0.002055 Acc: 13.3438\n",
      " |~~ train@3776  Loss: 0.002657 Acc: 13.0781\n",
      " |~~ train@3840  Loss: 0.001885 Acc: 13.4844\n",
      " |~~ train@3904  Loss: 0.002107 Acc: 13.3125\n",
      " |~~ train@3968  Loss: 0.002270 Acc: 13.3125\n",
      " |~~ train@4032  Loss: 0.002079 Acc: 13.3281\n",
      " |~~ train@4096  Loss: 0.002393 Acc: 13.1406\n",
      " |~~ train@4160  Loss: 0.002158 Acc: 13.3125\n",
      " |~~ train@4224  Loss: 0.002433 Acc: 13.2188\n",
      " |~~ train@4288  Loss: 0.002278 Acc: 13.3125\n",
      " |~~ train@4352  Loss: 0.002142 Acc: 13.2969\n",
      " |~~ train@4416  Loss: 0.001676 Acc: 13.4375\n",
      " |~~ train@4480  Loss: 0.002536 Acc: 13.2188\n",
      " |~~ train@4544  Loss: 0.001841 Acc: 13.3750\n",
      " |~~ train@4608  Loss: 0.001997 Acc: 13.4062\n",
      " |~~ train@4672  Loss: 0.001729 Acc: 13.4844\n",
      " |~~ train@4736  Loss: 0.001890 Acc: 13.3594\n",
      " |~~ train@4800  Loss: 0.002024 Acc: 13.3438\n",
      " |~~ train@4864  Loss: 0.001813 Acc: 13.4844\n",
      " |~~ train@4928  Loss: 0.001873 Acc: 13.3594\n",
      " |~~ train@4992  Loss: 0.001580 Acc: 13.5156\n",
      " |~~ train@5056  Loss: 0.001995 Acc: 13.2500\n",
      " |~~ train@5120  Loss: 0.001800 Acc: 13.5469\n",
      " |~~ train@5184  Loss: 0.001670 Acc: 13.4844\n",
      " |~~ train@5248  Loss: 0.001784 Acc: 13.4844\n",
      " |~~ train@5312  Loss: 0.002105 Acc: 13.2969\n",
      " |~~ train@5376  Loss: 0.001559 Acc: 13.4844\n",
      " |~~ train@5440  Loss: 0.001709 Acc: 13.4531\n",
      " |~~ train@5504  Loss: 0.001814 Acc: 13.3750\n",
      " |~~ train@5568  Loss: 0.001402 Acc: 13.6250\n",
      " |~~ train@5632  Loss: 0.001949 Acc: 13.5000\n",
      " |~~ train@5696  Loss: 0.002132 Acc: 13.3281\n",
      " |~~ train@5760  Loss: 0.002121 Acc: 13.2969\n",
      " |~~ train@5824  Loss: 0.001800 Acc: 13.3594\n",
      " |~~ train@5888  Loss: 0.002092 Acc: 13.3906\n",
      " |~~ train@5952  Loss: 0.001747 Acc: 13.3906\n",
      " |~~ train@6016  Loss: 0.002361 Acc: 13.2656\n",
      " |~~ train@6080  Loss: 0.002361 Acc: 13.2344\n",
      " |~~ train@6144  Loss: 0.001641 Acc: 13.5000\n",
      " |~~ train@6208  Loss: 0.001838 Acc: 13.4531\n",
      " |~~ train@6272  Loss: 0.001637 Acc: 13.4844\n",
      " |~~ train@6336  Loss: 0.001568 Acc: 13.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@6400  Loss: 0.001589 Acc: 13.5781\n",
      " |~~ train@6464  Loss: 0.001586 Acc: 13.5781\n",
      " |~~ train@6528  Loss: 0.001745 Acc: 13.3594\n",
      " |~~ train@6592  Loss: 0.002416 Acc: 13.1406\n",
      " |~~ train@6656  Loss: 0.001778 Acc: 13.4688\n",
      " |~~ train@6720  Loss: 0.001569 Acc: 13.4844\n",
      " |~~ train@6784  Loss: 0.002292 Acc: 13.2812\n",
      " |~~ train@6848  Loss: 0.001694 Acc: 13.5312\n",
      " |~~ train@6912  Loss: 0.001555 Acc: 13.4688\n",
      " |~~ train@6976  Loss: 0.002034 Acc: 13.3750\n",
      " |~~ train@7040  Loss: 0.002090 Acc: 13.2656\n",
      " |~~ train@7104  Loss: 0.001849 Acc: 13.3906\n",
      " |~~ train@7168  Loss: 0.001967 Acc: 13.3906\n",
      " |~~ train@7232  Loss: 0.002312 Acc: 13.2031\n",
      " |~~ train@7296  Loss: 0.001920 Acc: 13.4062\n",
      " |~~ train@7360  Loss: 0.001885 Acc: 13.4688\n",
      " |~~ train@7424  Loss: 0.001971 Acc: 13.3594\n",
      " |~~ train@7488  Loss: 0.001867 Acc: 13.3750\n",
      " |~~ train@7552  Loss: 0.002243 Acc: 13.2188\n",
      " |~~ train@7616  Loss: 0.002492 Acc: 13.1562\n",
      " |~~ train@7680  Loss: 0.002308 Acc: 13.2031\n",
      " |~~ train@7744  Loss: 0.002253 Acc: 13.2656\n",
      " |~~ train@7808  Loss: 0.002070 Acc: 13.3750\n",
      " |~~ train@7872  Loss: 0.002704 Acc: 13.0781\n",
      " |~~ train@7936  Loss: 0.001968 Acc: 13.3750\n",
      " |~~ train@8000  Loss: 0.002373 Acc: 13.2969\n",
      " |~~ train@8064  Loss: 0.001697 Acc: 13.5000\n",
      " |~~ train@8128  Loss: 0.001564 Acc: 13.5625\n",
      " |~~ train@8192  Loss: 0.001982 Acc: 13.3125\n",
      " |~~ train@8256  Loss: 0.001521 Acc: 13.5156\n",
      " |~~ train@8320  Loss: 0.001920 Acc: 13.3906\n",
      " |~~ train@8384  Loss: 0.002086 Acc: 13.3750\n",
      " |~~ train@8448  Loss: 0.002385 Acc: 13.1719\n",
      " |~~ train@8512  Loss: 0.002386 Acc: 13.2031\n",
      " |~~ train@8576  Loss: 0.001650 Acc: 13.3906\n",
      " |~~ train@8640  Loss: 0.002523 Acc: 13.1094\n",
      " |~~ train@8704  Loss: 0.001798 Acc: 13.3594\n",
      " |~~ train@8768  Loss: 0.002795 Acc: 13.2031\n",
      " |~~ train@8832  Loss: 0.002042 Acc: 13.4531\n",
      " |~~ train@8896  Loss: 0.001757 Acc: 13.4062\n",
      " |~~ train@8960  Loss: 0.001785 Acc: 13.3906\n",
      " |~~ train@9024  Loss: 0.002093 Acc: 13.3750\n",
      " |~~ train@9088  Loss: 0.002777 Acc: 13.1250\n",
      " |~~ train@9152  Loss: 0.002101 Acc: 13.2656\n",
      " |~~ train@9216  Loss: 0.002142 Acc: 13.1875\n",
      " |~~ train@9280  Loss: 0.002115 Acc: 13.2812\n",
      " |~~ train@9344  Loss: 0.001853 Acc: 13.3750\n",
      " |~~ train@9408  Loss: 0.001816 Acc: 13.4375\n",
      " |~~ train@9472  Loss: 0.002432 Acc: 13.2188\n",
      " |~~ train@9536  Loss: 0.002074 Acc: 13.4062\n",
      " |~~ train@9600  Loss: 0.002281 Acc: 13.2500\n",
      " |~~ train@9664  Loss: 0.002125 Acc: 13.3281\n",
      " |~~ train@9728  Loss: 0.002082 Acc: 13.2812\n",
      " |~~ train@9792  Loss: 0.001882 Acc: 13.4688\n",
      " |~~ train@9856  Loss: 0.001608 Acc: 13.5156\n",
      " |~~ train@9920  Loss: 0.001607 Acc: 13.4531\n",
      " |~~ train@9984  Loss: 0.001622 Acc: 13.5469\n",
      " |~~ train@10048  Loss: 0.002340 Acc: 13.1875\n",
      " |~~ train@10112  Loss: 0.001842 Acc: 13.3750\n",
      " |~~ train@10176  Loss: 0.002192 Acc: 13.2969\n",
      " |~~ train@10240  Loss: 0.001537 Acc: 13.5000\n",
      " |~~ train@10304  Loss: 0.001595 Acc: 13.4688\n",
      " |~~ train@10368  Loss: 0.002165 Acc: 13.2344\n",
      " |~~ train@10432  Loss: 0.002174 Acc: 13.2500\n",
      " |~~ train@10496  Loss: 0.002136 Acc: 13.2812\n",
      " |~~ train@10560  Loss: 0.002351 Acc: 13.2500\n",
      " |~~ train@10624  Loss: 0.001605 Acc: 13.5000\n",
      " |~~ train@10688  Loss: 0.001633 Acc: 13.4844\n",
      " |~~ train@10752  Loss: 0.001917 Acc: 13.4375\n",
      " |~~ train@10816  Loss: 0.002438 Acc: 13.1719\n",
      " |~~ train@10880  Loss: 0.002213 Acc: 13.3125\n",
      " |~~ train@10944  Loss: 0.001650 Acc: 13.5625\n",
      " |~~ train@11008  Loss: 0.002037 Acc: 13.2969\n",
      " |~~ train@11072  Loss: 0.002143 Acc: 13.2500\n",
      " |~~ train@11136  Loss: 0.001984 Acc: 13.3438\n",
      " |~~ train@11200  Loss: 0.002044 Acc: 13.3438\n",
      " |~~ train@11264  Loss: 0.002259 Acc: 13.1719\n",
      " |~~ train@11328  Loss: 0.001575 Acc: 13.5625\n",
      " |~~ train@11392  Loss: 0.001853 Acc: 13.3281\n",
      " |~~ train@11456  Loss: 0.002487 Acc: 13.1406\n",
      " |~~ train@11520  Loss: 0.002073 Acc: 13.3906\n",
      " |~~ train@11584  Loss: 0.001858 Acc: 13.3750\n",
      " |~~ train@11648  Loss: 0.002047 Acc: 13.4219\n",
      " |~~ train@11712  Loss: 0.001712 Acc: 13.4531\n",
      " |~~ train@11776  Loss: 0.002133 Acc: 13.2812\n",
      " |~~ train@11840  Loss: 0.002173 Acc: 13.2812\n",
      " |~~ train@11904  Loss: 0.002407 Acc: 13.1562\n",
      " |~~ train@11968  Loss: 0.001725 Acc: 13.4219\n",
      " |~~ train@12032  Loss: 0.001813 Acc: 13.4375\n",
      " |~~ train@12096  Loss: 0.001951 Acc: 13.3750\n",
      " |~~ train@12160  Loss: 0.002064 Acc: 13.2656\n",
      " |~~ train@12224  Loss: 0.001924 Acc: 13.4531\n",
      " |~~ train@12288  Loss: 0.002435 Acc: 13.1406\n",
      " |~~ train@12352  Loss: 0.002584 Acc: 13.1875\n",
      " |~~ train@12416  Loss: 0.002171 Acc: 13.3281\n",
      " |~~ train@12480  Loss: 0.002355 Acc: 13.2031\n",
      " |~~ train@12544  Loss: 0.001849 Acc: 13.5156\n",
      " |~~ train@12608  Loss: 0.002191 Acc: 13.2969\n",
      " |~~ train@12672  Loss: 0.001696 Acc: 13.5156\n",
      " |~~ train@12736  Loss: 0.001890 Acc: 13.3594\n",
      " |~~ train@12800  Loss: 0.001923 Acc: 13.3281\n",
      " |~~ train@12864  Loss: 0.002124 Acc: 13.3281\n",
      " |~~ train@12928  Loss: 0.002072 Acc: 13.2500\n",
      " |~~ train@12992  Loss: 0.001997 Acc: 13.2656\n",
      " |~~ train@13056  Loss: 0.001852 Acc: 13.3906\n",
      " |~~ train@13120  Loss: 0.001887 Acc: 13.4688\n",
      " |~~ train@13184  Loss: 0.001934 Acc: 13.2969\n",
      " |~~ train@13248  Loss: 0.002517 Acc: 13.1719\n",
      " |~~ train@13312  Loss: 0.002005 Acc: 13.2188\n",
      " |~~ train@13376  Loss: 0.002341 Acc: 13.2812\n",
      " |~~ train@13440  Loss: 0.001732 Acc: 13.4688\n",
      " |~~ train@13504  Loss: 0.001705 Acc: 13.4688\n",
      " |~~ train@13568  Loss: 0.002142 Acc: 13.3281\n",
      " |~~ train@13632  Loss: 0.001973 Acc: 13.3906\n",
      " |~~ train@13696  Loss: 0.001955 Acc: 13.4062\n",
      " |~~ train@13760  Loss: 0.001918 Acc: 13.3906\n",
      " |~~ train@13824  Loss: 0.002113 Acc: 13.2188\n",
      " |~~ train@13888  Loss: 0.001717 Acc: 13.5000\n",
      " |~~ train@13952  Loss: 0.001902 Acc: 13.3594\n",
      " |~~ train@14016  Loss: 0.002406 Acc: 13.2188\n",
      " |~~ train@14080  Loss: 0.002096 Acc: 13.3125\n",
      " |~~ train@14144  Loss: 0.001732 Acc: 13.4062\n",
      " |~~ train@14208  Loss: 0.002059 Acc: 13.3906\n",
      " |~~ train@14272  Loss: 0.002024 Acc: 13.2812\n",
      " |~~ train@14336  Loss: 0.002111 Acc: 13.2188\n",
      " |~~ train@14400  Loss: 0.002325 Acc: 13.3125\n",
      " |~~ train@14464  Loss: 0.001876 Acc: 13.4688\n",
      " |~~ train@14528  Loss: 0.002345 Acc: 13.3594\n",
      " |~~ train@14592  Loss: 0.001735 Acc: 13.4688\n",
      " |~~ train@14656  Loss: 0.002121 Acc: 13.2969\n",
      " |~~ train@14720  Loss: 0.002005 Acc: 13.3906\n",
      " |~~ train@14784  Loss: 0.001811 Acc: 13.4219\n",
      " |~~ train@14848  Loss: 0.002094 Acc: 13.2188\n",
      " |~~ train@14912  Loss: 0.001675 Acc: 13.3750\n",
      " |~~ train@14976  Loss: 0.002042 Acc: 13.3750\n",
      " |~~ train@15040  Loss: 0.002114 Acc: 13.2812\n",
      " |~~ train@15104  Loss: 0.002164 Acc: 13.2344\n",
      " |~~ train@15168  Loss: 0.002034 Acc: 13.3125\n",
      " |~~ train@15232  Loss: 0.001815 Acc: 13.4844\n",
      " |~~ train@15296  Loss: 0.002588 Acc: 13.1562\n",
      " |~~ train@15360  Loss: 0.001912 Acc: 13.3438\n",
      " |~~ train@15424  Loss: 0.001918 Acc: 13.3906\n",
      " |~~ train@15488  Loss: 0.002062 Acc: 13.2969\n",
      " |~~ train@15552  Loss: 0.001668 Acc: 13.4062\n",
      " |~~ train@15616  Loss: 0.002191 Acc: 13.2812\n",
      " |~~ train@15680  Loss: 0.002557 Acc: 13.2188\n",
      " |~~ train@15744  Loss: 0.001456 Acc: 13.5312\n",
      " |~~ train@15808  Loss: 0.002314 Acc: 13.2188\n",
      " |~~ train@15872  Loss: 0.002045 Acc: 13.4219\n",
      " |~~ train@15936  Loss: 0.002181 Acc: 13.2500\n",
      " |~~ train@16000  Loss: 0.001999 Acc: 13.3125\n",
      " |~~ train@16064  Loss: 0.001981 Acc: 13.3750\n",
      " |~~ train@16128  Loss: 0.002259 Acc: 13.2188\n",
      " |~~ train@16192  Loss: 0.002057 Acc: 13.3281\n",
      " |~~ train@16256  Loss: 0.001595 Acc: 13.5156\n",
      " |~~ train@16320  Loss: 0.002090 Acc: 13.3125\n",
      " |~~ train@16384  Loss: 0.001735 Acc: 13.4531\n",
      " |~~ train@16448  Loss: 0.001973 Acc: 13.3125\n",
      " |~~ train@16512  Loss: 0.002181 Acc: 13.2969\n",
      " |~~ train@16576  Loss: 0.002321 Acc: 13.2500\n",
      " |~~ train@16640  Loss: 0.001786 Acc: 13.3594\n",
      " |~~ train@16704  Loss: 0.002398 Acc: 13.1719\n",
      " |~~ train@16768  Loss: 0.002208 Acc: 13.3125\n",
      " |~~ train@16832  Loss: 0.001929 Acc: 13.3125\n",
      " |~~ train@16896  Loss: 0.002032 Acc: 13.3750\n",
      " |~~ train@16960  Loss: 0.001929 Acc: 13.3750\n",
      " |~~ train@17024  Loss: 0.001915 Acc: 13.5000\n",
      " |~~ train@17088  Loss: 0.001880 Acc: 13.3594\n",
      " |~~ train@17152  Loss: 0.002022 Acc: 13.3750\n",
      " |~~ train@17216  Loss: 0.002083 Acc: 13.3438\n",
      " |~~ train@17280  Loss: 0.001947 Acc: 13.4062\n",
      " |~~ train@17344  Loss: 0.001858 Acc: 13.4219\n",
      " |~~ train@17408  Loss: 0.002064 Acc: 13.2969\n",
      " |~~ train@17472  Loss: 0.001759 Acc: 13.3750\n",
      " |~~ train@17536  Loss: 0.002299 Acc: 13.2188\n",
      " |~~ train@17600  Loss: 0.001624 Acc: 13.4531\n",
      " |~~ train@17664  Loss: 0.002032 Acc: 13.3281\n",
      " |~~ train@17728  Loss: 0.001688 Acc: 13.4844\n",
      " |~~ train@17792  Loss: 0.002133 Acc: 13.3281\n",
      " |~~ train@17856  Loss: 0.001293 Acc: 13.5938\n",
      " |~~ train@17920  Loss: 0.001686 Acc: 13.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@17984  Loss: 0.001815 Acc: 13.4844\n",
      " |~~ train@18048  Loss: 0.001995 Acc: 13.4062\n",
      " |~~ train@18112  Loss: 0.002092 Acc: 13.3281\n",
      " |~~ train@18176  Loss: 0.002292 Acc: 13.2188\n",
      " |~~ train@18240  Loss: 0.001982 Acc: 13.3594\n",
      " |~~ train@18304  Loss: 0.002071 Acc: 13.4062\n",
      " |~~ train@18368  Loss: 0.002310 Acc: 13.1719\n",
      " |~~ train@18432  Loss: 0.001833 Acc: 13.3750\n",
      " |~~ train@18496  Loss: 0.001683 Acc: 13.4062\n",
      " |~~ train@18560  Loss: 0.001967 Acc: 13.3906\n",
      " |~~ train@18624  Loss: 0.002200 Acc: 13.3906\n",
      " |~~ train@18688  Loss: 0.001958 Acc: 13.4219\n",
      " |~~ train@18752  Loss: 0.001745 Acc: 13.4531\n",
      " |~~ train@18816  Loss: 0.002028 Acc: 13.2812\n",
      " |~~ train@18880  Loss: 0.001961 Acc: 13.3906\n",
      " |~~ train@18944  Loss: 0.001883 Acc: 13.3281\n",
      " |~~ train@19008  Loss: 0.002318 Acc: 13.1875\n",
      " |~~ train@19072  Loss: 0.002014 Acc: 13.2969\n",
      " |~~ train@19136  Loss: 0.001947 Acc: 13.2969\n",
      " |~~ train@19200  Loss: 0.001585 Acc: 13.5781\n",
      " |~~ train@19264  Loss: 0.001972 Acc: 13.3125\n",
      " |~~ train@19328  Loss: 0.001823 Acc: 13.3750\n",
      " |~~ train@19392  Loss: 0.002419 Acc: 13.2344\n",
      " |~~ train@19456  Loss: 0.002212 Acc: 13.2969\n",
      " |~~ train@19520  Loss: 0.002156 Acc: 13.1875\n",
      " |~~ train@19584  Loss: 0.002224 Acc: 13.3125\n",
      " |~~ train@19648  Loss: 0.002206 Acc: 13.2344\n",
      " |~~ train@19712  Loss: 0.001789 Acc: 13.4062\n",
      " |~~ train@19776  Loss: 0.001970 Acc: 13.3438\n",
      " |~~ train@19840  Loss: 0.002129 Acc: 13.2969\n",
      " |~~ train@19904  Loss: 0.001867 Acc: 13.3438\n",
      " |~~ train@19968  Loss: 0.002309 Acc: 13.2812\n",
      " |~~ train@20032  Loss: 0.002288 Acc: 13.2969\n",
      " |~~ train@20096  Loss: 0.002180 Acc: 13.3125\n",
      " |~~ train@20160  Loss: 0.001779 Acc: 13.3750\n",
      " |~~ train@20224  Loss: 0.002148 Acc: 13.3438\n",
      " |~~ train@20288  Loss: 0.002102 Acc: 13.2812\n",
      " |~~ train@20352  Loss: 0.002095 Acc: 13.3750\n",
      " |~~ train@20416  Loss: 0.002451 Acc: 13.1875\n",
      " |~~ train@20480  Loss: 0.002532 Acc: 13.0938\n",
      " |~~ train@20544  Loss: 0.001686 Acc: 13.4531\n",
      " |~~ train@20608  Loss: 0.001680 Acc: 13.5000\n",
      " |~~ train@20672  Loss: 0.002174 Acc: 13.2188\n",
      " |~~ train@20736  Loss: 0.002458 Acc: 13.0469\n",
      " |~~ train@20800  Loss: 0.002084 Acc: 13.3750\n",
      " |~~ train@20864  Loss: 0.001813 Acc: 13.3125\n",
      " |~~ train@20928  Loss: 0.001806 Acc: 13.3906\n",
      " |~~ train@20992  Loss: 0.002100 Acc: 13.1719\n",
      " |~~ train@21056  Loss: 0.002025 Acc: 13.2812\n",
      " |~~ train@21120  Loss: 0.002329 Acc: 13.3125\n",
      " |~~ train@21184  Loss: 0.001995 Acc: 13.2969\n",
      " |~~ train@21248  Loss: 0.002225 Acc: 13.2812\n",
      " |~~ train@21312  Loss: 0.001994 Acc: 13.3281\n",
      " |~~ train@21376  Loss: 0.001881 Acc: 13.4375\n",
      " |~~ train@21440  Loss: 0.001503 Acc: 13.5312\n",
      " |~~ train@21504  Loss: 0.001690 Acc: 13.5000\n",
      " |~~ train@21568  Loss: 0.002363 Acc: 13.2812\n",
      " |~~ train@21632  Loss: 0.001533 Acc: 13.4844\n",
      " |~~ train@21696  Loss: 0.002189 Acc: 13.2656\n",
      " |~~ train@21760  Loss: 0.002190 Acc: 13.2656\n",
      " |~~ train@21824  Loss: 0.002206 Acc: 13.2656\n",
      " |~~ train@21888  Loss: 0.001630 Acc: 13.4531\n",
      " |~~ train@21952  Loss: 0.002001 Acc: 13.3438\n",
      " |~~ train@22016  Loss: 0.001558 Acc: 13.5938\n",
      " |~~ train@22080  Loss: 0.002394 Acc: 13.2812\n",
      " |~~ train@22144  Loss: 0.001882 Acc: 13.3750\n",
      " |~~ train@22208  Loss: 0.001521 Acc: 13.5312\n",
      " |~~ train@22272  Loss: 0.002017 Acc: 13.3594\n",
      " |~~ train@22336  Loss: 0.001781 Acc: 13.4688\n",
      " |~~ train@22400  Loss: 0.001941 Acc: 13.3125\n",
      " |~~ train@22464  Loss: 0.002636 Acc: 13.1094\n",
      " |~~ train@22528  Loss: 0.001852 Acc: 13.4219\n",
      " |~~ train@22592  Loss: 0.001741 Acc: 13.3906\n",
      " |~~ train@22656  Loss: 0.002003 Acc: 13.3594\n",
      " |~~ train@22720  Loss: 0.002200 Acc: 13.2812\n",
      " |~~ train@22784  Loss: 0.002067 Acc: 13.2969\n",
      " |~~ train@22848  Loss: 0.002131 Acc: 13.3281\n",
      " |~~ train@22912  Loss: 0.002137 Acc: 13.3281\n",
      " |~~ train@22976  Loss: 0.001844 Acc: 13.4375\n",
      " |~~ train@23040  Loss: 0.002651 Acc: 13.1250\n",
      " |~~ train@23104  Loss: 0.001924 Acc: 13.2969\n",
      " |~~ train@23168  Loss: 0.002177 Acc: 13.3125\n",
      " |~~ train@23232  Loss: 0.001673 Acc: 13.5312\n",
      " |~~ train@23296  Loss: 0.001979 Acc: 13.3750\n",
      " |~~ train@23360  Loss: 0.002012 Acc: 13.2969\n",
      " |~~ train@23424  Loss: 0.001875 Acc: 13.3906\n",
      " |~~ train@23488  Loss: 0.001803 Acc: 13.4219\n",
      " |~~ train@23552  Loss: 0.002083 Acc: 13.3594\n",
      " |~~ train@23616  Loss: 0.002109 Acc: 13.2812\n",
      " |~~ train@23680  Loss: 0.001839 Acc: 13.4375\n",
      " |~~ train@23744  Loss: 0.001618 Acc: 13.5156\n",
      " |~~ train@23808  Loss: 0.002095 Acc: 13.2969\n",
      " |~~ train@23872  Loss: 0.002175 Acc: 13.2500\n",
      " |~~ train@23936  Loss: 0.001742 Acc: 13.4219\n",
      " |~~ train@24000  Loss: 0.002034 Acc: 13.4062\n",
      " |~~ train@24064  Loss: 0.001760 Acc: 13.4375\n",
      " |~~ train@24128  Loss: 0.002410 Acc: 13.2031\n",
      " |~~ train@24192  Loss: 0.002340 Acc: 13.2031\n",
      " |~~ train@24256  Loss: 0.002198 Acc: 13.2969\n",
      " |~~ train@24320  Loss: 0.001664 Acc: 13.4844\n",
      " |~~ train@24384  Loss: 0.002173 Acc: 13.3594\n",
      " |~~ train@24448  Loss: 0.002335 Acc: 13.3125\n",
      " |~~ train@24512  Loss: 0.001780 Acc: 13.5000\n",
      " |~~ train@24576  Loss: 0.002075 Acc: 13.2344\n",
      " |~~ train@24640  Loss: 0.002049 Acc: 13.3906\n",
      " |~~ train@24704  Loss: 0.002000 Acc: 13.3438\n",
      " |~~ train@24768  Loss: 0.002474 Acc: 13.1719\n",
      " |~~ train@24832  Loss: 0.001925 Acc: 13.3125\n",
      " |~~ train@24896  Loss: 0.001896 Acc: 13.2344\n",
      " |~~ train@24960  Loss: 0.002191 Acc: 13.2812\n",
      " |~~ train@25024  Loss: 0.001891 Acc: 13.3750\n",
      " |~~ train@25088  Loss: 0.001704 Acc: 13.4219\n",
      " |~~ train@25152  Loss: 0.001897 Acc: 13.3906\n",
      " |~~ train@25216  Loss: 0.001909 Acc: 13.3594\n",
      " |~~ train@25280  Loss: 0.002472 Acc: 13.2812\n",
      " |~~ train@25344  Loss: 0.002153 Acc: 13.3594\n",
      " |~~ train@25408  Loss: 0.001617 Acc: 13.5625\n",
      " |~~ train@25472  Loss: 0.002098 Acc: 13.3438\n",
      " |~~ train@25536  Loss: 0.001583 Acc: 13.5156\n",
      " |~~ train@25600  Loss: 0.001521 Acc: 13.5469\n",
      " |~~ train@25664  Loss: 0.001821 Acc: 13.4219\n",
      " |~~ train@25728  Loss: 0.001795 Acc: 13.5000\n",
      " |~~ train@25792  Loss: 0.002406 Acc: 13.2500\n",
      " |~~ train@25856  Loss: 0.001674 Acc: 13.4375\n",
      " |~~ train@25920  Loss: 0.001960 Acc: 13.3281\n",
      " |~~ train@25984  Loss: 0.002047 Acc: 13.4375\n",
      " |~~ train@26048  Loss: 0.001567 Acc: 13.5156\n",
      " |~~ train@26112  Loss: 0.001996 Acc: 13.3906\n",
      " |~~ train@26176  Loss: 0.002417 Acc: 13.2188\n",
      " |~~ train@26240  Loss: 0.001589 Acc: 13.5625\n",
      " |~~ train@26304  Loss: 0.001836 Acc: 13.5000\n",
      " |~~ train@26368  Loss: 0.002250 Acc: 13.2031\n",
      " |~~ train@26432  Loss: 0.002049 Acc: 13.3594\n",
      " |~~ train@26496  Loss: 0.002012 Acc: 13.4375\n",
      " |~~ train@26560  Loss: 0.001860 Acc: 13.5156\n",
      " |~~ train@26624  Loss: 0.001878 Acc: 13.3594\n",
      " |~~ train@26688  Loss: 0.002526 Acc: 13.1719\n",
      " |~~ train@26752  Loss: 0.001706 Acc: 13.5000\n",
      " |~~ train@26816  Loss: 0.001521 Acc: 13.4688\n",
      " |~~ train@26880  Loss: 0.001582 Acc: 13.5469\n",
      " |~~ train@26944  Loss: 0.001941 Acc: 13.3594\n",
      " |~~ train@27008  Loss: 0.001774 Acc: 13.5000\n",
      " |~~ train@27072  Loss: 0.001549 Acc: 13.5156\n",
      " |~~ train@27136  Loss: 0.002088 Acc: 13.2812\n",
      " |~~ train@27200  Loss: 0.001954 Acc: 13.2656\n",
      " |~~ train@27264  Loss: 0.001859 Acc: 13.3750\n",
      " |~~ train@27328  Loss: 0.001878 Acc: 13.3281\n",
      " |~~ train@27392  Loss: 0.001977 Acc: 13.4062\n",
      " |~~ train@27456  Loss: 0.002516 Acc: 13.0938\n",
      " |~~ train@27520  Loss: 0.002116 Acc: 13.2344\n",
      " |~~ train@27584  Loss: 0.001478 Acc: 13.5469\n",
      " |~~ train@27648  Loss: 0.001676 Acc: 13.4844\n",
      " |~~ train@27712  Loss: 0.001989 Acc: 13.4688\n",
      " |~~ train@27776  Loss: 0.002108 Acc: 13.2969\n",
      " |~~ train@27840  Loss: 0.001717 Acc: 13.4844\n",
      " |~~ train@27904  Loss: 0.002122 Acc: 13.2500\n",
      " |~~ train@27968  Loss: 0.002069 Acc: 13.2344\n",
      " |~~ train@28032  Loss: 0.001978 Acc: 13.4219\n",
      " |~~ train@28096  Loss: 0.002217 Acc: 13.2812\n",
      " |~~ train@28160  Loss: 0.002086 Acc: 13.4062\n",
      " |~~ train@28224  Loss: 0.001623 Acc: 13.5625\n",
      " |~~ train@28288  Loss: 0.002003 Acc: 13.3125\n",
      " |~~ train@28352  Loss: 0.002431 Acc: 13.2344\n",
      " |~~ train@28416  Loss: 0.001894 Acc: 13.4062\n",
      " |~~ train@28480  Loss: 0.001836 Acc: 13.3906\n",
      " |~~ train@28544  Loss: 0.001872 Acc: 13.3750\n",
      " |~~ train@28608  Loss: 0.002771 Acc: 13.1875\n",
      " |~~ train@28672  Loss: 0.002460 Acc: 13.2500\n",
      " |~~ train@28736  Loss: 0.002434 Acc: 13.2188\n",
      " |~~ train@28800  Loss: 0.002468 Acc: 13.2188\n",
      " |~~ train@28864  Loss: 0.001734 Acc: 13.4688\n",
      " |~~ train@28928  Loss: 0.001698 Acc: 13.4219\n",
      " |~~ train@28992  Loss: 0.001489 Acc: 13.4844\n",
      " |~~ train@29056  Loss: 0.002198 Acc: 13.2344\n",
      " |~~ train@29120  Loss: 0.001852 Acc: 13.3281\n",
      " |~~ train@29184  Loss: 0.001886 Acc: 13.3906\n",
      " |~~ train@29248  Loss: 0.002402 Acc: 13.1406\n",
      " |~~ train@29312  Loss: 0.001964 Acc: 13.3281\n",
      " |~~ train@29376  Loss: 0.001990 Acc: 13.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@29440  Loss: 0.001947 Acc: 13.3438\n",
      " |~~ train@29504  Loss: 0.002118 Acc: 13.3125\n",
      " |~~ train@29568  Loss: 0.002050 Acc: 13.3438\n",
      " |~~ train@29632  Loss: 0.002307 Acc: 13.2812\n",
      " |~~ train@29696  Loss: 0.001904 Acc: 13.4219\n",
      " |~~ train@29760  Loss: 0.002241 Acc: 13.2344\n",
      " |~~ train@29824  Loss: 0.001917 Acc: 13.4062\n",
      " |~~ train@29888  Loss: 0.002112 Acc: 13.3750\n",
      " |~~ train@29952  Loss: 0.001725 Acc: 13.4531\n",
      " |~~ train@30016  Loss: 0.002218 Acc: 13.3125\n",
      " |~~ train@30080  Loss: 0.002340 Acc: 13.2500\n",
      " |~~ train@30144  Loss: 0.001920 Acc: 13.4062\n",
      " |~~ train@30208  Loss: 0.001982 Acc: 13.3125\n",
      " |~~ train@30272  Loss: 0.001821 Acc: 13.5000\n",
      " |~~ train@30336  Loss: 0.001801 Acc: 13.3750\n",
      " |~~ train@30400  Loss: 0.001924 Acc: 13.2656\n",
      " |~~ train@30464  Loss: 0.002020 Acc: 13.2188\n",
      " |~~ train@30528  Loss: 0.001686 Acc: 13.4531\n",
      " |~~ train@30592  Loss: 0.002032 Acc: 13.3594\n",
      " |~~ train@30656  Loss: 0.002338 Acc: 13.2500\n",
      " |~~ train@30720  Loss: 0.001851 Acc: 13.4062\n",
      " |~~ train@30784  Loss: 0.002876 Acc: 13.0312\n",
      " |~~ train@30848  Loss: 0.001828 Acc: 13.4375\n",
      " |~~ train@30912  Loss: 0.002032 Acc: 13.3750\n",
      " |~~ train@30976  Loss: 0.002300 Acc: 13.2031\n",
      " |~~ train@31040  Loss: 0.002007 Acc: 13.3438\n",
      " |~~ train@31104  Loss: 0.001836 Acc: 13.3125\n",
      " |~~ train@31168  Loss: 0.002325 Acc: 13.2188\n",
      " |~~ train@31232  Loss: 0.001981 Acc: 13.3438\n",
      " |~~ train@31296  Loss: 0.001774 Acc: 13.4531\n",
      " |~~ train@31360  Loss: 0.002520 Acc: 13.2031\n",
      " |~~ train@31424  Loss: 0.002545 Acc: 13.1719\n",
      " |~~ train@31488  Loss: 0.001862 Acc: 13.3906\n",
      " |~~ train@31552  Loss: 0.002602 Acc: 13.0938\n",
      " |~~ train@31616  Loss: 0.002073 Acc: 13.3125\n",
      " |~~ train@31680  Loss: 0.002623 Acc: 13.2031\n",
      " |~~ train@31744  Loss: 0.002349 Acc: 13.2656\n",
      " |~~ train@31808  Loss: 0.001853 Acc: 13.3906\n",
      " |~~ train@31872  Loss: 0.001449 Acc: 13.5312\n",
      " |~~ train@31936  Loss: 0.002163 Acc: 13.3125\n",
      " |~~ train@32000  Loss: 0.001794 Acc: 13.4219\n",
      " |~~ train@32064  Loss: 0.002057 Acc: 13.3438\n",
      " |~~ train@32128  Loss: 0.002066 Acc: 13.3438\n",
      " |~~ train@32192  Loss: 0.001996 Acc: 13.2500\n",
      " |~~ train@32256  Loss: 0.001976 Acc: 13.3594\n",
      " |~~ train@32320  Loss: 0.001641 Acc: 13.5469\n",
      " |~~ train@32384  Loss: 0.002460 Acc: 13.2500\n",
      " |~~ train@32448  Loss: 0.002421 Acc: 13.1094\n",
      " |~~ train@32512  Loss: 0.001758 Acc: 13.4844\n",
      " |~~ train@32576  Loss: 0.001778 Acc: 13.4688\n",
      " |~~ train@32640  Loss: 0.002107 Acc: 13.2344\n",
      " |~~ train@32704  Loss: 0.002450 Acc: 13.3125\n",
      " |~~ train@32768  Loss: 0.002234 Acc: 13.2656\n",
      " |~~ train@32832  Loss: 0.001947 Acc: 13.3438\n",
      " |~~ train@32896  Loss: 0.002189 Acc: 13.2812\n",
      " |~~ train@32960  Loss: 0.001835 Acc: 13.3906\n",
      " |~~ train@33024  Loss: 0.002146 Acc: 13.3125\n",
      " |~~ train@33088  Loss: 0.002377 Acc: 13.0938\n",
      " |~~ train@33152  Loss: 0.001817 Acc: 13.3750\n",
      " |~~ train@33216  Loss: 0.002000 Acc: 13.2969\n",
      " |~~ train@33280  Loss: 0.002426 Acc: 13.2500\n",
      " |~~ train@33344  Loss: 0.001997 Acc: 13.3750\n",
      " |~~ train@33408  Loss: 0.002192 Acc: 13.2969\n",
      " |~~ train@33472  Loss: 0.001961 Acc: 13.4219\n",
      " |~~ train@33536  Loss: 0.002061 Acc: 13.3906\n",
      " |~~ train@33600  Loss: 0.002268 Acc: 13.1875\n",
      " |~~ train@33664  Loss: 0.002032 Acc: 13.4219\n",
      " |~~ train@33728  Loss: 0.001833 Acc: 13.3750\n",
      " |~~ train@33792  Loss: 0.001866 Acc: 13.4219\n",
      " |~~ train@33856  Loss: 0.001819 Acc: 13.2969\n",
      " |~~ train@33920  Loss: 0.001417 Acc: 13.6094\n",
      " |~~ train@33984  Loss: 0.001656 Acc: 13.5938\n",
      " |~~ train@34048  Loss: 0.002550 Acc: 13.1562\n",
      " |~~ train@34112  Loss: 0.002278 Acc: 13.2500\n",
      " |~~ train@34176  Loss: 0.001678 Acc: 13.4219\n",
      " |~~ train@34240  Loss: 0.002204 Acc: 13.2656\n",
      " |~~ train@34304  Loss: 0.001614 Acc: 13.4688\n",
      " |~~ train@34368  Loss: 0.001686 Acc: 13.5000\n",
      " |~~ train@34432  Loss: 0.002254 Acc: 13.1562\n",
      " |~~ train@34496  Loss: 0.002014 Acc: 13.3594\n",
      " |~~ train@34560  Loss: 0.001910 Acc: 13.3750\n",
      " |~~ train@34624  Loss: 0.002271 Acc: 13.1875\n",
      " |~~ train@34688  Loss: 0.002115 Acc: 13.3594\n",
      " |~~ train@34752  Loss: 0.002141 Acc: 13.2969\n",
      " |~~ train@34816  Loss: 0.001678 Acc: 13.4688\n",
      " |~~ train@34880  Loss: 0.002003 Acc: 13.2969\n",
      " |~~ train@34944  Loss: 0.001935 Acc: 13.3906\n",
      " |~~ train@35008  Loss: 0.001725 Acc: 13.4531\n",
      " |~~ train@35072  Loss: 0.002452 Acc: 13.1250\n",
      " |~~ train@35136  Loss: 0.002299 Acc: 13.2031\n",
      " |~~ train@35200  Loss: 0.002260 Acc: 13.2812\n",
      " |~~ train@35264  Loss: 0.001848 Acc: 13.4688\n",
      " |~~ train@35328  Loss: 0.002630 Acc: 13.1562\n",
      " |~~ train@35392  Loss: 0.001605 Acc: 13.4844\n",
      " |~~ train@35456  Loss: 0.001802 Acc: 13.3281\n",
      " |~~ train@35520  Loss: 0.001744 Acc: 13.4844\n",
      " |~~ train@35584  Loss: 0.001862 Acc: 13.4531\n",
      " |~~ train@35648  Loss: 0.001940 Acc: 13.2969\n",
      " |~~ train@35712  Loss: 0.002575 Acc: 13.0781\n",
      " |~~ train@35776  Loss: 0.002408 Acc: 13.2188\n",
      " |~~ train@35840  Loss: 0.002077 Acc: 13.2656\n",
      " |~~ train@35904  Loss: 0.001651 Acc: 13.4219\n",
      " |~~ train@35968  Loss: 0.001694 Acc: 13.4531\n",
      " |~~ train@36032  Loss: 0.001747 Acc: 13.4688\n",
      " |~~ train@36096  Loss: 0.001968 Acc: 13.3594\n",
      " |~~ train@36160  Loss: 0.001700 Acc: 13.4062\n",
      " |~~ train@36224  Loss: 0.001774 Acc: 13.3750\n",
      " |~~ train@36288  Loss: 0.001804 Acc: 13.4219\n",
      " |~~ train@36352  Loss: 0.001676 Acc: 13.5469\n",
      " |~~ train@36416  Loss: 0.002238 Acc: 13.0938\n",
      " |~~ train@36480  Loss: 0.002082 Acc: 13.3438\n",
      " |~~ train@36544  Loss: 0.002258 Acc: 13.2656\n",
      " |~~ train@36608  Loss: 0.001816 Acc: 13.4844\n",
      " |~~ train@36672  Loss: 0.001790 Acc: 13.4531\n",
      " |~~ train@36736  Loss: 0.001809 Acc: 13.3438\n",
      " |~~ train@36800  Loss: 0.002050 Acc: 13.2969\n",
      " |~~ train@36864  Loss: 0.002083 Acc: 13.3438\n",
      " |~~ train@36928  Loss: 0.002389 Acc: 13.1562\n",
      " |~~ train@36992  Loss: 0.002271 Acc: 13.2500\n",
      " |~~ train@37056  Loss: 0.001806 Acc: 13.4219\n",
      " |~~ train@37120  Loss: 0.002100 Acc: 13.3594\n",
      " |~~ train@37184  Loss: 0.002498 Acc: 13.1250\n",
      " |~~ train@37248  Loss: 0.001921 Acc: 13.4219\n",
      " |~~ train@37312  Loss: 0.001547 Acc: 13.5156\n",
      " |~~ train@37376  Loss: 0.002014 Acc: 13.3906\n",
      " |~~ train@37440  Loss: 0.002020 Acc: 13.2500\n",
      " |~~ train@37504  Loss: 0.002297 Acc: 13.2969\n",
      " |~~ train@37568  Loss: 0.001533 Acc: 13.5469\n",
      " |~~ train@37632  Loss: 0.001825 Acc: 13.5000\n",
      " |~~ train@37696  Loss: 0.001807 Acc: 13.3125\n",
      " |~~ train@37760  Loss: 0.002298 Acc: 13.2188\n",
      " |~~ train@37824  Loss: 0.001794 Acc: 13.5000\n",
      " |~~ train@37888  Loss: 0.001923 Acc: 13.3281\n",
      " |~~ train@37952  Loss: 0.002089 Acc: 13.2656\n",
      " |~~ train@38016  Loss: 0.002582 Acc: 13.1250\n",
      " |~~ train@38080  Loss: 0.001668 Acc: 13.4844\n",
      " |~~ train@38144  Loss: 0.002126 Acc: 13.3281\n",
      " |~~ train@38208  Loss: 0.002461 Acc: 13.2656\n",
      " |~~ train@38272  Loss: 0.001775 Acc: 13.4062\n",
      " |~~ train@38336  Loss: 0.002059 Acc: 13.3594\n",
      " |~~ train@38400  Loss: 0.002423 Acc: 13.2031\n",
      " |~~ train@38464  Loss: 0.001670 Acc: 13.5156\n",
      " |~~ train@38528  Loss: 0.002178 Acc: 13.3125\n",
      " |~~ train@38592  Loss: 0.002127 Acc: 13.2500\n",
      " |~~ train@38656  Loss: 0.001781 Acc: 13.5312\n",
      " |~~ train@38720  Loss: 0.002216 Acc: 13.3125\n",
      " |~~ train@38784  Loss: 0.002379 Acc: 13.1875\n",
      " |~~ train@38848  Loss: 0.001657 Acc: 13.4531\n",
      " |~~ train@38912  Loss: 0.001684 Acc: 13.5781\n",
      " |~~ train@38976  Loss: 0.001435 Acc: 13.5938\n",
      " |~~ train@39040  Loss: 0.002243 Acc: 13.2656\n",
      " |~~ train@39104  Loss: 0.001690 Acc: 13.4844\n",
      " |~~ train@39168  Loss: 0.002059 Acc: 13.3125\n",
      " |~~ train@39232  Loss: 0.002272 Acc: 13.2188\n",
      " |~~ train@39296  Loss: 0.002095 Acc: 13.2656\n",
      " |~~ train@39360  Loss: 0.002120 Acc: 13.3281\n",
      " |~~ train@39424  Loss: 0.002168 Acc: 13.3438\n",
      " |~~ train@39488  Loss: 0.002037 Acc: 13.3906\n",
      " |~~ train@39552  Loss: 0.001684 Acc: 13.4375\n",
      " |~~ train@39616  Loss: 0.002190 Acc: 13.3750\n",
      " |~~ train@39680  Loss: 0.001928 Acc: 13.4688\n",
      " |~~ train@39744  Loss: 0.002433 Acc: 13.1719\n",
      " |~~ train@39808  Loss: 0.002442 Acc: 13.2031\n",
      " |~~ train@39872  Loss: 0.001846 Acc: 13.4375\n",
      " |~~ train@39936  Loss: 0.001944 Acc: 13.4375\n",
      " |~~ train@40000  Loss: 0.002111 Acc: 13.2188\n",
      " |~~ train@40064  Loss: 0.001675 Acc: 13.4062\n",
      " |~~ train@40128  Loss: 0.002168 Acc: 13.2344\n",
      " |~~ train@40192  Loss: 0.001611 Acc: 13.5000\n",
      " |~~ train@40256  Loss: 0.002179 Acc: 13.3281\n",
      " |~~ train@40320  Loss: 0.001988 Acc: 13.2812\n",
      " |~~ train@40384  Loss: 0.002011 Acc: 13.2969\n",
      " |~~ train@40448  Loss: 0.001618 Acc: 13.5469\n",
      " |~~ train@40512  Loss: 0.002188 Acc: 13.2656\n",
      " |~~ train@40576  Loss: 0.001960 Acc: 13.3750\n",
      " |~~ train@40640  Loss: 0.001958 Acc: 13.3594\n",
      " |~~ train@40704  Loss: 0.001966 Acc: 13.2969\n",
      " |~~ train@40768  Loss: 0.002113 Acc: 13.3281\n",
      " |~~ train@40832  Loss: 0.001785 Acc: 13.3906\n",
      " |~~ train@40896  Loss: 0.001726 Acc: 13.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@40960  Loss: 0.001526 Acc: 13.5312\n",
      " |~~ train@41024  Loss: 0.001930 Acc: 13.3125\n",
      " |~~ train@41088  Loss: 0.001800 Acc: 13.4688\n",
      " |~~ train@41152  Loss: 0.001725 Acc: 13.5156\n",
      " |~~ train@41216  Loss: 0.002099 Acc: 13.3750\n",
      " |~~ train@41280  Loss: 0.002389 Acc: 13.1562\n",
      " |~~ train@41344  Loss: 0.001928 Acc: 13.4219\n",
      " |~~ train@41408  Loss: 0.002280 Acc: 13.2031\n",
      " |~~ train@41472  Loss: 0.002116 Acc: 13.3438\n",
      " |~~ train@41536  Loss: 0.001711 Acc: 13.4531\n",
      " |~~ train@41600  Loss: 0.001459 Acc: 13.5625\n",
      " |~~ train@41664  Loss: 0.001802 Acc: 13.4219\n",
      " |~~ train@41728  Loss: 0.001531 Acc: 13.5156\n",
      " |~~ train@41792  Loss: 0.002033 Acc: 13.2969\n",
      " |~~ train@41856  Loss: 0.001537 Acc: 13.6094\n",
      " |~~ train@41920  Loss: 0.002037 Acc: 13.3438\n",
      " |~~ train@41984  Loss: 0.002288 Acc: 13.2500\n",
      " |~~ train@42048  Loss: 0.002029 Acc: 13.4062\n",
      " |~~ train@42112  Loss: 0.001518 Acc: 13.5000\n",
      " |~~ train@42176  Loss: 0.002240 Acc: 13.2969\n",
      " |~~ train@42240  Loss: 0.001723 Acc: 13.4375\n",
      " |~~ train@42304  Loss: 0.001999 Acc: 13.3281\n",
      " |~~ train@42368  Loss: 0.001881 Acc: 13.4688\n",
      " |~~ train@42432  Loss: 0.002065 Acc: 13.4062\n",
      " |~~ train@42496  Loss: 0.001990 Acc: 13.3125\n",
      " |~~ train@42560  Loss: 0.002023 Acc: 13.3281\n",
      " |~~ train@42624  Loss: 0.002569 Acc: 13.1875\n",
      " |~~ train@42688  Loss: 0.001845 Acc: 13.3906\n",
      " |~~ train@42752  Loss: 0.002250 Acc: 13.2969\n",
      " |~~ train@42816  Loss: 0.002399 Acc: 13.1719\n",
      " |~~ train@42880  Loss: 0.002295 Acc: 13.2188\n",
      " |~~ train@42944  Loss: 0.001715 Acc: 13.4531\n",
      " |~~ train@43008  Loss: 0.001902 Acc: 13.4062\n",
      " |~~ train@43072  Loss: 0.001696 Acc: 13.4688\n",
      " |~~ train@43136  Loss: 0.002124 Acc: 13.2969\n",
      " |~~ train@43200  Loss: 0.001947 Acc: 13.3594\n",
      " |~~ train@43264  Loss: 0.002190 Acc: 13.2812\n",
      " |~~ train@43328  Loss: 0.001678 Acc: 13.4688\n",
      " |~~ train@43392  Loss: 0.001816 Acc: 13.4219\n",
      " |~~ train@43456  Loss: 0.002197 Acc: 13.3125\n",
      " |~~ train@43520  Loss: 0.002174 Acc: 13.2188\n",
      " |~~ train@43584  Loss: 0.001535 Acc: 13.5938\n",
      " |~~ train@43648  Loss: 0.001873 Acc: 13.4688\n",
      " |~~ train@43712  Loss: 0.002420 Acc: 13.2656\n",
      " |~~ train@43776  Loss: 0.002018 Acc: 13.2656\n",
      " |~~ train@43840  Loss: 0.002248 Acc: 13.2812\n",
      " |~~ train@43904  Loss: 0.001912 Acc: 13.3906\n",
      " |~~ train@43968  Loss: 0.001675 Acc: 13.4375\n",
      " |~~ train@44032  Loss: 0.001833 Acc: 13.4531\n",
      " |~~ train@44096  Loss: 0.002188 Acc: 13.2500\n",
      " |~~ train@44160  Loss: 0.002231 Acc: 13.2656\n",
      " |~~ train@44224  Loss: 0.001610 Acc: 13.5312\n",
      " |~~ train@44288  Loss: 0.001753 Acc: 13.4531\n",
      " |~~ train@44352  Loss: 0.002127 Acc: 13.3594\n",
      " |~~ train@44416  Loss: 0.001914 Acc: 13.3438\n",
      " |~~ train@44480  Loss: 0.002107 Acc: 13.3438\n",
      " |~~ train@44544  Loss: 0.002002 Acc: 13.2969\n",
      " |~~ train@44608  Loss: 0.002175 Acc: 13.2344\n",
      " |~~ train@44672  Loss: 0.001788 Acc: 13.3750\n",
      " |~~ train@44736  Loss: 0.001593 Acc: 13.5312\n",
      " |~~ train@44800  Loss: 0.001744 Acc: 13.5000\n",
      " |~~ train@44864  Loss: 0.002276 Acc: 13.2188\n",
      " |~~ train@44928  Loss: 0.001576 Acc: 13.6250\n",
      " |~~ train@44992  Loss: 0.002268 Acc: 13.2344\n",
      " |~~ train@45056  Loss: 0.001931 Acc: 13.4531\n",
      " |~~ train@45120  Loss: 0.002105 Acc: 13.2812\n",
      " |~~ train@45184  Loss: 0.002200 Acc: 13.2969\n",
      " |~~ train@45248  Loss: 0.001963 Acc: 13.3750\n",
      " |~~ train@45312  Loss: 0.002503 Acc: 13.1719\n",
      " |~~ train@45376  Loss: 0.002339 Acc: 13.3438\n",
      " |~~ train@45440  Loss: 0.001565 Acc: 13.4375\n",
      " |~~ train@45504  Loss: 0.002026 Acc: 13.2812\n",
      " |~~ train@45568  Loss: 0.001981 Acc: 13.3125\n",
      " |~~ train@45632  Loss: 0.001519 Acc: 13.5312\n",
      " |~~ train@45696  Loss: 0.001554 Acc: 13.4531\n",
      " |~~ train@45760  Loss: 0.001986 Acc: 13.3281\n",
      " |~~ train@45824  Loss: 0.002097 Acc: 13.3438\n",
      " |~~ train@45888  Loss: 0.001693 Acc: 13.4062\n",
      " |~~ train@45952  Loss: 0.001794 Acc: 13.4375\n",
      " |~~ train@46016  Loss: 0.002013 Acc: 13.4688\n",
      " |~~ train@46080  Loss: 0.002351 Acc: 13.2188\n",
      " |~~ train@46144  Loss: 0.001681 Acc: 13.5312\n",
      " |~~ train@46208  Loss: 0.002192 Acc: 13.2969\n",
      " |~~ train@46272  Loss: 0.001917 Acc: 13.4062\n",
      " |~~ train@46336  Loss: 0.002068 Acc: 13.3594\n",
      " |~~ train@46400  Loss: 0.001489 Acc: 13.5781\n",
      " |~~ train@46464  Loss: 0.002185 Acc: 13.2812\n",
      " |~~ train@46528  Loss: 0.001790 Acc: 13.4062\n",
      " |~~ train@46592  Loss: 0.002116 Acc: 13.3125\n",
      " |~~ train@46656  Loss: 0.001987 Acc: 13.4219\n",
      " |~~ train@46720  Loss: 0.001905 Acc: 13.4219\n",
      " |~~ train@46784  Loss: 0.001837 Acc: 13.3906\n",
      " |~~ train@46848  Loss: 0.001908 Acc: 13.3281\n",
      " |~~ train@46912  Loss: 0.001643 Acc: 13.4688\n",
      " |~~ train@46976  Loss: 0.001687 Acc: 13.5000\n",
      " |~~ train@47040  Loss: 0.002391 Acc: 13.2188\n",
      " |~~ train@47104  Loss: 0.001982 Acc: 13.3594\n",
      " |~~ train@47168  Loss: 0.002414 Acc: 13.2500\n",
      " |~~ train@47232  Loss: 0.001644 Acc: 13.5000\n",
      " |~~ train@47296  Loss: 0.002151 Acc: 13.2344\n",
      " |~~ train@47360  Loss: 0.002187 Acc: 13.2031\n",
      " |~~ train@47424  Loss: 0.001878 Acc: 13.5000\n",
      " |~~ train@47488  Loss: 0.002001 Acc: 13.3906\n",
      " |~~ train@47552  Loss: 0.002185 Acc: 13.3281\n",
      " |~~ train@47616  Loss: 0.002100 Acc: 13.3125\n",
      " |~~ train@47680  Loss: 0.002030 Acc: 13.3594\n",
      " |~~ train@47744  Loss: 0.001684 Acc: 13.4844\n",
      " |~~ train@47808  Loss: 0.002388 Acc: 13.1562\n",
      " |~~ train@47872  Loss: 0.002244 Acc: 13.1875\n",
      " |~~ train@47936  Loss: 0.001708 Acc: 13.4375\n",
      " |~~ train@48000  Loss: 0.001677 Acc: 13.4219\n",
      " |~~ train@48064  Loss: 0.001589 Acc: 13.5312\n",
      " |~~ train@48128  Loss: 0.002000 Acc: 13.3750\n",
      " |~~ train@48192  Loss: 0.001867 Acc: 13.3281\n",
      " |~~ train@48256  Loss: 0.001926 Acc: 13.3906\n",
      " |~~ train@48320  Loss: 0.002186 Acc: 13.2344\n",
      " |~~ train@48384  Loss: 0.002214 Acc: 13.3438\n",
      " |~~ train@48448  Loss: 0.002045 Acc: 13.3281\n",
      " |~~ train@48512  Loss: 0.001745 Acc: 13.4375\n",
      " |~~ train@48576  Loss: 0.001681 Acc: 13.4375\n",
      " |~~ train@48640  Loss: 0.001787 Acc: 13.5156\n",
      " |~~ train@48704  Loss: 0.001762 Acc: 13.3438\n",
      " |~~ train@48768  Loss: 0.001584 Acc: 13.5000\n",
      " |~~ train@48832  Loss: 0.001877 Acc: 13.3750\n",
      " |~~ train@48896  Loss: 0.002718 Acc: 13.2500\n",
      " |~~ train@48960  Loss: 0.001934 Acc: 13.2969\n",
      " |~~ train@49024  Loss: 0.001943 Acc: 13.4219\n",
      " |~~ train@49088  Loss: 0.001725 Acc: 13.5625\n",
      " |~~ train@49152  Loss: 0.002100 Acc: 13.3281\n",
      " |~~ train@49216  Loss: 0.001707 Acc: 13.4531\n",
      " |~~ train@49280  Loss: 0.001760 Acc: 13.4688\n",
      " |~~ train@49344  Loss: 0.002165 Acc: 13.2344\n",
      " |~~ train@49408  Loss: 0.002157 Acc: 13.2656\n",
      " |~~ train@49472  Loss: 0.001634 Acc: 13.5312\n",
      " |~~ train@49536  Loss: 0.001839 Acc: 13.3750\n",
      " |~~ train@49600  Loss: 0.001639 Acc: 13.4531\n",
      " |~~ train@49664  Loss: 0.002005 Acc: 13.3125\n",
      " |~~ train@49728  Loss: 0.001910 Acc: 13.3438\n",
      " |~~ train@49792  Loss: 0.001530 Acc: 13.5625\n",
      " |~~ train@49856  Loss: 0.001288 Acc: 13.6719\n",
      " |~~ train@49920  Loss: 0.002401 Acc: 13.2969\n",
      " |~~ train@49984  Loss: 0.001720 Acc: 13.5312\n",
      " |~~ train@50048  Loss: 0.002274 Acc: 13.2969\n",
      " |~~ train@50112  Loss: 0.002091 Acc: 13.3750\n",
      " |~~ train@50176  Loss: 0.001757 Acc: 13.3281\n",
      " |~~ train@50240  Loss: 0.001969 Acc: 13.3281\n",
      " |~~ train@50304  Loss: 0.002063 Acc: 13.3438\n",
      " |~~ train@50368  Loss: 0.001294 Acc: 13.6406\n",
      " |~~ train@50432  Loss: 0.002362 Acc: 13.2500\n",
      " |~~ train@50496  Loss: 0.002338 Acc: 13.2500\n",
      " |~~ train@50560  Loss: 0.001792 Acc: 13.4219\n",
      " |~~ train@50624  Loss: 0.002336 Acc: 13.3125\n",
      " |~~ train@50688  Loss: 0.001871 Acc: 13.4062\n",
      " |~~ train@50752  Loss: 0.001664 Acc: 13.4062\n",
      " |~~ train@50816  Loss: 0.001818 Acc: 13.4844\n",
      " |~~ train@50880  Loss: 0.001867 Acc: 13.4062\n",
      " |~~ train@50944  Loss: 0.001990 Acc: 13.3281\n",
      " |~~ train@51008  Loss: 0.001880 Acc: 13.3750\n",
      " |~~ train@51072  Loss: 0.001733 Acc: 13.5000\n",
      " |~~ train@51136  Loss: 0.001850 Acc: 13.3906\n",
      " |~~ train@51200  Loss: 0.001541 Acc: 13.5625\n",
      " |~~ train@51264  Loss: 0.001866 Acc: 13.3906\n",
      " |~~ train@51328  Loss: 0.002046 Acc: 13.2812\n",
      " |~~ train@51392  Loss: 0.002073 Acc: 13.2656\n",
      " |~~ train@51456  Loss: 0.002064 Acc: 13.3438\n",
      " |~~ train@51520  Loss: 0.001941 Acc: 13.3594\n",
      " |~~ train@51584  Loss: 0.002198 Acc: 13.2969\n",
      " |~~ train@51648  Loss: 0.002222 Acc: 13.2812\n",
      " |~~ train@51712  Loss: 0.002395 Acc: 13.2344\n",
      " |~~ train@51776  Loss: 0.002058 Acc: 13.3594\n",
      " |~~ train@51840  Loss: 0.002229 Acc: 13.2656\n",
      " |~~ train@51904  Loss: 0.001653 Acc: 13.4531\n",
      " |~~ train@51968  Loss: 0.001772 Acc: 13.5000\n",
      " |~~ train@52032  Loss: 0.002262 Acc: 13.1875\n",
      " |~~ train@52096  Loss: 0.002119 Acc: 13.3594\n",
      " |~~ train@52160  Loss: 0.002463 Acc: 13.2500\n",
      " |~~ train@52224  Loss: 0.001979 Acc: 13.4062\n",
      " |~~ train@52288  Loss: 0.002162 Acc: 13.2656\n",
      " |~~ train@52352  Loss: 0.001940 Acc: 13.4531\n",
      " |~~ train@52416  Loss: 0.002250 Acc: 13.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@52480  Loss: 0.001698 Acc: 13.4844\n",
      " |~~ train@52544  Loss: 0.001802 Acc: 13.3906\n",
      " |~~ train@52608  Loss: 0.002071 Acc: 13.3281\n",
      " |~~ train@52672  Loss: 0.002156 Acc: 13.2812\n",
      " |~~ train@52736  Loss: 0.002301 Acc: 13.2344\n",
      " |~~ train@52800  Loss: 0.001945 Acc: 13.3750\n",
      " |~~ train@52864  Loss: 0.001763 Acc: 13.3750\n",
      " |~~ train@52928  Loss: 0.001700 Acc: 13.4844\n",
      " |~~ train@52992  Loss: 0.002163 Acc: 13.2500\n",
      " |~~ train@53056  Loss: 0.001980 Acc: 13.3750\n",
      " |~~ train@53120  Loss: 0.002128 Acc: 13.2656\n",
      " |~~ train@53184  Loss: 0.001758 Acc: 13.4375\n",
      " |~~ train@53248  Loss: 0.002119 Acc: 13.3438\n",
      " |~~ train@53312  Loss: 0.001685 Acc: 13.4688\n",
      " |~~ train@53376  Loss: 0.001820 Acc: 13.3438\n",
      " |~~ train@53440  Loss: 0.001744 Acc: 13.3906\n",
      " |~~ train@53504  Loss: 0.002321 Acc: 13.2969\n",
      " |~~ train@53568  Loss: 0.002017 Acc: 13.3906\n",
      " |~~ train@53632  Loss: 0.002361 Acc: 13.2344\n",
      " |~~ train@53696  Loss: 0.002067 Acc: 13.3125\n",
      " |~~ train@53760  Loss: 0.001725 Acc: 13.4375\n",
      " |~~ train@53824  Loss: 0.001847 Acc: 13.4375\n",
      " |~~ train@53888  Loss: 0.001702 Acc: 13.4219\n",
      " |~~ train@53952  Loss: 0.002006 Acc: 13.2656\n",
      " |~~ train@54016  Loss: 0.001955 Acc: 13.4219\n",
      " |~~ train@54080  Loss: 0.001860 Acc: 13.4219\n",
      " |~~ train@54144  Loss: 0.002075 Acc: 13.3594\n",
      " |~~ train@54208  Loss: 0.001975 Acc: 13.3438\n",
      " |~~ train@54272  Loss: 0.001907 Acc: 13.3750\n",
      " |~~ train@54336  Loss: 0.002009 Acc: 13.3281\n",
      " |~~ train@54400  Loss: 0.001870 Acc: 13.4062\n",
      " |~~ train@54464  Loss: 0.001752 Acc: 13.5312\n",
      " |~~ train@54528  Loss: 0.002456 Acc: 13.0156\n",
      " |~~ train@54592  Loss: 0.001639 Acc: 13.4375\n",
      " |~~ train@54656  Loss: 0.002015 Acc: 13.2812\n",
      " |~~ train@54720  Loss: 0.002143 Acc: 13.2969\n",
      " |~~ train@54784  Loss: 0.002241 Acc: 13.2969\n",
      " |~~ train@54848  Loss: 0.002403 Acc: 13.2188\n",
      " |~~ train@54912  Loss: 0.001943 Acc: 13.3281\n",
      " |~~ train@54976  Loss: 0.001916 Acc: 13.2969\n",
      " |~~ train@55040  Loss: 0.002238 Acc: 13.2656\n",
      " |~~ train@55104  Loss: 0.002160 Acc: 13.2031\n",
      " |~~ train@55168  Loss: 0.001617 Acc: 13.4375\n",
      " |~~ train@55232  Loss: 0.001993 Acc: 13.3438\n",
      " |~~ train@55296  Loss: 0.001743 Acc: 13.4375\n",
      " |~~ train@55360  Loss: 0.002086 Acc: 13.3594\n",
      " |~~ train@55424  Loss: 0.001838 Acc: 13.3438\n",
      " |~~ train@55488  Loss: 0.001764 Acc: 13.4375\n",
      " |~~ train@55552  Loss: 0.002252 Acc: 13.2812\n",
      " |~~ train@55616  Loss: 0.001959 Acc: 13.4062\n",
      " |~~ train@55680  Loss: 0.002073 Acc: 13.2500\n",
      " |~~ train@55744  Loss: 0.002273 Acc: 13.2812\n",
      " |~~ train@55808  Loss: 0.001972 Acc: 13.4531\n",
      " |~~ train@55872  Loss: 0.002121 Acc: 13.2656\n",
      " |~~ train@55936  Loss: 0.002083 Acc: 13.2969\n",
      " |~~ train@56000  Loss: 0.001851 Acc: 13.3438\n",
      " |~~ train@56064  Loss: 0.001981 Acc: 13.3750\n",
      " |~~ train@56128  Loss: 0.001733 Acc: 13.3438\n",
      " |~~ train@56192  Loss: 0.001726 Acc: 13.5156\n",
      " |~~ train@56256  Loss: 0.001974 Acc: 13.4531\n",
      " |~~ train@56320  Loss: 0.002061 Acc: 13.2812\n",
      " |~~ train@56384  Loss: 0.001976 Acc: 13.4062\n",
      " |~~ train@56448  Loss: 0.001893 Acc: 13.3281\n",
      " |~~ train@56512  Loss: 0.002426 Acc: 13.2031\n",
      " |~~ train@56576  Loss: 0.001891 Acc: 13.3750\n",
      " |~~ train@56640  Loss: 0.001849 Acc: 13.3438\n",
      " |~~ train@56704  Loss: 0.002051 Acc: 13.3125\n",
      " |~~ train@56768  Loss: 0.001959 Acc: 13.3125\n",
      " |~~ train@56832  Loss: 0.001638 Acc: 13.4062\n",
      " |~~ train@56896  Loss: 0.002145 Acc: 13.3594\n",
      " |~~ train@56960  Loss: 0.001792 Acc: 13.4219\n",
      " |~~ train@57024  Loss: 0.002191 Acc: 13.3438\n",
      " |~~ train@57088  Loss: 0.001956 Acc: 13.3281\n",
      " |~~ train@57152  Loss: 0.002684 Acc: 13.0625\n",
      " |~~ train@57216  Loss: 0.002364 Acc: 13.2031\n",
      " |~~ train@57280  Loss: 0.001697 Acc: 13.4531\n",
      " |~~ train@57344  Loss: 0.002055 Acc: 13.2500\n",
      " |~~ train@57408  Loss: 0.002046 Acc: 13.2812\n",
      " |~~ train@57472  Loss: 0.002069 Acc: 13.3750\n",
      " |~~ train@57536  Loss: 0.002480 Acc: 13.1719\n",
      " |~~ train@57600  Loss: 0.001654 Acc: 13.4219\n",
      " |~~ train@57664  Loss: 0.002118 Acc: 13.2500\n",
      " |~~ train@57728  Loss: 0.001498 Acc: 13.5938\n",
      " |~~ train@57792  Loss: 0.001993 Acc: 13.3750\n",
      " |~~ train@57856  Loss: 0.002202 Acc: 13.3281\n",
      " |~~ train@57920  Loss: 0.002289 Acc: 13.2031\n",
      " |~~ train@57984  Loss: 0.002415 Acc: 13.2031\n",
      " |~~ train@58048  Loss: 0.001868 Acc: 13.3750\n",
      " |~~ train@58112  Loss: 0.001556 Acc: 13.5625\n",
      " |~~ train@58176  Loss: 0.002887 Acc: 13.1094\n",
      " |~~ train@58240  Loss: 0.002019 Acc: 13.3438\n",
      " |~~ train@58304  Loss: 0.002521 Acc: 13.2188\n",
      " |~~ train@58368  Loss: 0.002183 Acc: 13.2969\n",
      " |~~ train@58432  Loss: 0.002087 Acc: 13.4062\n",
      " |~~ train@58496  Loss: 0.001859 Acc: 13.4219\n",
      " |~~ train@58560  Loss: 0.002136 Acc: 13.1719\n",
      " |~~ train@58624  Loss: 0.001920 Acc: 13.3438\n",
      " |~~ train@58688  Loss: 0.002174 Acc: 13.3125\n",
      " |~~ train@58752  Loss: 0.001948 Acc: 13.4375\n",
      " |~~ train@58816  Loss: 0.002545 Acc: 13.2656\n",
      " |~~ train@58880  Loss: 0.001866 Acc: 13.5156\n",
      " |~~ train@58944  Loss: 0.002002 Acc: 13.4375\n",
      " |~~ train@59008  Loss: 0.002004 Acc: 13.4062\n",
      " |~~ train@59072  Loss: 0.001701 Acc: 13.5312\n",
      " |~~ train@59136  Loss: 0.001768 Acc: 13.4062\n",
      " |~~ train@59200  Loss: 0.001928 Acc: 13.3906\n",
      " |~~ train@59264  Loss: 0.001755 Acc: 13.4375\n",
      " |~~ train@59328  Loss: 0.001940 Acc: 13.4219\n",
      " |~~ train@59392  Loss: 0.001462 Acc: 13.5625\n",
      " |~~ train@59456  Loss: 0.001871 Acc: 13.4844\n",
      " |~~ train@59520  Loss: 0.002205 Acc: 13.2812\n",
      " |~~ train@59584  Loss: 0.002036 Acc: 13.2812\n",
      " |~~ train@59648  Loss: 0.002090 Acc: 13.3750\n",
      " |~~ train@59712  Loss: 0.002352 Acc: 13.1250\n",
      " |~~ train@59776  Loss: 0.001906 Acc: 13.4062\n",
      " |~~ train@59840  Loss: 0.002176 Acc: 13.3438\n",
      " |~~ train@59904  Loss: 0.001714 Acc: 13.4531\n",
      " |~~ train@59968  Loss: 0.001904 Acc: 13.3906\n",
      " |~~ train@60032  Loss: 0.002145 Acc: 13.2656\n",
      " |~~ train@60096  Loss: 0.002462 Acc: 13.1250\n",
      " |~~ train@60160  Loss: 0.001949 Acc: 13.3750\n",
      " |~~ train@60224  Loss: 0.001832 Acc: 13.5156\n",
      " |~~ train@60288  Loss: 0.002010 Acc: 13.3750\n",
      " |~~ train@60352  Loss: 0.002120 Acc: 13.3281\n",
      " |~~ train@60416  Loss: 0.002097 Acc: 13.2969\n",
      " |~~ train@60480  Loss: 0.002030 Acc: 13.5000\n",
      " |~~ train@60544  Loss: 0.002348 Acc: 13.2031\n",
      " |~~ train@60608  Loss: 0.001855 Acc: 13.3594\n",
      " |~~ train@60672  Loss: 0.001949 Acc: 13.4688\n",
      " |~~ train@60736  Loss: 0.002061 Acc: 13.2656\n",
      " |~~ train@60800  Loss: 0.001776 Acc: 13.5000\n",
      " |~~ train@60864  Loss: 0.002324 Acc: 13.2031\n",
      " |~~ train@60928  Loss: 0.002125 Acc: 13.2969\n",
      " |~~ train@60992  Loss: 0.001693 Acc: 13.4844\n",
      " |~~ train@61056  Loss: 0.001886 Acc: 13.4062\n",
      " |~~ train@61120  Loss: 0.001858 Acc: 13.3594\n",
      " |~~ train@61184  Loss: 0.002111 Acc: 13.3750\n",
      " |~~ train@61248  Loss: 0.001940 Acc: 13.4219\n",
      " |~~ train@61312  Loss: 0.002108 Acc: 13.3281\n",
      " |~~ train@61376  Loss: 0.002017 Acc: 13.4531\n",
      " |~~ train@61440  Loss: 0.002253 Acc: 13.2344\n",
      " |~~ train@61504  Loss: 0.001288 Acc: 13.6250\n",
      " |~~ train@61568  Loss: 0.002161 Acc: 13.3438\n",
      " |~~ train@61632  Loss: 0.001700 Acc: 13.5000\n",
      " |~~ train@61696  Loss: 0.001624 Acc: 13.4844\n",
      " |~~ train@61760  Loss: 0.002321 Acc: 13.2812\n",
      " |~~ train@61824  Loss: 0.002282 Acc: 13.3750\n",
      " |~~ train@61888  Loss: 0.002234 Acc: 13.3125\n",
      " |~~ train@61952  Loss: 0.002332 Acc: 13.1719\n",
      " |~~ train@62016  Loss: 0.001734 Acc: 13.3594\n",
      " |~~ train@62080  Loss: 0.002321 Acc: 13.3125\n",
      " |~~ train@62144  Loss: 0.001851 Acc: 13.3750\n",
      " |~~ train@62208  Loss: 0.002013 Acc: 13.3281\n",
      " |~~ train@62272  Loss: 0.002452 Acc: 13.1406\n",
      " |~~ train@62336  Loss: 0.002167 Acc: 13.3281\n",
      " |~~ train@62400  Loss: 0.001984 Acc: 13.3594\n",
      " |~~ train@62464  Loss: 0.002397 Acc: 13.2656\n",
      " |~~ train@62528  Loss: 0.001447 Acc: 13.5312\n",
      " |~~ train@62592  Loss: 0.002113 Acc: 13.3125\n",
      " |~~ train@62656  Loss: 0.001971 Acc: 13.4062\n",
      " |~~ train@62720  Loss: 0.002047 Acc: 13.3281\n",
      " |~~ train@62784  Loss: 0.002200 Acc: 13.3125\n",
      " |~~ train@62848  Loss: 0.002085 Acc: 13.2969\n",
      " |~~ train@62912  Loss: 0.002190 Acc: 13.2500\n",
      " |~~ train@62976  Loss: 0.002101 Acc: 13.2812\n",
      " |~~ train@63040  Loss: 0.001398 Acc: 13.5312\n",
      " |~~ train@63104  Loss: 0.001852 Acc: 13.4531\n",
      " |~~ train@63168  Loss: 0.001798 Acc: 13.4062\n",
      " |~~ train@63232  Loss: 0.001560 Acc: 13.6406\n",
      " |~~ train@63296  Loss: 0.002356 Acc: 13.2500\n",
      " |~~ train@63360  Loss: 0.002294 Acc: 13.2812\n",
      " |~~ train@63424  Loss: 0.001649 Acc: 13.5000\n",
      " |~~ train@63488  Loss: 0.002482 Acc: 13.2031\n",
      " |~~ train@63552  Loss: 0.002038 Acc: 13.2188\n",
      " |~~ train@63616  Loss: 0.001996 Acc: 13.3906\n",
      " |~~ train@63680  Loss: 0.001809 Acc: 13.4219\n",
      " |~~ train@63744  Loss: 0.001618 Acc: 13.5156\n",
      " |~~ train@63808  Loss: 0.001618 Acc: 13.4688\n",
      " |~~ train@63872  Loss: 0.001695 Acc: 13.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@63936  Loss: 0.002032 Acc: 13.4062\n",
      " |~~ train@64000  Loss: 0.001773 Acc: 13.4375\n",
      " |~~ train@64064  Loss: 0.001549 Acc: 13.4688\n",
      " |~~ train@64128  Loss: 0.002043 Acc: 13.3594\n",
      " |~~ train@64192  Loss: 0.001986 Acc: 13.3750\n",
      " |~~ train@64256  Loss: 0.002235 Acc: 13.3125\n",
      " |~~ train@64320  Loss: 0.001975 Acc: 13.3125\n",
      " |~~ train@64384  Loss: 0.001779 Acc: 13.4531\n",
      " |~~ train@64448  Loss: 0.001940 Acc: 13.3438\n",
      " |~~ train@64512  Loss: 0.001601 Acc: 13.4062\n",
      " |~~ train@64576  Loss: 0.001874 Acc: 13.4062\n",
      " |~~ train@64640  Loss: 0.001994 Acc: 13.4688\n",
      " |~~ train@64704  Loss: 0.002247 Acc: 13.2500\n",
      " |~~ train@64768  Loss: 0.002124 Acc: 13.3438\n",
      " |~~ train@64832  Loss: 0.002299 Acc: 13.2656\n",
      " |~~ train@64896  Loss: 0.002183 Acc: 13.3281\n",
      " |~~ train@64960  Loss: 0.001916 Acc: 13.4375\n",
      " |~~ train@65024  Loss: 0.002383 Acc: 13.2656\n",
      " |~~ train@65088  Loss: 0.002107 Acc: 13.3594\n",
      " |~~ train@65152  Loss: 0.001555 Acc: 13.5781\n",
      " |~~ train@65216  Loss: 0.002137 Acc: 13.2812\n",
      " |~~ train@65280  Loss: 0.001933 Acc: 13.3594\n",
      " |~~ train@65344  Loss: 0.001852 Acc: 13.3750\n",
      " |~~ train@65408  Loss: 0.002076 Acc: 13.4062\n",
      " |~~ train@65472  Loss: 0.002085 Acc: 13.2188\n",
      " |~~ train@65536  Loss: 0.001522 Acc: 13.4844\n",
      " |~~ train@65600  Loss: 0.001828 Acc: 13.3906\n",
      " |~~ train@65664  Loss: 0.002169 Acc: 13.3594\n",
      " |~~ train@65728  Loss: 0.002137 Acc: 13.2656\n",
      " |~~ train@65792  Loss: 0.001886 Acc: 13.4062\n",
      " |~~ train@65856  Loss: 0.002165 Acc: 13.2344\n",
      " |~~ train@65920  Loss: 0.002333 Acc: 13.2344\n",
      " |~~ train@65984  Loss: 0.001821 Acc: 13.3906\n",
      " |~~ train@66048  Loss: 0.001786 Acc: 13.5156\n",
      " |~~ train@66112  Loss: 0.002165 Acc: 13.2344\n",
      " |~~ train@66176  Loss: 0.001744 Acc: 13.4219\n",
      " |~~ train@66240  Loss: 0.001893 Acc: 13.4531\n",
      " |~~ train@66304  Loss: 0.002097 Acc: 13.2344\n",
      " |~~ train@66368  Loss: 0.002022 Acc: 13.3125\n",
      " |~~ train@66432  Loss: 0.002209 Acc: 13.3594\n",
      " |~~ train@66496  Loss: 0.002042 Acc: 13.2969\n",
      " |~~ train@66560  Loss: 0.001757 Acc: 13.3906\n",
      " |~~ train@66624  Loss: 0.001959 Acc: 13.4375\n",
      " |~~ train@66688  Loss: 0.002415 Acc: 13.2500\n",
      " |~~ train@66752  Loss: 0.001910 Acc: 13.3594\n",
      " |~~ train@66816  Loss: 0.001691 Acc: 13.4531\n",
      " |~~ train@66880  Loss: 0.001932 Acc: 13.3438\n",
      " |~~ train@66944  Loss: 0.001748 Acc: 13.5156\n",
      " |~~ train@67008  Loss: 0.001651 Acc: 13.5469\n",
      " |~~ train@67072  Loss: 0.001842 Acc: 13.4531\n",
      " |~~ train@67136  Loss: 0.002147 Acc: 13.3281\n",
      " |~~ train@67200  Loss: 0.002202 Acc: 13.1719\n",
      " |~~ train@67264  Loss: 0.002239 Acc: 13.2656\n",
      " |~~ train@67328  Loss: 0.002242 Acc: 13.3906\n",
      " |~~ train@67392  Loss: 0.002194 Acc: 13.2812\n",
      " |~~ train@67456  Loss: 0.001808 Acc: 13.4375\n",
      " |~~ train@67520  Loss: 0.002428 Acc: 13.0312\n",
      " |~~ train@67584  Loss: 0.001811 Acc: 13.5469\n",
      " |~~ train@67648  Loss: 0.002038 Acc: 13.3594\n",
      " |~~ train@67712  Loss: 0.002056 Acc: 13.3281\n",
      " |~~ train@67776  Loss: 0.002115 Acc: 13.2031\n",
      " |~~ train@67840  Loss: 0.002144 Acc: 13.3281\n",
      " |~~ train@67904  Loss: 0.002505 Acc: 13.1875\n",
      " |~~ train@67968  Loss: 0.001740 Acc: 13.4219\n",
      " |~~ train@68032  Loss: 0.002266 Acc: 13.1875\n",
      " |~~ train@68096  Loss: 0.002210 Acc: 13.2031\n",
      " |~~ train@68160  Loss: 0.002450 Acc: 13.2031\n",
      " |~~ train@68224  Loss: 0.001822 Acc: 13.3906\n",
      " |~~ train@68288  Loss: 0.002246 Acc: 13.2188\n",
      " |~~ train@68352  Loss: 0.002134 Acc: 13.2812\n",
      " |~~ train@68416  Loss: 0.001964 Acc: 13.3438\n",
      " |~~ train@68480  Loss: 0.002296 Acc: 13.2344\n",
      " |~~ train@68544  Loss: 0.001798 Acc: 13.3906\n",
      " |~~ train@68608  Loss: 0.002019 Acc: 13.3906\n",
      " |~~ train@68672  Loss: 0.001914 Acc: 13.3906\n",
      " |~~ train@68736  Loss: 0.002421 Acc: 13.1562\n",
      " |~~ train@68800  Loss: 0.002264 Acc: 13.2969\n",
      " |~~ train@68864  Loss: 0.001903 Acc: 13.3906\n",
      " |~~ train@68928  Loss: 0.002136 Acc: 13.4219\n",
      " |~~ train@68992  Loss: 0.001691 Acc: 13.3906\n",
      " |~~ train@69056  Loss: 0.002230 Acc: 13.3125\n",
      " |~~ train@69120  Loss: 0.001795 Acc: 13.4844\n",
      " |~~ train@69184  Loss: 0.001661 Acc: 13.4531\n",
      " |~~ train@69248  Loss: 0.002021 Acc: 13.3594\n",
      " |~~ train@69312  Loss: 0.001634 Acc: 13.5000\n",
      " |~~ train@69376  Loss: 0.002386 Acc: 13.2500\n",
      " |~~ train@69440  Loss: 0.002145 Acc: 13.2500\n",
      " |~~ train@69504  Loss: 0.001927 Acc: 13.4062\n",
      " |~~ train@69568  Loss: 0.001863 Acc: 13.2969\n",
      " |~~ train@69632  Loss: 0.002065 Acc: 13.3281\n",
      " |~~ train@69696  Loss: 0.002021 Acc: 13.3906\n",
      " |~~ train@69760  Loss: 0.002409 Acc: 13.1250\n",
      " |~~ train@69824  Loss: 0.001968 Acc: 13.3750\n",
      " |~~ train@69888  Loss: 0.002016 Acc: 13.2969\n",
      " |~~ train@69952  Loss: 0.001865 Acc: 13.4375\n",
      " |~~ train@70016  Loss: 0.002000 Acc: 13.3125\n",
      " |~~ train@70080  Loss: 0.002250 Acc: 13.2656\n",
      " |~~ train@70144  Loss: 0.001724 Acc: 13.3750\n",
      " |~~ train@70208  Loss: 0.001725 Acc: 13.4688\n",
      " |~~ train@70272  Loss: 0.001914 Acc: 13.3594\n",
      " |~~ train@70336  Loss: 0.002250 Acc: 13.2656\n",
      " |~~ train@70400  Loss: 0.001868 Acc: 13.3594\n",
      " |~~ train@70464  Loss: 0.001930 Acc: 13.3594\n",
      " |~~ train@70528  Loss: 0.002403 Acc: 13.2344\n",
      " |~~ train@70592  Loss: 0.002145 Acc: 13.2500\n",
      " |~~ train@70656  Loss: 0.002085 Acc: 13.3438\n",
      " |~~ train@70720  Loss: 0.002257 Acc: 13.2344\n",
      " |~~ train@70784  Loss: 0.002004 Acc: 13.3125\n",
      " |~~ train@70848  Loss: 0.002191 Acc: 13.2812\n",
      " |~~ train@70912  Loss: 0.001810 Acc: 13.4844\n",
      " |~~ train@70976  Loss: 0.002367 Acc: 13.1875\n",
      " |~~ train@71040  Loss: 0.001687 Acc: 13.4531\n",
      " |~~ train@71104  Loss: 0.002157 Acc: 13.2969\n",
      " |~~ train@71168  Loss: 0.002149 Acc: 13.2188\n",
      " |~~ train@71232  Loss: 0.002196 Acc: 13.2500\n",
      " |~~ train@71296  Loss: 0.002046 Acc: 13.4062\n",
      " |~~ train@71360  Loss: 0.002069 Acc: 13.3281\n",
      " |~~ train@71424  Loss: 0.001977 Acc: 13.4375\n",
      " |~~ train@71488  Loss: 0.002492 Acc: 13.1250\n",
      " |~~ train@71552  Loss: 0.001986 Acc: 13.3594\n",
      " |~~ train@71616  Loss: 0.001514 Acc: 13.5469\n",
      " |~~ train@71680  Loss: 0.002025 Acc: 13.4375\n",
      " |~~ train@71744  Loss: 0.001798 Acc: 13.4062\n",
      " |~~ train@71808  Loss: 0.002076 Acc: 13.3750\n",
      " |~~ train@71872  Loss: 0.002792 Acc: 13.1250\n",
      " |~~ train@71936  Loss: 0.001860 Acc: 13.3750\n",
      " |~~ train@72000  Loss: 0.002591 Acc: 13.1562\n",
      " |~~ train@72064  Loss: 0.002670 Acc: 13.0625\n",
      " |~~ train@72128  Loss: 0.001943 Acc: 13.3594\n",
      " |~~ train@72192  Loss: 0.002226 Acc: 13.2344\n",
      " |~~ train@72256  Loss: 0.002330 Acc: 13.1406\n",
      " |~~ train@72320  Loss: 0.001649 Acc: 13.4688\n",
      " |~~ train@72384  Loss: 0.001982 Acc: 13.2969\n",
      " |~~ train@72448  Loss: 0.001946 Acc: 13.4062\n",
      " |~~ train@72512  Loss: 0.002188 Acc: 13.2656\n",
      " |~~ train@72576  Loss: 0.001646 Acc: 13.4844\n",
      " |~~ train@72640  Loss: 0.002168 Acc: 13.3281\n",
      " |~~ train@72704  Loss: 0.002421 Acc: 13.2344\n",
      " |~~ train@72768  Loss: 0.001831 Acc: 13.4219\n",
      " |~~ train@72832  Loss: 0.002455 Acc: 13.1719\n",
      " |~~ train@72896  Loss: 0.002047 Acc: 13.2969\n",
      " |~~ train@72960  Loss: 0.002195 Acc: 13.1719\n",
      " |~~ train@73024  Loss: 0.001897 Acc: 13.4688\n",
      " |~~ train@73088  Loss: 0.001839 Acc: 13.3750\n",
      " |~~ train@73152  Loss: 0.001890 Acc: 13.4219\n",
      " |~~ train@73216  Loss: 0.001983 Acc: 13.3906\n",
      " |~~ train@73280  Loss: 0.001847 Acc: 13.4219\n",
      " |~~ train@73344  Loss: 0.002125 Acc: 13.2969\n",
      " |~~ train@73408  Loss: 0.001695 Acc: 13.5156\n",
      " |~~ train@73472  Loss: 0.003017 Acc: 13.0312\n",
      " |~~ train@73536  Loss: 0.001790 Acc: 13.3750\n",
      " |~~ train@73600  Loss: 0.002047 Acc: 13.2656\n",
      " |~~ train@73664  Loss: 0.001911 Acc: 13.3750\n",
      " |~~ train@73728  Loss: 0.001667 Acc: 13.5000\n",
      " |~~ train@73792  Loss: 0.001756 Acc: 13.5156\n",
      " |~~ train@73856  Loss: 0.002431 Acc: 13.0781\n",
      " |~~ train@73920  Loss: 0.001984 Acc: 13.4062\n",
      " |~~ train@73984  Loss: 0.002208 Acc: 13.2812\n",
      " |~~ train@74048  Loss: 0.001819 Acc: 13.4062\n",
      " |~~ train@74112  Loss: 0.002174 Acc: 13.2031\n",
      " |~~ train@74176  Loss: 0.001832 Acc: 13.3594\n",
      " |~~ train@74240  Loss: 0.002017 Acc: 13.3750\n",
      " |~~ train@74304  Loss: 0.002462 Acc: 13.1406\n",
      " |~~ train@74368  Loss: 0.002183 Acc: 13.2812\n",
      " |~~ train@74432  Loss: 0.002134 Acc: 13.2656\n",
      " |~~ train@74496  Loss: 0.002215 Acc: 13.2344\n",
      " |~~ train@74560  Loss: 0.001900 Acc: 13.3438\n",
      " |~~ train@74624  Loss: 0.002176 Acc: 13.3125\n",
      " |~~ train@74688  Loss: 0.002115 Acc: 13.3281\n",
      " |~~ train@74752  Loss: 0.002413 Acc: 13.1250\n",
      " |~~ train@74816  Loss: 0.002245 Acc: 13.2656\n",
      " |~~ train@74880  Loss: 0.001616 Acc: 13.5000\n",
      " |~~ train@74944  Loss: 0.002089 Acc: 13.2500\n",
      " |~~ train@75008  Loss: 0.002475 Acc: 13.0469\n",
      " |~~ train@75072  Loss: 0.001865 Acc: 13.3906\n",
      " |~~ train@75136  Loss: 0.001902 Acc: 13.3281\n",
      " |~~ train@75200  Loss: 0.002145 Acc: 13.2500\n",
      " |~~ train@75264  Loss: 0.002135 Acc: 13.3125\n",
      " |~~ train@75328  Loss: 0.001553 Acc: 13.5156\n",
      " |~~ train@75392  Loss: 0.001683 Acc: 13.4844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@75456  Loss: 0.001889 Acc: 13.4375\n",
      " |~~ train@75520  Loss: 0.001929 Acc: 13.3125\n",
      " |~~ train@75584  Loss: 0.001659 Acc: 13.3750\n",
      " |~~ train@75648  Loss: 0.002142 Acc: 13.3594\n",
      " |~~ train@75712  Loss: 0.001658 Acc: 13.5312\n",
      " |~~ train@75776  Loss: 0.001651 Acc: 13.5000\n",
      " |~~ train@75840  Loss: 0.002212 Acc: 13.3281\n",
      " |~~ train@75904  Loss: 0.002323 Acc: 13.2812\n",
      " |~~ train@75968  Loss: 0.001746 Acc: 13.5312\n",
      " |~~ train@76032  Loss: 0.002232 Acc: 13.2969\n",
      " |~~ train@76096  Loss: 0.001906 Acc: 13.3750\n",
      " |~~ train@76160  Loss: 0.002003 Acc: 13.2500\n",
      " |~~ train@76224  Loss: 0.001742 Acc: 13.4219\n",
      " |~~ train@76288  Loss: 0.002027 Acc: 13.3906\n",
      " |~~ train@76352  Loss: 0.001771 Acc: 13.4219\n",
      " |~~ train@76416  Loss: 0.002118 Acc: 13.3125\n",
      " |~~ train@76480  Loss: 0.002077 Acc: 13.2500\n",
      " |~~ train@76544  Loss: 0.001812 Acc: 13.4375\n",
      " |~~ train@76608  Loss: 0.001818 Acc: 13.4844\n",
      " |~~ train@76672  Loss: 0.001917 Acc: 13.4375\n",
      " |~~ train@76736  Loss: 0.002085 Acc: 13.2969\n",
      " |~~ train@76800  Loss: 0.002126 Acc: 13.3125\n",
      " |~~ train@76864  Loss: 0.001767 Acc: 13.3750\n",
      " |~~ train@76928  Loss: 0.001939 Acc: 13.4219\n",
      " |~~ train@76992  Loss: 0.001861 Acc: 13.4375\n",
      " |~~ train@77056  Loss: 0.001967 Acc: 13.3594\n",
      " |~~ train@77120  Loss: 0.001797 Acc: 13.3438\n",
      " |~~ train@77184  Loss: 0.002059 Acc: 13.3594\n",
      " |~~ train@77248  Loss: 0.001709 Acc: 13.3906\n",
      " |~~ train@77312  Loss: 0.002061 Acc: 13.4219\n",
      " |~~ train@77376  Loss: 0.002454 Acc: 13.1406\n",
      " |~~ train@77440  Loss: 0.001534 Acc: 13.4531\n",
      " |~~ train@77504  Loss: 0.001940 Acc: 13.3281\n",
      " |~~ train@77568  Loss: 0.001573 Acc: 13.4844\n",
      " |~~ train@77632  Loss: 0.001875 Acc: 13.3438\n",
      " |~~ train@77696  Loss: 0.001756 Acc: 13.4531\n",
      " |~~ train@77760  Loss: 0.001931 Acc: 13.3594\n",
      " |~~ train@77824  Loss: 0.002236 Acc: 13.2812\n",
      " |~~ train@77888  Loss: 0.002193 Acc: 13.2812\n",
      " |~~ train@77952  Loss: 0.001397 Acc: 13.5781\n",
      " |~~ train@78016  Loss: 0.002175 Acc: 13.2656\n",
      " |~~ train@78080  Loss: 0.001989 Acc: 13.4375\n",
      " |~~ train@78144  Loss: 0.002005 Acc: 13.3281\n",
      " |~~ train@78208  Loss: 0.001793 Acc: 13.4688\n",
      " |~~ train@78272  Loss: 0.002396 Acc: 13.2031\n",
      " |~~ train@78336  Loss: 0.001813 Acc: 13.4844\n",
      " |~~ train@78400  Loss: 0.001947 Acc: 13.4062\n",
      " |~~ train@78464  Loss: 0.001716 Acc: 13.5625\n",
      " |~~ train@78484  Loss: 0.004477 Acc: 13.6000\n",
      "train  Loss: 0.002002 Acc: 13.3524\n",
      " |~~ val@64  Loss: 0.002402 Acc: 13.3125\n",
      " |~~ val@128  Loss: 0.002518 Acc: 13.2344\n",
      " |~~ val@192  Loss: 0.002851 Acc: 13.1094\n",
      " |~~ val@256  Loss: 0.002087 Acc: 13.4062\n",
      " |~~ val@320  Loss: 0.002586 Acc: 13.2031\n",
      " |~~ val@384  Loss: 0.001478 Acc: 13.5469\n",
      " |~~ val@448  Loss: 0.002338 Acc: 13.2656\n",
      " |~~ val@512  Loss: 0.002672 Acc: 13.2188\n",
      " |~~ val@576  Loss: 0.002669 Acc: 13.1875\n",
      " |~~ val@640  Loss: 0.002540 Acc: 13.2188\n",
      " |~~ val@704  Loss: 0.002468 Acc: 13.2500\n",
      " |~~ val@768  Loss: 0.002174 Acc: 13.2969\n",
      " |~~ val@832  Loss: 0.001886 Acc: 13.3906\n",
      " |~~ val@896  Loss: 0.002313 Acc: 13.2969\n",
      " |~~ val@960  Loss: 0.002268 Acc: 13.3281\n",
      " |~~ val@1024  Loss: 0.002474 Acc: 13.1562\n",
      " |~~ val@1088  Loss: 0.002395 Acc: 13.3125\n",
      " |~~ val@1152  Loss: 0.002284 Acc: 13.3750\n",
      " |~~ val@1216  Loss: 0.002173 Acc: 13.3125\n",
      " |~~ val@1280  Loss: 0.002678 Acc: 13.2969\n",
      " |~~ val@1344  Loss: 0.002406 Acc: 13.1875\n",
      " |~~ val@1408  Loss: 0.002229 Acc: 13.2812\n",
      " |~~ val@1472  Loss: 0.002496 Acc: 13.2188\n",
      " |~~ val@1536  Loss: 0.002069 Acc: 13.3594\n",
      " |~~ val@1600  Loss: 0.002673 Acc: 13.2812\n",
      " |~~ val@1664  Loss: 0.001972 Acc: 13.4375\n",
      " |~~ val@1728  Loss: 0.002821 Acc: 13.1094\n",
      " |~~ val@1792  Loss: 0.002712 Acc: 13.1719\n",
      " |~~ val@1856  Loss: 0.002238 Acc: 13.3594\n",
      " |~~ val@1920  Loss: 0.002189 Acc: 13.2969\n",
      " |~~ val@1984  Loss: 0.002243 Acc: 13.2969\n",
      " |~~ val@2048  Loss: 0.002548 Acc: 13.2344\n",
      " |~~ val@2112  Loss: 0.002080 Acc: 13.3281\n",
      " |~~ val@2176  Loss: 0.001945 Acc: 13.4062\n",
      " |~~ val@2240  Loss: 0.002156 Acc: 13.3438\n",
      " |~~ val@2304  Loss: 0.002336 Acc: 13.2812\n",
      " |~~ val@2368  Loss: 0.002111 Acc: 13.3281\n",
      " |~~ val@2432  Loss: 0.002690 Acc: 13.0781\n",
      " |~~ val@2496  Loss: 0.002441 Acc: 13.2969\n",
      " |~~ val@2560  Loss: 0.002255 Acc: 13.2344\n",
      " |~~ val@2624  Loss: 0.002186 Acc: 13.1406\n",
      " |~~ val@2688  Loss: 0.002100 Acc: 13.4375\n",
      " |~~ val@2752  Loss: 0.002314 Acc: 13.3438\n",
      " |~~ val@2816  Loss: 0.002111 Acc: 13.3750\n",
      " |~~ val@2880  Loss: 0.002826 Acc: 13.1562\n",
      " |~~ val@2944  Loss: 0.002050 Acc: 13.4219\n",
      " |~~ val@3008  Loss: 0.002487 Acc: 13.2969\n",
      " |~~ val@3072  Loss: 0.001999 Acc: 13.4062\n",
      " |~~ val@3136  Loss: 0.002513 Acc: 13.3125\n",
      " |~~ val@3200  Loss: 0.001953 Acc: 13.3281\n",
      " |~~ val@3264  Loss: 0.002805 Acc: 13.1719\n",
      " |~~ val@3328  Loss: 0.002109 Acc: 13.3438\n",
      " |~~ val@3392  Loss: 0.001708 Acc: 13.4062\n",
      " |~~ val@3456  Loss: 0.001953 Acc: 13.4219\n",
      " |~~ val@3520  Loss: 0.002177 Acc: 13.3281\n",
      " |~~ val@3584  Loss: 0.003277 Acc: 13.0156\n",
      " |~~ val@3648  Loss: 0.002436 Acc: 13.3750\n",
      " |~~ val@3712  Loss: 0.002867 Acc: 13.0781\n",
      " |~~ val@3776  Loss: 0.002782 Acc: 13.2031\n",
      " |~~ val@3840  Loss: 0.001886 Acc: 13.4375\n",
      " |~~ val@3904  Loss: 0.002161 Acc: 13.3281\n",
      " |~~ val@3968  Loss: 0.002133 Acc: 13.3906\n",
      " |~~ val@4032  Loss: 0.003176 Acc: 12.8906\n",
      " |~~ val@4096  Loss: 0.003002 Acc: 13.1094\n",
      " |~~ val@4160  Loss: 0.003027 Acc: 13.0938\n",
      " |~~ val@4224  Loss: 0.002196 Acc: 13.4688\n",
      " |~~ val@4288  Loss: 0.002228 Acc: 13.2500\n",
      " |~~ val@4352  Loss: 0.002261 Acc: 13.2500\n",
      " |~~ val@4416  Loss: 0.002314 Acc: 13.2500\n",
      " |~~ val@4480  Loss: 0.002415 Acc: 13.2656\n",
      " |~~ val@4544  Loss: 0.002321 Acc: 13.2500\n",
      " |~~ val@4608  Loss: 0.001891 Acc: 13.5156\n",
      " |~~ val@4672  Loss: 0.002558 Acc: 13.2500\n",
      " |~~ val@4736  Loss: 0.002842 Acc: 13.1875\n",
      " |~~ val@4800  Loss: 0.002282 Acc: 13.3750\n",
      " |~~ val@4864  Loss: 0.001936 Acc: 13.4531\n",
      " |~~ val@4928  Loss: 0.002682 Acc: 13.0938\n",
      " |~~ val@4992  Loss: 0.002769 Acc: 13.1875\n",
      " |~~ val@5056  Loss: 0.003307 Acc: 12.9844\n",
      " |~~ val@5120  Loss: 0.002302 Acc: 13.2812\n",
      " |~~ val@5184  Loss: 0.003372 Acc: 13.0625\n",
      " |~~ val@5248  Loss: 0.002528 Acc: 13.2656\n",
      " |~~ val@5312  Loss: 0.002763 Acc: 13.1562\n",
      " |~~ val@5376  Loss: 0.002343 Acc: 13.2812\n",
      " |~~ val@5440  Loss: 0.003221 Acc: 13.0000\n",
      " |~~ val@5504  Loss: 0.002785 Acc: 13.2031\n",
      " |~~ val@5568  Loss: 0.002102 Acc: 13.4375\n",
      " |~~ val@5632  Loss: 0.002758 Acc: 13.2344\n",
      " |~~ val@5696  Loss: 0.002462 Acc: 13.2344\n",
      " |~~ val@5760  Loss: 0.002127 Acc: 13.2969\n",
      " |~~ val@5824  Loss: 0.002458 Acc: 13.3125\n",
      " |~~ val@5888  Loss: 0.002807 Acc: 13.2500\n",
      " |~~ val@5952  Loss: 0.002163 Acc: 13.3438\n",
      " |~~ val@6016  Loss: 0.002377 Acc: 13.2188\n",
      " |~~ val@6080  Loss: 0.002187 Acc: 13.3281\n",
      " |~~ val@6144  Loss: 0.003024 Acc: 13.1562\n",
      " |~~ val@6208  Loss: 0.002335 Acc: 13.2344\n",
      " |~~ val@6272  Loss: 0.002540 Acc: 13.2812\n",
      " |~~ val@6336  Loss: 0.002124 Acc: 13.3438\n",
      " |~~ val@6400  Loss: 0.002293 Acc: 13.4062\n",
      " |~~ val@6464  Loss: 0.002221 Acc: 13.3125\n",
      " |~~ val@6528  Loss: 0.002003 Acc: 13.3594\n",
      " |~~ val@6592  Loss: 0.002664 Acc: 13.1719\n",
      " |~~ val@6656  Loss: 0.002927 Acc: 13.0469\n",
      " |~~ val@6720  Loss: 0.002947 Acc: 13.1094\n",
      " |~~ val@6784  Loss: 0.002101 Acc: 13.2969\n",
      " |~~ val@6848  Loss: 0.002249 Acc: 13.3281\n",
      " |~~ val@6912  Loss: 0.002552 Acc: 13.3438\n",
      " |~~ val@6976  Loss: 0.001584 Acc: 13.4844\n",
      " |~~ val@7040  Loss: 0.001986 Acc: 13.3750\n",
      " |~~ val@7104  Loss: 0.002576 Acc: 13.1875\n",
      " |~~ val@7168  Loss: 0.002609 Acc: 13.2344\n",
      " |~~ val@7232  Loss: 0.001915 Acc: 13.5000\n",
      " |~~ val@7296  Loss: 0.002706 Acc: 13.2969\n",
      " |~~ val@7360  Loss: 0.001894 Acc: 13.4062\n",
      " |~~ val@7424  Loss: 0.002492 Acc: 13.2344\n",
      " |~~ val@7488  Loss: 0.002695 Acc: 13.1719\n",
      " |~~ val@7552  Loss: 0.002631 Acc: 13.2188\n",
      " |~~ val@7616  Loss: 0.002094 Acc: 13.3594\n",
      " |~~ val@7680  Loss: 0.002682 Acc: 13.2344\n",
      " |~~ val@7744  Loss: 0.002230 Acc: 13.3281\n",
      " |~~ val@7808  Loss: 0.002235 Acc: 13.3281\n",
      " |~~ val@7872  Loss: 0.002028 Acc: 13.2656\n",
      " |~~ val@7936  Loss: 0.001812 Acc: 13.5312\n",
      " |~~ val@8000  Loss: 0.002270 Acc: 13.2500\n",
      " |~~ val@8064  Loss: 0.002143 Acc: 13.3750\n",
      " |~~ val@8128  Loss: 0.001844 Acc: 13.4375\n",
      " |~~ val@8192  Loss: 0.002719 Acc: 13.1719\n",
      " |~~ val@8256  Loss: 0.002363 Acc: 13.2656\n",
      " |~~ val@8320  Loss: 0.001968 Acc: 13.3906\n",
      " |~~ val@8384  Loss: 0.002976 Acc: 13.0469\n",
      " |~~ val@8448  Loss: 0.002110 Acc: 13.3438\n",
      " |~~ val@8512  Loss: 0.002922 Acc: 13.0625\n",
      " |~~ val@8576  Loss: 0.002652 Acc: 13.2344\n",
      " |~~ val@8640  Loss: 0.002271 Acc: 13.3594\n",
      " |~~ val@8704  Loss: 0.002379 Acc: 13.2344\n",
      " |~~ val@8768  Loss: 0.002334 Acc: 13.3750\n",
      " |~~ val@8832  Loss: 0.002520 Acc: 13.2031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@8896  Loss: 0.002239 Acc: 13.3906\n",
      " |~~ val@8960  Loss: 0.002428 Acc: 13.2031\n",
      " |~~ val@9024  Loss: 0.002369 Acc: 13.3125\n",
      " |~~ val@9088  Loss: 0.002833 Acc: 13.1875\n",
      " |~~ val@9152  Loss: 0.002601 Acc: 13.2031\n",
      " |~~ val@9216  Loss: 0.002566 Acc: 13.3438\n",
      " |~~ val@9280  Loss: 0.002618 Acc: 13.0469\n",
      " |~~ val@9344  Loss: 0.002132 Acc: 13.3906\n",
      " |~~ val@9408  Loss: 0.001995 Acc: 13.4688\n",
      " |~~ val@9472  Loss: 0.002271 Acc: 13.2812\n",
      " |~~ val@9536  Loss: 0.002230 Acc: 13.3438\n",
      " |~~ val@9600  Loss: 0.003160 Acc: 13.0469\n",
      " |~~ val@9664  Loss: 0.002044 Acc: 13.3750\n",
      " |~~ val@9728  Loss: 0.002299 Acc: 13.3750\n",
      " |~~ val@9792  Loss: 0.002533 Acc: 13.2031\n",
      " |~~ val@9856  Loss: 0.002816 Acc: 13.1094\n",
      " |~~ val@9920  Loss: 0.002666 Acc: 13.1094\n",
      " |~~ val@9984  Loss: 0.001797 Acc: 13.5156\n",
      " |~~ val@10048  Loss: 0.002401 Acc: 13.3281\n",
      " |~~ val@10112  Loss: 0.002193 Acc: 13.3906\n",
      " |~~ val@10176  Loss: 0.001989 Acc: 13.4375\n",
      " |~~ val@10240  Loss: 0.001964 Acc: 13.4688\n",
      " |~~ val@10304  Loss: 0.001862 Acc: 13.4688\n",
      " |~~ val@10368  Loss: 0.002685 Acc: 13.1094\n",
      " |~~ val@10432  Loss: 0.002719 Acc: 13.1875\n",
      " |~~ val@10496  Loss: 0.002265 Acc: 13.3438\n",
      " |~~ val@10560  Loss: 0.001690 Acc: 13.5625\n",
      " |~~ val@10624  Loss: 0.002012 Acc: 13.4375\n",
      " |~~ val@10688  Loss: 0.002478 Acc: 13.2344\n",
      " |~~ val@10752  Loss: 0.001947 Acc: 13.4531\n",
      " |~~ val@10816  Loss: 0.002245 Acc: 13.2812\n",
      " |~~ val@10880  Loss: 0.002152 Acc: 13.4375\n",
      " |~~ val@10944  Loss: 0.002013 Acc: 13.3750\n",
      " |~~ val@11008  Loss: 0.002085 Acc: 13.4375\n",
      " |~~ val@11072  Loss: 0.002721 Acc: 13.2812\n",
      " |~~ val@11136  Loss: 0.001720 Acc: 13.5156\n",
      " |~~ val@11200  Loss: 0.002204 Acc: 13.3281\n",
      " |~~ val@11264  Loss: 0.002392 Acc: 13.2812\n",
      " |~~ val@11328  Loss: 0.001830 Acc: 13.3906\n",
      " |~~ val@11392  Loss: 0.003004 Acc: 13.1094\n",
      " |~~ val@11456  Loss: 0.002652 Acc: 13.2500\n",
      " |~~ val@11520  Loss: 0.002353 Acc: 13.3281\n",
      " |~~ val@11584  Loss: 0.001975 Acc: 13.3906\n",
      " |~~ val@11648  Loss: 0.002428 Acc: 13.2812\n",
      " |~~ val@11712  Loss: 0.002449 Acc: 13.1875\n",
      " |~~ val@11776  Loss: 0.002009 Acc: 13.3750\n",
      " |~~ val@11840  Loss: 0.002271 Acc: 13.3281\n",
      " |~~ val@11904  Loss: 0.002791 Acc: 13.1875\n",
      " |~~ val@11968  Loss: 0.002601 Acc: 13.3594\n",
      " |~~ val@12032  Loss: 0.002305 Acc: 13.2500\n",
      " |~~ val@12096  Loss: 0.001961 Acc: 13.4688\n",
      " |~~ val@12160  Loss: 0.002494 Acc: 13.2188\n",
      " |~~ val@12224  Loss: 0.002582 Acc: 13.2344\n",
      " |~~ val@12288  Loss: 0.002104 Acc: 13.3125\n",
      " |~~ val@12352  Loss: 0.002158 Acc: 13.3438\n",
      " |~~ val@12416  Loss: 0.002477 Acc: 13.2031\n",
      " |~~ val@12480  Loss: 0.002171 Acc: 13.3125\n",
      " |~~ val@12544  Loss: 0.002231 Acc: 13.3281\n",
      " |~~ val@12608  Loss: 0.002720 Acc: 13.1094\n",
      " |~~ val@12672  Loss: 0.002370 Acc: 13.3281\n",
      " |~~ val@12736  Loss: 0.002252 Acc: 13.3125\n",
      " |~~ val@12800  Loss: 0.002098 Acc: 13.3594\n",
      " |~~ val@12864  Loss: 0.002403 Acc: 13.2656\n",
      " |~~ val@12928  Loss: 0.002679 Acc: 13.3750\n",
      " |~~ val@12992  Loss: 0.002619 Acc: 13.2188\n",
      " |~~ val@13056  Loss: 0.001892 Acc: 13.4375\n",
      " |~~ val@13120  Loss: 0.002439 Acc: 13.1406\n",
      " |~~ val@13184  Loss: 0.002711 Acc: 13.2344\n",
      " |~~ val@13248  Loss: 0.002449 Acc: 13.3125\n",
      " |~~ val@13312  Loss: 0.002470 Acc: 13.3125\n",
      " |~~ val@13376  Loss: 0.002352 Acc: 13.3125\n",
      " |~~ val@13440  Loss: 0.002571 Acc: 13.1719\n",
      " |~~ val@13504  Loss: 0.002310 Acc: 13.3281\n",
      " |~~ val@13568  Loss: 0.002132 Acc: 13.2500\n",
      " |~~ val@13632  Loss: 0.002395 Acc: 13.2969\n",
      " |~~ val@13696  Loss: 0.002595 Acc: 13.1875\n",
      " |~~ val@13760  Loss: 0.002260 Acc: 13.3438\n",
      " |~~ val@13824  Loss: 0.002432 Acc: 13.2031\n",
      " |~~ val@13888  Loss: 0.002461 Acc: 13.2344\n",
      " |~~ val@13952  Loss: 0.002565 Acc: 13.3125\n",
      " |~~ val@14016  Loss: 0.002731 Acc: 13.1406\n",
      " |~~ val@14080  Loss: 0.002369 Acc: 13.2188\n",
      " |~~ val@14144  Loss: 0.002381 Acc: 13.2031\n",
      " |~~ val@14208  Loss: 0.003176 Acc: 13.0938\n",
      " |~~ val@14272  Loss: 0.002642 Acc: 13.2656\n",
      " |~~ val@14336  Loss: 0.002330 Acc: 13.3438\n",
      " |~~ val@14400  Loss: 0.001966 Acc: 13.4062\n",
      " |~~ val@14464  Loss: 0.002604 Acc: 13.1719\n",
      " |~~ val@14528  Loss: 0.001935 Acc: 13.3750\n",
      " |~~ val@14592  Loss: 0.002210 Acc: 13.3594\n",
      " |~~ val@14656  Loss: 0.002356 Acc: 13.2812\n",
      " |~~ val@14720  Loss: 0.003111 Acc: 13.1719\n",
      " |~~ val@14784  Loss: 0.002044 Acc: 13.3594\n",
      " |~~ val@14848  Loss: 0.002495 Acc: 13.2500\n",
      " |~~ val@14912  Loss: 0.001977 Acc: 13.3594\n",
      " |~~ val@14976  Loss: 0.002631 Acc: 13.2344\n",
      " |~~ val@15040  Loss: 0.001964 Acc: 13.3438\n",
      " |~~ val@15104  Loss: 0.002418 Acc: 13.2969\n",
      " |~~ val@15168  Loss: 0.002751 Acc: 13.2188\n",
      " |~~ val@15232  Loss: 0.002168 Acc: 13.2500\n",
      " |~~ val@15296  Loss: 0.002164 Acc: 13.3594\n",
      " |~~ val@15360  Loss: 0.002422 Acc: 13.3438\n",
      " |~~ val@15424  Loss: 0.002703 Acc: 13.2500\n",
      " |~~ val@15488  Loss: 0.002199 Acc: 13.4375\n",
      " |~~ val@15552  Loss: 0.002072 Acc: 13.3125\n",
      " |~~ val@15616  Loss: 0.002536 Acc: 13.1406\n",
      " |~~ val@15680  Loss: 0.002542 Acc: 13.2188\n",
      " |~~ val@15744  Loss: 0.002239 Acc: 13.3594\n",
      " |~~ val@15808  Loss: 0.002671 Acc: 13.2344\n",
      " |~~ val@15872  Loss: 0.002710 Acc: 13.2656\n",
      " |~~ val@15936  Loss: 0.002054 Acc: 13.4844\n",
      " |~~ val@16000  Loss: 0.002486 Acc: 13.3281\n",
      " |~~ val@16064  Loss: 0.003023 Acc: 12.9531\n",
      " |~~ val@16128  Loss: 0.001926 Acc: 13.3750\n",
      " |~~ val@16192  Loss: 0.002673 Acc: 13.1250\n",
      " |~~ val@16256  Loss: 0.002064 Acc: 13.3594\n",
      " |~~ val@16320  Loss: 0.002361 Acc: 13.1875\n",
      " |~~ val@16384  Loss: 0.002487 Acc: 13.1875\n",
      " |~~ val@16448  Loss: 0.002545 Acc: 13.1875\n",
      " |~~ val@16512  Loss: 0.002532 Acc: 13.1719\n",
      " |~~ val@16576  Loss: 0.002457 Acc: 13.1719\n",
      " |~~ val@16640  Loss: 0.002722 Acc: 13.0469\n",
      " |~~ val@16704  Loss: 0.003133 Acc: 13.1094\n",
      " |~~ val@16768  Loss: 0.002193 Acc: 13.3438\n",
      " |~~ val@16832  Loss: 0.002307 Acc: 13.2812\n",
      " |~~ val@16896  Loss: 0.001783 Acc: 13.4531\n",
      " |~~ val@16960  Loss: 0.002414 Acc: 13.2656\n",
      " |~~ val@17024  Loss: 0.001960 Acc: 13.4062\n",
      " |~~ val@17088  Loss: 0.002719 Acc: 13.1562\n",
      " |~~ val@17152  Loss: 0.002556 Acc: 13.1875\n",
      " |~~ val@17216  Loss: 0.002598 Acc: 13.2188\n",
      " |~~ val@17280  Loss: 0.002589 Acc: 13.1719\n",
      " |~~ val@17344  Loss: 0.002418 Acc: 13.2969\n",
      " |~~ val@17408  Loss: 0.001838 Acc: 13.4062\n",
      " |~~ val@17472  Loss: 0.002253 Acc: 13.3281\n",
      " |~~ val@17536  Loss: 0.001971 Acc: 13.3594\n",
      " |~~ val@17600  Loss: 0.002827 Acc: 13.0156\n",
      " |~~ val@17664  Loss: 0.002389 Acc: 13.2031\n",
      " |~~ val@17728  Loss: 0.002015 Acc: 13.4375\n",
      " |~~ val@17792  Loss: 0.002668 Acc: 13.1250\n",
      " |~~ val@17856  Loss: 0.002478 Acc: 13.3281\n",
      " |~~ val@17920  Loss: 0.002618 Acc: 13.2656\n",
      " |~~ val@17984  Loss: 0.002513 Acc: 13.2188\n",
      " |~~ val@18048  Loss: 0.002085 Acc: 13.3438\n",
      " |~~ val@18112  Loss: 0.001675 Acc: 13.5000\n",
      " |~~ val@18176  Loss: 0.002227 Acc: 13.2656\n",
      " |~~ val@18240  Loss: 0.002659 Acc: 13.2344\n",
      " |~~ val@18304  Loss: 0.002821 Acc: 13.0781\n",
      " |~~ val@18368  Loss: 0.002528 Acc: 13.1719\n",
      " |~~ val@18432  Loss: 0.002349 Acc: 13.2188\n",
      " |~~ val@18496  Loss: 0.002083 Acc: 13.3281\n",
      " |~~ val@18560  Loss: 0.001996 Acc: 13.4531\n",
      " |~~ val@18624  Loss: 0.002119 Acc: 13.2188\n",
      " |~~ val@18688  Loss: 0.002053 Acc: 13.2969\n",
      " |~~ val@18752  Loss: 0.001889 Acc: 13.4062\n",
      " |~~ val@18816  Loss: 0.002237 Acc: 13.2812\n",
      " |~~ val@18880  Loss: 0.002635 Acc: 13.1875\n",
      " |~~ val@18944  Loss: 0.002463 Acc: 13.3125\n",
      " |~~ val@19008  Loss: 0.002448 Acc: 13.2031\n",
      " |~~ val@19072  Loss: 0.002673 Acc: 13.2188\n",
      " |~~ val@19136  Loss: 0.002553 Acc: 13.1719\n",
      " |~~ val@19200  Loss: 0.002232 Acc: 13.3750\n",
      " |~~ val@19264  Loss: 0.001898 Acc: 13.3281\n",
      " |~~ val@19328  Loss: 0.002352 Acc: 13.1719\n",
      " |~~ val@19392  Loss: 0.002071 Acc: 13.4219\n",
      " |~~ val@19456  Loss: 0.002020 Acc: 13.3594\n",
      " |~~ val@19520  Loss: 0.002290 Acc: 13.2500\n",
      " |~~ val@19584  Loss: 0.002521 Acc: 13.2812\n",
      " |~~ val@19648  Loss: 0.001905 Acc: 13.5000\n",
      " |~~ val@19712  Loss: 0.002775 Acc: 13.0938\n",
      " |~~ val@19776  Loss: 0.001902 Acc: 13.4219\n",
      " |~~ val@19840  Loss: 0.002572 Acc: 13.3438\n",
      " |~~ val@19904  Loss: 0.002360 Acc: 13.2500\n",
      " |~~ val@19968  Loss: 0.002283 Acc: 13.2969\n",
      " |~~ val@20032  Loss: 0.002657 Acc: 13.2188\n",
      " |~~ val@20096  Loss: 0.002628 Acc: 13.2031\n",
      " |~~ val@20160  Loss: 0.003064 Acc: 13.1562\n",
      " |~~ val@20224  Loss: 0.003051 Acc: 13.1094\n",
      " |~~ val@20288  Loss: 0.002295 Acc: 13.4062\n",
      " |~~ val@20352  Loss: 0.002162 Acc: 13.3281\n",
      " |~~ val@20416  Loss: 0.002516 Acc: 13.2188\n",
      " |~~ val@20480  Loss: 0.002177 Acc: 13.3281\n",
      " |~~ val@20544  Loss: 0.001997 Acc: 13.3906\n",
      " |~~ val@20608  Loss: 0.002462 Acc: 13.1719\n",
      " |~~ val@20672  Loss: 0.002202 Acc: 13.3906\n",
      " |~~ val@20736  Loss: 0.002619 Acc: 13.1875\n",
      " |~~ val@20800  Loss: 0.002645 Acc: 13.2656\n",
      " |~~ val@20864  Loss: 0.002569 Acc: 13.2344\n",
      " |~~ val@20928  Loss: 0.002122 Acc: 13.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@20992  Loss: 0.002971 Acc: 13.1094\n",
      " |~~ val@21056  Loss: 0.002370 Acc: 13.2344\n",
      " |~~ val@21120  Loss: 0.002438 Acc: 13.3125\n",
      " |~~ val@21184  Loss: 0.002499 Acc: 13.1719\n",
      " |~~ val@21248  Loss: 0.002252 Acc: 13.2812\n",
      " |~~ val@21312  Loss: 0.002359 Acc: 13.3750\n",
      " |~~ val@21376  Loss: 0.002413 Acc: 13.1875\n",
      " |~~ val@21440  Loss: 0.002218 Acc: 13.3125\n",
      " |~~ val@21504  Loss: 0.002282 Acc: 13.2188\n",
      " |~~ val@21568  Loss: 0.002416 Acc: 13.2656\n",
      " |~~ val@21632  Loss: 0.002565 Acc: 13.2656\n",
      " |~~ val@21696  Loss: 0.001822 Acc: 13.5156\n",
      " |~~ val@21760  Loss: 0.002162 Acc: 13.2812\n",
      " |~~ val@21824  Loss: 0.001629 Acc: 13.5000\n",
      " |~~ val@21888  Loss: 0.002569 Acc: 13.1719\n",
      " |~~ val@21952  Loss: 0.002377 Acc: 13.3594\n",
      " |~~ val@22016  Loss: 0.002971 Acc: 13.0781\n",
      " |~~ val@22080  Loss: 0.001957 Acc: 13.4219\n",
      " |~~ val@22144  Loss: 0.002743 Acc: 13.1406\n",
      " |~~ val@22208  Loss: 0.001825 Acc: 13.5312\n",
      " |~~ val@22272  Loss: 0.001681 Acc: 13.4375\n",
      " |~~ val@22336  Loss: 0.002327 Acc: 13.3438\n",
      " |~~ val@22400  Loss: 0.002431 Acc: 13.2969\n",
      " |~~ val@22424  Loss: 0.005391 Acc: 13.3333\n",
      "val  Loss: 0.002377 Acc: 13.2811\n",
      "Epoch 9/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.001965 Acc: 13.3438\n",
      " |~~ train@128  Loss: 0.002080 Acc: 13.2344\n",
      " |~~ train@192  Loss: 0.002426 Acc: 13.1719\n",
      " |~~ train@256  Loss: 0.002379 Acc: 13.2500\n",
      " |~~ train@320  Loss: 0.002226 Acc: 13.2344\n",
      " |~~ train@384  Loss: 0.001892 Acc: 13.4219\n",
      " |~~ train@448  Loss: 0.002198 Acc: 13.3125\n",
      " |~~ train@512  Loss: 0.001616 Acc: 13.4844\n",
      " |~~ train@576  Loss: 0.001927 Acc: 13.3750\n",
      " |~~ train@640  Loss: 0.002333 Acc: 13.1562\n",
      " |~~ train@704  Loss: 0.001822 Acc: 13.4062\n",
      " |~~ train@768  Loss: 0.002205 Acc: 13.2500\n",
      " |~~ train@832  Loss: 0.002200 Acc: 13.2812\n",
      " |~~ train@896  Loss: 0.001918 Acc: 13.4219\n",
      " |~~ train@960  Loss: 0.002005 Acc: 13.3125\n",
      " |~~ train@1024  Loss: 0.001969 Acc: 13.3594\n",
      " |~~ train@1088  Loss: 0.001733 Acc: 13.4219\n",
      " |~~ train@1152  Loss: 0.001938 Acc: 13.4062\n",
      " |~~ train@1216  Loss: 0.001900 Acc: 13.3906\n",
      " |~~ train@1280  Loss: 0.001285 Acc: 13.6250\n",
      " |~~ train@1344  Loss: 0.002235 Acc: 13.2500\n",
      " |~~ train@1408  Loss: 0.001931 Acc: 13.2969\n",
      " |~~ train@1472  Loss: 0.002261 Acc: 13.2656\n",
      " |~~ train@1536  Loss: 0.001865 Acc: 13.4688\n",
      " |~~ train@1600  Loss: 0.001839 Acc: 13.2656\n",
      " |~~ train@1664  Loss: 0.001606 Acc: 13.4219\n",
      " |~~ train@1728  Loss: 0.001817 Acc: 13.4062\n",
      " |~~ train@1792  Loss: 0.001718 Acc: 13.4844\n",
      " |~~ train@1856  Loss: 0.002018 Acc: 13.3906\n",
      " |~~ train@1920  Loss: 0.001802 Acc: 13.4062\n",
      " |~~ train@1984  Loss: 0.002004 Acc: 13.3906\n",
      " |~~ train@2048  Loss: 0.002321 Acc: 13.1250\n",
      " |~~ train@2112  Loss: 0.002365 Acc: 13.2969\n",
      " |~~ train@2176  Loss: 0.002440 Acc: 13.1406\n",
      " |~~ train@2240  Loss: 0.002007 Acc: 13.3281\n",
      " |~~ train@2304  Loss: 0.002100 Acc: 13.2656\n",
      " |~~ train@2368  Loss: 0.001624 Acc: 13.4688\n",
      " |~~ train@2432  Loss: 0.001957 Acc: 13.3438\n",
      " |~~ train@2496  Loss: 0.002049 Acc: 13.2969\n",
      " |~~ train@2560  Loss: 0.002295 Acc: 13.3438\n",
      " |~~ train@2624  Loss: 0.001809 Acc: 13.4531\n",
      " |~~ train@2688  Loss: 0.001972 Acc: 13.3750\n",
      " |~~ train@2752  Loss: 0.001702 Acc: 13.4375\n",
      " |~~ train@2816  Loss: 0.002474 Acc: 13.1562\n",
      " |~~ train@2880  Loss: 0.002013 Acc: 13.3906\n",
      " |~~ train@2944  Loss: 0.001736 Acc: 13.4062\n",
      " |~~ train@3008  Loss: 0.001823 Acc: 13.4062\n",
      " |~~ train@3072  Loss: 0.002033 Acc: 13.2969\n",
      " |~~ train@3136  Loss: 0.001967 Acc: 13.4688\n",
      " |~~ train@3200  Loss: 0.002131 Acc: 13.3125\n",
      " |~~ train@3264  Loss: 0.002022 Acc: 13.3594\n",
      " |~~ train@3328  Loss: 0.002270 Acc: 13.2188\n",
      " |~~ train@3392  Loss: 0.001619 Acc: 13.4219\n",
      " |~~ train@3456  Loss: 0.001594 Acc: 13.5000\n",
      " |~~ train@3520  Loss: 0.002457 Acc: 13.2969\n",
      " |~~ train@3584  Loss: 0.002233 Acc: 13.2031\n",
      " |~~ train@3648  Loss: 0.001893 Acc: 13.3594\n",
      " |~~ train@3712  Loss: 0.001904 Acc: 13.4062\n",
      " |~~ train@3776  Loss: 0.002485 Acc: 13.2031\n",
      " |~~ train@3840  Loss: 0.001647 Acc: 13.5625\n",
      " |~~ train@3904  Loss: 0.001593 Acc: 13.5781\n",
      " |~~ train@3968  Loss: 0.002199 Acc: 13.3125\n",
      " |~~ train@4032  Loss: 0.001939 Acc: 13.4375\n",
      " |~~ train@4096  Loss: 0.001744 Acc: 13.5156\n",
      " |~~ train@4160  Loss: 0.001363 Acc: 13.5312\n",
      " |~~ train@4224  Loss: 0.001894 Acc: 13.4219\n",
      " |~~ train@4288  Loss: 0.001802 Acc: 13.3750\n",
      " |~~ train@4352  Loss: 0.001825 Acc: 13.4375\n",
      " |~~ train@4416  Loss: 0.002172 Acc: 13.2812\n",
      " |~~ train@4480  Loss: 0.002109 Acc: 13.2812\n",
      " |~~ train@4544  Loss: 0.001678 Acc: 13.4844\n",
      " |~~ train@4608  Loss: 0.001763 Acc: 13.3906\n",
      " |~~ train@4672  Loss: 0.001797 Acc: 13.4844\n",
      " |~~ train@4736  Loss: 0.001707 Acc: 13.5156\n",
      " |~~ train@4800  Loss: 0.001955 Acc: 13.2344\n",
      " |~~ train@4864  Loss: 0.001911 Acc: 13.4688\n",
      " |~~ train@4928  Loss: 0.002351 Acc: 13.1875\n",
      " |~~ train@4992  Loss: 0.001787 Acc: 13.4531\n",
      " |~~ train@5056  Loss: 0.001717 Acc: 13.4688\n",
      " |~~ train@5120  Loss: 0.002160 Acc: 13.2344\n",
      " |~~ train@5184  Loss: 0.002128 Acc: 13.3125\n",
      " |~~ train@5248  Loss: 0.002051 Acc: 13.2969\n",
      " |~~ train@5312  Loss: 0.002602 Acc: 13.0625\n",
      " |~~ train@5376  Loss: 0.002481 Acc: 13.2188\n",
      " |~~ train@5440  Loss: 0.001895 Acc: 13.4375\n",
      " |~~ train@5504  Loss: 0.002149 Acc: 13.3281\n",
      " |~~ train@5568  Loss: 0.002893 Acc: 13.0469\n",
      " |~~ train@5632  Loss: 0.001877 Acc: 13.3750\n",
      " |~~ train@5696  Loss: 0.001890 Acc: 13.4531\n",
      " |~~ train@5760  Loss: 0.002094 Acc: 13.2344\n",
      " |~~ train@5824  Loss: 0.001765 Acc: 13.4062\n",
      " |~~ train@5888  Loss: 0.002400 Acc: 13.2031\n",
      " |~~ train@5952  Loss: 0.003027 Acc: 13.0156\n",
      " |~~ train@6016  Loss: 0.002030 Acc: 13.3594\n",
      " |~~ train@6080  Loss: 0.002205 Acc: 13.2188\n",
      " |~~ train@6144  Loss: 0.001703 Acc: 13.4844\n",
      " |~~ train@6208  Loss: 0.001887 Acc: 13.3750\n",
      " |~~ train@6272  Loss: 0.001979 Acc: 13.3281\n",
      " |~~ train@6336  Loss: 0.001648 Acc: 13.4375\n",
      " |~~ train@6400  Loss: 0.002095 Acc: 13.3281\n",
      " |~~ train@6464  Loss: 0.001968 Acc: 13.3594\n",
      " |~~ train@6528  Loss: 0.001864 Acc: 13.4062\n",
      " |~~ train@6592  Loss: 0.002612 Acc: 13.1719\n",
      " |~~ train@6656  Loss: 0.002338 Acc: 13.2188\n",
      " |~~ train@6720  Loss: 0.001850 Acc: 13.3906\n",
      " |~~ train@6784  Loss: 0.001582 Acc: 13.4531\n",
      " |~~ train@6848  Loss: 0.001814 Acc: 13.4375\n",
      " |~~ train@6912  Loss: 0.002235 Acc: 13.3438\n",
      " |~~ train@6976  Loss: 0.002180 Acc: 13.3281\n",
      " |~~ train@7040  Loss: 0.002004 Acc: 13.3438\n",
      " |~~ train@7104  Loss: 0.001896 Acc: 13.3125\n",
      " |~~ train@7168  Loss: 0.002237 Acc: 13.3281\n",
      " |~~ train@7232  Loss: 0.001851 Acc: 13.3906\n",
      " |~~ train@7296  Loss: 0.002242 Acc: 13.2344\n",
      " |~~ train@7360  Loss: 0.002008 Acc: 13.3750\n",
      " |~~ train@7424  Loss: 0.002233 Acc: 13.2656\n",
      " |~~ train@7488  Loss: 0.002370 Acc: 13.2500\n",
      " |~~ train@7552  Loss: 0.001897 Acc: 13.3125\n",
      " |~~ train@7616  Loss: 0.001758 Acc: 13.4375\n",
      " |~~ train@7680  Loss: 0.001917 Acc: 13.3594\n",
      " |~~ train@7744  Loss: 0.002304 Acc: 13.2031\n",
      " |~~ train@7808  Loss: 0.002037 Acc: 13.2500\n",
      " |~~ train@7872  Loss: 0.002003 Acc: 13.3438\n",
      " |~~ train@7936  Loss: 0.001857 Acc: 13.3594\n",
      " |~~ train@8000  Loss: 0.002028 Acc: 13.3438\n",
      " |~~ train@8064  Loss: 0.001954 Acc: 13.4062\n",
      " |~~ train@8128  Loss: 0.001877 Acc: 13.4219\n",
      " |~~ train@8192  Loss: 0.002139 Acc: 13.2500\n",
      " |~~ train@8256  Loss: 0.002038 Acc: 13.3750\n",
      " |~~ train@8320  Loss: 0.001755 Acc: 13.3906\n",
      " |~~ train@8384  Loss: 0.001444 Acc: 13.6406\n",
      " |~~ train@8448  Loss: 0.001878 Acc: 13.3750\n",
      " |~~ train@8512  Loss: 0.001932 Acc: 13.4375\n",
      " |~~ train@8576  Loss: 0.001660 Acc: 13.4688\n",
      " |~~ train@8640  Loss: 0.001695 Acc: 13.5625\n",
      " |~~ train@8704  Loss: 0.002435 Acc: 13.2812\n",
      " |~~ train@8768  Loss: 0.002522 Acc: 13.2344\n",
      " |~~ train@8832  Loss: 0.002255 Acc: 13.3125\n",
      " |~~ train@8896  Loss: 0.001574 Acc: 13.4375\n",
      " |~~ train@8960  Loss: 0.002101 Acc: 13.3281\n",
      " |~~ train@9024  Loss: 0.001531 Acc: 13.5000\n",
      " |~~ train@9088  Loss: 0.001907 Acc: 13.3906\n",
      " |~~ train@9152  Loss: 0.001757 Acc: 13.4219\n",
      " |~~ train@9216  Loss: 0.001946 Acc: 13.2656\n",
      " |~~ train@9280  Loss: 0.001888 Acc: 13.3750\n",
      " |~~ train@9344  Loss: 0.001851 Acc: 13.3906\n",
      " |~~ train@9408  Loss: 0.002240 Acc: 13.3281\n",
      " |~~ train@9472  Loss: 0.002305 Acc: 13.3281\n",
      " |~~ train@9536  Loss: 0.001978 Acc: 13.2969\n",
      " |~~ train@9600  Loss: 0.002254 Acc: 13.2656\n",
      " |~~ train@9664  Loss: 0.002176 Acc: 13.2969\n",
      " |~~ train@9728  Loss: 0.001943 Acc: 13.3125\n",
      " |~~ train@9792  Loss: 0.001617 Acc: 13.4688\n",
      " |~~ train@9856  Loss: 0.001638 Acc: 13.5156\n",
      " |~~ train@9920  Loss: 0.001723 Acc: 13.4531\n",
      " |~~ train@9984  Loss: 0.002265 Acc: 13.2656\n",
      " |~~ train@10048  Loss: 0.001500 Acc: 13.5469\n",
      " |~~ train@10112  Loss: 0.001703 Acc: 13.3906\n",
      " |~~ train@10176  Loss: 0.001932 Acc: 13.4531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@10240  Loss: 0.002053 Acc: 13.2969\n",
      " |~~ train@10304  Loss: 0.001930 Acc: 13.3438\n",
      " |~~ train@10368  Loss: 0.001746 Acc: 13.4375\n",
      " |~~ train@10432  Loss: 0.001897 Acc: 13.4375\n",
      " |~~ train@10496  Loss: 0.002065 Acc: 13.3594\n",
      " |~~ train@10560  Loss: 0.001935 Acc: 13.4375\n",
      " |~~ train@10624  Loss: 0.001839 Acc: 13.4219\n",
      " |~~ train@10688  Loss: 0.002277 Acc: 13.2031\n",
      " |~~ train@10752  Loss: 0.002411 Acc: 13.1875\n",
      " |~~ train@10816  Loss: 0.002220 Acc: 13.2812\n",
      " |~~ train@10880  Loss: 0.002523 Acc: 13.1406\n",
      " |~~ train@10944  Loss: 0.002328 Acc: 13.1250\n",
      " |~~ train@11008  Loss: 0.002110 Acc: 13.4375\n",
      " |~~ train@11072  Loss: 0.002220 Acc: 13.3281\n",
      " |~~ train@11136  Loss: 0.002285 Acc: 13.2812\n",
      " |~~ train@11200  Loss: 0.001805 Acc: 13.4062\n",
      " |~~ train@11264  Loss: 0.001952 Acc: 13.3438\n",
      " |~~ train@11328  Loss: 0.001674 Acc: 13.4688\n",
      " |~~ train@11392  Loss: 0.001704 Acc: 13.4062\n",
      " |~~ train@11456  Loss: 0.002402 Acc: 13.1406\n",
      " |~~ train@11520  Loss: 0.002135 Acc: 13.3125\n",
      " |~~ train@11584  Loss: 0.001764 Acc: 13.4375\n",
      " |~~ train@11648  Loss: 0.001602 Acc: 13.5156\n",
      " |~~ train@11712  Loss: 0.002235 Acc: 13.1719\n",
      " |~~ train@11776  Loss: 0.001879 Acc: 13.4531\n",
      " |~~ train@11840  Loss: 0.001873 Acc: 13.2969\n",
      " |~~ train@11904  Loss: 0.001832 Acc: 13.5000\n",
      " |~~ train@11968  Loss: 0.002150 Acc: 13.3438\n",
      " |~~ train@12032  Loss: 0.001913 Acc: 13.4375\n",
      " |~~ train@12096  Loss: 0.001859 Acc: 13.3594\n",
      " |~~ train@12160  Loss: 0.002374 Acc: 13.2500\n",
      " |~~ train@12224  Loss: 0.001791 Acc: 13.4688\n",
      " |~~ train@12288  Loss: 0.001594 Acc: 13.5312\n",
      " |~~ train@12352  Loss: 0.001734 Acc: 13.4531\n",
      " |~~ train@12416  Loss: 0.001857 Acc: 13.3906\n",
      " |~~ train@12480  Loss: 0.001526 Acc: 13.4688\n",
      " |~~ train@12544  Loss: 0.002218 Acc: 13.2969\n",
      " |~~ train@12608  Loss: 0.002021 Acc: 13.3594\n",
      " |~~ train@12672  Loss: 0.001704 Acc: 13.4375\n",
      " |~~ train@12736  Loss: 0.002044 Acc: 13.3438\n",
      " |~~ train@12800  Loss: 0.002022 Acc: 13.3125\n",
      " |~~ train@12864  Loss: 0.001723 Acc: 13.4375\n",
      " |~~ train@12928  Loss: 0.002326 Acc: 13.1562\n",
      " |~~ train@12992  Loss: 0.002056 Acc: 13.2969\n",
      " |~~ train@13056  Loss: 0.001720 Acc: 13.4844\n",
      " |~~ train@13120  Loss: 0.002381 Acc: 13.1719\n",
      " |~~ train@13184  Loss: 0.001777 Acc: 13.3906\n",
      " |~~ train@13248  Loss: 0.002312 Acc: 13.3281\n",
      " |~~ train@13312  Loss: 0.001648 Acc: 13.6094\n",
      " |~~ train@13376  Loss: 0.001666 Acc: 13.5469\n",
      " |~~ train@13440  Loss: 0.002306 Acc: 13.2969\n",
      " |~~ train@13504  Loss: 0.002021 Acc: 13.3750\n",
      " |~~ train@13568  Loss: 0.001881 Acc: 13.4062\n",
      " |~~ train@13632  Loss: 0.001648 Acc: 13.4844\n",
      " |~~ train@13696  Loss: 0.001887 Acc: 13.4688\n",
      " |~~ train@13760  Loss: 0.002056 Acc: 13.3281\n",
      " |~~ train@13824  Loss: 0.001803 Acc: 13.5469\n",
      " |~~ train@13888  Loss: 0.001903 Acc: 13.4531\n",
      " |~~ train@13952  Loss: 0.002032 Acc: 13.3750\n",
      " |~~ train@14016  Loss: 0.002092 Acc: 13.3438\n",
      " |~~ train@14080  Loss: 0.001937 Acc: 13.3125\n",
      " |~~ train@14144  Loss: 0.002188 Acc: 13.2812\n",
      " |~~ train@14208  Loss: 0.001947 Acc: 13.4688\n",
      " |~~ train@14272  Loss: 0.002023 Acc: 13.2031\n",
      " |~~ train@14336  Loss: 0.002425 Acc: 13.2500\n",
      " |~~ train@14400  Loss: 0.001959 Acc: 13.4219\n",
      " |~~ train@14464  Loss: 0.002158 Acc: 13.3594\n",
      " |~~ train@14528  Loss: 0.002150 Acc: 13.3438\n",
      " |~~ train@14592  Loss: 0.002330 Acc: 13.2031\n",
      " |~~ train@14656  Loss: 0.001896 Acc: 13.4375\n",
      " |~~ train@14720  Loss: 0.001959 Acc: 13.4531\n",
      " |~~ train@14784  Loss: 0.002757 Acc: 13.1406\n",
      " |~~ train@14848  Loss: 0.001649 Acc: 13.4375\n",
      " |~~ train@14912  Loss: 0.001827 Acc: 13.3438\n",
      " |~~ train@14976  Loss: 0.002049 Acc: 13.3281\n",
      " |~~ train@15040  Loss: 0.001542 Acc: 13.5781\n",
      " |~~ train@15104  Loss: 0.002255 Acc: 13.2500\n",
      " |~~ train@15168  Loss: 0.001933 Acc: 13.4219\n",
      " |~~ train@15232  Loss: 0.001824 Acc: 13.3906\n",
      " |~~ train@15296  Loss: 0.001850 Acc: 13.4062\n",
      " |~~ train@15360  Loss: 0.001615 Acc: 13.4531\n",
      " |~~ train@15424  Loss: 0.001990 Acc: 13.2812\n",
      " |~~ train@15488  Loss: 0.001654 Acc: 13.5625\n",
      " |~~ train@15552  Loss: 0.001718 Acc: 13.4531\n",
      " |~~ train@15616  Loss: 0.001666 Acc: 13.5156\n",
      " |~~ train@15680  Loss: 0.001773 Acc: 13.4688\n",
      " |~~ train@15744  Loss: 0.001683 Acc: 13.3906\n",
      " |~~ train@15808  Loss: 0.001670 Acc: 13.4219\n",
      " |~~ train@15872  Loss: 0.001626 Acc: 13.4844\n",
      " |~~ train@15936  Loss: 0.002514 Acc: 13.1719\n",
      " |~~ train@16000  Loss: 0.001788 Acc: 13.4531\n",
      " |~~ train@16064  Loss: 0.002057 Acc: 13.2969\n",
      " |~~ train@16128  Loss: 0.001814 Acc: 13.4688\n",
      " |~~ train@16192  Loss: 0.002008 Acc: 13.3125\n",
      " |~~ train@16256  Loss: 0.001562 Acc: 13.5156\n",
      " |~~ train@16320  Loss: 0.001871 Acc: 13.4531\n",
      " |~~ train@16384  Loss: 0.001996 Acc: 13.3750\n",
      " |~~ train@16448  Loss: 0.002007 Acc: 13.3125\n",
      " |~~ train@16512  Loss: 0.001915 Acc: 13.3906\n",
      " |~~ train@16576  Loss: 0.002081 Acc: 13.4062\n",
      " |~~ train@16640  Loss: 0.001879 Acc: 13.4219\n",
      " |~~ train@16704  Loss: 0.002338 Acc: 13.1562\n",
      " |~~ train@16768  Loss: 0.001891 Acc: 13.3594\n",
      " |~~ train@16832  Loss: 0.001866 Acc: 13.3906\n",
      " |~~ train@16896  Loss: 0.001643 Acc: 13.5625\n",
      " |~~ train@16960  Loss: 0.001817 Acc: 13.4375\n",
      " |~~ train@17024  Loss: 0.002019 Acc: 13.2969\n",
      " |~~ train@17088  Loss: 0.002375 Acc: 13.2500\n",
      " |~~ train@17152  Loss: 0.002436 Acc: 13.1719\n",
      " |~~ train@17216  Loss: 0.001919 Acc: 13.3438\n",
      " |~~ train@17280  Loss: 0.002083 Acc: 13.3125\n",
      " |~~ train@17344  Loss: 0.001717 Acc: 13.4531\n",
      " |~~ train@17408  Loss: 0.001855 Acc: 13.4219\n",
      " |~~ train@17472  Loss: 0.002208 Acc: 13.2500\n",
      " |~~ train@17536  Loss: 0.001977 Acc: 13.4062\n",
      " |~~ train@17600  Loss: 0.002096 Acc: 13.2969\n",
      " |~~ train@17664  Loss: 0.002062 Acc: 13.2188\n",
      " |~~ train@17728  Loss: 0.002433 Acc: 13.2031\n",
      " |~~ train@17792  Loss: 0.002211 Acc: 13.2031\n",
      " |~~ train@17856  Loss: 0.002102 Acc: 13.2812\n",
      " |~~ train@17920  Loss: 0.001750 Acc: 13.4375\n",
      " |~~ train@17984  Loss: 0.002288 Acc: 13.2500\n",
      " |~~ train@18048  Loss: 0.002056 Acc: 13.2656\n",
      " |~~ train@18112  Loss: 0.002225 Acc: 13.2188\n",
      " |~~ train@18176  Loss: 0.001921 Acc: 13.3750\n",
      " |~~ train@18240  Loss: 0.002470 Acc: 13.1406\n",
      " |~~ train@18304  Loss: 0.001894 Acc: 13.3594\n",
      " |~~ train@18368  Loss: 0.001882 Acc: 13.4688\n",
      " |~~ train@18432  Loss: 0.002265 Acc: 13.2812\n",
      " |~~ train@18496  Loss: 0.001808 Acc: 13.3281\n",
      " |~~ train@18560  Loss: 0.002088 Acc: 13.2969\n",
      " |~~ train@18624  Loss: 0.001950 Acc: 13.3906\n",
      " |~~ train@18688  Loss: 0.002122 Acc: 13.4375\n",
      " |~~ train@18752  Loss: 0.002420 Acc: 13.1250\n",
      " |~~ train@18816  Loss: 0.002628 Acc: 13.1406\n",
      " |~~ train@18880  Loss: 0.002276 Acc: 13.3125\n",
      " |~~ train@18944  Loss: 0.001780 Acc: 13.4062\n",
      " |~~ train@19008  Loss: 0.002034 Acc: 13.2812\n",
      " |~~ train@19072  Loss: 0.001519 Acc: 13.5469\n",
      " |~~ train@19136  Loss: 0.001519 Acc: 13.5156\n",
      " |~~ train@19200  Loss: 0.001752 Acc: 13.4531\n",
      " |~~ train@19264  Loss: 0.001768 Acc: 13.3750\n",
      " |~~ train@19328  Loss: 0.002473 Acc: 13.1562\n",
      " |~~ train@19392  Loss: 0.002441 Acc: 13.1719\n",
      " |~~ train@19456  Loss: 0.001664 Acc: 13.4219\n",
      " |~~ train@19520  Loss: 0.002091 Acc: 13.3125\n",
      " |~~ train@19584  Loss: 0.002043 Acc: 13.3125\n",
      " |~~ train@19648  Loss: 0.001716 Acc: 13.4375\n",
      " |~~ train@19712  Loss: 0.001836 Acc: 13.3906\n",
      " |~~ train@19776  Loss: 0.001882 Acc: 13.4688\n",
      " |~~ train@19840  Loss: 0.002191 Acc: 13.2969\n",
      " |~~ train@19904  Loss: 0.002278 Acc: 13.1719\n",
      " |~~ train@19968  Loss: 0.002104 Acc: 13.2969\n",
      " |~~ train@20032  Loss: 0.002224 Acc: 13.2656\n",
      " |~~ train@20096  Loss: 0.002192 Acc: 13.2500\n",
      " |~~ train@20160  Loss: 0.002011 Acc: 13.3594\n",
      " |~~ train@20224  Loss: 0.001890 Acc: 13.3906\n",
      " |~~ train@20288  Loss: 0.002186 Acc: 13.3438\n",
      " |~~ train@20352  Loss: 0.001627 Acc: 13.5000\n",
      " |~~ train@20416  Loss: 0.002453 Acc: 13.1406\n",
      " |~~ train@20480  Loss: 0.002447 Acc: 13.1250\n",
      " |~~ train@20544  Loss: 0.001968 Acc: 13.3281\n",
      " |~~ train@20608  Loss: 0.001758 Acc: 13.4375\n",
      " |~~ train@20672  Loss: 0.002505 Acc: 13.1094\n",
      " |~~ train@20736  Loss: 0.002289 Acc: 13.2188\n",
      " |~~ train@20800  Loss: 0.001701 Acc: 13.5312\n",
      " |~~ train@20864  Loss: 0.002393 Acc: 13.1562\n",
      " |~~ train@20928  Loss: 0.002304 Acc: 13.2969\n",
      " |~~ train@20992  Loss: 0.001685 Acc: 13.4531\n",
      " |~~ train@21056  Loss: 0.001808 Acc: 13.4844\n",
      " |~~ train@21120  Loss: 0.001767 Acc: 13.3594\n",
      " |~~ train@21184  Loss: 0.001977 Acc: 13.2656\n",
      " |~~ train@21248  Loss: 0.001706 Acc: 13.5000\n",
      " |~~ train@21312  Loss: 0.002404 Acc: 13.2344\n",
      " |~~ train@21376  Loss: 0.002461 Acc: 13.1094\n",
      " |~~ train@21440  Loss: 0.002027 Acc: 13.3281\n",
      " |~~ train@21504  Loss: 0.001745 Acc: 13.5000\n",
      " |~~ train@21568  Loss: 0.001566 Acc: 13.5312\n",
      " |~~ train@21632  Loss: 0.001778 Acc: 13.4219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@21696  Loss: 0.002122 Acc: 13.2812\n",
      " |~~ train@21760  Loss: 0.002021 Acc: 13.3750\n",
      " |~~ train@21824  Loss: 0.001818 Acc: 13.4375\n",
      " |~~ train@21888  Loss: 0.003073 Acc: 12.9375\n",
      " |~~ train@21952  Loss: 0.002050 Acc: 13.4062\n",
      " |~~ train@22016  Loss: 0.002099 Acc: 13.3438\n",
      " |~~ train@22080  Loss: 0.001878 Acc: 13.3906\n",
      " |~~ train@22144  Loss: 0.002087 Acc: 13.3125\n",
      " |~~ train@22208  Loss: 0.001850 Acc: 13.3438\n",
      " |~~ train@22272  Loss: 0.002440 Acc: 13.1562\n",
      " |~~ train@22336  Loss: 0.001949 Acc: 13.4531\n",
      " |~~ train@22400  Loss: 0.001773 Acc: 13.4688\n",
      " |~~ train@22464  Loss: 0.002057 Acc: 13.3281\n",
      " |~~ train@22528  Loss: 0.001909 Acc: 13.4219\n",
      " |~~ train@22592  Loss: 0.001880 Acc: 13.3906\n",
      " |~~ train@22656  Loss: 0.002559 Acc: 13.2031\n",
      " |~~ train@22720  Loss: 0.002256 Acc: 13.4375\n",
      " |~~ train@22784  Loss: 0.001848 Acc: 13.3594\n",
      " |~~ train@22848  Loss: 0.001960 Acc: 13.3281\n",
      " |~~ train@22912  Loss: 0.002489 Acc: 13.1875\n",
      " |~~ train@22976  Loss: 0.001709 Acc: 13.3906\n",
      " |~~ train@23040  Loss: 0.002072 Acc: 13.3906\n",
      " |~~ train@23104  Loss: 0.001758 Acc: 13.3594\n",
      " |~~ train@23168  Loss: 0.002005 Acc: 13.3281\n",
      " |~~ train@23232  Loss: 0.002046 Acc: 13.3125\n",
      " |~~ train@23296  Loss: 0.001971 Acc: 13.3594\n",
      " |~~ train@23360  Loss: 0.002139 Acc: 13.2344\n",
      " |~~ train@23424  Loss: 0.001703 Acc: 13.4688\n",
      " |~~ train@23488  Loss: 0.002070 Acc: 13.3594\n",
      " |~~ train@23552  Loss: 0.001974 Acc: 13.3594\n",
      " |~~ train@23616  Loss: 0.001947 Acc: 13.3906\n",
      " |~~ train@23680  Loss: 0.001627 Acc: 13.4219\n",
      " |~~ train@23744  Loss: 0.002265 Acc: 13.3125\n",
      " |~~ train@23808  Loss: 0.001857 Acc: 13.2812\n",
      " |~~ train@23872  Loss: 0.002153 Acc: 13.2969\n",
      " |~~ train@23936  Loss: 0.002240 Acc: 13.2969\n",
      " |~~ train@24000  Loss: 0.001946 Acc: 13.3281\n",
      " |~~ train@24064  Loss: 0.001893 Acc: 13.4375\n",
      " |~~ train@24128  Loss: 0.002111 Acc: 13.2656\n",
      " |~~ train@24192  Loss: 0.002387 Acc: 13.2656\n",
      " |~~ train@24256  Loss: 0.002563 Acc: 13.2188\n",
      " |~~ train@24320  Loss: 0.001682 Acc: 13.5156\n",
      " |~~ train@24384  Loss: 0.002103 Acc: 13.4062\n",
      " |~~ train@24448  Loss: 0.002029 Acc: 13.3281\n",
      " |~~ train@24512  Loss: 0.002145 Acc: 13.2969\n",
      " |~~ train@24576  Loss: 0.002037 Acc: 13.4219\n",
      " |~~ train@24640  Loss: 0.001925 Acc: 13.3906\n",
      " |~~ train@24704  Loss: 0.001738 Acc: 13.4219\n",
      " |~~ train@24768  Loss: 0.001948 Acc: 13.3750\n",
      " |~~ train@24832  Loss: 0.002238 Acc: 13.2188\n",
      " |~~ train@24896  Loss: 0.001880 Acc: 13.4219\n",
      " |~~ train@24960  Loss: 0.001624 Acc: 13.4062\n",
      " |~~ train@25024  Loss: 0.001886 Acc: 13.2969\n",
      " |~~ train@25088  Loss: 0.002096 Acc: 13.2656\n",
      " |~~ train@25152  Loss: 0.002072 Acc: 13.2969\n",
      " |~~ train@25216  Loss: 0.002116 Acc: 13.2812\n",
      " |~~ train@25280  Loss: 0.001983 Acc: 13.4219\n",
      " |~~ train@25344  Loss: 0.001896 Acc: 13.4062\n",
      " |~~ train@25408  Loss: 0.002116 Acc: 13.4375\n",
      " |~~ train@25472  Loss: 0.001522 Acc: 13.4844\n",
      " |~~ train@25536  Loss: 0.001824 Acc: 13.4062\n",
      " |~~ train@25600  Loss: 0.002056 Acc: 13.3906\n",
      " |~~ train@25664  Loss: 0.002373 Acc: 13.2500\n",
      " |~~ train@25728  Loss: 0.001814 Acc: 13.4219\n",
      " |~~ train@25792  Loss: 0.001734 Acc: 13.5312\n",
      " |~~ train@25856  Loss: 0.002553 Acc: 13.2500\n",
      " |~~ train@25920  Loss: 0.001545 Acc: 13.5469\n",
      " |~~ train@25984  Loss: 0.002052 Acc: 13.2500\n",
      " |~~ train@26048  Loss: 0.002075 Acc: 13.3438\n",
      " |~~ train@26112  Loss: 0.002441 Acc: 13.2969\n",
      " |~~ train@26176  Loss: 0.002400 Acc: 13.2344\n",
      " |~~ train@26240  Loss: 0.002051 Acc: 13.3438\n",
      " |~~ train@26304  Loss: 0.001708 Acc: 13.5156\n",
      " |~~ train@26368  Loss: 0.002032 Acc: 13.3594\n",
      " |~~ train@26432  Loss: 0.002384 Acc: 13.2031\n",
      " |~~ train@26496  Loss: 0.002663 Acc: 13.1094\n",
      " |~~ train@26560  Loss: 0.001820 Acc: 13.4375\n",
      " |~~ train@26624  Loss: 0.002209 Acc: 13.2812\n",
      " |~~ train@26688  Loss: 0.002090 Acc: 13.3125\n",
      " |~~ train@26752  Loss: 0.001801 Acc: 13.3594\n",
      " |~~ train@26816  Loss: 0.002060 Acc: 13.2344\n",
      " |~~ train@26880  Loss: 0.002339 Acc: 13.1719\n",
      " |~~ train@26944  Loss: 0.001903 Acc: 13.3438\n",
      " |~~ train@27008  Loss: 0.001782 Acc: 13.4844\n",
      " |~~ train@27072  Loss: 0.001944 Acc: 13.3438\n",
      " |~~ train@27136  Loss: 0.002463 Acc: 13.2344\n",
      " |~~ train@27200  Loss: 0.001623 Acc: 13.4688\n",
      " |~~ train@27264  Loss: 0.001490 Acc: 13.5781\n",
      " |~~ train@27328  Loss: 0.001561 Acc: 13.4844\n",
      " |~~ train@27392  Loss: 0.002539 Acc: 13.0781\n",
      " |~~ train@27456  Loss: 0.001599 Acc: 13.5781\n",
      " |~~ train@27520  Loss: 0.001757 Acc: 13.4375\n",
      " |~~ train@27584  Loss: 0.001855 Acc: 13.3281\n",
      " |~~ train@27648  Loss: 0.002570 Acc: 13.1094\n",
      " |~~ train@27712  Loss: 0.002547 Acc: 13.0938\n",
      " |~~ train@27776  Loss: 0.002354 Acc: 13.2344\n",
      " |~~ train@27840  Loss: 0.001925 Acc: 13.3281\n",
      " |~~ train@27904  Loss: 0.001806 Acc: 13.4375\n",
      " |~~ train@27968  Loss: 0.001795 Acc: 13.3750\n",
      " |~~ train@28032  Loss: 0.001445 Acc: 13.6250\n",
      " |~~ train@28096  Loss: 0.001595 Acc: 13.5156\n",
      " |~~ train@28160  Loss: 0.001846 Acc: 13.4688\n",
      " |~~ train@28224  Loss: 0.002768 Acc: 13.0625\n",
      " |~~ train@28288  Loss: 0.002142 Acc: 13.3750\n",
      " |~~ train@28352  Loss: 0.002243 Acc: 13.2812\n",
      " |~~ train@28416  Loss: 0.002015 Acc: 13.3750\n",
      " |~~ train@28480  Loss: 0.001486 Acc: 13.5469\n",
      " |~~ train@28544  Loss: 0.002107 Acc: 13.2812\n",
      " |~~ train@28608  Loss: 0.001678 Acc: 13.4062\n",
      " |~~ train@28672  Loss: 0.001271 Acc: 13.5938\n",
      " |~~ train@28736  Loss: 0.001875 Acc: 13.4531\n",
      " |~~ train@28800  Loss: 0.001808 Acc: 13.4844\n",
      " |~~ train@28864  Loss: 0.001804 Acc: 13.5000\n",
      " |~~ train@28928  Loss: 0.001904 Acc: 13.3438\n",
      " |~~ train@28992  Loss: 0.001730 Acc: 13.4531\n",
      " |~~ train@29056  Loss: 0.002088 Acc: 13.3281\n",
      " |~~ train@29120  Loss: 0.001772 Acc: 13.3906\n",
      " |~~ train@29184  Loss: 0.001813 Acc: 13.5156\n",
      " |~~ train@29248  Loss: 0.001882 Acc: 13.4531\n",
      " |~~ train@29312  Loss: 0.002249 Acc: 13.2344\n",
      " |~~ train@29376  Loss: 0.002681 Acc: 13.0469\n",
      " |~~ train@29440  Loss: 0.001919 Acc: 13.3906\n",
      " |~~ train@29504  Loss: 0.001862 Acc: 13.3906\n",
      " |~~ train@29568  Loss: 0.002500 Acc: 13.1875\n",
      " |~~ train@29632  Loss: 0.002041 Acc: 13.3906\n",
      " |~~ train@29696  Loss: 0.001521 Acc: 13.5938\n",
      " |~~ train@29760  Loss: 0.001933 Acc: 13.4688\n",
      " |~~ train@29824  Loss: 0.002166 Acc: 13.2031\n",
      " |~~ train@29888  Loss: 0.001671 Acc: 13.4531\n",
      " |~~ train@29952  Loss: 0.002074 Acc: 13.3125\n",
      " |~~ train@30016  Loss: 0.002324 Acc: 13.2969\n",
      " |~~ train@30080  Loss: 0.002021 Acc: 13.3125\n",
      " |~~ train@30144  Loss: 0.001923 Acc: 13.4531\n",
      " |~~ train@30208  Loss: 0.001894 Acc: 13.4219\n",
      " |~~ train@30272  Loss: 0.002126 Acc: 13.2812\n",
      " |~~ train@30336  Loss: 0.001810 Acc: 13.5000\n",
      " |~~ train@30400  Loss: 0.001831 Acc: 13.3906\n",
      " |~~ train@30464  Loss: 0.001407 Acc: 13.5156\n",
      " |~~ train@30528  Loss: 0.001787 Acc: 13.5000\n",
      " |~~ train@30592  Loss: 0.001755 Acc: 13.4531\n",
      " |~~ train@30656  Loss: 0.002558 Acc: 13.1250\n",
      " |~~ train@30720  Loss: 0.001252 Acc: 13.6250\n",
      " |~~ train@30784  Loss: 0.002187 Acc: 13.3125\n",
      " |~~ train@30848  Loss: 0.002158 Acc: 13.2656\n",
      " |~~ train@30912  Loss: 0.002161 Acc: 13.2812\n",
      " |~~ train@30976  Loss: 0.001614 Acc: 13.5312\n",
      " |~~ train@31040  Loss: 0.001897 Acc: 13.3125\n",
      " |~~ train@31104  Loss: 0.001889 Acc: 13.4062\n",
      " |~~ train@31168  Loss: 0.001747 Acc: 13.4531\n",
      " |~~ train@31232  Loss: 0.001922 Acc: 13.3906\n",
      " |~~ train@31296  Loss: 0.001826 Acc: 13.4688\n",
      " |~~ train@31360  Loss: 0.002436 Acc: 13.1250\n",
      " |~~ train@31424  Loss: 0.001834 Acc: 13.3281\n",
      " |~~ train@31488  Loss: 0.002137 Acc: 13.3125\n",
      " |~~ train@31552  Loss: 0.001638 Acc: 13.4844\n",
      " |~~ train@31616  Loss: 0.002474 Acc: 13.2031\n",
      " |~~ train@31680  Loss: 0.001838 Acc: 13.4375\n",
      " |~~ train@31744  Loss: 0.001967 Acc: 13.2812\n",
      " |~~ train@31808  Loss: 0.002325 Acc: 13.1875\n",
      " |~~ train@31872  Loss: 0.002003 Acc: 13.3125\n",
      " |~~ train@31936  Loss: 0.001925 Acc: 13.3594\n",
      " |~~ train@32000  Loss: 0.001651 Acc: 13.4844\n",
      " |~~ train@32064  Loss: 0.002281 Acc: 13.1406\n",
      " |~~ train@32128  Loss: 0.002013 Acc: 13.3125\n",
      " |~~ train@32192  Loss: 0.001968 Acc: 13.2969\n",
      " |~~ train@32256  Loss: 0.001578 Acc: 13.5781\n",
      " |~~ train@32320  Loss: 0.002282 Acc: 13.2812\n",
      " |~~ train@32384  Loss: 0.002037 Acc: 13.2188\n",
      " |~~ train@32448  Loss: 0.001876 Acc: 13.3438\n",
      " |~~ train@32512  Loss: 0.001917 Acc: 13.3281\n",
      " |~~ train@32576  Loss: 0.002479 Acc: 13.1719\n",
      " |~~ train@32640  Loss: 0.001746 Acc: 13.4062\n",
      " |~~ train@32704  Loss: 0.002053 Acc: 13.3594\n",
      " |~~ train@32768  Loss: 0.002058 Acc: 13.3906\n",
      " |~~ train@32832  Loss: 0.001930 Acc: 13.4688\n",
      " |~~ train@32896  Loss: 0.002479 Acc: 13.2812\n",
      " |~~ train@32960  Loss: 0.001712 Acc: 13.4688\n",
      " |~~ train@33024  Loss: 0.002053 Acc: 13.3281\n",
      " |~~ train@33088  Loss: 0.002056 Acc: 13.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@33152  Loss: 0.002245 Acc: 13.2656\n",
      " |~~ train@33216  Loss: 0.001921 Acc: 13.3438\n",
      " |~~ train@33280  Loss: 0.001904 Acc: 13.4531\n",
      " |~~ train@33344  Loss: 0.001941 Acc: 13.4062\n",
      " |~~ train@33408  Loss: 0.002374 Acc: 13.2812\n",
      " |~~ train@33472  Loss: 0.001907 Acc: 13.3906\n",
      " |~~ train@33536  Loss: 0.002659 Acc: 12.9844\n",
      " |~~ train@33600  Loss: 0.001687 Acc: 13.4688\n",
      " |~~ train@33664  Loss: 0.001934 Acc: 13.3281\n",
      " |~~ train@33728  Loss: 0.001677 Acc: 13.3750\n",
      " |~~ train@33792  Loss: 0.002367 Acc: 13.2344\n",
      " |~~ train@33856  Loss: 0.002055 Acc: 13.3281\n",
      " |~~ train@33920  Loss: 0.002333 Acc: 13.1719\n",
      " |~~ train@33984  Loss: 0.002006 Acc: 13.3438\n",
      " |~~ train@34048  Loss: 0.002356 Acc: 13.2344\n",
      " |~~ train@34112  Loss: 0.002055 Acc: 13.2969\n",
      " |~~ train@34176  Loss: 0.001455 Acc: 13.5469\n",
      " |~~ train@34240  Loss: 0.002325 Acc: 13.2500\n",
      " |~~ train@34304  Loss: 0.001870 Acc: 13.4219\n",
      " |~~ train@34368  Loss: 0.002415 Acc: 13.1719\n",
      " |~~ train@34432  Loss: 0.001301 Acc: 13.6406\n",
      " |~~ train@34496  Loss: 0.001999 Acc: 13.3906\n",
      " |~~ train@34560  Loss: 0.002078 Acc: 13.2344\n",
      " |~~ train@34624  Loss: 0.001710 Acc: 13.4844\n",
      " |~~ train@34688  Loss: 0.002128 Acc: 13.3438\n",
      " |~~ train@34752  Loss: 0.001893 Acc: 13.3906\n",
      " |~~ train@34816  Loss: 0.002240 Acc: 13.3438\n",
      " |~~ train@34880  Loss: 0.001998 Acc: 13.3125\n",
      " |~~ train@34944  Loss: 0.002036 Acc: 13.4375\n",
      " |~~ train@35008  Loss: 0.001997 Acc: 13.3594\n",
      " |~~ train@35072  Loss: 0.001638 Acc: 13.5000\n",
      " |~~ train@35136  Loss: 0.002025 Acc: 13.3750\n",
      " |~~ train@35200  Loss: 0.002229 Acc: 13.3125\n",
      " |~~ train@35264  Loss: 0.002094 Acc: 13.3438\n",
      " |~~ train@35328  Loss: 0.002340 Acc: 13.2031\n",
      " |~~ train@35392  Loss: 0.002227 Acc: 13.2656\n",
      " |~~ train@35456  Loss: 0.002153 Acc: 13.1719\n",
      " |~~ train@35520  Loss: 0.001865 Acc: 13.3906\n",
      " |~~ train@35584  Loss: 0.001932 Acc: 13.3594\n",
      " |~~ train@35648  Loss: 0.001966 Acc: 13.3125\n",
      " |~~ train@35712  Loss: 0.002063 Acc: 13.2656\n",
      " |~~ train@35776  Loss: 0.002170 Acc: 13.4219\n",
      " |~~ train@35840  Loss: 0.001573 Acc: 13.4688\n",
      " |~~ train@35904  Loss: 0.002086 Acc: 13.4219\n",
      " |~~ train@35968  Loss: 0.002597 Acc: 13.1562\n",
      " |~~ train@36032  Loss: 0.002286 Acc: 13.2188\n",
      " |~~ train@36096  Loss: 0.002191 Acc: 13.2969\n",
      " |~~ train@36160  Loss: 0.002172 Acc: 13.3281\n",
      " |~~ train@36224  Loss: 0.002210 Acc: 13.3750\n",
      " |~~ train@36288  Loss: 0.001715 Acc: 13.5156\n",
      " |~~ train@36352  Loss: 0.001951 Acc: 13.3594\n",
      " |~~ train@36416  Loss: 0.002001 Acc: 13.3125\n",
      " |~~ train@36480  Loss: 0.002184 Acc: 13.3594\n",
      " |~~ train@36544  Loss: 0.001952 Acc: 13.3125\n",
      " |~~ train@36608  Loss: 0.001756 Acc: 13.4375\n",
      " |~~ train@36672  Loss: 0.002352 Acc: 13.2344\n",
      " |~~ train@36736  Loss: 0.001908 Acc: 13.4688\n",
      " |~~ train@36800  Loss: 0.002122 Acc: 13.4062\n",
      " |~~ train@36864  Loss: 0.002110 Acc: 13.3281\n",
      " |~~ train@36928  Loss: 0.001922 Acc: 13.3594\n",
      " |~~ train@36992  Loss: 0.001686 Acc: 13.4062\n",
      " |~~ train@37056  Loss: 0.001675 Acc: 13.5312\n",
      " |~~ train@37120  Loss: 0.001599 Acc: 13.5312\n",
      " |~~ train@37184  Loss: 0.002393 Acc: 13.2344\n",
      " |~~ train@37248  Loss: 0.002018 Acc: 13.3281\n",
      " |~~ train@37312  Loss: 0.001507 Acc: 13.5469\n",
      " |~~ train@37376  Loss: 0.002044 Acc: 13.3281\n",
      " |~~ train@37440  Loss: 0.002237 Acc: 13.3750\n",
      " |~~ train@37504  Loss: 0.002505 Acc: 13.1250\n",
      " |~~ train@37568  Loss: 0.001659 Acc: 13.4531\n",
      " |~~ train@37632  Loss: 0.002135 Acc: 13.3438\n",
      " |~~ train@37696  Loss: 0.002460 Acc: 13.1406\n",
      " |~~ train@37760  Loss: 0.002035 Acc: 13.3594\n",
      " |~~ train@37824  Loss: 0.001879 Acc: 13.3750\n",
      " |~~ train@37888  Loss: 0.001989 Acc: 13.3281\n",
      " |~~ train@37952  Loss: 0.001964 Acc: 13.3750\n",
      " |~~ train@38016  Loss: 0.001914 Acc: 13.3750\n",
      " |~~ train@38080  Loss: 0.001713 Acc: 13.4688\n",
      " |~~ train@38144  Loss: 0.002041 Acc: 13.3594\n",
      " |~~ train@38208  Loss: 0.002248 Acc: 13.3125\n",
      " |~~ train@38272  Loss: 0.001826 Acc: 13.3750\n",
      " |~~ train@38336  Loss: 0.002036 Acc: 13.3125\n",
      " |~~ train@38400  Loss: 0.002239 Acc: 13.2344\n",
      " |~~ train@38464  Loss: 0.001678 Acc: 13.4062\n",
      " |~~ train@38528  Loss: 0.001774 Acc: 13.4375\n",
      " |~~ train@38592  Loss: 0.002812 Acc: 13.0938\n",
      " |~~ train@38656  Loss: 0.001549 Acc: 13.5625\n",
      " |~~ train@38720  Loss: 0.002018 Acc: 13.2969\n",
      " |~~ train@38784  Loss: 0.001891 Acc: 13.3281\n",
      " |~~ train@38848  Loss: 0.001737 Acc: 13.4375\n",
      " |~~ train@38912  Loss: 0.002031 Acc: 13.4062\n",
      " |~~ train@38976  Loss: 0.001792 Acc: 13.4531\n",
      " |~~ train@39040  Loss: 0.001779 Acc: 13.5000\n",
      " |~~ train@39104  Loss: 0.002308 Acc: 13.2188\n",
      " |~~ train@39168  Loss: 0.002086 Acc: 13.3438\n",
      " |~~ train@39232  Loss: 0.001754 Acc: 13.4531\n",
      " |~~ train@39296  Loss: 0.002130 Acc: 13.2969\n",
      " |~~ train@39360  Loss: 0.001657 Acc: 13.4844\n",
      " |~~ train@39424  Loss: 0.002183 Acc: 13.3438\n",
      " |~~ train@39488  Loss: 0.002153 Acc: 13.3125\n",
      " |~~ train@39552  Loss: 0.001759 Acc: 13.4531\n",
      " |~~ train@39616  Loss: 0.002001 Acc: 13.2969\n",
      " |~~ train@39680  Loss: 0.001916 Acc: 13.4062\n",
      " |~~ train@39744  Loss: 0.001889 Acc: 13.3125\n",
      " |~~ train@39808  Loss: 0.001874 Acc: 13.4219\n",
      " |~~ train@39872  Loss: 0.001412 Acc: 13.4844\n",
      " |~~ train@39936  Loss: 0.002266 Acc: 13.1719\n",
      " |~~ train@40000  Loss: 0.001981 Acc: 13.4062\n",
      " |~~ train@40064  Loss: 0.002549 Acc: 13.1406\n",
      " |~~ train@40128  Loss: 0.002225 Acc: 13.2500\n",
      " |~~ train@40192  Loss: 0.002059 Acc: 13.3438\n",
      " |~~ train@40256  Loss: 0.001907 Acc: 13.3750\n",
      " |~~ train@40320  Loss: 0.002535 Acc: 13.1250\n",
      " |~~ train@40384  Loss: 0.002158 Acc: 13.2969\n",
      " |~~ train@40448  Loss: 0.002018 Acc: 13.3750\n",
      " |~~ train@40512  Loss: 0.001638 Acc: 13.5938\n",
      " |~~ train@40576  Loss: 0.002283 Acc: 13.2188\n",
      " |~~ train@40640  Loss: 0.001943 Acc: 13.3906\n",
      " |~~ train@40704  Loss: 0.002504 Acc: 13.1094\n",
      " |~~ train@40768  Loss: 0.002462 Acc: 13.2500\n",
      " |~~ train@40832  Loss: 0.002070 Acc: 13.3906\n",
      " |~~ train@40896  Loss: 0.002245 Acc: 13.4062\n",
      " |~~ train@40960  Loss: 0.002455 Acc: 13.2188\n",
      " |~~ train@41024  Loss: 0.002038 Acc: 13.4062\n",
      " |~~ train@41088  Loss: 0.001996 Acc: 13.3125\n",
      " |~~ train@41152  Loss: 0.001884 Acc: 13.3281\n",
      " |~~ train@41216  Loss: 0.002522 Acc: 13.2188\n",
      " |~~ train@41280  Loss: 0.002109 Acc: 13.3281\n",
      " |~~ train@41344  Loss: 0.001810 Acc: 13.3438\n",
      " |~~ train@41408  Loss: 0.001658 Acc: 13.4688\n",
      " |~~ train@41472  Loss: 0.001809 Acc: 13.3438\n",
      " |~~ train@41536  Loss: 0.002095 Acc: 13.4062\n",
      " |~~ train@41600  Loss: 0.002038 Acc: 13.2969\n",
      " |~~ train@41664  Loss: 0.002440 Acc: 13.2031\n",
      " |~~ train@41728  Loss: 0.001778 Acc: 13.4375\n",
      " |~~ train@41792  Loss: 0.002039 Acc: 13.2969\n",
      " |~~ train@41856  Loss: 0.002359 Acc: 13.1875\n",
      " |~~ train@41920  Loss: 0.002148 Acc: 13.2812\n",
      " |~~ train@41984  Loss: 0.002153 Acc: 13.3594\n",
      " |~~ train@42048  Loss: 0.001793 Acc: 13.4062\n",
      " |~~ train@42112  Loss: 0.002068 Acc: 13.3125\n",
      " |~~ train@42176  Loss: 0.002368 Acc: 13.2500\n",
      " |~~ train@42240  Loss: 0.002188 Acc: 13.2188\n",
      " |~~ train@42304  Loss: 0.001962 Acc: 13.3281\n",
      " |~~ train@42368  Loss: 0.001845 Acc: 13.4375\n",
      " |~~ train@42432  Loss: 0.002236 Acc: 13.2812\n",
      " |~~ train@42496  Loss: 0.002385 Acc: 13.3125\n",
      " |~~ train@42560  Loss: 0.002192 Acc: 13.1875\n",
      " |~~ train@42624  Loss: 0.001753 Acc: 13.3906\n",
      " |~~ train@42688  Loss: 0.001839 Acc: 13.4375\n",
      " |~~ train@42752  Loss: 0.001879 Acc: 13.3438\n",
      " |~~ train@42816  Loss: 0.001978 Acc: 13.4062\n",
      " |~~ train@42880  Loss: 0.001729 Acc: 13.4531\n",
      " |~~ train@42944  Loss: 0.001452 Acc: 13.5625\n",
      " |~~ train@43008  Loss: 0.002882 Acc: 13.0469\n",
      " |~~ train@43072  Loss: 0.001925 Acc: 13.4062\n",
      " |~~ train@43136  Loss: 0.001799 Acc: 13.4688\n",
      " |~~ train@43200  Loss: 0.001823 Acc: 13.4062\n",
      " |~~ train@43264  Loss: 0.001820 Acc: 13.4219\n",
      " |~~ train@43328  Loss: 0.001755 Acc: 13.4531\n",
      " |~~ train@43392  Loss: 0.002303 Acc: 13.2656\n",
      " |~~ train@43456  Loss: 0.001993 Acc: 13.3438\n",
      " |~~ train@43520  Loss: 0.002401 Acc: 13.2656\n",
      " |~~ train@43584  Loss: 0.001928 Acc: 13.4219\n",
      " |~~ train@43648  Loss: 0.001885 Acc: 13.4062\n",
      " |~~ train@43712  Loss: 0.002526 Acc: 13.1875\n",
      " |~~ train@43776  Loss: 0.001799 Acc: 13.3125\n",
      " |~~ train@43840  Loss: 0.002089 Acc: 13.2812\n",
      " |~~ train@43904  Loss: 0.001963 Acc: 13.3281\n",
      " |~~ train@43968  Loss: 0.002362 Acc: 13.1875\n",
      " |~~ train@44032  Loss: 0.001629 Acc: 13.5000\n",
      " |~~ train@44096  Loss: 0.001984 Acc: 13.3594\n",
      " |~~ train@44160  Loss: 0.001934 Acc: 13.4062\n",
      " |~~ train@44224  Loss: 0.002228 Acc: 13.2969\n",
      " |~~ train@44288  Loss: 0.002237 Acc: 13.2344\n",
      " |~~ train@44352  Loss: 0.002212 Acc: 13.2500\n",
      " |~~ train@44416  Loss: 0.001668 Acc: 13.4688\n",
      " |~~ train@44480  Loss: 0.002373 Acc: 13.2969\n",
      " |~~ train@44544  Loss: 0.002157 Acc: 13.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@44608  Loss: 0.001774 Acc: 13.5000\n",
      " |~~ train@44672  Loss: 0.002307 Acc: 13.2344\n",
      " |~~ train@44736  Loss: 0.002530 Acc: 13.1562\n",
      " |~~ train@44800  Loss: 0.001661 Acc: 13.4375\n",
      " |~~ train@44864  Loss: 0.001719 Acc: 13.4688\n",
      " |~~ train@44928  Loss: 0.001668 Acc: 13.4219\n",
      " |~~ train@44992  Loss: 0.001978 Acc: 13.3750\n",
      " |~~ train@45056  Loss: 0.002369 Acc: 13.2656\n",
      " |~~ train@45120  Loss: 0.001915 Acc: 13.3438\n",
      " |~~ train@45184  Loss: 0.001859 Acc: 13.3594\n",
      " |~~ train@45248  Loss: 0.001875 Acc: 13.3281\n",
      " |~~ train@45312  Loss: 0.001841 Acc: 13.3594\n",
      " |~~ train@45376  Loss: 0.002302 Acc: 13.2500\n",
      " |~~ train@45440  Loss: 0.001947 Acc: 13.3125\n",
      " |~~ train@45504  Loss: 0.001940 Acc: 13.3125\n",
      " |~~ train@45568  Loss: 0.001538 Acc: 13.5469\n",
      " |~~ train@45632  Loss: 0.002411 Acc: 13.2031\n",
      " |~~ train@45696  Loss: 0.001951 Acc: 13.3438\n",
      " |~~ train@45760  Loss: 0.001501 Acc: 13.5469\n",
      " |~~ train@45824  Loss: 0.002687 Acc: 13.1094\n",
      " |~~ train@45888  Loss: 0.001978 Acc: 13.3281\n",
      " |~~ train@45952  Loss: 0.001997 Acc: 13.2656\n",
      " |~~ train@46016  Loss: 0.002400 Acc: 13.1719\n",
      " |~~ train@46080  Loss: 0.001571 Acc: 13.4531\n",
      " |~~ train@46144  Loss: 0.001957 Acc: 13.2969\n",
      " |~~ train@46208  Loss: 0.001866 Acc: 13.3906\n",
      " |~~ train@46272  Loss: 0.001900 Acc: 13.3906\n",
      " |~~ train@46336  Loss: 0.001832 Acc: 13.4844\n",
      " |~~ train@46400  Loss: 0.001618 Acc: 13.5312\n",
      " |~~ train@46464  Loss: 0.002237 Acc: 13.2656\n",
      " |~~ train@46528  Loss: 0.001892 Acc: 13.3438\n",
      " |~~ train@46592  Loss: 0.001762 Acc: 13.4531\n",
      " |~~ train@46656  Loss: 0.001639 Acc: 13.4844\n",
      " |~~ train@46720  Loss: 0.002105 Acc: 13.3125\n",
      " |~~ train@46784  Loss: 0.002024 Acc: 13.2812\n",
      " |~~ train@46848  Loss: 0.002034 Acc: 13.2188\n",
      " |~~ train@46912  Loss: 0.002352 Acc: 13.2500\n",
      " |~~ train@46976  Loss: 0.002088 Acc: 13.3125\n",
      " |~~ train@47040  Loss: 0.001993 Acc: 13.3438\n",
      " |~~ train@47104  Loss: 0.001761 Acc: 13.4844\n",
      " |~~ train@47168  Loss: 0.001924 Acc: 13.4062\n",
      " |~~ train@47232  Loss: 0.001830 Acc: 13.4062\n",
      " |~~ train@47296  Loss: 0.002179 Acc: 13.3438\n",
      " |~~ train@47360  Loss: 0.001812 Acc: 13.3750\n",
      " |~~ train@47424  Loss: 0.002293 Acc: 13.2344\n",
      " |~~ train@47488  Loss: 0.001974 Acc: 13.4062\n",
      " |~~ train@47552  Loss: 0.001885 Acc: 13.4219\n",
      " |~~ train@47616  Loss: 0.001838 Acc: 13.4375\n",
      " |~~ train@47680  Loss: 0.001536 Acc: 13.5312\n",
      " |~~ train@47744  Loss: 0.001920 Acc: 13.3906\n",
      " |~~ train@47808  Loss: 0.002155 Acc: 13.2656\n",
      " |~~ train@47872  Loss: 0.001562 Acc: 13.5156\n",
      " |~~ train@47936  Loss: 0.001871 Acc: 13.3906\n",
      " |~~ train@48000  Loss: 0.001985 Acc: 13.4375\n",
      " |~~ train@48064  Loss: 0.001886 Acc: 13.3906\n",
      " |~~ train@48128  Loss: 0.001846 Acc: 13.3906\n",
      " |~~ train@48192  Loss: 0.001746 Acc: 13.3906\n",
      " |~~ train@48256  Loss: 0.002293 Acc: 13.2344\n",
      " |~~ train@48320  Loss: 0.002247 Acc: 13.2656\n",
      " |~~ train@48384  Loss: 0.002272 Acc: 13.2969\n",
      " |~~ train@48448  Loss: 0.001649 Acc: 13.5625\n",
      " |~~ train@48512  Loss: 0.001667 Acc: 13.4531\n",
      " |~~ train@48576  Loss: 0.002011 Acc: 13.4375\n",
      " |~~ train@48640  Loss: 0.001860 Acc: 13.4219\n",
      " |~~ train@48704  Loss: 0.001769 Acc: 13.5156\n",
      " |~~ train@48768  Loss: 0.001863 Acc: 13.4688\n",
      " |~~ train@48832  Loss: 0.002255 Acc: 13.2031\n",
      " |~~ train@48896  Loss: 0.002382 Acc: 13.1250\n",
      " |~~ train@48960  Loss: 0.002186 Acc: 13.2812\n",
      " |~~ train@49024  Loss: 0.001766 Acc: 13.4531\n",
      " |~~ train@49088  Loss: 0.001756 Acc: 13.3906\n",
      " |~~ train@49152  Loss: 0.001669 Acc: 13.4062\n",
      " |~~ train@49216  Loss: 0.001568 Acc: 13.5000\n",
      " |~~ train@49280  Loss: 0.001786 Acc: 13.5156\n",
      " |~~ train@49344  Loss: 0.001730 Acc: 13.3594\n",
      " |~~ train@49408  Loss: 0.002096 Acc: 13.2969\n",
      " |~~ train@49472  Loss: 0.001874 Acc: 13.4219\n",
      " |~~ train@49536  Loss: 0.001876 Acc: 13.4219\n",
      " |~~ train@49600  Loss: 0.002025 Acc: 13.3438\n",
      " |~~ train@49664  Loss: 0.001940 Acc: 13.3594\n",
      " |~~ train@49728  Loss: 0.002048 Acc: 13.2344\n",
      " |~~ train@49792  Loss: 0.001786 Acc: 13.3125\n",
      " |~~ train@49856  Loss: 0.002022 Acc: 13.2969\n",
      " |~~ train@49920  Loss: 0.001862 Acc: 13.3750\n",
      " |~~ train@49984  Loss: 0.002168 Acc: 13.2812\n",
      " |~~ train@50048  Loss: 0.001879 Acc: 13.3281\n",
      " |~~ train@50112  Loss: 0.002220 Acc: 13.2656\n",
      " |~~ train@50176  Loss: 0.001968 Acc: 13.3438\n",
      " |~~ train@50240  Loss: 0.002055 Acc: 13.2812\n",
      " |~~ train@50304  Loss: 0.002622 Acc: 13.1719\n",
      " |~~ train@50368  Loss: 0.001667 Acc: 13.4531\n",
      " |~~ train@50432  Loss: 0.002232 Acc: 13.2656\n",
      " |~~ train@50496  Loss: 0.001705 Acc: 13.4844\n",
      " |~~ train@50560  Loss: 0.001720 Acc: 13.5156\n",
      " |~~ train@50624  Loss: 0.001706 Acc: 13.5000\n",
      " |~~ train@50688  Loss: 0.001912 Acc: 13.4219\n",
      " |~~ train@50752  Loss: 0.002003 Acc: 13.3750\n",
      " |~~ train@50816  Loss: 0.002015 Acc: 13.3906\n",
      " |~~ train@50880  Loss: 0.001791 Acc: 13.4219\n",
      " |~~ train@50944  Loss: 0.001956 Acc: 13.3125\n",
      " |~~ train@51008  Loss: 0.001913 Acc: 13.3438\n",
      " |~~ train@51072  Loss: 0.002004 Acc: 13.3906\n",
      " |~~ train@51136  Loss: 0.001596 Acc: 13.4531\n",
      " |~~ train@51200  Loss: 0.002052 Acc: 13.2812\n",
      " |~~ train@51264  Loss: 0.002218 Acc: 13.2812\n",
      " |~~ train@51328  Loss: 0.002284 Acc: 13.3438\n",
      " |~~ train@51392  Loss: 0.001774 Acc: 13.3750\n",
      " |~~ train@51456  Loss: 0.001811 Acc: 13.3125\n",
      " |~~ train@51520  Loss: 0.002245 Acc: 13.2344\n",
      " |~~ train@51584  Loss: 0.001522 Acc: 13.5000\n",
      " |~~ train@51648  Loss: 0.001872 Acc: 13.2969\n",
      " |~~ train@51712  Loss: 0.002032 Acc: 13.2812\n",
      " |~~ train@51776  Loss: 0.002006 Acc: 13.3438\n",
      " |~~ train@51840  Loss: 0.002169 Acc: 13.2656\n",
      " |~~ train@51904  Loss: 0.002008 Acc: 13.3438\n",
      " |~~ train@51968  Loss: 0.002022 Acc: 13.3125\n",
      " |~~ train@52032  Loss: 0.002238 Acc: 13.2500\n",
      " |~~ train@52096  Loss: 0.002236 Acc: 13.3125\n",
      " |~~ train@52160  Loss: 0.001782 Acc: 13.5156\n",
      " |~~ train@52224  Loss: 0.001915 Acc: 13.3594\n",
      " |~~ train@52288  Loss: 0.001436 Acc: 13.6250\n",
      " |~~ train@52352  Loss: 0.002177 Acc: 13.2344\n",
      " |~~ train@52416  Loss: 0.002289 Acc: 13.2656\n",
      " |~~ train@52480  Loss: 0.001817 Acc: 13.4062\n",
      " |~~ train@52544  Loss: 0.001852 Acc: 13.4062\n",
      " |~~ train@52608  Loss: 0.002438 Acc: 13.2031\n",
      " |~~ train@52672  Loss: 0.001772 Acc: 13.3594\n",
      " |~~ train@52736  Loss: 0.002216 Acc: 13.2812\n",
      " |~~ train@52800  Loss: 0.002076 Acc: 13.3438\n",
      " |~~ train@52864  Loss: 0.001968 Acc: 13.4062\n",
      " |~~ train@52928  Loss: 0.001712 Acc: 13.5000\n",
      " |~~ train@52992  Loss: 0.002530 Acc: 13.0781\n",
      " |~~ train@53056  Loss: 0.001824 Acc: 13.3750\n",
      " |~~ train@53120  Loss: 0.001702 Acc: 13.4531\n",
      " |~~ train@53184  Loss: 0.001554 Acc: 13.5469\n",
      " |~~ train@53248  Loss: 0.001671 Acc: 13.4375\n",
      " |~~ train@53312  Loss: 0.002151 Acc: 13.3438\n",
      " |~~ train@53376  Loss: 0.001794 Acc: 13.4219\n",
      " |~~ train@53440  Loss: 0.002514 Acc: 13.1875\n",
      " |~~ train@53504  Loss: 0.002151 Acc: 13.2031\n",
      " |~~ train@53568  Loss: 0.002192 Acc: 13.3125\n",
      " |~~ train@53632  Loss: 0.002266 Acc: 13.1875\n",
      " |~~ train@53696  Loss: 0.001973 Acc: 13.3906\n",
      " |~~ train@53760  Loss: 0.002080 Acc: 13.3281\n",
      " |~~ train@53824  Loss: 0.002092 Acc: 13.3594\n",
      " |~~ train@53888  Loss: 0.001907 Acc: 13.3281\n",
      " |~~ train@53952  Loss: 0.001368 Acc: 13.5469\n",
      " |~~ train@54016  Loss: 0.001784 Acc: 13.4531\n",
      " |~~ train@54080  Loss: 0.002671 Acc: 13.2031\n",
      " |~~ train@54144  Loss: 0.001873 Acc: 13.4844\n",
      " |~~ train@54208  Loss: 0.001877 Acc: 13.4219\n",
      " |~~ train@54272  Loss: 0.001509 Acc: 13.5625\n",
      " |~~ train@54336  Loss: 0.001595 Acc: 13.4375\n",
      " |~~ train@54400  Loss: 0.001889 Acc: 13.3594\n",
      " |~~ train@54464  Loss: 0.001649 Acc: 13.5781\n",
      " |~~ train@54528  Loss: 0.002682 Acc: 13.1094\n",
      " |~~ train@54592  Loss: 0.002397 Acc: 13.1719\n",
      " |~~ train@54656  Loss: 0.002148 Acc: 13.3438\n",
      " |~~ train@54720  Loss: 0.001884 Acc: 13.4062\n",
      " |~~ train@54784  Loss: 0.001812 Acc: 13.3594\n",
      " |~~ train@54848  Loss: 0.001553 Acc: 13.5312\n",
      " |~~ train@54912  Loss: 0.001629 Acc: 13.3594\n",
      " |~~ train@54976  Loss: 0.002097 Acc: 13.1719\n",
      " |~~ train@55040  Loss: 0.002409 Acc: 13.1719\n",
      " |~~ train@55104  Loss: 0.001933 Acc: 13.3750\n",
      " |~~ train@55168  Loss: 0.001850 Acc: 13.3594\n",
      " |~~ train@55232  Loss: 0.001540 Acc: 13.5781\n",
      " |~~ train@55296  Loss: 0.002157 Acc: 13.2969\n",
      " |~~ train@55360  Loss: 0.001798 Acc: 13.4062\n",
      " |~~ train@55424  Loss: 0.001973 Acc: 13.3125\n",
      " |~~ train@55488  Loss: 0.001985 Acc: 13.3906\n",
      " |~~ train@55552  Loss: 0.001800 Acc: 13.5000\n",
      " |~~ train@55616  Loss: 0.002071 Acc: 13.2656\n",
      " |~~ train@55680  Loss: 0.002065 Acc: 13.3125\n",
      " |~~ train@55744  Loss: 0.001846 Acc: 13.4375\n",
      " |~~ train@55808  Loss: 0.002025 Acc: 13.3438\n",
      " |~~ train@55872  Loss: 0.002108 Acc: 13.4062\n",
      " |~~ train@55936  Loss: 0.001697 Acc: 13.5000\n",
      " |~~ train@56000  Loss: 0.001726 Acc: 13.4219\n",
      " |~~ train@56064  Loss: 0.002143 Acc: 13.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@56128  Loss: 0.002627 Acc: 13.1562\n",
      " |~~ train@56192  Loss: 0.002588 Acc: 13.1875\n",
      " |~~ train@56256  Loss: 0.001794 Acc: 13.4531\n",
      " |~~ train@56320  Loss: 0.001839 Acc: 13.3750\n",
      " |~~ train@56384  Loss: 0.002213 Acc: 13.2031\n",
      " |~~ train@56448  Loss: 0.001700 Acc: 13.5000\n",
      " |~~ train@56512  Loss: 0.002065 Acc: 13.2969\n",
      " |~~ train@56576  Loss: 0.002169 Acc: 13.3906\n",
      " |~~ train@56640  Loss: 0.001784 Acc: 13.3906\n",
      " |~~ train@56704  Loss: 0.002447 Acc: 13.1406\n",
      " |~~ train@56768  Loss: 0.002255 Acc: 13.2031\n",
      " |~~ train@56832  Loss: 0.001978 Acc: 13.2812\n",
      " |~~ train@56896  Loss: 0.001859 Acc: 13.4062\n",
      " |~~ train@56960  Loss: 0.001894 Acc: 13.3906\n",
      " |~~ train@57024  Loss: 0.001874 Acc: 13.3906\n",
      " |~~ train@57088  Loss: 0.002125 Acc: 13.3594\n",
      " |~~ train@57152  Loss: 0.001974 Acc: 13.3281\n",
      " |~~ train@57216  Loss: 0.001634 Acc: 13.4531\n",
      " |~~ train@57280  Loss: 0.001915 Acc: 13.3594\n",
      " |~~ train@57344  Loss: 0.002505 Acc: 13.2656\n",
      " |~~ train@57408  Loss: 0.001971 Acc: 13.3438\n",
      " |~~ train@57472  Loss: 0.002243 Acc: 13.2031\n",
      " |~~ train@57536  Loss: 0.001581 Acc: 13.5156\n",
      " |~~ train@57600  Loss: 0.001543 Acc: 13.6094\n",
      " |~~ train@57664  Loss: 0.002415 Acc: 13.0938\n",
      " |~~ train@57728  Loss: 0.002295 Acc: 13.2344\n",
      " |~~ train@57792  Loss: 0.001660 Acc: 13.4062\n",
      " |~~ train@57856  Loss: 0.002123 Acc: 13.2969\n",
      " |~~ train@57920  Loss: 0.001690 Acc: 13.5000\n",
      " |~~ train@57984  Loss: 0.001839 Acc: 13.3750\n",
      " |~~ train@58048  Loss: 0.002138 Acc: 13.3125\n",
      " |~~ train@58112  Loss: 0.002320 Acc: 13.2344\n",
      " |~~ train@58176  Loss: 0.001978 Acc: 13.3125\n",
      " |~~ train@58240  Loss: 0.002116 Acc: 13.2656\n",
      " |~~ train@58304  Loss: 0.001988 Acc: 13.3438\n",
      " |~~ train@58368  Loss: 0.001743 Acc: 13.3750\n",
      " |~~ train@58432  Loss: 0.001838 Acc: 13.4375\n",
      " |~~ train@58496  Loss: 0.001758 Acc: 13.4062\n",
      " |~~ train@58560  Loss: 0.001976 Acc: 13.3906\n",
      " |~~ train@58624  Loss: 0.001592 Acc: 13.5312\n",
      " |~~ train@58688  Loss: 0.002448 Acc: 13.2969\n",
      " |~~ train@58752  Loss: 0.002638 Acc: 13.1094\n",
      " |~~ train@58816  Loss: 0.001812 Acc: 13.4219\n",
      " |~~ train@58880  Loss: 0.002044 Acc: 13.3438\n",
      " |~~ train@58944  Loss: 0.001759 Acc: 13.5000\n",
      " |~~ train@59008  Loss: 0.001835 Acc: 13.4219\n",
      " |~~ train@59072  Loss: 0.002180 Acc: 13.1875\n",
      " |~~ train@59136  Loss: 0.002034 Acc: 13.4219\n",
      " |~~ train@59200  Loss: 0.001814 Acc: 13.3750\n",
      " |~~ train@59264  Loss: 0.002175 Acc: 13.4688\n",
      " |~~ train@59328  Loss: 0.002010 Acc: 13.3750\n",
      " |~~ train@59392  Loss: 0.001680 Acc: 13.5469\n",
      " |~~ train@59456  Loss: 0.002416 Acc: 13.2188\n",
      " |~~ train@59520  Loss: 0.002138 Acc: 13.2812\n",
      " |~~ train@59584  Loss: 0.001716 Acc: 13.3906\n",
      " |~~ train@59648  Loss: 0.001700 Acc: 13.4531\n",
      " |~~ train@59712  Loss: 0.002362 Acc: 13.2500\n",
      " |~~ train@59776  Loss: 0.002128 Acc: 13.2500\n",
      " |~~ train@59840  Loss: 0.002156 Acc: 13.3594\n",
      " |~~ train@59904  Loss: 0.002223 Acc: 13.2656\n",
      " |~~ train@59968  Loss: 0.002117 Acc: 13.2969\n",
      " |~~ train@60032  Loss: 0.001876 Acc: 13.5000\n",
      " |~~ train@60096  Loss: 0.002675 Acc: 13.0781\n",
      " |~~ train@60160  Loss: 0.002260 Acc: 13.3125\n",
      " |~~ train@60224  Loss: 0.002092 Acc: 13.3594\n",
      " |~~ train@60288  Loss: 0.002253 Acc: 13.2812\n",
      " |~~ train@60352  Loss: 0.002105 Acc: 13.2969\n",
      " |~~ train@60416  Loss: 0.002025 Acc: 13.3594\n",
      " |~~ train@60480  Loss: 0.002016 Acc: 13.3125\n",
      " |~~ train@60544  Loss: 0.001873 Acc: 13.4531\n",
      " |~~ train@60608  Loss: 0.002014 Acc: 13.3906\n",
      " |~~ train@60672  Loss: 0.002390 Acc: 13.1562\n",
      " |~~ train@60736  Loss: 0.002027 Acc: 13.3906\n",
      " |~~ train@60800  Loss: 0.002041 Acc: 13.3594\n",
      " |~~ train@60864  Loss: 0.002319 Acc: 13.3125\n",
      " |~~ train@60928  Loss: 0.001994 Acc: 13.3906\n",
      " |~~ train@60992  Loss: 0.002383 Acc: 13.2031\n",
      " |~~ train@61056  Loss: 0.001615 Acc: 13.5312\n",
      " |~~ train@61120  Loss: 0.002192 Acc: 13.3438\n",
      " |~~ train@61184  Loss: 0.002028 Acc: 13.2812\n",
      " |~~ train@61248  Loss: 0.001916 Acc: 13.2656\n",
      " |~~ train@61312  Loss: 0.001955 Acc: 13.4219\n",
      " |~~ train@61376  Loss: 0.002870 Acc: 13.0469\n",
      " |~~ train@61440  Loss: 0.002285 Acc: 13.2500\n",
      " |~~ train@61504  Loss: 0.001678 Acc: 13.5312\n",
      " |~~ train@61568  Loss: 0.001728 Acc: 13.5781\n",
      " |~~ train@61632  Loss: 0.002371 Acc: 13.2188\n",
      " |~~ train@61696  Loss: 0.001798 Acc: 13.3906\n",
      " |~~ train@61760  Loss: 0.001907 Acc: 13.3438\n",
      " |~~ train@61824  Loss: 0.001663 Acc: 13.4062\n",
      " |~~ train@61888  Loss: 0.002095 Acc: 13.3438\n",
      " |~~ train@61952  Loss: 0.001866 Acc: 13.4531\n",
      " |~~ train@62016  Loss: 0.001819 Acc: 13.4062\n",
      " |~~ train@62080  Loss: 0.001835 Acc: 13.4062\n",
      " |~~ train@62144  Loss: 0.001960 Acc: 13.4062\n",
      " |~~ train@62208  Loss: 0.001657 Acc: 13.5000\n",
      " |~~ train@62272  Loss: 0.001718 Acc: 13.4844\n",
      " |~~ train@62336  Loss: 0.002123 Acc: 13.3125\n",
      " |~~ train@62400  Loss: 0.002232 Acc: 13.2969\n",
      " |~~ train@62464  Loss: 0.001678 Acc: 13.4531\n",
      " |~~ train@62528  Loss: 0.002308 Acc: 13.2344\n",
      " |~~ train@62592  Loss: 0.002260 Acc: 13.2188\n",
      " |~~ train@62656  Loss: 0.002000 Acc: 13.3125\n",
      " |~~ train@62720  Loss: 0.001886 Acc: 13.3125\n",
      " |~~ train@62784  Loss: 0.001521 Acc: 13.5312\n",
      " |~~ train@62848  Loss: 0.002072 Acc: 13.3594\n",
      " |~~ train@62912  Loss: 0.002435 Acc: 13.2031\n",
      " |~~ train@62976  Loss: 0.002196 Acc: 13.2969\n",
      " |~~ train@63040  Loss: 0.002057 Acc: 13.3594\n",
      " |~~ train@63104  Loss: 0.001972 Acc: 13.3281\n",
      " |~~ train@63168  Loss: 0.002407 Acc: 13.2656\n",
      " |~~ train@63232  Loss: 0.002071 Acc: 13.2969\n",
      " |~~ train@63296  Loss: 0.001889 Acc: 13.3281\n",
      " |~~ train@63360  Loss: 0.002244 Acc: 13.1719\n",
      " |~~ train@63424  Loss: 0.002246 Acc: 13.2031\n",
      " |~~ train@63488  Loss: 0.002152 Acc: 13.2344\n",
      " |~~ train@63552  Loss: 0.002453 Acc: 13.1094\n",
      " |~~ train@63616  Loss: 0.002180 Acc: 13.2344\n",
      " |~~ train@63680  Loss: 0.002084 Acc: 13.3594\n",
      " |~~ train@63744  Loss: 0.002155 Acc: 13.2812\n",
      " |~~ train@63808  Loss: 0.002047 Acc: 13.2969\n",
      " |~~ train@63872  Loss: 0.002002 Acc: 13.3750\n",
      " |~~ train@63936  Loss: 0.001994 Acc: 13.3750\n",
      " |~~ train@64000  Loss: 0.002177 Acc: 13.3906\n",
      " |~~ train@64064  Loss: 0.002442 Acc: 13.2969\n",
      " |~~ train@64128  Loss: 0.002068 Acc: 13.2969\n",
      " |~~ train@64192  Loss: 0.001664 Acc: 13.5469\n",
      " |~~ train@64256  Loss: 0.002024 Acc: 13.2969\n",
      " |~~ train@64320  Loss: 0.002248 Acc: 13.2812\n",
      " |~~ train@64384  Loss: 0.002470 Acc: 13.1719\n",
      " |~~ train@64448  Loss: 0.002152 Acc: 13.3438\n",
      " |~~ train@64512  Loss: 0.001642 Acc: 13.5156\n",
      " |~~ train@64576  Loss: 0.001672 Acc: 13.4844\n",
      " |~~ train@64640  Loss: 0.002110 Acc: 13.1875\n",
      " |~~ train@64704  Loss: 0.002155 Acc: 13.2812\n",
      " |~~ train@64768  Loss: 0.002047 Acc: 13.3281\n",
      " |~~ train@64832  Loss: 0.002308 Acc: 13.2656\n",
      " |~~ train@64896  Loss: 0.002083 Acc: 13.3438\n",
      " |~~ train@64960  Loss: 0.002723 Acc: 13.1250\n",
      " |~~ train@65024  Loss: 0.001878 Acc: 13.3906\n",
      " |~~ train@65088  Loss: 0.001674 Acc: 13.4219\n",
      " |~~ train@65152  Loss: 0.001576 Acc: 13.5000\n",
      " |~~ train@65216  Loss: 0.001857 Acc: 13.3594\n",
      " |~~ train@65280  Loss: 0.001774 Acc: 13.4688\n",
      " |~~ train@65344  Loss: 0.001958 Acc: 13.3438\n",
      " |~~ train@65408  Loss: 0.002277 Acc: 13.2969\n",
      " |~~ train@65472  Loss: 0.001881 Acc: 13.4531\n",
      " |~~ train@65536  Loss: 0.002048 Acc: 13.3125\n",
      " |~~ train@65600  Loss: 0.001887 Acc: 13.3281\n",
      " |~~ train@65664  Loss: 0.002028 Acc: 13.2656\n",
      " |~~ train@65728  Loss: 0.002280 Acc: 13.2500\n",
      " |~~ train@65792  Loss: 0.001935 Acc: 13.3906\n",
      " |~~ train@65856  Loss: 0.002183 Acc: 13.3281\n",
      " |~~ train@65920  Loss: 0.002345 Acc: 13.2031\n",
      " |~~ train@65984  Loss: 0.001645 Acc: 13.4844\n",
      " |~~ train@66048  Loss: 0.002104 Acc: 13.2969\n",
      " |~~ train@66112  Loss: 0.001971 Acc: 13.3906\n",
      " |~~ train@66176  Loss: 0.001357 Acc: 13.5938\n",
      " |~~ train@66240  Loss: 0.001721 Acc: 13.4844\n",
      " |~~ train@66304  Loss: 0.001794 Acc: 13.4531\n",
      " |~~ train@66368  Loss: 0.002675 Acc: 13.0625\n",
      " |~~ train@66432  Loss: 0.002217 Acc: 13.2500\n",
      " |~~ train@66496  Loss: 0.001741 Acc: 13.4688\n",
      " |~~ train@66560  Loss: 0.001895 Acc: 13.3906\n",
      " |~~ train@66624  Loss: 0.002236 Acc: 13.3281\n",
      " |~~ train@66688  Loss: 0.002548 Acc: 13.1719\n",
      " |~~ train@66752  Loss: 0.002306 Acc: 13.2344\n",
      " |~~ train@66816  Loss: 0.001958 Acc: 13.4219\n",
      " |~~ train@66880  Loss: 0.001905 Acc: 13.4062\n",
      " |~~ train@66944  Loss: 0.002215 Acc: 13.2344\n",
      " |~~ train@67008  Loss: 0.001993 Acc: 13.3125\n",
      " |~~ train@67072  Loss: 0.002180 Acc: 13.2656\n",
      " |~~ train@67136  Loss: 0.001928 Acc: 13.3594\n",
      " |~~ train@67200  Loss: 0.001977 Acc: 13.3750\n",
      " |~~ train@67264  Loss: 0.001734 Acc: 13.5000\n",
      " |~~ train@67328  Loss: 0.001752 Acc: 13.3438\n",
      " |~~ train@67392  Loss: 0.001574 Acc: 13.5781\n",
      " |~~ train@67456  Loss: 0.001948 Acc: 13.3281\n",
      " |~~ train@67520  Loss: 0.001844 Acc: 13.3594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@67584  Loss: 0.002423 Acc: 13.2188\n",
      " |~~ train@67648  Loss: 0.001922 Acc: 13.3594\n",
      " |~~ train@67712  Loss: 0.002176 Acc: 13.1719\n",
      " |~~ train@67776  Loss: 0.002346 Acc: 13.2656\n",
      " |~~ train@67840  Loss: 0.001695 Acc: 13.5156\n",
      " |~~ train@67904  Loss: 0.002225 Acc: 13.2812\n",
      " |~~ train@67968  Loss: 0.002164 Acc: 13.2969\n",
      " |~~ train@68032  Loss: 0.002246 Acc: 13.2500\n",
      " |~~ train@68096  Loss: 0.001783 Acc: 13.3438\n",
      " |~~ train@68160  Loss: 0.002272 Acc: 13.2031\n",
      " |~~ train@68224  Loss: 0.002510 Acc: 13.2188\n",
      " |~~ train@68288  Loss: 0.001818 Acc: 13.5156\n",
      " |~~ train@68352  Loss: 0.002206 Acc: 13.2500\n",
      " |~~ train@68416  Loss: 0.001914 Acc: 13.3438\n",
      " |~~ train@68480  Loss: 0.002117 Acc: 13.3281\n",
      " |~~ train@68544  Loss: 0.001951 Acc: 13.4062\n",
      " |~~ train@68608  Loss: 0.001929 Acc: 13.3750\n",
      " |~~ train@68672  Loss: 0.002048 Acc: 13.4219\n",
      " |~~ train@68736  Loss: 0.001951 Acc: 13.4062\n",
      " |~~ train@68800  Loss: 0.001941 Acc: 13.3281\n",
      " |~~ train@68864  Loss: 0.002025 Acc: 13.2188\n",
      " |~~ train@68928  Loss: 0.001883 Acc: 13.3750\n",
      " |~~ train@68992  Loss: 0.001734 Acc: 13.4688\n",
      " |~~ train@69056  Loss: 0.001922 Acc: 13.2969\n",
      " |~~ train@69120  Loss: 0.002028 Acc: 13.2500\n",
      " |~~ train@69184  Loss: 0.002065 Acc: 13.3125\n",
      " |~~ train@69248  Loss: 0.002074 Acc: 13.2969\n",
      " |~~ train@69312  Loss: 0.001612 Acc: 13.5625\n",
      " |~~ train@69376  Loss: 0.001914 Acc: 13.3125\n",
      " |~~ train@69440  Loss: 0.001882 Acc: 13.4531\n",
      " |~~ train@69504  Loss: 0.002051 Acc: 13.2969\n",
      " |~~ train@69568  Loss: 0.001827 Acc: 13.3750\n",
      " |~~ train@69632  Loss: 0.002069 Acc: 13.2500\n",
      " |~~ train@69696  Loss: 0.002136 Acc: 13.2969\n",
      " |~~ train@69760  Loss: 0.001995 Acc: 13.3281\n",
      " |~~ train@69824  Loss: 0.002226 Acc: 13.3281\n",
      " |~~ train@69888  Loss: 0.001782 Acc: 13.4688\n",
      " |~~ train@69952  Loss: 0.001456 Acc: 13.5625\n",
      " |~~ train@70016  Loss: 0.001461 Acc: 13.4844\n",
      " |~~ train@70080  Loss: 0.001717 Acc: 13.4375\n",
      " |~~ train@70144  Loss: 0.002758 Acc: 13.0312\n",
      " |~~ train@70208  Loss: 0.001903 Acc: 13.2656\n",
      " |~~ train@70272  Loss: 0.002150 Acc: 13.2969\n",
      " |~~ train@70336  Loss: 0.002601 Acc: 13.1250\n",
      " |~~ train@70400  Loss: 0.002095 Acc: 13.2969\n",
      " |~~ train@70464  Loss: 0.001591 Acc: 13.4688\n",
      " |~~ train@70528  Loss: 0.001783 Acc: 13.3281\n",
      " |~~ train@70592  Loss: 0.002076 Acc: 13.4531\n",
      " |~~ train@70656  Loss: 0.001897 Acc: 13.4375\n",
      " |~~ train@70720  Loss: 0.002489 Acc: 13.1875\n",
      " |~~ train@70784  Loss: 0.002102 Acc: 13.3281\n",
      " |~~ train@70848  Loss: 0.002388 Acc: 13.2188\n",
      " |~~ train@70912  Loss: 0.002118 Acc: 13.2656\n",
      " |~~ train@70976  Loss: 0.002048 Acc: 13.3594\n",
      " |~~ train@71040  Loss: 0.001882 Acc: 13.4219\n",
      " |~~ train@71104  Loss: 0.001586 Acc: 13.5000\n",
      " |~~ train@71168  Loss: 0.002511 Acc: 13.1562\n",
      " |~~ train@71232  Loss: 0.002200 Acc: 13.3750\n",
      " |~~ train@71296  Loss: 0.002338 Acc: 13.1875\n",
      " |~~ train@71360  Loss: 0.002261 Acc: 13.2812\n",
      " |~~ train@71424  Loss: 0.002013 Acc: 13.2969\n",
      " |~~ train@71488  Loss: 0.002334 Acc: 13.3750\n",
      " |~~ train@71552  Loss: 0.001837 Acc: 13.3438\n",
      " |~~ train@71616  Loss: 0.001843 Acc: 13.4219\n",
      " |~~ train@71680  Loss: 0.001805 Acc: 13.4375\n",
      " |~~ train@71744  Loss: 0.002021 Acc: 13.3594\n",
      " |~~ train@71808  Loss: 0.002040 Acc: 13.3906\n",
      " |~~ train@71872  Loss: 0.001954 Acc: 13.3438\n",
      " |~~ train@71936  Loss: 0.002799 Acc: 13.0781\n",
      " |~~ train@72000  Loss: 0.002033 Acc: 13.3750\n",
      " |~~ train@72064  Loss: 0.001797 Acc: 13.3594\n",
      " |~~ train@72128  Loss: 0.001890 Acc: 13.4688\n",
      " |~~ train@72192  Loss: 0.001390 Acc: 13.5469\n",
      " |~~ train@72256  Loss: 0.001878 Acc: 13.3906\n",
      " |~~ train@72320  Loss: 0.002242 Acc: 13.2344\n",
      " |~~ train@72384  Loss: 0.001700 Acc: 13.5156\n",
      " |~~ train@72448  Loss: 0.002375 Acc: 13.1719\n",
      " |~~ train@72512  Loss: 0.002414 Acc: 13.1875\n",
      " |~~ train@72576  Loss: 0.002157 Acc: 13.3438\n",
      " |~~ train@72640  Loss: 0.001862 Acc: 13.3750\n",
      " |~~ train@72704  Loss: 0.001839 Acc: 13.3594\n",
      " |~~ train@72768  Loss: 0.001967 Acc: 13.4062\n",
      " |~~ train@72832  Loss: 0.001948 Acc: 13.4062\n",
      " |~~ train@72896  Loss: 0.001963 Acc: 13.4219\n",
      " |~~ train@72960  Loss: 0.001742 Acc: 13.4844\n",
      " |~~ train@73024  Loss: 0.002062 Acc: 13.3438\n",
      " |~~ train@73088  Loss: 0.001843 Acc: 13.4375\n",
      " |~~ train@73152  Loss: 0.001986 Acc: 13.3125\n",
      " |~~ train@73216  Loss: 0.002095 Acc: 13.3594\n",
      " |~~ train@73280  Loss: 0.001996 Acc: 13.3906\n",
      " |~~ train@73344  Loss: 0.001746 Acc: 13.4688\n",
      " |~~ train@73408  Loss: 0.001953 Acc: 13.3594\n",
      " |~~ train@73472  Loss: 0.002081 Acc: 13.3281\n",
      " |~~ train@73536  Loss: 0.001899 Acc: 13.4844\n",
      " |~~ train@73600  Loss: 0.001739 Acc: 13.4531\n",
      " |~~ train@73664  Loss: 0.001814 Acc: 13.4219\n",
      " |~~ train@73728  Loss: 0.001659 Acc: 13.4219\n",
      " |~~ train@73792  Loss: 0.001868 Acc: 13.4688\n",
      " |~~ train@73856  Loss: 0.002256 Acc: 13.2500\n",
      " |~~ train@73920  Loss: 0.001532 Acc: 13.5000\n",
      " |~~ train@73984  Loss: 0.001912 Acc: 13.3906\n",
      " |~~ train@74048  Loss: 0.001853 Acc: 13.3594\n",
      " |~~ train@74112  Loss: 0.001901 Acc: 13.4062\n",
      " |~~ train@74176  Loss: 0.001990 Acc: 13.3750\n",
      " |~~ train@74240  Loss: 0.002361 Acc: 13.2969\n",
      " |~~ train@74304  Loss: 0.001855 Acc: 13.3906\n",
      " |~~ train@74368  Loss: 0.001784 Acc: 13.4844\n",
      " |~~ train@74432  Loss: 0.002595 Acc: 13.0469\n",
      " |~~ train@74496  Loss: 0.002173 Acc: 13.2500\n",
      " |~~ train@74560  Loss: 0.002187 Acc: 13.1875\n",
      " |~~ train@74624  Loss: 0.002370 Acc: 13.2031\n",
      " |~~ train@74688  Loss: 0.002122 Acc: 13.3281\n",
      " |~~ train@74752  Loss: 0.002245 Acc: 13.2188\n",
      " |~~ train@74816  Loss: 0.001819 Acc: 13.4062\n",
      " |~~ train@74880  Loss: 0.001992 Acc: 13.4062\n",
      " |~~ train@74944  Loss: 0.002338 Acc: 13.2969\n",
      " |~~ train@75008  Loss: 0.002062 Acc: 13.2969\n",
      " |~~ train@75072  Loss: 0.002415 Acc: 13.2031\n",
      " |~~ train@75136  Loss: 0.001943 Acc: 13.2969\n",
      " |~~ train@75200  Loss: 0.002048 Acc: 13.3594\n",
      " |~~ train@75264  Loss: 0.001691 Acc: 13.5156\n",
      " |~~ train@75328  Loss: 0.001876 Acc: 13.4219\n",
      " |~~ train@75392  Loss: 0.002404 Acc: 13.2656\n",
      " |~~ train@75456  Loss: 0.002027 Acc: 13.3438\n",
      " |~~ train@75520  Loss: 0.002260 Acc: 13.2969\n",
      " |~~ train@75584  Loss: 0.001780 Acc: 13.4375\n",
      " |~~ train@75648  Loss: 0.001916 Acc: 13.3906\n",
      " |~~ train@75712  Loss: 0.002007 Acc: 13.3438\n",
      " |~~ train@75776  Loss: 0.001777 Acc: 13.4375\n",
      " |~~ train@75840  Loss: 0.001927 Acc: 13.3594\n",
      " |~~ train@75904  Loss: 0.001804 Acc: 13.3438\n",
      " |~~ train@75968  Loss: 0.001985 Acc: 13.2969\n",
      " |~~ train@76032  Loss: 0.002566 Acc: 13.1562\n",
      " |~~ train@76096  Loss: 0.001470 Acc: 13.5312\n",
      " |~~ train@76160  Loss: 0.002574 Acc: 13.1719\n",
      " |~~ train@76224  Loss: 0.001778 Acc: 13.5156\n",
      " |~~ train@76288  Loss: 0.002255 Acc: 13.3438\n",
      " |~~ train@76352  Loss: 0.002128 Acc: 13.2344\n",
      " |~~ train@76416  Loss: 0.001786 Acc: 13.4531\n",
      " |~~ train@76480  Loss: 0.001692 Acc: 13.4688\n",
      " |~~ train@76544  Loss: 0.001682 Acc: 13.4062\n",
      " |~~ train@76608  Loss: 0.001653 Acc: 13.5000\n",
      " |~~ train@76672  Loss: 0.001580 Acc: 13.5000\n",
      " |~~ train@76736  Loss: 0.002148 Acc: 13.3438\n",
      " |~~ train@76800  Loss: 0.001525 Acc: 13.5156\n",
      " |~~ train@76864  Loss: 0.002055 Acc: 13.3594\n",
      " |~~ train@76928  Loss: 0.002299 Acc: 13.2812\n",
      " |~~ train@76992  Loss: 0.001882 Acc: 13.4219\n",
      " |~~ train@77056  Loss: 0.002127 Acc: 13.3594\n",
      " |~~ train@77120  Loss: 0.002125 Acc: 13.3750\n",
      " |~~ train@77184  Loss: 0.001934 Acc: 13.2969\n",
      " |~~ train@77248  Loss: 0.001748 Acc: 13.3594\n",
      " |~~ train@77312  Loss: 0.002185 Acc: 13.2344\n",
      " |~~ train@77376  Loss: 0.001869 Acc: 13.3750\n",
      " |~~ train@77440  Loss: 0.001777 Acc: 13.4219\n",
      " |~~ train@77504  Loss: 0.002046 Acc: 13.3281\n",
      " |~~ train@77568  Loss: 0.001515 Acc: 13.5781\n",
      " |~~ train@77632  Loss: 0.002423 Acc: 13.0469\n",
      " |~~ train@77696  Loss: 0.002399 Acc: 13.2188\n",
      " |~~ train@77760  Loss: 0.001883 Acc: 13.4531\n",
      " |~~ train@77824  Loss: 0.001669 Acc: 13.4062\n",
      " |~~ train@77888  Loss: 0.001806 Acc: 13.4375\n",
      " |~~ train@77952  Loss: 0.001824 Acc: 13.2969\n",
      " |~~ train@78016  Loss: 0.001840 Acc: 13.3750\n",
      " |~~ train@78080  Loss: 0.001875 Acc: 13.4688\n",
      " |~~ train@78144  Loss: 0.001665 Acc: 13.3906\n",
      " |~~ train@78208  Loss: 0.001640 Acc: 13.3906\n",
      " |~~ train@78272  Loss: 0.002189 Acc: 13.2188\n",
      " |~~ train@78336  Loss: 0.002024 Acc: 13.4375\n",
      " |~~ train@78400  Loss: 0.001783 Acc: 13.4531\n",
      " |~~ train@78464  Loss: 0.002114 Acc: 13.4219\n",
      " |~~ train@78484  Loss: 0.006970 Acc: 13.3500\n",
      "train  Loss: 0.002003 Acc: 13.3512\n",
      " |~~ val@64  Loss: 0.002861 Acc: 13.0938\n",
      " |~~ val@128  Loss: 0.002437 Acc: 13.2656\n",
      " |~~ val@192  Loss: 0.002698 Acc: 13.1562\n",
      " |~~ val@256  Loss: 0.002616 Acc: 13.2188\n",
      " |~~ val@320  Loss: 0.002472 Acc: 13.2188\n",
      " |~~ val@384  Loss: 0.002556 Acc: 13.1250\n",
      " |~~ val@448  Loss: 0.002204 Acc: 13.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@512  Loss: 0.002568 Acc: 13.1406\n",
      " |~~ val@576  Loss: 0.002912 Acc: 13.0000\n",
      " |~~ val@640  Loss: 0.002637 Acc: 13.2188\n",
      " |~~ val@704  Loss: 0.002376 Acc: 13.2344\n",
      " |~~ val@768  Loss: 0.002538 Acc: 13.1875\n",
      " |~~ val@832  Loss: 0.002241 Acc: 13.2656\n",
      " |~~ val@896  Loss: 0.002188 Acc: 13.2188\n",
      " |~~ val@960  Loss: 0.002262 Acc: 13.3438\n",
      " |~~ val@1024  Loss: 0.002264 Acc: 13.2500\n",
      " |~~ val@1088  Loss: 0.002390 Acc: 13.2344\n",
      " |~~ val@1152  Loss: 0.002145 Acc: 13.4062\n",
      " |~~ val@1216  Loss: 0.002227 Acc: 13.3750\n",
      " |~~ val@1280  Loss: 0.002888 Acc: 13.0938\n",
      " |~~ val@1344  Loss: 0.002699 Acc: 13.2812\n",
      " |~~ val@1408  Loss: 0.002243 Acc: 13.3281\n",
      " |~~ val@1472  Loss: 0.002734 Acc: 13.1250\n",
      " |~~ val@1536  Loss: 0.002251 Acc: 13.2188\n",
      " |~~ val@1600  Loss: 0.002111 Acc: 13.4062\n",
      " |~~ val@1664  Loss: 0.001808 Acc: 13.5000\n",
      " |~~ val@1728  Loss: 0.002353 Acc: 13.2812\n",
      " |~~ val@1792  Loss: 0.001899 Acc: 13.4688\n",
      " |~~ val@1856  Loss: 0.003428 Acc: 12.9375\n",
      " |~~ val@1920  Loss: 0.002167 Acc: 13.3906\n",
      " |~~ val@1984  Loss: 0.002363 Acc: 13.3594\n",
      " |~~ val@2048  Loss: 0.002788 Acc: 13.1406\n",
      " |~~ val@2112  Loss: 0.002185 Acc: 13.3281\n",
      " |~~ val@2176  Loss: 0.002919 Acc: 13.1094\n",
      " |~~ val@2240  Loss: 0.003031 Acc: 13.0625\n",
      " |~~ val@2304  Loss: 0.002123 Acc: 13.3906\n",
      " |~~ val@2368  Loss: 0.001664 Acc: 13.5781\n",
      " |~~ val@2432  Loss: 0.002727 Acc: 13.1250\n",
      " |~~ val@2496  Loss: 0.002179 Acc: 13.4062\n",
      " |~~ val@2560  Loss: 0.002609 Acc: 13.2188\n",
      " |~~ val@2624  Loss: 0.002383 Acc: 13.2031\n",
      " |~~ val@2688  Loss: 0.002743 Acc: 13.0938\n",
      " |~~ val@2752  Loss: 0.002731 Acc: 13.1406\n",
      " |~~ val@2816  Loss: 0.001929 Acc: 13.2969\n",
      " |~~ val@2880  Loss: 0.002128 Acc: 13.4219\n",
      " |~~ val@2944  Loss: 0.002231 Acc: 13.3438\n",
      " |~~ val@3008  Loss: 0.002255 Acc: 13.3906\n",
      " |~~ val@3072  Loss: 0.002458 Acc: 13.1875\n",
      " |~~ val@3136  Loss: 0.001942 Acc: 13.4219\n",
      " |~~ val@3200  Loss: 0.002800 Acc: 13.2188\n",
      " |~~ val@3264  Loss: 0.002279 Acc: 13.3125\n",
      " |~~ val@3328  Loss: 0.002551 Acc: 13.1719\n",
      " |~~ val@3392  Loss: 0.002030 Acc: 13.3906\n",
      " |~~ val@3456  Loss: 0.002040 Acc: 13.2969\n",
      " |~~ val@3520  Loss: 0.001963 Acc: 13.4688\n",
      " |~~ val@3584  Loss: 0.002499 Acc: 13.2500\n",
      " |~~ val@3648  Loss: 0.002750 Acc: 13.1094\n",
      " |~~ val@3712  Loss: 0.002272 Acc: 13.3281\n",
      " |~~ val@3776  Loss: 0.002609 Acc: 13.3594\n",
      " |~~ val@3840  Loss: 0.002229 Acc: 13.4219\n",
      " |~~ val@3904  Loss: 0.001885 Acc: 13.3906\n",
      " |~~ val@3968  Loss: 0.001425 Acc: 13.5938\n",
      " |~~ val@4032  Loss: 0.002509 Acc: 13.2812\n",
      " |~~ val@4096  Loss: 0.002188 Acc: 13.2344\n",
      " |~~ val@4160  Loss: 0.002341 Acc: 13.2500\n",
      " |~~ val@4224  Loss: 0.001598 Acc: 13.5781\n",
      " |~~ val@4288  Loss: 0.002003 Acc: 13.3438\n",
      " |~~ val@4352  Loss: 0.002465 Acc: 13.1719\n",
      " |~~ val@4416  Loss: 0.002302 Acc: 13.2344\n",
      " |~~ val@4480  Loss: 0.003041 Acc: 13.0312\n",
      " |~~ val@4544  Loss: 0.001864 Acc: 13.3438\n",
      " |~~ val@4608  Loss: 0.002511 Acc: 13.2344\n",
      " |~~ val@4672  Loss: 0.002509 Acc: 13.3281\n",
      " |~~ val@4736  Loss: 0.002555 Acc: 13.2656\n",
      " |~~ val@4800  Loss: 0.002419 Acc: 13.3594\n",
      " |~~ val@4864  Loss: 0.001870 Acc: 13.4219\n",
      " |~~ val@4928  Loss: 0.003178 Acc: 13.0156\n",
      " |~~ val@4992  Loss: 0.002373 Acc: 13.2188\n",
      " |~~ val@5056  Loss: 0.002491 Acc: 13.1719\n",
      " |~~ val@5120  Loss: 0.002337 Acc: 13.4219\n",
      " |~~ val@5184  Loss: 0.002217 Acc: 13.3281\n",
      " |~~ val@5248  Loss: 0.002401 Acc: 13.3438\n",
      " |~~ val@5312  Loss: 0.002366 Acc: 13.2656\n",
      " |~~ val@5376  Loss: 0.002448 Acc: 13.2656\n",
      " |~~ val@5440  Loss: 0.002663 Acc: 13.2031\n",
      " |~~ val@5504  Loss: 0.002188 Acc: 13.3125\n",
      " |~~ val@5568  Loss: 0.002274 Acc: 13.3125\n",
      " |~~ val@5632  Loss: 0.002398 Acc: 13.3750\n",
      " |~~ val@5696  Loss: 0.002591 Acc: 13.1562\n",
      " |~~ val@5760  Loss: 0.002211 Acc: 13.2969\n",
      " |~~ val@5824  Loss: 0.002507 Acc: 13.2656\n",
      " |~~ val@5888  Loss: 0.002812 Acc: 13.0312\n",
      " |~~ val@5952  Loss: 0.002474 Acc: 13.2812\n",
      " |~~ val@6016  Loss: 0.002534 Acc: 13.2031\n",
      " |~~ val@6080  Loss: 0.002771 Acc: 13.0625\n",
      " |~~ val@6144  Loss: 0.002468 Acc: 13.2344\n",
      " |~~ val@6208  Loss: 0.002023 Acc: 13.3906\n",
      " |~~ val@6272  Loss: 0.002189 Acc: 13.3281\n",
      " |~~ val@6336  Loss: 0.002253 Acc: 13.3125\n",
      " |~~ val@6400  Loss: 0.002965 Acc: 13.1406\n",
      " |~~ val@6464  Loss: 0.002106 Acc: 13.3438\n",
      " |~~ val@6528  Loss: 0.002586 Acc: 13.2344\n",
      " |~~ val@6592  Loss: 0.003296 Acc: 12.9844\n",
      " |~~ val@6656  Loss: 0.002294 Acc: 13.3906\n",
      " |~~ val@6720  Loss: 0.001961 Acc: 13.4531\n",
      " |~~ val@6784  Loss: 0.002225 Acc: 13.2500\n",
      " |~~ val@6848  Loss: 0.002295 Acc: 13.2969\n",
      " |~~ val@6912  Loss: 0.002098 Acc: 13.4844\n",
      " |~~ val@6976  Loss: 0.002466 Acc: 13.3125\n",
      " |~~ val@7040  Loss: 0.002328 Acc: 13.1875\n",
      " |~~ val@7104  Loss: 0.002422 Acc: 13.2656\n",
      " |~~ val@7168  Loss: 0.002014 Acc: 13.4531\n",
      " |~~ val@7232  Loss: 0.002289 Acc: 13.2344\n",
      " |~~ val@7296  Loss: 0.001868 Acc: 13.4688\n",
      " |~~ val@7360  Loss: 0.002110 Acc: 13.4062\n",
      " |~~ val@7424  Loss: 0.001805 Acc: 13.3750\n",
      " |~~ val@7488  Loss: 0.002442 Acc: 13.2812\n",
      " |~~ val@7552  Loss: 0.002466 Acc: 13.2031\n",
      " |~~ val@7616  Loss: 0.002302 Acc: 13.2969\n",
      " |~~ val@7680  Loss: 0.002295 Acc: 13.3125\n",
      " |~~ val@7744  Loss: 0.002512 Acc: 13.2969\n",
      " |~~ val@7808  Loss: 0.001703 Acc: 13.4062\n",
      " |~~ val@7872  Loss: 0.002541 Acc: 13.3438\n",
      " |~~ val@7936  Loss: 0.002003 Acc: 13.3438\n",
      " |~~ val@8000  Loss: 0.002487 Acc: 13.2812\n",
      " |~~ val@8064  Loss: 0.002416 Acc: 13.2656\n",
      " |~~ val@8128  Loss: 0.002087 Acc: 13.4375\n",
      " |~~ val@8192  Loss: 0.002134 Acc: 13.2812\n",
      " |~~ val@8256  Loss: 0.002672 Acc: 13.2031\n",
      " |~~ val@8320  Loss: 0.002712 Acc: 13.2188\n",
      " |~~ val@8384  Loss: 0.001838 Acc: 13.4062\n",
      " |~~ val@8448  Loss: 0.002461 Acc: 13.1094\n",
      " |~~ val@8512  Loss: 0.002093 Acc: 13.5000\n",
      " |~~ val@8576  Loss: 0.002232 Acc: 13.3281\n",
      " |~~ val@8640  Loss: 0.002421 Acc: 13.2344\n",
      " |~~ val@8704  Loss: 0.002060 Acc: 13.4375\n",
      " |~~ val@8768  Loss: 0.002113 Acc: 13.4375\n",
      " |~~ val@8832  Loss: 0.002215 Acc: 13.3438\n",
      " |~~ val@8896  Loss: 0.002910 Acc: 13.0469\n",
      " |~~ val@8960  Loss: 0.002656 Acc: 13.1875\n",
      " |~~ val@9024  Loss: 0.002110 Acc: 13.2656\n",
      " |~~ val@9088  Loss: 0.002032 Acc: 13.2969\n",
      " |~~ val@9152  Loss: 0.002265 Acc: 13.2969\n",
      " |~~ val@9216  Loss: 0.002709 Acc: 13.1875\n",
      " |~~ val@9280  Loss: 0.002539 Acc: 13.1719\n",
      " |~~ val@9344  Loss: 0.002386 Acc: 13.1250\n",
      " |~~ val@9408  Loss: 0.003075 Acc: 13.0781\n",
      " |~~ val@9472  Loss: 0.002576 Acc: 13.2500\n",
      " |~~ val@9536  Loss: 0.001914 Acc: 13.3750\n",
      " |~~ val@9600  Loss: 0.002582 Acc: 13.1562\n",
      " |~~ val@9664  Loss: 0.002498 Acc: 13.2500\n",
      " |~~ val@9728  Loss: 0.002239 Acc: 13.3906\n",
      " |~~ val@9792  Loss: 0.002751 Acc: 13.1406\n",
      " |~~ val@9856  Loss: 0.002433 Acc: 13.2344\n",
      " |~~ val@9920  Loss: 0.002519 Acc: 13.2188\n",
      " |~~ val@9984  Loss: 0.003242 Acc: 12.9375\n",
      " |~~ val@10048  Loss: 0.002152 Acc: 13.3125\n",
      " |~~ val@10112  Loss: 0.002249 Acc: 13.2031\n",
      " |~~ val@10176  Loss: 0.003257 Acc: 13.1250\n",
      " |~~ val@10240  Loss: 0.002192 Acc: 13.3281\n",
      " |~~ val@10304  Loss: 0.001904 Acc: 13.4062\n",
      " |~~ val@10368  Loss: 0.001960 Acc: 13.3750\n",
      " |~~ val@10432  Loss: 0.002271 Acc: 13.3438\n",
      " |~~ val@10496  Loss: 0.002504 Acc: 13.2656\n",
      " |~~ val@10560  Loss: 0.002441 Acc: 13.2812\n",
      " |~~ val@10624  Loss: 0.002341 Acc: 13.3750\n",
      " |~~ val@10688  Loss: 0.002009 Acc: 13.3750\n",
      " |~~ val@10752  Loss: 0.002204 Acc: 13.3438\n",
      " |~~ val@10816  Loss: 0.002727 Acc: 13.0938\n",
      " |~~ val@10880  Loss: 0.002693 Acc: 13.2344\n",
      " |~~ val@10944  Loss: 0.002285 Acc: 13.2969\n",
      " |~~ val@11008  Loss: 0.002186 Acc: 13.2500\n",
      " |~~ val@11072  Loss: 0.002787 Acc: 13.2188\n",
      " |~~ val@11136  Loss: 0.002251 Acc: 13.3125\n",
      " |~~ val@11200  Loss: 0.002897 Acc: 13.0938\n",
      " |~~ val@11264  Loss: 0.002081 Acc: 13.3594\n",
      " |~~ val@11328  Loss: 0.002331 Acc: 13.3750\n",
      " |~~ val@11392  Loss: 0.002583 Acc: 13.1406\n",
      " |~~ val@11456  Loss: 0.002357 Acc: 13.2812\n",
      " |~~ val@11520  Loss: 0.002983 Acc: 13.1094\n",
      " |~~ val@11584  Loss: 0.002599 Acc: 13.1406\n",
      " |~~ val@11648  Loss: 0.002222 Acc: 13.3750\n",
      " |~~ val@11712  Loss: 0.002333 Acc: 13.2812\n",
      " |~~ val@11776  Loss: 0.002240 Acc: 13.3281\n",
      " |~~ val@11840  Loss: 0.002370 Acc: 13.3281\n",
      " |~~ val@11904  Loss: 0.002167 Acc: 13.2344\n",
      " |~~ val@11968  Loss: 0.002794 Acc: 13.1406\n",
      " |~~ val@12032  Loss: 0.002726 Acc: 13.1094\n",
      " |~~ val@12096  Loss: 0.002695 Acc: 13.1250\n",
      " |~~ val@12160  Loss: 0.002016 Acc: 13.4062\n",
      " |~~ val@12224  Loss: 0.002081 Acc: 13.2969\n",
      " |~~ val@12288  Loss: 0.002176 Acc: 13.3125\n",
      " |~~ val@12352  Loss: 0.002922 Acc: 13.1719\n",
      " |~~ val@12416  Loss: 0.002161 Acc: 13.2812\n",
      " |~~ val@12480  Loss: 0.002095 Acc: 13.2812\n",
      " |~~ val@12544  Loss: 0.002156 Acc: 13.3594\n",
      " |~~ val@12608  Loss: 0.002105 Acc: 13.3438\n",
      " |~~ val@12672  Loss: 0.002899 Acc: 13.1719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ val@12736  Loss: 0.002462 Acc: 13.2656\n",
      " |~~ val@12800  Loss: 0.002473 Acc: 13.3281\n",
      " |~~ val@12864  Loss: 0.002482 Acc: 13.2969\n",
      " |~~ val@12928  Loss: 0.002351 Acc: 13.3594\n",
      " |~~ val@12992  Loss: 0.002779 Acc: 13.2188\n",
      " |~~ val@13056  Loss: 0.002660 Acc: 13.1875\n",
      " |~~ val@13120  Loss: 0.002327 Acc: 13.3281\n",
      " |~~ val@13184  Loss: 0.002118 Acc: 13.2969\n",
      " |~~ val@13248  Loss: 0.002784 Acc: 13.1406\n",
      " |~~ val@13312  Loss: 0.002443 Acc: 13.2812\n",
      " |~~ val@13376  Loss: 0.002684 Acc: 13.0625\n",
      " |~~ val@13440  Loss: 0.002251 Acc: 13.2188\n",
      " |~~ val@13504  Loss: 0.002343 Acc: 13.2188\n",
      " |~~ val@13568  Loss: 0.001937 Acc: 13.4531\n",
      " |~~ val@13632  Loss: 0.002224 Acc: 13.3125\n",
      " |~~ val@13696  Loss: 0.002109 Acc: 13.3906\n",
      " |~~ val@13760  Loss: 0.002045 Acc: 13.4375\n",
      " |~~ val@13824  Loss: 0.002142 Acc: 13.3281\n",
      " |~~ val@13888  Loss: 0.002199 Acc: 13.2500\n",
      " |~~ val@13952  Loss: 0.002653 Acc: 13.2656\n",
      " |~~ val@14016  Loss: 0.002689 Acc: 13.2188\n",
      " |~~ val@14080  Loss: 0.002248 Acc: 13.2969\n",
      " |~~ val@14144  Loss: 0.002443 Acc: 13.2500\n",
      " |~~ val@14208  Loss: 0.001999 Acc: 13.4219\n",
      " |~~ val@14272  Loss: 0.002365 Acc: 13.2656\n",
      " |~~ val@14336  Loss: 0.003239 Acc: 12.9219\n",
      " |~~ val@14400  Loss: 0.002209 Acc: 13.2656\n",
      " |~~ val@14464  Loss: 0.002223 Acc: 13.4062\n",
      " |~~ val@14528  Loss: 0.001575 Acc: 13.5625\n",
      " |~~ val@14592  Loss: 0.002396 Acc: 13.2500\n",
      " |~~ val@14656  Loss: 0.002295 Acc: 13.3750\n",
      " |~~ val@14720  Loss: 0.002208 Acc: 13.3438\n",
      " |~~ val@14784  Loss: 0.002096 Acc: 13.4375\n",
      " |~~ val@14848  Loss: 0.002420 Acc: 13.2344\n",
      " |~~ val@14912  Loss: 0.003183 Acc: 13.1406\n",
      " |~~ val@14976  Loss: 0.002131 Acc: 13.4062\n",
      " |~~ val@15040  Loss: 0.002106 Acc: 13.2969\n",
      " |~~ val@15104  Loss: 0.002610 Acc: 13.2969\n",
      " |~~ val@15168  Loss: 0.003278 Acc: 13.0000\n",
      " |~~ val@15232  Loss: 0.002500 Acc: 13.3125\n",
      " |~~ val@15296  Loss: 0.002055 Acc: 13.4375\n",
      " |~~ val@15360  Loss: 0.002269 Acc: 13.2812\n",
      " |~~ val@15424  Loss: 0.002689 Acc: 13.1250\n",
      " |~~ val@15488  Loss: 0.002351 Acc: 13.3594\n",
      " |~~ val@15552  Loss: 0.002314 Acc: 13.2500\n",
      " |~~ val@15616  Loss: 0.002103 Acc: 13.4062\n",
      " |~~ val@15680  Loss: 0.002324 Acc: 13.3594\n",
      " |~~ val@15744  Loss: 0.002460 Acc: 13.2031\n",
      " |~~ val@15808  Loss: 0.001879 Acc: 13.5000\n",
      " |~~ val@15872  Loss: 0.002987 Acc: 13.0000\n",
      " |~~ val@15936  Loss: 0.002273 Acc: 13.2812\n",
      " |~~ val@16000  Loss: 0.002270 Acc: 13.3125\n",
      " |~~ val@16064  Loss: 0.002534 Acc: 13.2500\n",
      " |~~ val@16128  Loss: 0.002665 Acc: 13.1562\n",
      " |~~ val@16192  Loss: 0.002329 Acc: 13.3906\n",
      " |~~ val@16256  Loss: 0.002100 Acc: 13.4219\n",
      " |~~ val@16320  Loss: 0.002238 Acc: 13.3750\n",
      " |~~ val@16384  Loss: 0.002242 Acc: 13.2500\n",
      " |~~ val@16448  Loss: 0.002762 Acc: 13.0469\n",
      " |~~ val@16512  Loss: 0.002128 Acc: 13.3594\n",
      " |~~ val@16576  Loss: 0.002628 Acc: 13.0938\n",
      " |~~ val@16640  Loss: 0.002585 Acc: 13.1875\n",
      " |~~ val@16704  Loss: 0.002727 Acc: 13.2656\n",
      " |~~ val@16768  Loss: 0.002319 Acc: 13.3750\n",
      " |~~ val@16832  Loss: 0.002486 Acc: 13.2812\n",
      " |~~ val@16896  Loss: 0.002002 Acc: 13.4062\n",
      " |~~ val@16960  Loss: 0.001778 Acc: 13.4531\n",
      " |~~ val@17024  Loss: 0.002065 Acc: 13.4219\n",
      " |~~ val@17088  Loss: 0.002696 Acc: 13.0781\n",
      " |~~ val@17152  Loss: 0.002087 Acc: 13.2969\n",
      " |~~ val@17216  Loss: 0.002059 Acc: 13.4375\n",
      " |~~ val@17280  Loss: 0.002048 Acc: 13.4844\n",
      " |~~ val@17344  Loss: 0.002344 Acc: 13.2656\n",
      " |~~ val@17408  Loss: 0.002646 Acc: 13.3125\n",
      " |~~ val@17472  Loss: 0.002172 Acc: 13.3594\n",
      " |~~ val@17536  Loss: 0.002278 Acc: 13.2500\n",
      " |~~ val@17600  Loss: 0.002208 Acc: 13.3750\n",
      " |~~ val@17664  Loss: 0.002720 Acc: 13.1875\n",
      " |~~ val@17728  Loss: 0.002434 Acc: 13.2812\n",
      " |~~ val@17792  Loss: 0.002196 Acc: 13.3906\n",
      " |~~ val@17856  Loss: 0.002084 Acc: 13.3594\n",
      " |~~ val@17920  Loss: 0.001984 Acc: 13.4062\n",
      " |~~ val@17984  Loss: 0.001917 Acc: 13.3906\n",
      " |~~ val@18048  Loss: 0.002696 Acc: 13.2031\n",
      " |~~ val@18112  Loss: 0.002027 Acc: 13.3281\n",
      " |~~ val@18176  Loss: 0.002048 Acc: 13.4844\n",
      " |~~ val@18240  Loss: 0.002120 Acc: 13.3750\n",
      " |~~ val@18304  Loss: 0.002770 Acc: 13.3125\n",
      " |~~ val@18368  Loss: 0.002832 Acc: 13.1875\n",
      " |~~ val@18432  Loss: 0.001869 Acc: 13.4375\n",
      " |~~ val@18496  Loss: 0.002604 Acc: 13.2969\n",
      " |~~ val@18560  Loss: 0.002266 Acc: 13.2969\n",
      " |~~ val@18624  Loss: 0.001834 Acc: 13.5469\n",
      " |~~ val@18688  Loss: 0.002257 Acc: 13.2969\n",
      " |~~ val@18752  Loss: 0.002361 Acc: 13.2656\n",
      " |~~ val@18816  Loss: 0.002665 Acc: 13.1250\n",
      " |~~ val@18880  Loss: 0.002984 Acc: 13.0625\n",
      " |~~ val@18944  Loss: 0.002275 Acc: 13.2812\n",
      " |~~ val@19008  Loss: 0.003066 Acc: 13.0000\n",
      " |~~ val@19072  Loss: 0.002055 Acc: 13.3438\n",
      " |~~ val@19136  Loss: 0.002136 Acc: 13.3594\n",
      " |~~ val@19200  Loss: 0.002357 Acc: 13.3281\n",
      " |~~ val@19264  Loss: 0.001931 Acc: 13.4688\n",
      " |~~ val@19328  Loss: 0.002570 Acc: 13.2656\n",
      " |~~ val@19392  Loss: 0.002252 Acc: 13.2969\n",
      " |~~ val@19456  Loss: 0.001798 Acc: 13.3594\n",
      " |~~ val@19520  Loss: 0.002396 Acc: 13.2500\n",
      " |~~ val@19584  Loss: 0.002467 Acc: 13.2969\n",
      " |~~ val@19648  Loss: 0.002627 Acc: 13.1094\n",
      " |~~ val@19712  Loss: 0.001701 Acc: 13.4219\n",
      " |~~ val@19776  Loss: 0.002482 Acc: 13.2188\n",
      " |~~ val@19840  Loss: 0.002426 Acc: 13.2812\n",
      " |~~ val@19904  Loss: 0.002574 Acc: 13.2812\n",
      " |~~ val@19968  Loss: 0.002026 Acc: 13.4219\n",
      " |~~ val@20032  Loss: 0.001966 Acc: 13.4062\n",
      " |~~ val@20096  Loss: 0.002837 Acc: 13.2031\n",
      " |~~ val@20160  Loss: 0.002850 Acc: 13.1406\n",
      " |~~ val@20224  Loss: 0.002530 Acc: 13.3281\n",
      " |~~ val@20288  Loss: 0.002958 Acc: 13.1094\n",
      " |~~ val@20352  Loss: 0.002662 Acc: 13.2969\n",
      " |~~ val@20416  Loss: 0.002679 Acc: 13.2812\n",
      " |~~ val@20480  Loss: 0.002432 Acc: 13.2344\n",
      " |~~ val@20544  Loss: 0.002183 Acc: 13.3125\n",
      " |~~ val@20608  Loss: 0.002516 Acc: 13.2500\n",
      " |~~ val@20672  Loss: 0.002329 Acc: 13.2500\n",
      " |~~ val@20736  Loss: 0.002815 Acc: 13.1406\n",
      " |~~ val@20800  Loss: 0.002326 Acc: 13.2500\n",
      " |~~ val@20864  Loss: 0.002498 Acc: 13.1875\n",
      " |~~ val@20928  Loss: 0.002242 Acc: 13.3438\n",
      " |~~ val@20992  Loss: 0.002469 Acc: 13.2812\n",
      " |~~ val@21056  Loss: 0.002552 Acc: 13.1875\n",
      " |~~ val@21120  Loss: 0.002673 Acc: 13.3125\n",
      " |~~ val@21184  Loss: 0.002411 Acc: 13.2344\n",
      " |~~ val@21248  Loss: 0.002357 Acc: 13.4844\n",
      " |~~ val@21312  Loss: 0.002361 Acc: 13.2812\n",
      " |~~ val@21376  Loss: 0.002694 Acc: 13.1875\n",
      " |~~ val@21440  Loss: 0.001936 Acc: 13.4531\n",
      " |~~ val@21504  Loss: 0.002388 Acc: 13.3281\n",
      " |~~ val@21568  Loss: 0.002243 Acc: 13.3906\n",
      " |~~ val@21632  Loss: 0.002309 Acc: 13.2344\n",
      " |~~ val@21696  Loss: 0.002020 Acc: 13.4062\n",
      " |~~ val@21760  Loss: 0.002475 Acc: 13.2344\n",
      " |~~ val@21824  Loss: 0.002318 Acc: 13.2500\n",
      " |~~ val@21888  Loss: 0.002142 Acc: 13.4375\n",
      " |~~ val@21952  Loss: 0.001993 Acc: 13.4219\n",
      " |~~ val@22016  Loss: 0.001952 Acc: 13.3906\n",
      " |~~ val@22080  Loss: 0.002699 Acc: 13.1094\n",
      " |~~ val@22144  Loss: 0.002583 Acc: 13.1562\n",
      " |~~ val@22208  Loss: 0.002178 Acc: 13.2656\n",
      " |~~ val@22272  Loss: 0.002011 Acc: 13.3438\n",
      " |~~ val@22336  Loss: 0.002528 Acc: 13.2812\n",
      " |~~ val@22400  Loss: 0.002318 Acc: 13.2500\n",
      " |~~ val@22424  Loss: 0.004605 Acc: 13.3750\n",
      "val  Loss: 0.002375 Acc: 13.2804\n",
      "Training complete in 55m 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d (3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d (64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d (128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d (256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "    (fc): Linear(in_features=512, out_features=14)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model_ft,\n",
    "            criterion,\n",
    "            optimizer_ft,\n",
    "            learning_scheduler,\n",
    "            num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model results to S3\n",
    "\n",
    "aws s3 cp ResNet18PlusFlexibleFC_Epoch9.tar s3://bdh-xrayproj-modelparameters/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.list_buckets()\n",
    "\n",
    "S3 Commands: http://docs.aws.amazon.com/cli/latest/userguide/using-s3-commands.html\n",
    "\n",
    "Boto3 QuickStart: http://boto3.readthedocs.io/en/latest/guide/quickstart.html\n",
    "\n",
    "Key Management: https://aws.amazon.com/blogs/security/a-safer-way-to-distribute-aws-credentials-to-ec2/\n",
    "\n",
    "AWS IAM Rules: http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-api.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

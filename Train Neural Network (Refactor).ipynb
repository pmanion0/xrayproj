{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ddb34fde-926f-42f6-8bfc-b1b19cb4881d"
    }
   },
   "source": [
    "# High-Level Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "80e3fe37-bc30-43b7-91c3-474b94a16db6"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:279: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "# General Python Packages\n",
    "import os, time, numbers, math\n",
    "\n",
    "# Torch Packages\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim import lr_scheduler, SGD\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import Module\n",
    "\n",
    "# General Analytics Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization / Image Packages\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Randomization Functions\n",
    "from random import random as randuni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "9b582614-ccd7-4f48-8b66-a49ebe66807f"
    }
   },
   "outputs": [],
   "source": [
    "# Put MatPlotLib in interactive mode\n",
    "plt.ion()\n",
    "\n",
    "# Plot graphics inline in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classes and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6fed3f3e-b14a-457d-95d2-c3726ce0fb3e"
    }
   },
   "source": [
    "### Image Data Utility Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "f962c744-4459-4ca1-851c-a19fe8457118"
    }
   },
   "outputs": [],
   "source": [
    "def is_image_file(fname):\n",
    "    \"\"\"Checks if a file is an image.\n",
    "    Args:\n",
    "        fname (string): path to a file\n",
    "    Returns:\n",
    "        bool: True if the filename ends with a known image extension\n",
    "    \"\"\"\n",
    "    return fname.lower().endswith('.png')\n",
    "\n",
    "def create_label_maps(details_df):\n",
    "    \"\"\" Take a descriptive dataframe and extract the unique labels and map to index values\n",
    "    Args:\n",
    "        details_df: Dataframe with the image details\n",
    "    Returns:\n",
    "        label_list: list of unique labels in the dataframe\n",
    "        label_to_index: map from labels to indices\n",
    "    \"\"\"\n",
    "    \"\"\" TODO: Research paper also excludes these labels but need to figure out how to handle\n",
    "              cases that have these as positive findings (completely exclude?)\n",
    "    excluded_labels = ['Edema','Hernia','Emphysema','Fibrosis','No Finding'\n",
    "                      'Pleural_Thickening','Consolidation']\n",
    "    \"\"\"\n",
    "    excluded_labels = ['No Finding']\n",
    "    \n",
    "    label_groups = details_df['Finding Labels'].unique()\n",
    "    unique_labels = set([label for sublist in label_groups.tolist() for label in sublist.split('|')])\n",
    "    \n",
    "    # Drop some label that we do not want to include\n",
    "    unique_labels = [l for l in unique_labels if l not in excluded_labels]\n",
    "\n",
    "    index_to_label = {idx: val for idx, val in enumerate(unique_labels)}\n",
    "    label_to_index = {val: idx for idx, val in index_to_label.items()}\n",
    "\n",
    "    label_list = list(label_to_index.keys())\n",
    "\n",
    "    return label_list, label_to_index\n",
    "\n",
    "def create_image_list(dir):\n",
    "    \"\"\" Create a full list of images available \n",
    "    Args:\n",
    "        dir (string): root directory of images with subdirectories underneath\n",
    "                      that have the .png images within them\n",
    "    Returns:\n",
    "        image_list: list of tuples with (image_name, full_image_path)\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    dir = os.path.expanduser(dir)\n",
    "    for subfolder in sorted(os.listdir(dir)):\n",
    "        d = os.path.join(dir, subfolder)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        for subfolder_path, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if is_image_file(fname):\n",
    "                    path = os.path.join(subfolder_path, fname)\n",
    "                    image_list.append((fname, path))\n",
    "    return image_list\n",
    "\n",
    "def pil_loader(path):\n",
    "    \"\"\" Opens path as file with Pillow (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    Args:\n",
    "        path (string): File path to the image\n",
    "    Returns:\n",
    "        img: Image in RGB format\n",
    "    \"\"\"\n",
    "    f = open(path, 'rb')\n",
    "    return Image.open(f)\n",
    "    #with open(path, 'rb') as f:\n",
    "    #    return Image.open(f)\n",
    "        #with Image.open(f) as img:\n",
    "        #    return img.load()\n",
    "        \n",
    "def imshow(inp, title=None):\n",
    "    \"\"\" Convert tensor array to an image (only use post-dataset transform) \"\"\"\n",
    "    inp = inp[0]\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d5d91972-9d4b-4022-842b-22c823f98fff"
    }
   },
   "source": [
    "### Torch Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "5bf4e82b-13ca-4ac2-bbb6-3081e820ab4e"
    }
   },
   "outputs": [],
   "source": [
    "class XrayImageSet(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image_root (string): root directory of the images in form image/subfolder/*.png\n",
    "        csv_file (string): path to the CSV data file\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an image given its path.\n",
    "     Attributes:\n",
    "        labels (list): list of the possible label names.\n",
    "        label_to_index (dict): look from label name to a label index\n",
    "        imgs (list): List of (filename, image path) tuples\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_root, csv_file, transform=None, target_transform=None, loader = pil_loader):\n",
    "        \"\"\" Create an instance of the Xray Dataset \"\"\"\n",
    "        img_details = pd.read_csv(csv_file)\n",
    "        \n",
    "        labels, label_to_index = create_label_maps(img_details)\n",
    "        imgs = create_image_list(image_root)\n",
    "\n",
    "        self.imgs = imgs\n",
    "        self.image_details = img_details\n",
    "        self.image_root = image_root\n",
    "        self.labels = labels\n",
    "        self.label_to_index = label_to_index\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.max_label_index = max(label_to_index.values())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get image,labels pair by index\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        fname, path = self.imgs[index]\n",
    "        target = self.get_one_hot_labels(fname)\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Calculate length of the dataset (number of images) \"\"\"\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def get_labels(self, fname):\n",
    "        \"\"\" Return the label string for the file \"\"\"\n",
    "        return self.image_details[self.image_details['Image Index'] == fname]['Finding Labels'].values[0]\n",
    "    \n",
    "    def one_hot_labels(self, labels):\n",
    "        \"\"\" Convert the labels string (with each label separated by |) into 1-hot encoding \"\"\"\n",
    "        if labels == None:\n",
    "            return None\n",
    "        \n",
    "        split_label_indices = [self.label_to_index.get(label)\n",
    "                               for label in labels.split('|')\n",
    "                               if label != 'No Finding']\n",
    "        \n",
    "        out = [1 if idx in split_label_indices else 0 for idx in range(self.max_label_index+1)]\n",
    "        # This code UNHOTs the labels:\n",
    "        # out = '|'.join([index_to_label.get(idx) for idx, val in enumerate(one_hot_tuple) if val == 1])\n",
    "        return out\n",
    "\n",
    "    def get_one_hot_labels(self, fname):\n",
    "        \"\"\" Get the 1-hot encoded label array for the provided file \"\"\"\n",
    "        labels = self.get_labels(fname)\n",
    "        one_hot_labels = self.one_hot_labels(labels)\n",
    "        return torch.FloatTensor(one_hot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Output Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "166ce9d1-ff17-4047-b9ae-b4903393ad15"
    }
   },
   "outputs": [],
   "source": [
    "class printer_writer:\n",
    "    def __init__(self, output_folder_path):\n",
    "        self.start_time = time.strftime('%Y%m%d-%Hh%Mm%Ss')\n",
    "        \n",
    "        self.outprefix = output_folder_path + '/' + self.start_time\n",
    "        \n",
    "        # Print Output File\n",
    "        self.print_out_path = self.outprefix + '_print.txt'\n",
    "        self.print_out_file = open(self.print_out_path, 'w', 1)\n",
    "        \n",
    "    def printw(self, string):\n",
    "        print(string)\n",
    "        try:\n",
    "            self.print_out_file.write(string + \"\\n\")\n",
    "        except: # Ignore errors\n",
    "            pass\n",
    "        \n",
    "    def save_checkpoint(self, epoch, model, optimizer, scheduler, val_error):\n",
    "        model_out_path = self.outprefix + '_model_' + str(epoch+1) + '.tar'\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'state': model.state_dict(),\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "            'val_error': val_error\n",
    "        }, model_out_path)\n",
    "        \n",
    "    def close(self):\n",
    "        self.print_out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "eb99e6e4-00db-494a-ad27-70005761f49e"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, outfolder = '/user/xrayproj/output/'):\n",
    "    since = time.time()\n",
    "    scribe = printer_writer(outfolder)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        scribe.printw('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        scribe.printw('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            obs_counter = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Store statistics (convert from autograd.Variable to float/int)\n",
    "                loss_val = loss.data[0]\n",
    "                correct_val = torch.sum( ((outputs.sigmoid()>0.5) == (labels>0.5)).long() ).data[0]\n",
    "                \n",
    "                running_loss += loss_val\n",
    "                running_corrects += correct_val\n",
    "                \n",
    "                obs_counter += len(inputs)\n",
    "                \n",
    "                batch_loss = 1.0 * loss_val / len(inputs)\n",
    "                batch_acc = 1.0 * correct_val / len(inputs)\n",
    "                status = ' |~~ {}@{}  Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    phase, obs_counter, batch_loss, batch_acc)\n",
    "                scribe.printw(status)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            scribe.printw('{}  Loss: {:.6f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Store the model on disk\n",
    "            if phase == 'val':\n",
    "                scheduler.step(epoch_loss)\n",
    "                if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    scribe.save_checkpoint(epoch, model, optimizer, None, epoch_loss)\n",
    "                else:\n",
    "                    scribe.save_checkpoint(epoch, model, optimizer, scheduler, epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    scribe.printw('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    scribe.close()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5e6eebab-809d-4550-b771-135dbf2b893d"
    }
   },
   "source": [
    "### Customized Binary Cross Entropy Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "f66b439c-1f87-4d08-939d-f64d085b846b"
    }
   },
   "outputs": [],
   "source": [
    "class BCEWithLogitsImbalanceWeightedLoss(Module):\n",
    "    def __init__(self, class_weight=None, size_average=True):\n",
    "        super(BCEWithLogitsImbalanceWeightedLoss, self).__init__()\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return self.imbalance_weighted_bce_with_logit(input, target, size_average=self.size_average)\n",
    "    \n",
    "    def imbalance_weighted_bce_with_logit(self, input, target, size_average=True):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        # Determine |P| and |N|\n",
    "        positive_labels = target.sum()\n",
    "        negative_labels = (1-target).sum()\n",
    "\n",
    "        # Upweight the less common class (very often the 1s)\n",
    "        beta_p = (positive_labels + negative_labels) / positive_labels\n",
    "        beta_n = (positive_labels + negative_labels) / negative_labels\n",
    "\n",
    "        # Adjust the losses accordingly\n",
    "        loss_weight = target * beta_p + (1-target) * beta_n\n",
    "\n",
    "        loss = loss * loss_weight\n",
    "\n",
    "        if size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TotalSumMeter:\n",
    "    def __init__(self):\n",
    "        self.obs_counter = 0.0\n",
    "        self.total_pred = Variable(torch.FloatTensor(torch.zeros(14)), volatile=True)\n",
    "        self.total_act = Variable(torch.FloatTensor(torch.zeros(14)), volatile=True)\n",
    "        \n",
    "    def update(self, preds, actuals):\n",
    "        self.total_act += actuals.sum(0).cpu()\n",
    "        self.total_pred += preds.sum(0).cpu()\n",
    "        self.obs_counter += len(actuals)\n",
    "        \n",
    "    def get_results(self):\n",
    "        return {\n",
    "            'pred': self.total_pred / self.obs_counter,\n",
    "            'act': self.total_act / self.obs_counter\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassAUCMeter:\n",
    "    \"\"\" Wrapper on the normal AUCMeter to handle multi-class predictions \"\"\"\n",
    "    def __init__(self, num_class):\n",
    "        self.num_class = num_class\n",
    "        self.meters = []\n",
    "        for i in range(self.num_class):\n",
    "            self.meters.append(AUCMeter())\n",
    "\n",
    "    def add(self, output, target):\n",
    "        for i in range(self.num_class):\n",
    "            self.meters[i].add(output[:,i], target[:,i])\n",
    "        \n",
    "    def value(self):\n",
    "        output = []\n",
    "        for i in range(self.num_class):\n",
    "            output.append(self.meters[i].value())\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCMeter:\n",
    "    \"\"\"\n",
    "    SOURCE: https://github.com/pytorch/tnt/blob/master/torchnet/meter/aucmeter.py\n",
    "    \n",
    "    The AUCMeter measures the area under the receiver-operating characteristic\n",
    "    (ROC) curve for binary classification problems. The area under the curve (AUC)\n",
    "    can be interpreted as the probability that, given a randomly selected positive\n",
    "    example and a randomly selected negative example, the positive example is\n",
    "    assigned a higher score by the classification model than the negative example.\n",
    "    The AUCMeter is designed to operate on one-dimensional Tensors `output`\n",
    "    and `target`, where (1) the `output` contains model output scores that ought to\n",
    "    be higher when the model is more convinced that the example should be positively\n",
    "    labeled, and smaller when the model believes the example should be negatively\n",
    "    labeled (for instance, the output of a signoid function); and (2) the `target`\n",
    "    contains only values 0 (for negative examples) and 1 (for positive examples).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(AUCMeter, self).__init__()\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.scores = torch.DoubleTensor(torch.DoubleStorage()).numpy()\n",
    "        self.targets = torch.LongTensor(torch.LongStorage()).numpy()\n",
    "\n",
    "    def add(self, output, target):\n",
    "        if torch.is_tensor(output):\n",
    "            output = output.cpu().squeeze().numpy()\n",
    "        if torch.is_tensor(target):\n",
    "            target = target.cpu().squeeze().numpy()\n",
    "        elif isinstance(target, numbers.Number):\n",
    "            target = np.asarray([target])\n",
    "        assert np.ndim(output) == 1, \\\n",
    "            'wrong output size (1D expected)'\n",
    "        assert np.ndim(target) == 1, \\\n",
    "            'wrong target size (1D expected)'\n",
    "        assert output.shape[0] == target.shape[0], \\\n",
    "            'number of outputs and targets does not match'\n",
    "        assert np.all(np.add(np.equal(target, 1), np.equal(target, 0))), \\\n",
    "            'targets should be binary (0, 1)'\n",
    "\n",
    "        self.scores = np.append(self.scores, output)\n",
    "        self.targets = np.append(self.targets, target)\n",
    "\n",
    "    def value(self):\n",
    "        # case when number of elements added are 0\n",
    "        if self.scores.shape[0] == 0:\n",
    "            return 0.5\n",
    "\n",
    "        # sorting the arrays\n",
    "        scores, sortind = torch.sort(torch.from_numpy(self.scores), dim=0, descending=True)\n",
    "        scores = scores.numpy()\n",
    "        sortind = sortind.numpy()\n",
    "\n",
    "        # creating the roc curve\n",
    "        tpr = np.zeros(shape=(scores.size + 1), dtype=np.float64)\n",
    "        fpr = np.zeros(shape=(scores.size + 1), dtype=np.float64)\n",
    "\n",
    "        for i in range(1, scores.size + 1):\n",
    "            if self.targets[sortind[i - 1]] == 1:\n",
    "                tpr[i] = tpr[i - 1] + 1\n",
    "                fpr[i] = fpr[i - 1]\n",
    "            else:\n",
    "                tpr[i] = tpr[i - 1]\n",
    "                fpr[i] = fpr[i - 1] + 1\n",
    "\n",
    "        tpr /= (self.targets.sum() * 1.0)\n",
    "        fpr /= ((self.targets - 1.0).sum() * -1.0)\n",
    "\n",
    "        # calculating area under curve using trapezoidal rule\n",
    "        n = tpr.shape[0]\n",
    "        h = fpr[1:n] - fpr[0:n - 1]\n",
    "        sum_h = np.zeros(fpr.shape)\n",
    "        sum_h[0:n - 1] = h\n",
    "        sum_h[1:n] += h\n",
    "        area = (sum_h * tpr).sum() / 2.0\n",
    "\n",
    "        return (area, tpr, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, dataset, num_classes = 14):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.num_classes = num_classes\n",
    "        self.is_run = False\n",
    "        \n",
    "    def score_obs(self, data_row):\n",
    "        inputs, actuals = data_row\n",
    "\n",
    "        inputs = Variable(inputs.cuda(), volatile=True)\n",
    "        actuals = Variable(actuals.cuda(), volatile=True)\n",
    "\n",
    "        outputs = self.model(inputs)\n",
    "        preds = outputs.sigmoid()\n",
    "        \n",
    "        return preds, actuals\n",
    "    \n",
    "    def run(self, force_rerun = False):\n",
    "        if self.is_run and not force_rerun:\n",
    "            print(\"Already evaluated this...\")\n",
    "            return None\n",
    "        \n",
    "        self.model.train(False)\n",
    "    \n",
    "        self.m_total_sums = TotalSumMeter()\n",
    "        self.m_auc = MultiClassAUCMeter(self.num_classes)\n",
    "\n",
    "        for data in self.dataset:\n",
    "            preds, actuals = self.score_obs(data)\n",
    "\n",
    "            self.m_total_sums.update(preds, actuals)\n",
    "            self.m_auc.add(preds.data, actuals.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetBase(base_size = 18, only_update_fc = True):\n",
    "    \"\"\" ResNet 18 with only final FC layer updatable \"\"\"\n",
    "    m = None\n",
    "    if base_size == 18:\n",
    "        m = models.resnet18(pretrained=True)\n",
    "    elif base_size == 34:\n",
    "        m = models.resnet34(pretrained=True)\n",
    "    elif base_size == 50:\n",
    "        m = models.resnet50(pretrained=True)\n",
    "    elif base_size == 101:\n",
    "        m = models.resnet101(pretrained=True)\n",
    "    elif base_size == 152:\n",
    "        m = models.resnet152(pretrained=True)\n",
    "    \n",
    "    if only_update_fc:\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    m.fc = nn.Linear(m.fc.in_features, len(img_data_train.labels))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean ± std. dev. of 7 runs, 10000000 loops each\n",
    "\n",
    "#### Time for __get_item__\n",
    "```\n",
    "%timeit img_data_train[3] # 30.8 ms ± 544 µs per loop\n",
    "```\n",
    "\n",
    "#### Breakdown for __get_item__\n",
    "```\n",
    "%timeit img_data_train.imgs[8] # 63 ns ± 0.0057 ns per loop\n",
    "%timeit img_data_train.get_one_hot_labels('00011558_012.png') # 8.72 ms ± 9.44 µs per loop\n",
    "%timeit img_data_train.loader('/user/images/images_006/00011558_012.png') # 14.1 ms ± 3.41 µs per loop\n",
    "%timeit img_data_train.transform(img) # 3.17 ms ± 1.32 µs per loop\n",
    "```\n",
    "\n",
    "#### Breakdown for loader() from __get_item__\n",
    "```\n",
    "%timeit open('/user/images/images_006/00011558_012.png', 'rb') # 7.72 µs ± 13.4 ns per loop\n",
    "%timeit Image.open(f) # 37.5 µs ± 2.25 µs per loop\n",
    "%timeit img.convert('RGB') # 498 µs ± 149 ns per loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Begin Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b6f705b5-c4e4-4fbd-a517-f0c3b58c4305"
    }
   },
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU: 1\n"
     ]
    }
   ],
   "source": [
    "nn_input_size = 224 #1024\n",
    "batch_size = 64\n",
    "pin_mem_setting = True\n",
    "num_gpus = torch.cuda.device_count()\n",
    "num_workers = 10\n",
    "\n",
    "print(\"Number of GPU: {}\".format(num_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbpresent": {
     "id": "6716d746-b7b1-4aff-aec0-2bd91632bf28"
    }
   },
   "outputs": [],
   "source": [
    "img_transforms_train = transforms.Compose(\n",
    "    [#transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms_nontrain = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbpresent": {
     "id": "62d30308-7ecb-40f4-a831-dd0a9274618a"
    }
   },
   "outputs": [],
   "source": [
    "img_data_train = XrayImageSet(image_root = '/user/images_processed/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms_train,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_train.imgs = [img for i, img in enumerate(img_data_train.imgs) if i % 10 >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbpresent": {
     "id": "13f86c44-50f2-4809-8ee1-afb0d8ec0b7a"
    }
   },
   "outputs": [],
   "source": [
    "img_data_val   = XrayImageSet(image_root = '/user/images_processed/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms_nontrain,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_val.imgs = [img for i, img in enumerate(img_data_val.imgs) if i % 10 in (1,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_test  = XrayImageSet(image_root = '/user/images_processed/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms_nontrain,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_test.imgs = [img for i, img in enumerate(img_data_test.imgs) if i % 10 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = set(img_data_train.imgs)\n",
    "val_set = set(img_data_val.imgs)\n",
    "test_set = set(img_data_test.imgs)\n",
    "assert len(train_set.intersection(val_set)) == 0\n",
    "assert len(train_set.intersection(test_set)) == 0\n",
    "assert len(val_set.intersection(test_set)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbpresent": {
     "id": "09ab4157-ad5b-4602-8b93-85c86bd5a620"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 78484\n",
      "Validation Set Size: 22424\n",
      "Test Set Size: 11212\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Size: {}\".format(len(img_data_train)))\n",
    "print(\"Validation Set Size: {}\".format(len(img_data_val)))\n",
    "print(\"Test Set Size: {}\".format(len(img_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbpresent": {
     "id": "1001fa5d-b820-4da6-9d18-0ee7f4462b90"
    }
   },
   "outputs": [],
   "source": [
    "img_loader_train = DataLoader(img_data_train,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = num_workers,\n",
    "                              pin_memory = pin_mem_setting)\n",
    "\n",
    "img_loader_val   = DataLoader(img_data_val,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = num_workers,\n",
    "                              pin_memory = pin_mem_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbpresent": {
     "id": "0e1d2cb0-4d0f-4ab1-a1cf-cd66a3e298a2"
    }
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': img_loader_train,\n",
    "    'val': img_loader_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "nbpresent": {
     "id": "91946119-bf67-4871-92af-649559fa9bfd"
    }
   },
   "outputs": [],
   "source": [
    "model_base = ResNetBase(base_size = 18, only_update_fc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "nbpresent": {
     "id": "0a904f1f-73ac-418b-86cf-cdafdf0f67b1"
    }
   },
   "outputs": [],
   "source": [
    "model_ft = DataParallel(model_base).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e6851de2-8645-4547-9f00-414ad8a3811a"
    }
   },
   "source": [
    "### Setup learning rates and procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "nbpresent": {
     "id": "1d61f077-84ec-4d2c-bdb0-82b28f8c4ed9"
    }
   },
   "outputs": [],
   "source": [
    "#criterion = BCEWithLogitsImbalanceWeightedLoss()\n",
    "criterion_base = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer_ft = SGD(model_ft.module.fc.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer_ft = SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "learning_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = criterion_base.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future code for allowing optimization of the base layer with a lower learning rate\n",
    "\n",
    "```\n",
    "ignored_params = list(map(id, model.fc.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model.parameters())\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "            {'params': base_params},\n",
    "            {'params': model.fc.parameters(), 'lr': opt.lr}\n",
    "        ], lr=opt.lr*0.1, momentum=0.9)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2f9596b5-a2fc-4e0c-984b-4e13b68dcd6d"
    }
   },
   "source": [
    "# Begin Training Network (Normal Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f1672c30-c299-4265-934b-6af391d9de8c"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      " |~~ train@64  Loss: 0.011634 Acc: 6.9219\n",
      " |~~ train@128  Loss: 0.010655 Acc: 7.9219\n",
      " |~~ train@192  Loss: 0.009005 Acc: 10.2656\n",
      " |~~ train@256  Loss: 0.007177 Acc: 12.5156\n",
      " |~~ train@320  Loss: 0.005410 Acc: 13.4219\n",
      " |~~ train@384  Loss: 0.004334 Acc: 13.3438\n",
      " |~~ train@448  Loss: 0.003355 Acc: 13.4062\n",
      " |~~ train@512  Loss: 0.003276 Acc: 13.2656\n",
      " |~~ train@576  Loss: 0.003737 Acc: 13.0312\n",
      " |~~ train@640  Loss: 0.003266 Acc: 13.1875\n",
      " |~~ train@704  Loss: 0.002882 Acc: 13.2969\n",
      " |~~ train@768  Loss: 0.003613 Acc: 13.1562\n",
      " |~~ train@832  Loss: 0.002868 Acc: 13.3281\n",
      " |~~ train@896  Loss: 0.002253 Acc: 13.5312\n",
      " |~~ train@960  Loss: 0.003345 Acc: 13.3125\n",
      " |~~ train@1024  Loss: 0.002522 Acc: 13.4844\n",
      " |~~ train@1088  Loss: 0.003177 Acc: 13.3438\n",
      " |~~ train@1152  Loss: 0.004283 Acc: 13.0781\n",
      " |~~ train@1216  Loss: 0.002363 Acc: 13.5312\n",
      " |~~ train@1280  Loss: 0.003883 Acc: 13.1406\n",
      " |~~ train@1344  Loss: 0.002413 Acc: 13.5156\n",
      " |~~ train@1408  Loss: 0.002887 Acc: 13.2969\n",
      " |~~ train@1472  Loss: 0.002823 Acc: 13.3750\n",
      " |~~ train@1536  Loss: 0.003398 Acc: 13.2656\n",
      " |~~ train@1600  Loss: 0.003287 Acc: 13.2969\n",
      " |~~ train@1664  Loss: 0.004059 Acc: 13.1562\n",
      " |~~ train@1728  Loss: 0.002964 Acc: 13.2969\n",
      " |~~ train@1792  Loss: 0.002778 Acc: 13.4688\n",
      " |~~ train@1856  Loss: 0.002538 Acc: 13.4062\n",
      " |~~ train@1920  Loss: 0.004051 Acc: 13.1094\n",
      " |~~ train@1984  Loss: 0.003294 Acc: 13.3594\n",
      " |~~ train@2048  Loss: 0.004164 Acc: 13.1250\n",
      " |~~ train@2112  Loss: 0.002905 Acc: 13.4219\n",
      " |~~ train@2176  Loss: 0.003233 Acc: 13.2500\n",
      " |~~ train@2240  Loss: 0.003449 Acc: 13.2969\n",
      " |~~ train@2304  Loss: 0.003540 Acc: 13.1719\n",
      " |~~ train@2368  Loss: 0.003526 Acc: 13.2188\n",
      " |~~ train@2432  Loss: 0.003280 Acc: 13.2344\n",
      " |~~ train@2496  Loss: 0.002921 Acc: 13.3750\n",
      " |~~ train@2560  Loss: 0.002867 Acc: 13.3594\n",
      " |~~ train@2624  Loss: 0.002910 Acc: 13.3281\n",
      " |~~ train@2688  Loss: 0.002805 Acc: 13.3125\n",
      " |~~ train@2752  Loss: 0.002708 Acc: 13.4219\n",
      " |~~ train@2816  Loss: 0.002460 Acc: 13.4531\n",
      " |~~ train@2880  Loss: 0.002989 Acc: 13.2812\n",
      " |~~ train@2944  Loss: 0.003066 Acc: 13.2656\n",
      " |~~ train@3008  Loss: 0.003762 Acc: 13.0938\n",
      " |~~ train@3072  Loss: 0.002549 Acc: 13.4688\n",
      " |~~ train@3136  Loss: 0.002752 Acc: 13.2656\n",
      " |~~ train@3200  Loss: 0.002934 Acc: 13.3281\n",
      " |~~ train@3264  Loss: 0.002143 Acc: 13.5156\n",
      " |~~ train@3328  Loss: 0.003453 Acc: 13.1250\n",
      " |~~ train@3392  Loss: 0.003054 Acc: 13.2500\n",
      " |~~ train@3456  Loss: 0.002865 Acc: 13.2656\n",
      " |~~ train@3520  Loss: 0.002656 Acc: 13.3750\n",
      " |~~ train@3584  Loss: 0.002580 Acc: 13.3750\n",
      " |~~ train@3648  Loss: 0.002554 Acc: 13.4219\n",
      " |~~ train@3712  Loss: 0.003261 Acc: 13.1562\n",
      " |~~ train@3776  Loss: 0.002882 Acc: 13.2188\n",
      " |~~ train@3840  Loss: 0.002706 Acc: 13.3750\n",
      " |~~ train@3904  Loss: 0.003616 Acc: 13.2188\n",
      " |~~ train@3968  Loss: 0.003127 Acc: 13.2500\n",
      " |~~ train@4032  Loss: 0.002191 Acc: 13.4375\n",
      " |~~ train@4096  Loss: 0.002888 Acc: 13.2656\n",
      " |~~ train@4160  Loss: 0.002721 Acc: 13.3438\n",
      " |~~ train@4224  Loss: 0.003409 Acc: 13.1875\n",
      " |~~ train@4288  Loss: 0.003195 Acc: 13.1406\n",
      " |~~ train@4352  Loss: 0.003008 Acc: 13.2188\n",
      " |~~ train@4416  Loss: 0.003304 Acc: 13.1875\n",
      " |~~ train@4480  Loss: 0.002949 Acc: 13.3125\n",
      " |~~ train@4544  Loss: 0.002784 Acc: 13.3281\n",
      " |~~ train@4608  Loss: 0.002665 Acc: 13.4219\n",
      " |~~ train@4672  Loss: 0.003082 Acc: 13.2031\n",
      " |~~ train@4736  Loss: 0.003017 Acc: 13.2031\n",
      " |~~ train@4800  Loss: 0.003979 Acc: 12.9219\n",
      " |~~ train@4864  Loss: 0.002337 Acc: 13.4375\n",
      " |~~ train@4928  Loss: 0.002882 Acc: 13.2656\n",
      " |~~ train@4992  Loss: 0.002789 Acc: 13.2969\n",
      " |~~ train@5056  Loss: 0.002746 Acc: 13.3438\n",
      " |~~ train@5120  Loss: 0.003393 Acc: 13.0938\n",
      " |~~ train@5184  Loss: 0.002679 Acc: 13.3594\n",
      " |~~ train@5248  Loss: 0.002890 Acc: 13.2500\n",
      " |~~ train@5312  Loss: 0.002653 Acc: 13.3594\n",
      " |~~ train@5376  Loss: 0.002844 Acc: 13.2344\n",
      " |~~ train@5440  Loss: 0.003331 Acc: 13.0938\n",
      " |~~ train@5504  Loss: 0.003042 Acc: 13.2344\n",
      " |~~ train@5568  Loss: 0.002467 Acc: 13.4062\n",
      " |~~ train@5632  Loss: 0.002476 Acc: 13.4062\n",
      " |~~ train@5696  Loss: 0.002997 Acc: 13.2500\n",
      " |~~ train@5760  Loss: 0.003097 Acc: 13.2344\n",
      " |~~ train@5824  Loss: 0.003134 Acc: 13.1719\n",
      " |~~ train@5888  Loss: 0.003173 Acc: 13.1406\n",
      " |~~ train@5952  Loss: 0.002710 Acc: 13.3438\n",
      " |~~ train@6016  Loss: 0.002191 Acc: 13.4375\n",
      " |~~ train@6080  Loss: 0.003106 Acc: 13.1562\n",
      " |~~ train@6144  Loss: 0.002955 Acc: 13.2031\n",
      " |~~ train@6208  Loss: 0.003020 Acc: 13.2031\n",
      " |~~ train@6272  Loss: 0.003070 Acc: 13.2500\n",
      " |~~ train@6336  Loss: 0.003111 Acc: 13.2031\n",
      " |~~ train@6400  Loss: 0.003095 Acc: 13.1719\n",
      " |~~ train@6464  Loss: 0.002582 Acc: 13.3281\n",
      " |~~ train@6528  Loss: 0.002369 Acc: 13.4375\n",
      " |~~ train@6592  Loss: 0.003111 Acc: 13.2188\n",
      " |~~ train@6656  Loss: 0.003997 Acc: 12.9219\n",
      " |~~ train@6720  Loss: 0.003281 Acc: 13.1250\n",
      " |~~ train@6784  Loss: 0.002945 Acc: 13.2344\n",
      " |~~ train@6848  Loss: 0.002619 Acc: 13.3750\n",
      " |~~ train@6912  Loss: 0.003106 Acc: 13.2344\n",
      " |~~ train@6976  Loss: 0.002568 Acc: 13.3750\n",
      " |~~ train@7040  Loss: 0.002876 Acc: 13.2031\n",
      " |~~ train@7104  Loss: 0.003564 Acc: 13.0781\n",
      " |~~ train@7168  Loss: 0.002577 Acc: 13.4062\n",
      " |~~ train@7232  Loss: 0.003208 Acc: 13.1094\n",
      " |~~ train@7296  Loss: 0.002786 Acc: 13.3125\n",
      " |~~ train@7360  Loss: 0.003121 Acc: 13.1719\n",
      " |~~ train@7424  Loss: 0.002992 Acc: 13.1406\n",
      " |~~ train@7488  Loss: 0.002913 Acc: 13.2500\n",
      " |~~ train@7552  Loss: 0.002957 Acc: 13.2656\n",
      " |~~ train@7616  Loss: 0.002286 Acc: 13.4844\n",
      " |~~ train@7680  Loss: 0.003655 Acc: 13.0312\n",
      " |~~ train@7744  Loss: 0.002694 Acc: 13.2656\n",
      " |~~ train@7808  Loss: 0.002909 Acc: 13.2969\n",
      " |~~ train@7872  Loss: 0.003246 Acc: 13.1406\n",
      " |~~ train@7936  Loss: 0.002789 Acc: 13.3125\n",
      " |~~ train@8000  Loss: 0.002327 Acc: 13.4375\n",
      " |~~ train@8064  Loss: 0.003008 Acc: 13.2500\n",
      " |~~ train@8128  Loss: 0.002703 Acc: 13.3125\n",
      " |~~ train@8192  Loss: 0.002714 Acc: 13.2969\n",
      " |~~ train@8256  Loss: 0.003113 Acc: 13.2188\n",
      " |~~ train@8320  Loss: 0.003301 Acc: 13.1406\n",
      " |~~ train@8384  Loss: 0.002637 Acc: 13.3125\n",
      " |~~ train@8448  Loss: 0.002545 Acc: 13.3438\n",
      " |~~ train@8512  Loss: 0.002701 Acc: 13.3906\n",
      " |~~ train@8576  Loss: 0.003019 Acc: 13.2344\n",
      " |~~ train@8640  Loss: 0.002994 Acc: 13.2812\n",
      " |~~ train@8704  Loss: 0.002711 Acc: 13.3125\n",
      " |~~ train@8768  Loss: 0.003344 Acc: 13.0938\n",
      " |~~ train@8832  Loss: 0.002480 Acc: 13.3594\n",
      " |~~ train@8896  Loss: 0.002852 Acc: 13.2031\n",
      " |~~ train@8960  Loss: 0.002641 Acc: 13.3594\n",
      " |~~ train@9024  Loss: 0.002600 Acc: 13.3906\n",
      " |~~ train@9088  Loss: 0.002433 Acc: 13.4062\n",
      " |~~ train@9152  Loss: 0.002973 Acc: 13.1875\n",
      " |~~ train@9216  Loss: 0.002514 Acc: 13.4219\n",
      " |~~ train@9280  Loss: 0.003455 Acc: 13.1562\n",
      " |~~ train@9344  Loss: 0.002531 Acc: 13.3906\n",
      " |~~ train@9408  Loss: 0.002395 Acc: 13.4375\n",
      " |~~ train@9472  Loss: 0.003149 Acc: 13.1562\n",
      " |~~ train@9536  Loss: 0.003225 Acc: 13.1562\n",
      " |~~ train@9600  Loss: 0.002634 Acc: 13.3750\n",
      " |~~ train@9664  Loss: 0.002982 Acc: 13.2500\n",
      " |~~ train@9728  Loss: 0.002691 Acc: 13.3125\n",
      " |~~ train@9792  Loss: 0.002452 Acc: 13.3906\n",
      " |~~ train@9856  Loss: 0.003426 Acc: 13.0938\n",
      " |~~ train@9920  Loss: 0.003223 Acc: 13.2031\n",
      " |~~ train@9984  Loss: 0.002623 Acc: 13.3594\n",
      " |~~ train@10048  Loss: 0.003013 Acc: 13.2656\n",
      " |~~ train@10112  Loss: 0.002724 Acc: 13.3438\n",
      " |~~ train@10176  Loss: 0.003138 Acc: 13.1250\n",
      " |~~ train@10240  Loss: 0.003219 Acc: 13.0625\n",
      " |~~ train@10304  Loss: 0.002608 Acc: 13.3750\n",
      " |~~ train@10368  Loss: 0.002860 Acc: 13.2344\n",
      " |~~ train@10432  Loss: 0.002960 Acc: 13.2969\n",
      " |~~ train@10496  Loss: 0.003279 Acc: 13.1562\n",
      " |~~ train@10560  Loss: 0.003739 Acc: 13.0312\n",
      " |~~ train@10624  Loss: 0.002984 Acc: 13.2812\n",
      " |~~ train@10688  Loss: 0.003449 Acc: 13.1406\n",
      " |~~ train@10752  Loss: 0.002302 Acc: 13.4375\n",
      " |~~ train@10816  Loss: 0.002505 Acc: 13.3594\n",
      " |~~ train@10880  Loss: 0.002879 Acc: 13.2969\n",
      " |~~ train@10944  Loss: 0.003157 Acc: 13.1406\n",
      " |~~ train@11008  Loss: 0.002759 Acc: 13.2500\n",
      " |~~ train@11072  Loss: 0.003079 Acc: 13.2031\n",
      " |~~ train@11136  Loss: 0.003557 Acc: 13.0781\n",
      " |~~ train@11200  Loss: 0.002846 Acc: 13.2500\n",
      " |~~ train@11264  Loss: 0.003225 Acc: 13.1719\n",
      " |~~ train@11328  Loss: 0.002928 Acc: 13.1719\n",
      " |~~ train@11392  Loss: 0.002542 Acc: 13.4062\n",
      " |~~ train@11456  Loss: 0.003388 Acc: 13.1719\n",
      " |~~ train@11520  Loss: 0.003254 Acc: 13.0938\n",
      " |~~ train@11584  Loss: 0.002546 Acc: 13.3750\n",
      " |~~ train@11648  Loss: 0.002814 Acc: 13.2656\n",
      " |~~ train@11712  Loss: 0.003262 Acc: 13.1719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@11776  Loss: 0.003176 Acc: 13.1719\n",
      " |~~ train@11840  Loss: 0.003065 Acc: 13.1875\n",
      " |~~ train@11904  Loss: 0.002752 Acc: 13.3281\n",
      " |~~ train@11968  Loss: 0.002826 Acc: 13.3438\n",
      " |~~ train@12032  Loss: 0.002832 Acc: 13.2031\n",
      " |~~ train@12096  Loss: 0.002732 Acc: 13.3594\n",
      " |~~ train@12160  Loss: 0.003303 Acc: 13.1250\n",
      " |~~ train@12224  Loss: 0.002940 Acc: 13.2344\n",
      " |~~ train@12288  Loss: 0.002836 Acc: 13.2812\n",
      " |~~ train@12352  Loss: 0.002915 Acc: 13.2188\n",
      " |~~ train@12416  Loss: 0.003329 Acc: 13.0938\n",
      " |~~ train@12480  Loss: 0.002755 Acc: 13.2969\n",
      " |~~ train@12544  Loss: 0.002221 Acc: 13.4531\n",
      " |~~ train@12608  Loss: 0.002919 Acc: 13.2344\n",
      " |~~ train@12672  Loss: 0.003227 Acc: 13.1875\n",
      " |~~ train@12736  Loss: 0.003162 Acc: 13.1094\n",
      " |~~ train@12800  Loss: 0.002673 Acc: 13.3125\n",
      " |~~ train@12864  Loss: 0.002903 Acc: 13.2500\n",
      " |~~ train@12928  Loss: 0.002525 Acc: 13.3594\n",
      " |~~ train@12992  Loss: 0.002238 Acc: 13.4688\n",
      " |~~ train@13056  Loss: 0.003073 Acc: 13.2344\n",
      " |~~ train@13120  Loss: 0.002783 Acc: 13.2188\n",
      " |~~ train@13184  Loss: 0.002146 Acc: 13.5000\n",
      " |~~ train@13248  Loss: 0.002773 Acc: 13.2500\n",
      " |~~ train@13312  Loss: 0.003514 Acc: 13.0469\n",
      " |~~ train@13376  Loss: 0.002916 Acc: 13.2188\n",
      " |~~ train@13440  Loss: 0.002497 Acc: 13.3594\n",
      " |~~ train@13504  Loss: 0.002987 Acc: 13.2188\n",
      " |~~ train@13568  Loss: 0.003347 Acc: 13.0625\n",
      " |~~ train@13632  Loss: 0.002858 Acc: 13.2812\n",
      " |~~ train@13696  Loss: 0.002925 Acc: 13.2656\n",
      " |~~ train@13760  Loss: 0.003678 Acc: 13.0312\n",
      " |~~ train@13824  Loss: 0.003280 Acc: 13.1562\n",
      " |~~ train@13888  Loss: 0.002737 Acc: 13.3594\n",
      " |~~ train@13952  Loss: 0.003055 Acc: 13.2031\n",
      " |~~ train@14016  Loss: 0.002476 Acc: 13.3594\n",
      " |~~ train@14080  Loss: 0.002089 Acc: 13.5469\n",
      " |~~ train@14144  Loss: 0.002523 Acc: 13.2812\n",
      " |~~ train@14208  Loss: 0.002974 Acc: 13.2031\n",
      " |~~ train@14272  Loss: 0.003140 Acc: 13.2500\n",
      " |~~ train@14336  Loss: 0.002704 Acc: 13.3438\n",
      " |~~ train@14400  Loss: 0.002682 Acc: 13.3125\n",
      " |~~ train@14464  Loss: 0.003140 Acc: 13.0938\n",
      " |~~ train@14528  Loss: 0.002320 Acc: 13.4062\n",
      " |~~ train@14592  Loss: 0.002603 Acc: 13.3125\n",
      " |~~ train@14656  Loss: 0.002692 Acc: 13.3438\n",
      " |~~ train@14720  Loss: 0.002767 Acc: 13.3125\n",
      " |~~ train@14784  Loss: 0.003276 Acc: 13.0625\n",
      " |~~ train@14848  Loss: 0.002608 Acc: 13.3438\n",
      " |~~ train@14912  Loss: 0.003132 Acc: 13.1406\n",
      " |~~ train@14976  Loss: 0.002655 Acc: 13.2812\n",
      " |~~ train@15040  Loss: 0.002631 Acc: 13.2656\n",
      " |~~ train@15104  Loss: 0.003371 Acc: 13.1094\n",
      " |~~ train@15168  Loss: 0.002951 Acc: 13.2656\n",
      " |~~ train@15232  Loss: 0.002692 Acc: 13.3594\n",
      " |~~ train@15296  Loss: 0.002594 Acc: 13.4062\n",
      " |~~ train@15360  Loss: 0.002346 Acc: 13.3750\n",
      " |~~ train@15424  Loss: 0.002564 Acc: 13.3281\n",
      " |~~ train@15488  Loss: 0.002635 Acc: 13.2812\n",
      " |~~ train@15552  Loss: 0.002351 Acc: 13.3906\n",
      " |~~ train@15616  Loss: 0.002510 Acc: 13.2969\n",
      " |~~ train@15680  Loss: 0.002901 Acc: 13.2188\n",
      " |~~ train@15744  Loss: 0.002943 Acc: 13.2656\n",
      " |~~ train@15808  Loss: 0.002504 Acc: 13.3906\n",
      " |~~ train@15872  Loss: 0.003236 Acc: 13.1250\n",
      " |~~ train@15936  Loss: 0.002506 Acc: 13.3594\n",
      " |~~ train@16000  Loss: 0.002898 Acc: 13.2344\n",
      " |~~ train@16064  Loss: 0.002632 Acc: 13.3281\n"
     ]
    }
   ],
   "source": [
    "train_model(model_ft,\n",
    "            criterion,\n",
    "            optimizer_ft,\n",
    "            learning_scheduler,\n",
    "            num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model results to S3\n",
    "\n",
    "aws s3 cp ResNet18PlusFlexibleFC_Epoch9.tar s3://bdh-xrayproj-modelparameters/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.list_buckets()\n",
    "\n",
    "S3 Commands: http://docs.aws.amazon.com/cli/latest/userguide/using-s3-commands.html\n",
    "\n",
    "Boto3 QuickStart: http://boto3.readthedocs.io/en/latest/guide/quickstart.html\n",
    "\n",
    "Key Management: https://aws.amazon.com/blogs/security/a-safer-way-to-distribute-aws-credentials-to-ec2/\n",
    "\n",
    "AWS IAM Rules: http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAHJCAYAAAAW4NEbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiax/wQR1y7PMiEqjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccacaedbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Training Sums\")\n",
    "#plot_compare_sums(epoch_evals[epoch]['train'])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Validation Sums\")\n",
    "plot_compare_sums(epoch_evals[epoch]['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "nbpresent": {
     "id": "9235665b-a758-4c35-a922-55466a19bd44"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING ITERATION...\n",
      "PROCESSING FIRST 750 OBSERVATIONS\n",
      "STARTING ITERATION...\n",
      "PROCESSING FIRST 406 OBSERVATIONS\n"
     ]
    }
   ],
   "source": [
    "out_model_30.train(mode=False)\n",
    "\n",
    "obs_counter = 0\n",
    "total_pred = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "total_act = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "\n",
    "conf_a = {}\n",
    "conf_b = {}\n",
    "conf_c = {}\n",
    "conf_d = {}\n",
    "for i in range(1,10):\n",
    "    conf_a[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_b[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_c[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_d[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "\n",
    "for data in dataloaders['val']:\n",
    "    print(\"STARTING ITERATION...\")\n",
    "    inputs, labels = data\n",
    "    print(\"PROCESSING FIRST {} OBSERVATIONS\".format(len(inputs)))\n",
    "\n",
    "    inputs = Variable(inputs.cuda())\n",
    "    labels = Variable(labels.cuda())\n",
    "\n",
    "    outputs = out_model_30(inputs).sigmoid()\n",
    "    \n",
    "    total_act += labels.sum(0).cpu()\n",
    "    total_pred += outputs.sum(0).cpu()\n",
    "\n",
    "    # Store statistics (convert from autograd.Variable to float/int)\n",
    "    for i in range(1,10):\n",
    "        t = i/10\n",
    "        conf_a[i] += ((outputs.sigmoid()>t) == (labels>0.5)).sum(0).cpu().float()\n",
    "        conf_b[i] += ((outputs.sigmoid()<t) == (labels>0.5)).sum(0).cpu().float()\n",
    "        conf_c[i] += ((outputs.sigmoid()>t) == (labels<0.5)).sum(0).cpu().float()\n",
    "        conf_d[i] += ((outputs.sigmoid()<t) == (labels<0.5)).sum(0).cpu().float()\n",
    "\n",
    "    obs_counter += len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "nbpresent": {
     "id": "82758b84-e7ce-48d3-a3e1-f012ab124eea"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00 -2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00 -2.1475e+09  0.0000e+00 -2.1475e+09  0.0000e+00\n",
      " 6.2634e+06 -1.0000e+00 -2.1475e+09  0.0000e+00 -2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "Columns 6 to 11 \n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00 -6.5460e+04  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "-2.1475e+09  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "-2.1475e+09  0.0000e+00 -2.1475e+09 -2.1475e+09 -2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "Columns 12 to 13 \n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      "-2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      "[torch.IntTensor of size 9x14]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comparison = Variable(torch.FloatTensor(9, 14))\n",
    "for i in range(9):\n",
    "    comparison[0] = conf_a[1] / obs_counter\n",
    "print(comparison.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model_run(model, dataset):\n",
    "    dataset\n",
    "    for data in self.dataset:\n",
    "        inputs, actuals = data\n",
    "\n",
    "        inputs = Variable(inputs.cuda(), volatile=True)\n",
    "        actuals = Variable(actuals.cuda(), volatile=True)\n",
    "\n",
    "        outputs = self.model(inputs)\n",
    "        preds = outputs.sigmoid()\n",
    "\n",
    "        self.m_total_sums.update(preds, actuals)\n",
    "        self.m_auc.add(preds, actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ddb34fde-926f-42f6-8bfc-b1b19cb4881d"
    }
   },
   "source": [
    "# Import and High-Level Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "nbpresent": {
     "id": "80e3fe37-bc30-43b7-91c3-474b94a16db6"
    }
   },
   "outputs": [],
   "source": [
    "# General Python Packages\n",
    "import os, time, numbers, math\n",
    "\n",
    "# Torch Packages\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim import lr_scheduler, SGD\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import Module\n",
    "\n",
    "# General Analytics Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization / Image Packages\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Randomization Functions\n",
    "from random import random as randuni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "nbpresent": {
     "id": "9b582614-ccd7-4f48-8b66-a49ebe66807f"
    }
   },
   "outputs": [],
   "source": [
    "# Put MatPlotLib in interactive mode\n",
    "plt.ion()\n",
    "\n",
    "# Plot graphics inline in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "97faafc3-219d-4a56-b587-32a9c2550eac"
    }
   },
   "source": [
    "# Define Data Manipulation Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6fed3f3e-b14a-457d-95d2-c3726ce0fb3e"
    }
   },
   "source": [
    "### Helper Utility Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "nbpresent": {
     "id": "f962c744-4459-4ca1-851c-a19fe8457118"
    }
   },
   "outputs": [],
   "source": [
    "def is_image_file(fname):\n",
    "    \"\"\"Checks if a file is an image.\n",
    "    Args:\n",
    "        fname (string): path to a file\n",
    "    Returns:\n",
    "        bool: True if the filename ends with a known image extension\n",
    "    \"\"\"\n",
    "    return fname.lower().endswith('.png')\n",
    "\n",
    "def create_label_maps(details_df):\n",
    "    \"\"\" Take a descriptive dataframe and extract the unique labels and map to index values\n",
    "    Args:\n",
    "        details_df: Dataframe with the image details\n",
    "    Returns:\n",
    "        label_list: list of unique labels in the dataframe\n",
    "        label_to_index: map from labels to indices\n",
    "    \"\"\"\n",
    "    \"\"\" TODO: Research paper also excludes these labels but need to figure out how to handle\n",
    "              cases that have these as positive findings (completely exclude?)\n",
    "    excluded_labels = ['Edema','Hernia','Emphysema','Fibrosis','No Finding'\n",
    "                      'Pleural_Thickening','Consolidation']\n",
    "    \"\"\"\n",
    "    excluded_labels = ['No Finding']\n",
    "    \n",
    "    label_groups = details_df['Finding Labels'].unique()\n",
    "    unique_labels = set([label for sublist in label_groups.tolist() for label in sublist.split('|')])\n",
    "    \n",
    "    # Drop some label that we do not want to include\n",
    "    unique_labels = [l for l in unique_labels if l not in excluded_labels]\n",
    "\n",
    "    index_to_label = {idx: val for idx, val in enumerate(unique_labels)}\n",
    "    label_to_index = {val: idx for idx, val in index_to_label.items()}\n",
    "\n",
    "    label_list = list(label_to_index.keys())\n",
    "\n",
    "    return label_list, label_to_index\n",
    "\n",
    "def create_image_list(dir):\n",
    "    \"\"\" Create a full list of images available \n",
    "    Args:\n",
    "        dir (string): root directory of images with subdirectories underneath\n",
    "                      that have the .png images within them\n",
    "    Returns:\n",
    "        image_list: list of tuples with (image_name, full_image_path)\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    dir = os.path.expanduser(dir)\n",
    "    for subfolder in sorted(os.listdir(dir)):\n",
    "        d = os.path.join(dir, subfolder)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        for subfolder_path, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if is_image_file(fname):\n",
    "                    path = os.path.join(subfolder_path, fname)\n",
    "                    image_list.append((fname, path))\n",
    "    return image_list\n",
    "\n",
    "def pil_loader(path):\n",
    "    \"\"\" Opens path as file with Pillow (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    Args:\n",
    "        path (string): File path to the image\n",
    "    Returns:\n",
    "        img: Image in RGB format\n",
    "    \"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "        \n",
    "def imshow(inp, title=None):\n",
    "    \"\"\" Convert tensor array to an image (only use post-dataset transform) \"\"\"\n",
    "    inp = inp[0]\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d5d91972-9d4b-4022-842b-22c823f98fff"
    }
   },
   "source": [
    "### Implementation of Torch's Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "nbpresent": {
     "id": "5bf4e82b-13ca-4ac2-bbb6-3081e820ab4e"
    }
   },
   "outputs": [],
   "source": [
    "class XrayImageSet(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image_root (string): root directory of the images in form image/subfolder/*.png\n",
    "        csv_file (string): path to the CSV data file\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an image given its path.\n",
    "     Attributes:\n",
    "        labels (list): list of the possible label names.\n",
    "        label_to_index (dict): look from label name to a label index\n",
    "        imgs (list): List of (filename, image path) tuples\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_root, csv_file, transform=None, target_transform=None, loader = pil_loader):\n",
    "        \"\"\" Create an instance of the Xray Dataset \"\"\"\n",
    "        img_details = pd.read_csv(csv_file)\n",
    "        \n",
    "        labels, label_to_index = create_label_maps(img_details)\n",
    "        imgs = create_image_list(image_root)\n",
    "\n",
    "        self.imgs = imgs\n",
    "        self.image_details = img_details\n",
    "        self.image_root = image_root\n",
    "        self.labels = labels\n",
    "        self.label_to_index = label_to_index\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.max_label_index = max(label_to_index.values())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get image,labels pair by index\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        fname, path = self.imgs[index]\n",
    "        target = self.get_one_hot_labels(fname)\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Calculate length of the dataset (number of images) \"\"\"\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def get_labels(self, fname):\n",
    "        \"\"\" Return the label string for the file \"\"\"\n",
    "        return self.image_details[self.image_details['Image Index'] == fname]['Finding Labels'].values[0]\n",
    "    \n",
    "    def one_hot_labels(self, labels):\n",
    "        \"\"\" Convert the labels string (with each label separated by |) into 1-hot encoding \"\"\"\n",
    "        if labels == None:\n",
    "            return None\n",
    "        \n",
    "        split_label_indices = [self.label_to_index.get(label)\n",
    "                               for label in labels.split('|')\n",
    "                               if label != 'No Finding']\n",
    "        \n",
    "        out = [1 if idx in split_label_indices else 0 for idx in range(self.max_label_index+1)]\n",
    "        # This code UNHOTs the labels:\n",
    "        # out = '|'.join([index_to_label.get(idx) for idx, val in enumerate(one_hot_tuple) if val == 1])\n",
    "        return out\n",
    "\n",
    "    def get_one_hot_labels(self, fname):\n",
    "        \"\"\" Get the 1-hot encoded label array for the provided file \"\"\"\n",
    "        labels = self.get_labels(fname)\n",
    "        one_hot_labels = self.one_hot_labels(labels)\n",
    "        return torch.FloatTensor(one_hot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean ± std. dev. of 7 runs, 10000000 loops each\n",
    "\n",
    "#### Time for __get_item__\n",
    "```\n",
    "%timeit img_data_train[3] # 30.8 ms ± 544 µs per loop\n",
    "```\n",
    "\n",
    "#### Breakdown for __get_item__\n",
    "```\n",
    "%timeit img_data_train.imgs[8] # 63 ns ± 0.0057 ns per loop\n",
    "%timeit img_data_train.get_one_hot_labels('00011558_012.png') # 8.72 ms ± 9.44 µs per loop\n",
    "%timeit img_data_train.loader('/user/images/images_006/00011558_012.png') # 14.1 ms ± 3.41 µs per loop\n",
    "%timeit img_data_train.transform(img) # 3.17 ms ± 1.32 µs per loop\n",
    "```\n",
    "\n",
    "#### Breakdown for loader() from __get_item__\n",
    "```\n",
    "%timeit open('/user/images/images_006/00011558_012.png', 'rb') # 7.72 µs ± 13.4 ns per loop\n",
    "%timeit Image.open(f) # 37.5 µs ± 2.25 µs per loop\n",
    "%timeit img.convert('RGB') # 498 µs ± 149 ns per loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b6f705b5-c4e4-4fbd-a517-f0c3b58c4305"
    }
   },
   "source": [
    "### Create the dataset with necessary transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_input_size = 224\n",
    "#nn_input_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "nbpresent": {
     "id": "6716d746-b7b1-4aff-aec0-2bd91632bf28"
    }
   },
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose(\n",
    "    [transforms.Resize(nn_input_size),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "nbpresent": {
     "id": "62d30308-7ecb-40f4-a831-dd0a9274618a"
    }
   },
   "outputs": [],
   "source": [
    "img_data_train = XrayImageSet(image_root = '/user/images/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_train.imgs = [img for i, img in enumerate(img_data_train.imgs) if i % 10 > 0]# and randuni() < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "nbpresent": {
     "id": "13f86c44-50f2-4809-8ee1-afb0d8ec0b7a"
    }
   },
   "outputs": [],
   "source": [
    "img_data_val   = XrayImageSet(image_root = '/user/images/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_val.imgs = [img for i, img in enumerate(img_data_val.imgs) if i % 10 == 0]# and randuni() < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "nbpresent": {
     "id": "09ab4157-ad5b-4602-8b93-85c86bd5a620"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 100908\n",
      "Validation Set Size: 11212\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Size: {}\".format(len(img_data_train)))\n",
    "print(\"Validation Set Size: {}\".format(len(img_data_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1b2e1feb-e832-41c5-8b1d-70384f1fe915"
    }
   },
   "source": [
    "### Put the dataset into a Dataloader to handle batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "nbpresent": {
     "id": "e0484420-b2a8-429b-8da4-368a592db7b8"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU: 1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_gpus = torch.cuda.device_count()\n",
    "pin_mem_setting = True\n",
    "\n",
    "print(\"Number of GPU: {}\".format(num_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "nbpresent": {
     "id": "1001fa5d-b820-4da6-9d18-0ee7f4462b90"
    }
   },
   "outputs": [],
   "source": [
    "img_loader_train = DataLoader(img_data_train,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = 10,\n",
    "                              pin_memory = pin_mem_setting)\n",
    "\n",
    "img_loader_val   = DataLoader(img_data_val,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = 10,\n",
    "                              pin_memory = pin_mem_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "nbpresent": {
     "id": "0e1d2cb0-4d0f-4ab1-a1cf-cd66a3e298a2"
    }
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': img_loader_train,\n",
    "    'val': img_loader_val\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "350daac2-9c37-42d0-a1ef-de7a8110b38f"
    }
   },
   "source": [
    "# Define model training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "nbpresent": {
     "id": "166ce9d1-ff17-4047-b9ae-b4903393ad15"
    }
   },
   "outputs": [],
   "source": [
    "class printer_writer:\n",
    "    def __init__(self, output_folder_path):\n",
    "        self.start_time = time.strftime('%Y%m%d-%Hh%Mm%Ss')\n",
    "        \n",
    "        self.outprefix = output_folder_path + '/' + self.start_time\n",
    "        \n",
    "        # Print Output File\n",
    "        self.print_out_path = self.outprefix + '_print.txt'\n",
    "        self.print_out_file = open(self.print_out_path, 'w', 1)\n",
    "        \n",
    "    def printw(self, string):\n",
    "        print(string)\n",
    "        try:\n",
    "            self.print_out_file.write(string + \"\\n\")\n",
    "        except: # Ignore errors\n",
    "            pass\n",
    "        \n",
    "    def save_checkpoint(self, epoch, model, optimizer, scheduler, val_error):\n",
    "        model_out_path = self.outprefix + '_model_' + str(epoch+1) + '.tar'\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'state': model.state_dict(),\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "            'val_error': val_error\n",
    "        }, model_out_path)\n",
    "        \n",
    "    def close(self):\n",
    "        self.print_out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "nbpresent": {
     "id": "eb99e6e4-00db-494a-ad27-70005761f49e"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, outfolder = '/user/xrayproj/output/'):\n",
    "    since = time.time()\n",
    "    scribe = printer_writer(outfolder)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        scribe.printw('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        scribe.printw('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            obs_counter = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Store statistics (convert from autograd.Variable to float/int)\n",
    "                loss_val = loss.data[0]\n",
    "                correct_val = torch.sum( ((outputs.sigmoid()>0.5) == (labels>0.5)).long() ).data[0]\n",
    "                \n",
    "                running_loss += loss_val\n",
    "                running_corrects += correct_val\n",
    "                \n",
    "                obs_counter += len(inputs)\n",
    "                \n",
    "                batch_loss = 1.0 * loss_val / len(inputs)\n",
    "                batch_acc = 1.0 * correct_val / len(inputs)\n",
    "                status = ' |~~ {}@{}  Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    phase, obs_counter, batch_loss, batch_acc)\n",
    "                scribe.printw(status)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            scribe.printw('{}  Loss: {:.6f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                scribe.save_checkpoint(epoch, model, optimizer, scheduler, epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    scribe.printw('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    scribe.close()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5e6eebab-809d-4550-b771-135dbf2b893d"
    }
   },
   "source": [
    "# Define Weighted Cost Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "nbpresent": {
     "id": "0c520d22-a18b-4e5f-b849-1960820f4d04"
    }
   },
   "outputs": [],
   "source": [
    "def imbalance_weighted_bce_with_logit(input, target, size_average=True):\n",
    "    if not (target.size() == input.size()):\n",
    "        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
    "\n",
    "    max_val = (-input).clamp(min=0)\n",
    "    loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "    # Determine |P| and |N|\n",
    "    positive_labels = target.sum()\n",
    "    negative_labels = (1-target).sum()\n",
    "\n",
    "    # Upweight the less common class (very often the 1s)\n",
    "    beta_p = (positive_labels + negative_labels) / positive_labels\n",
    "    beta_n = (positive_labels + negative_labels) / negative_labels\n",
    "\n",
    "    # Adjust the losses accordingly\n",
    "    loss_weight = target * beta_p + (1-target) * beta_n\n",
    "    \n",
    "    loss = loss * loss_weight\n",
    "\n",
    "    if size_average:\n",
    "        return loss.mean()\n",
    "    else:\n",
    "        return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "nbpresent": {
     "id": "f66b439c-1f87-4d08-939d-f64d085b846b"
    }
   },
   "outputs": [],
   "source": [
    "class BCEWithLogitsImbalanceWeightedLoss(Module):\n",
    "    def __init__(self, class_weight=None, size_average=True):\n",
    "        super(BCEWithLogitsImbalanceWeightedLoss, self).__init__()\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return imbalance_weighted_bce_with_logit(input, target, size_average=self.size_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8ca6e253-06b7-4a15-ac6c-370629667ad6"
    }
   },
   "source": [
    "# Setup Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18PlusFlexibleFC():\n",
    "    # Create a base ResNet18 model\n",
    "    m = models.resnet18(pretrained=True)\n",
    "    for param in m.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace the final FC layer\n",
    "    m.fc = nn.Linear(m.fc.in_features, len(img_data_train.labels))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50PlusFlexibleFC():\n",
    "    # Create a base ResNet18 model\n",
    "    m = models.resnet50(pretrained=True)\n",
    "    for param in m.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace the final FC layer\n",
    "    m.fc = nn.Linear(m.fc.in_features, len(img_data_train.labels))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18PlusFCFullyFlexible():\n",
    "    # Create a base ResNet18 model\n",
    "    m = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Replace the final FC layer\n",
    "    m.fc = nn.Linear(m.fc.in_features, len(img_data_train.labels))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BrandNewArchitecture():\n",
    "    m = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 2, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(),\n",
    "            nn.Conv2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(),\n",
    "            nn.Conv2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(),\n",
    "            nn.Conv2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(),\n",
    "            nn.Conv2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(),\n",
    "            nn.Conv2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(),\n",
    "            nn.Conv2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(),\n",
    "            nn.Conv2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5580486c-3807-459c-a02d-68be7ffc7e08"
    }
   },
   "source": [
    "### Pull the ResNet-18 pre-trained model and replace the fully connected layer at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "nbpresent": {
     "id": "91946119-bf67-4871-92af-649559fa9bfd"
    }
   },
   "outputs": [],
   "source": [
    "#model_base = ResNet18PlusFlexibleFC()\n",
    "#model_base = ResNet18PlusFCFullyFlexible()\n",
    "model_base = ResNet50PlusFlexibleFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b85990f9-2c42-48b1-9e5b-857ebd8c2f30"
    }
   },
   "source": [
    "### Push model to CUDA/GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "nbpresent": {
     "id": "0a904f1f-73ac-418b-86cf-cdafdf0f67b1"
    }
   },
   "outputs": [],
   "source": [
    "model_ft = DataParallel(model_base).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e6851de2-8645-4547-9f00-414ad8a3811a"
    }
   },
   "source": [
    "### Define loss measure and learning rates/procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "nbpresent": {
     "id": "1d61f077-84ec-4d2c-bdb0-82b28f8c4ed9"
    }
   },
   "outputs": [],
   "source": [
    "#criterion = BCEWithLogitsImbalanceWeightedLoss()\n",
    "criterion_base = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer_ft = SGD(model_ft.module.fc.parameters(), lr=0.0001, momentum=0.9)\n",
    "#optimizer_ft = SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = criterion_base.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future code for allowing optimization of the base layer with a lower learning rate\n",
    "\n",
    "```\n",
    "ignored_params = list(map(id, model.fc.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model.parameters())\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "            {'params': base_params},\n",
    "            {'params': model.fc.parameters(), 'lr': opt.lr}\n",
    "        ], lr=opt.lr*0.1, momentum=0.9)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2f9596b5-a2fc-4e0c-984b-4e13b68dcd6d"
    }
   },
   "source": [
    "# Begin Training Network (Normal Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "nbpresent": {
     "id": "f1672c30-c299-4265-934b-6af391d9de8c"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/7\n",
      "----------\n",
      " |~~ train@64  Loss: 0.011481 Acc: 6.3594\n",
      " |~~ train@128  Loss: 0.011471 Acc: 6.2969\n",
      " |~~ train@192  Loss: 0.011460 Acc: 6.3594\n",
      " |~~ train@256  Loss: 0.011437 Acc: 6.1719\n",
      " |~~ train@320  Loss: 0.011352 Acc: 6.3750\n",
      " |~~ train@384  Loss: 0.011356 Acc: 6.5000\n",
      " |~~ train@448  Loss: 0.011292 Acc: 6.4688\n",
      " |~~ train@512  Loss: 0.011278 Acc: 6.8594\n",
      " |~~ train@576  Loss: 0.011164 Acc: 7.0000\n",
      " |~~ train@640  Loss: 0.011089 Acc: 7.0312\n",
      " |~~ train@704  Loss: 0.011062 Acc: 6.9062\n",
      " |~~ train@768  Loss: 0.011015 Acc: 7.2812\n",
      " |~~ train@832  Loss: 0.010835 Acc: 7.5469\n",
      " |~~ train@896  Loss: 0.010854 Acc: 7.7344\n",
      " |~~ train@960  Loss: 0.010718 Acc: 7.8438\n",
      " |~~ train@1024  Loss: 0.010678 Acc: 7.9062\n",
      " |~~ train@1088  Loss: 0.010591 Acc: 8.2031\n",
      " |~~ train@1152  Loss: 0.010481 Acc: 8.4844\n",
      " |~~ train@1216  Loss: 0.010409 Acc: 8.5938\n",
      " |~~ train@1280  Loss: 0.010343 Acc: 8.8750\n",
      " |~~ train@1344  Loss: 0.010219 Acc: 9.1719\n",
      " |~~ train@1408  Loss: 0.010137 Acc: 9.2969\n",
      " |~~ train@1472  Loss: 0.010073 Acc: 9.4844\n",
      " |~~ train@1536  Loss: 0.010021 Acc: 9.6562\n",
      " |~~ train@1600  Loss: 0.009976 Acc: 9.5000\n",
      " |~~ train@1664  Loss: 0.009842 Acc: 9.8594\n",
      " |~~ train@1728  Loss: 0.009713 Acc: 10.0781\n",
      " |~~ train@1792  Loss: 0.009655 Acc: 10.2344\n",
      " |~~ train@1856  Loss: 0.009516 Acc: 10.6562\n",
      " |~~ train@1920  Loss: 0.009580 Acc: 10.3281\n",
      " |~~ train@1984  Loss: 0.009432 Acc: 10.9219\n",
      " |~~ train@2048  Loss: 0.009374 Acc: 10.8125\n",
      " |~~ train@2112  Loss: 0.009225 Acc: 11.4375\n",
      " |~~ train@2176  Loss: 0.009135 Acc: 11.5469\n",
      " |~~ train@2240  Loss: 0.009127 Acc: 11.4062\n",
      " |~~ train@2304  Loss: 0.009104 Acc: 11.5625\n",
      " |~~ train@2368  Loss: 0.008909 Acc: 12.0938\n",
      " |~~ train@2432  Loss: 0.008924 Acc: 11.8750\n",
      " |~~ train@2496  Loss: 0.008863 Acc: 11.7500\n",
      " |~~ train@2560  Loss: 0.008818 Acc: 12.1406\n",
      " |~~ train@2624  Loss: 0.008706 Acc: 12.4062\n",
      " |~~ train@2688  Loss: 0.008627 Acc: 12.3125\n",
      " |~~ train@2752  Loss: 0.008690 Acc: 12.2344\n",
      " |~~ train@2816  Loss: 0.008504 Acc: 12.6719\n",
      " |~~ train@2880  Loss: 0.008385 Acc: 12.7344\n",
      " |~~ train@2944  Loss: 0.008374 Acc: 12.6406\n",
      " |~~ train@3008  Loss: 0.008220 Acc: 12.8906\n",
      " |~~ train@3072  Loss: 0.008247 Acc: 12.9688\n",
      " |~~ train@3136  Loss: 0.008113 Acc: 13.0000\n",
      " |~~ train@3200  Loss: 0.007983 Acc: 13.2812\n",
      " |~~ train@3264  Loss: 0.008106 Acc: 12.9062\n",
      " |~~ train@3328  Loss: 0.007934 Acc: 13.2031\n",
      " |~~ train@3392  Loss: 0.008107 Acc: 12.7656\n",
      " |~~ train@3456  Loss: 0.007788 Acc: 13.2344\n",
      " |~~ train@3520  Loss: 0.007810 Acc: 13.1562\n",
      " |~~ train@3584  Loss: 0.007606 Acc: 13.2969\n",
      " |~~ train@3648  Loss: 0.007697 Acc: 13.1875\n",
      " |~~ train@3712  Loss: 0.007577 Acc: 13.2656\n",
      " |~~ train@3776  Loss: 0.007511 Acc: 13.2812\n",
      " |~~ train@3840  Loss: 0.007540 Acc: 13.2031\n",
      " |~~ train@3904  Loss: 0.007415 Acc: 13.3125\n",
      " |~~ train@3968  Loss: 0.007435 Acc: 13.1875\n",
      " |~~ train@4032  Loss: 0.007580 Acc: 12.9844\n",
      " |~~ train@4096  Loss: 0.007452 Acc: 13.0625\n",
      " |~~ train@4160  Loss: 0.007193 Acc: 13.3750\n",
      " |~~ train@4224  Loss: 0.007262 Acc: 13.2031\n",
      " |~~ train@4288  Loss: 0.007176 Acc: 13.2344\n",
      " |~~ train@4352  Loss: 0.006964 Acc: 13.5000\n",
      " |~~ train@4416  Loss: 0.007124 Acc: 13.1719\n",
      " |~~ train@4480  Loss: 0.006868 Acc: 13.4844\n",
      " |~~ train@4544  Loss: 0.007086 Acc: 13.1562\n",
      " |~~ train@4608  Loss: 0.006875 Acc: 13.3906\n",
      " |~~ train@4672  Loss: 0.006915 Acc: 13.2031\n",
      " |~~ train@4736  Loss: 0.006888 Acc: 13.2031\n",
      " |~~ train@4800  Loss: 0.006785 Acc: 13.2812\n",
      " |~~ train@4864  Loss: 0.006707 Acc: 13.3906\n",
      " |~~ train@4928  Loss: 0.006736 Acc: 13.2812\n",
      " |~~ train@4992  Loss: 0.006747 Acc: 13.2031\n",
      " |~~ train@5056  Loss: 0.006559 Acc: 13.3594\n",
      " |~~ train@5120  Loss: 0.006620 Acc: 13.2656\n",
      " |~~ train@5184  Loss: 0.006594 Acc: 13.2656\n",
      " |~~ train@5248  Loss: 0.006640 Acc: 13.1406\n",
      " |~~ train@5312  Loss: 0.006477 Acc: 13.2812\n",
      " |~~ train@5376  Loss: 0.006554 Acc: 13.1562\n",
      " |~~ train@5440  Loss: 0.006295 Acc: 13.4844\n",
      " |~~ train@5504  Loss: 0.006362 Acc: 13.2656\n",
      " |~~ train@5568  Loss: 0.006106 Acc: 13.5156\n",
      " |~~ train@5632  Loss: 0.006574 Acc: 12.9844\n",
      " |~~ train@5696  Loss: 0.006354 Acc: 13.1562\n",
      " |~~ train@5760  Loss: 0.006224 Acc: 13.2812\n",
      " |~~ train@5824  Loss: 0.006420 Acc: 13.0156\n",
      " |~~ train@5888  Loss: 0.006230 Acc: 13.2344\n",
      " |~~ train@5952  Loss: 0.005971 Acc: 13.4688\n",
      " |~~ train@6016  Loss: 0.006332 Acc: 13.0469\n",
      " |~~ train@6080  Loss: 0.005879 Acc: 13.5000\n",
      " |~~ train@6144  Loss: 0.006011 Acc: 13.3281\n",
      " |~~ train@6208  Loss: 0.006152 Acc: 13.1406\n",
      " |~~ train@6272  Loss: 0.005983 Acc: 13.3125\n",
      " |~~ train@6336  Loss: 0.005853 Acc: 13.4062\n",
      " |~~ train@6400  Loss: 0.005699 Acc: 13.5312\n",
      " |~~ train@6464  Loss: 0.006020 Acc: 13.2344\n",
      " |~~ train@6528  Loss: 0.005688 Acc: 13.4688\n",
      " |~~ train@6592  Loss: 0.005756 Acc: 13.3281\n",
      " |~~ train@6656  Loss: 0.005701 Acc: 13.3750\n",
      " |~~ train@6720  Loss: 0.005840 Acc: 13.2344\n",
      " |~~ train@6784  Loss: 0.005630 Acc: 13.3594\n",
      " |~~ train@6848  Loss: 0.005944 Acc: 13.1094\n",
      " |~~ train@6912  Loss: 0.005606 Acc: 13.3594\n",
      " |~~ train@6976  Loss: 0.005770 Acc: 13.1875\n",
      " |~~ train@7040  Loss: 0.005666 Acc: 13.2812\n",
      " |~~ train@7104  Loss: 0.005558 Acc: 13.3438\n",
      " |~~ train@7168  Loss: 0.005693 Acc: 13.2031\n",
      " |~~ train@7232  Loss: 0.005792 Acc: 13.0781\n",
      " |~~ train@7296  Loss: 0.005670 Acc: 13.1875\n",
      " |~~ train@7360  Loss: 0.005552 Acc: 13.2969\n",
      " |~~ train@7424  Loss: 0.005468 Acc: 13.3125\n",
      " |~~ train@7488  Loss: 0.005564 Acc: 13.1562\n",
      " |~~ train@7552  Loss: 0.005498 Acc: 13.2188\n",
      " |~~ train@7616  Loss: 0.005318 Acc: 13.3750\n",
      " |~~ train@7680  Loss: 0.005159 Acc: 13.5156\n",
      " |~~ train@7744  Loss: 0.005309 Acc: 13.3438\n",
      " |~~ train@7808  Loss: 0.005461 Acc: 13.1406\n",
      " |~~ train@7872  Loss: 0.005227 Acc: 13.3906\n",
      " |~~ train@7936  Loss: 0.005336 Acc: 13.2969\n",
      " |~~ train@8000  Loss: 0.004943 Acc: 13.5938\n",
      " |~~ train@8064  Loss: 0.005215 Acc: 13.3281\n",
      " |~~ train@8128  Loss: 0.005264 Acc: 13.2812\n",
      " |~~ train@8192  Loss: 0.005081 Acc: 13.4062\n",
      " |~~ train@8256  Loss: 0.005156 Acc: 13.3438\n",
      " |~~ train@8320  Loss: 0.005290 Acc: 13.2188\n",
      " |~~ train@8384  Loss: 0.005530 Acc: 13.0000\n",
      " |~~ train@8448  Loss: 0.004979 Acc: 13.4531\n",
      " |~~ train@8512  Loss: 0.005007 Acc: 13.4219\n",
      " |~~ train@8576  Loss: 0.005200 Acc: 13.2031\n",
      " |~~ train@8640  Loss: 0.005087 Acc: 13.2500\n",
      " |~~ train@8704  Loss: 0.005147 Acc: 13.2344\n",
      " |~~ train@8768  Loss: 0.004889 Acc: 13.4375\n",
      " |~~ train@8832  Loss: 0.005276 Acc: 13.1094\n",
      " |~~ train@8896  Loss: 0.005073 Acc: 13.2500\n",
      " |~~ train@8960  Loss: 0.004936 Acc: 13.3594\n",
      " |~~ train@9024  Loss: 0.004948 Acc: 13.3125\n",
      " |~~ train@9088  Loss: 0.004863 Acc: 13.3750\n",
      " |~~ train@9152  Loss: 0.004987 Acc: 13.2344\n",
      " |~~ train@9216  Loss: 0.004773 Acc: 13.4219\n",
      " |~~ train@9280  Loss: 0.004582 Acc: 13.5469\n",
      " |~~ train@9344  Loss: 0.004837 Acc: 13.3125\n",
      " |~~ train@9408  Loss: 0.004736 Acc: 13.3906\n",
      " |~~ train@9472  Loss: 0.004869 Acc: 13.2656\n",
      " |~~ train@9536  Loss: 0.004788 Acc: 13.3438\n",
      " |~~ train@9600  Loss: 0.004841 Acc: 13.2500\n",
      " |~~ train@9664  Loss: 0.004600 Acc: 13.4688\n",
      " |~~ train@9728  Loss: 0.005058 Acc: 13.0781\n",
      " |~~ train@9792  Loss: 0.004956 Acc: 13.1875\n",
      " |~~ train@9856  Loss: 0.005236 Acc: 12.9688\n",
      " |~~ train@9920  Loss: 0.004568 Acc: 13.4219\n",
      " |~~ train@9984  Loss: 0.004795 Acc: 13.2656\n",
      " |~~ train@10048  Loss: 0.004886 Acc: 13.1719\n",
      " |~~ train@10112  Loss: 0.004535 Acc: 13.4219\n",
      " |~~ train@10176  Loss: 0.004828 Acc: 13.2188\n",
      " |~~ train@10240  Loss: 0.004582 Acc: 13.3438\n",
      " |~~ train@10304  Loss: 0.004645 Acc: 13.2969\n",
      " |~~ train@10368  Loss: 0.004603 Acc: 13.3750\n",
      " |~~ train@10432  Loss: 0.004579 Acc: 13.3750\n",
      " |~~ train@10496  Loss: 0.004643 Acc: 13.2969\n",
      " |~~ train@10560  Loss: 0.004324 Acc: 13.5156\n",
      " |~~ train@10624  Loss: 0.004642 Acc: 13.2656\n",
      " |~~ train@10688  Loss: 0.004689 Acc: 13.2188\n",
      " |~~ train@10752  Loss: 0.004580 Acc: 13.3125\n",
      " |~~ train@10816  Loss: 0.004501 Acc: 13.3438\n",
      " |~~ train@10880  Loss: 0.004707 Acc: 13.1719\n",
      " |~~ train@10944  Loss: 0.004261 Acc: 13.5312\n",
      " |~~ train@11008  Loss: 0.004459 Acc: 13.3281\n",
      " |~~ train@11072  Loss: 0.004702 Acc: 13.1562\n",
      " |~~ train@11136  Loss: 0.004568 Acc: 13.2344\n",
      " |~~ train@11200  Loss: 0.004541 Acc: 13.3281\n",
      " |~~ train@11264  Loss: 0.004164 Acc: 13.5312\n",
      " |~~ train@11328  Loss: 0.004483 Acc: 13.2812\n",
      " |~~ train@11392  Loss: 0.004691 Acc: 13.1250\n",
      " |~~ train@11456  Loss: 0.004473 Acc: 13.2188\n",
      " |~~ train@11520  Loss: 0.004405 Acc: 13.2969\n",
      " |~~ train@11584  Loss: 0.004572 Acc: 13.2031\n",
      " |~~ train@11648  Loss: 0.004425 Acc: 13.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@11712  Loss: 0.004805 Acc: 13.0312\n",
      " |~~ train@11776  Loss: 0.004137 Acc: 13.4531\n",
      " |~~ train@11840  Loss: 0.004379 Acc: 13.2812\n",
      " |~~ train@11904  Loss: 0.004817 Acc: 12.9844\n",
      " |~~ train@11968  Loss: 0.004396 Acc: 13.2500\n",
      " |~~ train@12032  Loss: 0.004363 Acc: 13.2656\n",
      " |~~ train@12096  Loss: 0.004373 Acc: 13.2812\n",
      " |~~ train@12160  Loss: 0.004535 Acc: 13.1719\n",
      " |~~ train@12224  Loss: 0.004498 Acc: 13.1406\n",
      " |~~ train@12288  Loss: 0.004281 Acc: 13.3438\n",
      " |~~ train@12352  Loss: 0.004352 Acc: 13.2656\n",
      " |~~ train@12416  Loss: 0.004153 Acc: 13.3750\n",
      " |~~ train@12480  Loss: 0.004273 Acc: 13.2812\n",
      " |~~ train@12544  Loss: 0.004749 Acc: 13.0156\n",
      " |~~ train@12608  Loss: 0.004240 Acc: 13.3438\n",
      " |~~ train@12672  Loss: 0.004494 Acc: 13.1250\n",
      " |~~ train@12736  Loss: 0.004436 Acc: 13.1875\n",
      " |~~ train@12800  Loss: 0.004221 Acc: 13.2812\n",
      " |~~ train@12864  Loss: 0.004167 Acc: 13.2969\n",
      " |~~ train@12928  Loss: 0.004291 Acc: 13.2344\n",
      " |~~ train@12992  Loss: 0.004092 Acc: 13.3750\n",
      " |~~ train@13056  Loss: 0.004259 Acc: 13.2344\n",
      " |~~ train@13120  Loss: 0.004163 Acc: 13.3125\n",
      " |~~ train@13184  Loss: 0.004266 Acc: 13.2656\n",
      " |~~ train@13248  Loss: 0.004108 Acc: 13.3438\n",
      " |~~ train@13312  Loss: 0.003920 Acc: 13.4219\n",
      " |~~ train@13376  Loss: 0.003901 Acc: 13.4688\n",
      " |~~ train@13440  Loss: 0.004361 Acc: 13.1719\n",
      " |~~ train@13504  Loss: 0.004195 Acc: 13.2500\n",
      " |~~ train@13568  Loss: 0.004472 Acc: 13.0938\n",
      " |~~ train@13632  Loss: 0.004666 Acc: 12.9688\n",
      " |~~ train@13696  Loss: 0.003792 Acc: 13.5312\n",
      " |~~ train@13760  Loss: 0.004106 Acc: 13.2969\n",
      " |~~ train@13824  Loss: 0.003816 Acc: 13.4688\n",
      " |~~ train@13888  Loss: 0.004775 Acc: 12.8906\n",
      " |~~ train@13952  Loss: 0.004657 Acc: 12.9531\n",
      " |~~ train@14016  Loss: 0.003962 Acc: 13.3438\n",
      " |~~ train@14080  Loss: 0.004201 Acc: 13.2031\n",
      " |~~ train@14144  Loss: 0.004592 Acc: 12.9844\n",
      " |~~ train@14208  Loss: 0.003786 Acc: 13.4375\n",
      " |~~ train@14272  Loss: 0.003916 Acc: 13.3594\n",
      " |~~ train@14336  Loss: 0.004231 Acc: 13.1562\n",
      " |~~ train@14400  Loss: 0.004263 Acc: 13.1719\n",
      " |~~ train@14464  Loss: 0.003955 Acc: 13.3125\n",
      " |~~ train@14528  Loss: 0.003873 Acc: 13.4062\n",
      " |~~ train@14592  Loss: 0.004123 Acc: 13.2031\n",
      " |~~ train@14656  Loss: 0.004053 Acc: 13.3125\n",
      " |~~ train@14720  Loss: 0.003936 Acc: 13.3281\n",
      " |~~ train@14784  Loss: 0.003954 Acc: 13.3438\n",
      " |~~ train@14848  Loss: 0.003673 Acc: 13.4844\n",
      " |~~ train@14912  Loss: 0.003889 Acc: 13.3594\n",
      " |~~ train@14976  Loss: 0.003849 Acc: 13.3750\n",
      " |~~ train@15040  Loss: 0.003897 Acc: 13.3281\n",
      " |~~ train@15104  Loss: 0.003770 Acc: 13.3906\n",
      " |~~ train@15168  Loss: 0.003813 Acc: 13.3594\n",
      " |~~ train@15232  Loss: 0.004116 Acc: 13.1719\n",
      " |~~ train@15296  Loss: 0.004020 Acc: 13.2656\n",
      " |~~ train@15360  Loss: 0.003969 Acc: 13.2656\n",
      " |~~ train@15424  Loss: 0.003748 Acc: 13.3906\n",
      " |~~ train@15488  Loss: 0.004419 Acc: 13.0156\n",
      " |~~ train@15552  Loss: 0.004053 Acc: 13.2031\n",
      " |~~ train@15616  Loss: 0.003805 Acc: 13.3438\n",
      " |~~ train@15680  Loss: 0.003796 Acc: 13.3750\n",
      " |~~ train@15744  Loss: 0.003879 Acc: 13.3125\n",
      " |~~ train@15808  Loss: 0.003853 Acc: 13.3281\n",
      " |~~ train@15872  Loss: 0.004188 Acc: 13.1094\n",
      " |~~ train@15936  Loss: 0.003943 Acc: 13.2344\n",
      " |~~ train@16000  Loss: 0.003910 Acc: 13.2500\n",
      " |~~ train@16064  Loss: 0.003837 Acc: 13.3125\n",
      " |~~ train@16128  Loss: 0.004251 Acc: 13.0781\n",
      " |~~ train@16192  Loss: 0.003717 Acc: 13.3594\n",
      " |~~ train@16256  Loss: 0.004182 Acc: 13.0938\n",
      " |~~ train@16320  Loss: 0.003806 Acc: 13.3125\n",
      " |~~ train@16384  Loss: 0.003796 Acc: 13.3125\n",
      " |~~ train@16448  Loss: 0.003708 Acc: 13.3594\n",
      " |~~ train@16512  Loss: 0.003703 Acc: 13.3594\n",
      " |~~ train@16576  Loss: 0.004396 Acc: 12.9844\n",
      " |~~ train@16640  Loss: 0.003497 Acc: 13.4688\n",
      " |~~ train@16704  Loss: 0.003824 Acc: 13.3125\n",
      " |~~ train@16768  Loss: 0.003376 Acc: 13.5625\n",
      " |~~ train@16832  Loss: 0.003717 Acc: 13.3281\n",
      " |~~ train@16896  Loss: 0.004440 Acc: 12.9531\n",
      " |~~ train@16960  Loss: 0.004068 Acc: 13.1406\n",
      " |~~ train@17024  Loss: 0.003856 Acc: 13.2500\n",
      " |~~ train@17088  Loss: 0.004195 Acc: 13.0625\n",
      " |~~ train@17152  Loss: 0.003999 Acc: 13.1719\n",
      " |~~ train@17216  Loss: 0.003770 Acc: 13.3125\n",
      " |~~ train@17280  Loss: 0.003923 Acc: 13.1875\n",
      " |~~ train@17344  Loss: 0.003989 Acc: 13.1250\n",
      " |~~ train@17408  Loss: 0.003562 Acc: 13.4219\n",
      " |~~ train@17472  Loss: 0.003914 Acc: 13.2031\n",
      " |~~ train@17536  Loss: 0.003939 Acc: 13.1719\n",
      " |~~ train@17600  Loss: 0.003842 Acc: 13.2656\n",
      " |~~ train@17664  Loss: 0.003677 Acc: 13.3125\n",
      " |~~ train@17728  Loss: 0.003235 Acc: 13.5312\n",
      " |~~ train@17792  Loss: 0.003900 Acc: 13.1875\n",
      " |~~ train@17856  Loss: 0.003737 Acc: 13.3125\n",
      " |~~ train@17920  Loss: 0.003951 Acc: 13.1562\n",
      " |~~ train@17984  Loss: 0.003467 Acc: 13.4219\n",
      " |~~ train@18048  Loss: 0.003810 Acc: 13.2656\n",
      " |~~ train@18112  Loss: 0.003388 Acc: 13.4531\n",
      " |~~ train@18176  Loss: 0.003925 Acc: 13.1875\n",
      " |~~ train@18240  Loss: 0.003807 Acc: 13.2500\n",
      " |~~ train@18304  Loss: 0.003692 Acc: 13.2812\n",
      " |~~ train@18368  Loss: 0.003846 Acc: 13.2031\n",
      " |~~ train@18432  Loss: 0.003994 Acc: 13.1250\n",
      " |~~ train@18496  Loss: 0.003945 Acc: 13.1562\n",
      " |~~ train@18560  Loss: 0.003584 Acc: 13.3281\n",
      " |~~ train@18624  Loss: 0.003814 Acc: 13.2031\n",
      " |~~ train@18688  Loss: 0.003596 Acc: 13.2969\n",
      " |~~ train@18752  Loss: 0.003778 Acc: 13.2188\n",
      " |~~ train@18816  Loss: 0.004016 Acc: 13.1094\n",
      " |~~ train@18880  Loss: 0.004110 Acc: 13.0469\n",
      " |~~ train@18944  Loss: 0.003355 Acc: 13.4531\n",
      " |~~ train@19008  Loss: 0.003782 Acc: 13.2500\n",
      " |~~ train@19072  Loss: 0.003424 Acc: 13.3906\n",
      " |~~ train@19136  Loss: 0.003656 Acc: 13.2812\n",
      " |~~ train@19200  Loss: 0.003810 Acc: 13.1562\n",
      " |~~ train@19264  Loss: 0.003658 Acc: 13.3125\n",
      " |~~ train@19328  Loss: 0.004409 Acc: 12.9219\n",
      " |~~ train@19392  Loss: 0.003826 Acc: 13.1719\n",
      " |~~ train@19456  Loss: 0.003400 Acc: 13.4062\n",
      " |~~ train@19520  Loss: 0.003420 Acc: 13.4062\n",
      " |~~ train@19584  Loss: 0.003545 Acc: 13.3281\n",
      " |~~ train@19648  Loss: 0.003447 Acc: 13.3594\n",
      " |~~ train@19712  Loss: 0.003768 Acc: 13.1875\n",
      " |~~ train@19776  Loss: 0.003491 Acc: 13.3438\n",
      " |~~ train@19840  Loss: 0.003953 Acc: 13.1094\n",
      " |~~ train@19904  Loss: 0.003911 Acc: 13.1562\n",
      " |~~ train@19968  Loss: 0.003891 Acc: 13.1094\n",
      " |~~ train@20032  Loss: 0.003501 Acc: 13.3438\n",
      " |~~ train@20096  Loss: 0.003210 Acc: 13.4688\n",
      " |~~ train@20160  Loss: 0.003362 Acc: 13.4531\n",
      " |~~ train@20224  Loss: 0.003411 Acc: 13.3594\n",
      " |~~ train@20288  Loss: 0.003399 Acc: 13.3750\n",
      " |~~ train@20352  Loss: 0.003819 Acc: 13.1562\n",
      " |~~ train@20416  Loss: 0.003275 Acc: 13.4375\n",
      " |~~ train@20480  Loss: 0.003649 Acc: 13.2500\n",
      " |~~ train@20544  Loss: 0.003704 Acc: 13.2500\n",
      " |~~ train@20608  Loss: 0.003595 Acc: 13.3281\n",
      " |~~ train@20672  Loss: 0.003548 Acc: 13.2969\n",
      " |~~ train@20736  Loss: 0.003546 Acc: 13.3125\n",
      " |~~ train@20800  Loss: 0.003555 Acc: 13.2969\n",
      " |~~ train@20864  Loss: 0.003468 Acc: 13.3438\n",
      " |~~ train@20928  Loss: 0.003798 Acc: 13.1719\n",
      " |~~ train@20992  Loss: 0.003289 Acc: 13.3750\n",
      " |~~ train@21056  Loss: 0.003235 Acc: 13.4531\n",
      " |~~ train@21120  Loss: 0.002988 Acc: 13.5781\n",
      " |~~ train@21184  Loss: 0.002979 Acc: 13.5625\n",
      " |~~ train@21248  Loss: 0.003609 Acc: 13.2188\n",
      " |~~ train@21312  Loss: 0.003351 Acc: 13.3750\n",
      " |~~ train@21376  Loss: 0.003611 Acc: 13.2344\n",
      " |~~ train@21440  Loss: 0.003040 Acc: 13.5469\n",
      " |~~ train@21504  Loss: 0.003673 Acc: 13.1719\n",
      " |~~ train@21568  Loss: 0.002926 Acc: 13.5938\n",
      " |~~ train@21632  Loss: 0.003588 Acc: 13.2188\n",
      " |~~ train@21696  Loss: 0.003638 Acc: 13.2500\n",
      " |~~ train@21760  Loss: 0.003456 Acc: 13.2969\n",
      " |~~ train@21824  Loss: 0.003548 Acc: 13.2812\n",
      " |~~ train@21888  Loss: 0.003574 Acc: 13.2656\n",
      " |~~ train@21952  Loss: 0.004047 Acc: 13.0312\n",
      " |~~ train@22016  Loss: 0.003570 Acc: 13.2656\n",
      " |~~ train@22080  Loss: 0.003761 Acc: 13.1406\n",
      " |~~ train@22144  Loss: 0.003355 Acc: 13.3438\n",
      " |~~ train@22208  Loss: 0.003675 Acc: 13.2031\n",
      " |~~ train@22272  Loss: 0.003295 Acc: 13.3750\n",
      " |~~ train@22336  Loss: 0.003240 Acc: 13.4531\n",
      " |~~ train@22400  Loss: 0.003446 Acc: 13.3125\n",
      " |~~ train@22464  Loss: 0.003651 Acc: 13.1875\n",
      " |~~ train@22528  Loss: 0.003362 Acc: 13.2969\n",
      " |~~ train@22592  Loss: 0.003738 Acc: 13.1406\n",
      " |~~ train@22656  Loss: 0.003685 Acc: 13.2031\n",
      " |~~ train@22720  Loss: 0.003351 Acc: 13.2969\n",
      " |~~ train@22784  Loss: 0.003789 Acc: 13.1875\n",
      " |~~ train@22848  Loss: 0.003768 Acc: 13.1250\n",
      " |~~ train@22912  Loss: 0.003373 Acc: 13.3281\n",
      " |~~ train@22976  Loss: 0.003709 Acc: 13.1250\n",
      " |~~ train@23040  Loss: 0.003239 Acc: 13.3750\n",
      " |~~ train@23104  Loss: 0.002990 Acc: 13.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@23168  Loss: 0.003894 Acc: 13.0781\n",
      " |~~ train@23232  Loss: 0.003272 Acc: 13.3594\n",
      " |~~ train@23296  Loss: 0.003450 Acc: 13.2812\n",
      " |~~ train@23360  Loss: 0.003315 Acc: 13.3438\n",
      " |~~ train@23424  Loss: 0.003120 Acc: 13.4062\n",
      " |~~ train@23488  Loss: 0.003849 Acc: 13.0625\n",
      " |~~ train@23552  Loss: 0.003677 Acc: 13.1562\n",
      " |~~ train@23616  Loss: 0.003482 Acc: 13.2812\n",
      " |~~ train@23680  Loss: 0.003695 Acc: 13.1719\n",
      " |~~ train@23744  Loss: 0.003220 Acc: 13.3906\n",
      " |~~ train@23808  Loss: 0.003684 Acc: 13.1406\n",
      " |~~ train@23872  Loss: 0.003616 Acc: 13.1875\n",
      " |~~ train@23936  Loss: 0.003685 Acc: 13.1250\n",
      " |~~ train@24000  Loss: 0.003628 Acc: 13.2031\n",
      " |~~ train@24064  Loss: 0.003702 Acc: 13.1094\n",
      " |~~ train@24128  Loss: 0.003560 Acc: 13.2031\n",
      " |~~ train@24192  Loss: 0.003490 Acc: 13.2812\n",
      " |~~ train@24256  Loss: 0.003422 Acc: 13.2812\n",
      " |~~ train@24320  Loss: 0.003445 Acc: 13.2812\n",
      " |~~ train@24384  Loss: 0.003689 Acc: 13.1562\n",
      " |~~ train@24448  Loss: 0.003481 Acc: 13.2031\n",
      " |~~ train@24512  Loss: 0.003297 Acc: 13.2812\n",
      " |~~ train@24576  Loss: 0.003330 Acc: 13.2969\n",
      " |~~ train@24640  Loss: 0.003148 Acc: 13.3906\n",
      " |~~ train@24704  Loss: 0.003190 Acc: 13.4062\n",
      " |~~ train@24768  Loss: 0.003519 Acc: 13.2344\n",
      " |~~ train@24832  Loss: 0.003240 Acc: 13.3281\n",
      " |~~ train@24896  Loss: 0.003247 Acc: 13.3281\n",
      " |~~ train@24960  Loss: 0.003037 Acc: 13.4688\n",
      " |~~ train@25024  Loss: 0.003353 Acc: 13.2969\n",
      " |~~ train@25088  Loss: 0.002971 Acc: 13.4844\n",
      " |~~ train@25152  Loss: 0.003390 Acc: 13.2344\n",
      " |~~ train@25216  Loss: 0.003538 Acc: 13.1875\n",
      " |~~ train@25280  Loss: 0.003220 Acc: 13.3438\n",
      " |~~ train@25344  Loss: 0.003031 Acc: 13.4375\n",
      " |~~ train@25408  Loss: 0.003436 Acc: 13.2812\n",
      " |~~ train@25472  Loss: 0.003551 Acc: 13.1875\n",
      " |~~ train@25536  Loss: 0.003641 Acc: 13.1562\n",
      " |~~ train@25600  Loss: 0.003431 Acc: 13.2188\n",
      " |~~ train@25664  Loss: 0.003363 Acc: 13.2656\n",
      " |~~ train@25728  Loss: 0.002764 Acc: 13.5625\n",
      " |~~ train@25792  Loss: 0.003444 Acc: 13.2656\n",
      " |~~ train@25856  Loss: 0.003185 Acc: 13.3438\n",
      " |~~ train@25920  Loss: 0.003894 Acc: 13.0000\n",
      " |~~ train@25984  Loss: 0.003435 Acc: 13.2188\n",
      " |~~ train@26048  Loss: 0.003501 Acc: 13.1719\n",
      " |~~ train@26112  Loss: 0.003380 Acc: 13.2344\n",
      " |~~ train@26176  Loss: 0.003622 Acc: 13.1562\n",
      " |~~ train@26240  Loss: 0.003654 Acc: 13.1562\n",
      " |~~ train@26304  Loss: 0.002570 Acc: 13.6250\n",
      " |~~ train@26368  Loss: 0.003272 Acc: 13.3438\n",
      " |~~ train@26432  Loss: 0.003593 Acc: 13.1406\n",
      " |~~ train@26496  Loss: 0.003396 Acc: 13.2812\n",
      " |~~ train@26560  Loss: 0.003346 Acc: 13.2344\n",
      " |~~ train@26624  Loss: 0.003111 Acc: 13.3594\n",
      " |~~ train@26688  Loss: 0.003401 Acc: 13.2656\n",
      " |~~ train@26752  Loss: 0.003280 Acc: 13.2812\n",
      " |~~ train@26816  Loss: 0.003441 Acc: 13.1875\n",
      " |~~ train@26880  Loss: 0.002946 Acc: 13.4531\n",
      " |~~ train@26944  Loss: 0.003301 Acc: 13.2656\n",
      " |~~ train@27008  Loss: 0.003617 Acc: 13.1719\n",
      " |~~ train@27072  Loss: 0.003036 Acc: 13.4062\n",
      " |~~ train@27136  Loss: 0.002917 Acc: 13.4844\n",
      " |~~ train@27200  Loss: 0.003129 Acc: 13.3594\n",
      " |~~ train@27264  Loss: 0.003541 Acc: 13.1562\n",
      " |~~ train@27328  Loss: 0.003414 Acc: 13.2031\n",
      " |~~ train@27392  Loss: 0.003067 Acc: 13.4062\n",
      " |~~ train@27456  Loss: 0.003231 Acc: 13.3125\n",
      " |~~ train@27520  Loss: 0.003416 Acc: 13.2031\n",
      " |~~ train@27584  Loss: 0.003056 Acc: 13.4062\n",
      " |~~ train@27648  Loss: 0.002939 Acc: 13.4375\n",
      " |~~ train@27712  Loss: 0.003061 Acc: 13.4219\n",
      " |~~ train@27776  Loss: 0.003152 Acc: 13.3438\n",
      " |~~ train@27840  Loss: 0.003209 Acc: 13.2969\n",
      " |~~ train@27904  Loss: 0.003561 Acc: 13.1875\n",
      " |~~ train@27968  Loss: 0.003280 Acc: 13.2500\n",
      " |~~ train@28032  Loss: 0.003391 Acc: 13.2188\n",
      " |~~ train@28096  Loss: 0.003103 Acc: 13.3438\n",
      " |~~ train@28160  Loss: 0.003189 Acc: 13.3281\n",
      " |~~ train@28224  Loss: 0.002952 Acc: 13.4375\n",
      " |~~ train@28288  Loss: 0.003287 Acc: 13.2656\n",
      " |~~ train@28352  Loss: 0.003418 Acc: 13.2500\n",
      " |~~ train@28416  Loss: 0.003321 Acc: 13.2812\n",
      " |~~ train@28480  Loss: 0.003309 Acc: 13.2656\n",
      " |~~ train@28544  Loss: 0.003288 Acc: 13.2969\n",
      " |~~ train@28608  Loss: 0.003145 Acc: 13.3125\n",
      " |~~ train@28672  Loss: 0.003090 Acc: 13.3906\n",
      " |~~ train@28736  Loss: 0.003322 Acc: 13.2188\n",
      " |~~ train@28800  Loss: 0.003288 Acc: 13.2812\n",
      " |~~ train@28864  Loss: 0.003045 Acc: 13.3906\n",
      " |~~ train@28928  Loss: 0.003381 Acc: 13.2188\n",
      " |~~ train@28992  Loss: 0.003025 Acc: 13.3906\n",
      " |~~ train@29056  Loss: 0.003036 Acc: 13.3594\n",
      " |~~ train@29120  Loss: 0.002985 Acc: 13.4219\n",
      " |~~ train@29184  Loss: 0.003074 Acc: 13.3750\n",
      " |~~ train@29248  Loss: 0.002999 Acc: 13.4375\n",
      " |~~ train@29312  Loss: 0.002873 Acc: 13.4844\n",
      " |~~ train@29376  Loss: 0.003797 Acc: 13.0469\n",
      " |~~ train@29440  Loss: 0.003789 Acc: 13.0625\n",
      " |~~ train@29504  Loss: 0.003025 Acc: 13.3906\n",
      " |~~ train@29568  Loss: 0.003753 Acc: 13.0625\n",
      " |~~ train@29632  Loss: 0.003104 Acc: 13.3125\n",
      " |~~ train@29696  Loss: 0.002989 Acc: 13.4062\n",
      " |~~ train@29760  Loss: 0.002873 Acc: 13.4375\n",
      " |~~ train@29824  Loss: 0.003074 Acc: 13.3594\n",
      " |~~ train@29888  Loss: 0.002847 Acc: 13.4688\n",
      " |~~ train@29952  Loss: 0.003246 Acc: 13.2969\n",
      " |~~ train@30016  Loss: 0.003217 Acc: 13.3125\n",
      " |~~ train@30080  Loss: 0.002945 Acc: 13.3906\n",
      " |~~ train@30144  Loss: 0.003346 Acc: 13.2500\n",
      " |~~ train@30208  Loss: 0.003127 Acc: 13.3281\n",
      " |~~ train@30272  Loss: 0.002846 Acc: 13.4688\n",
      " |~~ train@30336  Loss: 0.002968 Acc: 13.4219\n",
      " |~~ train@30400  Loss: 0.002751 Acc: 13.4844\n",
      " |~~ train@30464  Loss: 0.003270 Acc: 13.2969\n",
      " |~~ train@30528  Loss: 0.003687 Acc: 13.0938\n",
      " |~~ train@30592  Loss: 0.003178 Acc: 13.3281\n",
      " |~~ train@30656  Loss: 0.002718 Acc: 13.5000\n",
      " |~~ train@30720  Loss: 0.003103 Acc: 13.3281\n",
      " |~~ train@30784  Loss: 0.003513 Acc: 13.1719\n",
      " |~~ train@30848  Loss: 0.003190 Acc: 13.2969\n",
      " |~~ train@30912  Loss: 0.003382 Acc: 13.2031\n",
      " |~~ train@30976  Loss: 0.003386 Acc: 13.2344\n",
      " |~~ train@31040  Loss: 0.003329 Acc: 13.2188\n",
      " |~~ train@31104  Loss: 0.003899 Acc: 12.9844\n",
      " |~~ train@31168  Loss: 0.002942 Acc: 13.4219\n",
      " |~~ train@31232  Loss: 0.003465 Acc: 13.1875\n",
      " |~~ train@31296  Loss: 0.003397 Acc: 13.1875\n",
      " |~~ train@31360  Loss: 0.003284 Acc: 13.2656\n",
      " |~~ train@31424  Loss: 0.003455 Acc: 13.1562\n",
      " |~~ train@31488  Loss: 0.003486 Acc: 13.1406\n",
      " |~~ train@31552  Loss: 0.002874 Acc: 13.4375\n",
      " |~~ train@31616  Loss: 0.003620 Acc: 13.1094\n",
      " |~~ train@31680  Loss: 0.002974 Acc: 13.3906\n",
      " |~~ train@31744  Loss: 0.003369 Acc: 13.1875\n",
      " |~~ train@31808  Loss: 0.003621 Acc: 13.1250\n",
      " |~~ train@31872  Loss: 0.003384 Acc: 13.1719\n",
      " |~~ train@31936  Loss: 0.003370 Acc: 13.2344\n",
      " |~~ train@32000  Loss: 0.003993 Acc: 12.9688\n",
      " |~~ train@32064  Loss: 0.003005 Acc: 13.3594\n",
      " |~~ train@32128  Loss: 0.003440 Acc: 13.1875\n",
      " |~~ train@32192  Loss: 0.003488 Acc: 13.0938\n",
      " |~~ train@32256  Loss: 0.003479 Acc: 13.1250\n",
      " |~~ train@32320  Loss: 0.003358 Acc: 13.2031\n",
      " |~~ train@32384  Loss: 0.003259 Acc: 13.2344\n",
      " |~~ train@32448  Loss: 0.002868 Acc: 13.4219\n",
      " |~~ train@32512  Loss: 0.003494 Acc: 13.1094\n",
      " |~~ train@32576  Loss: 0.003027 Acc: 13.2969\n",
      " |~~ train@32640  Loss: 0.003336 Acc: 13.2656\n",
      " |~~ train@32704  Loss: 0.003204 Acc: 13.2812\n",
      " |~~ train@32768  Loss: 0.003231 Acc: 13.2188\n",
      " |~~ train@32832  Loss: 0.003306 Acc: 13.2188\n",
      " |~~ train@32896  Loss: 0.003042 Acc: 13.2969\n",
      " |~~ train@32960  Loss: 0.003291 Acc: 13.2500\n",
      " |~~ train@33024  Loss: 0.002731 Acc: 13.4688\n",
      " |~~ train@33088  Loss: 0.002911 Acc: 13.4219\n",
      " |~~ train@33152  Loss: 0.003537 Acc: 13.1094\n",
      " |~~ train@33216  Loss: 0.003094 Acc: 13.3281\n",
      " |~~ train@33280  Loss: 0.003188 Acc: 13.2656\n",
      " |~~ train@33344  Loss: 0.003401 Acc: 13.2188\n",
      " |~~ train@33408  Loss: 0.003229 Acc: 13.2344\n",
      " |~~ train@33472  Loss: 0.002864 Acc: 13.4219\n",
      " |~~ train@33536  Loss: 0.003597 Acc: 13.1250\n",
      " |~~ train@33600  Loss: 0.003136 Acc: 13.2812\n",
      " |~~ train@33664  Loss: 0.003321 Acc: 13.2031\n",
      " |~~ train@33728  Loss: 0.003129 Acc: 13.2969\n",
      " |~~ train@33792  Loss: 0.002932 Acc: 13.4062\n",
      " |~~ train@33856  Loss: 0.003419 Acc: 13.2188\n",
      " |~~ train@33920  Loss: 0.003380 Acc: 13.2031\n",
      " |~~ train@33984  Loss: 0.002980 Acc: 13.3594\n",
      " |~~ train@34048  Loss: 0.003217 Acc: 13.2656\n",
      " |~~ train@34112  Loss: 0.003347 Acc: 13.1719\n",
      " |~~ train@34176  Loss: 0.003134 Acc: 13.2812\n",
      " |~~ train@34240  Loss: 0.003860 Acc: 12.9844\n",
      " |~~ train@34304  Loss: 0.002747 Acc: 13.4844\n",
      " |~~ train@34368  Loss: 0.002866 Acc: 13.3906\n",
      " |~~ train@34432  Loss: 0.003605 Acc: 13.1094\n",
      " |~~ train@34496  Loss: 0.003627 Acc: 13.0938\n",
      " |~~ train@34560  Loss: 0.003252 Acc: 13.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@34624  Loss: 0.003180 Acc: 13.2969\n",
      " |~~ train@34688  Loss: 0.003463 Acc: 13.1562\n",
      " |~~ train@34752  Loss: 0.003419 Acc: 13.1406\n",
      " |~~ train@34816  Loss: 0.003369 Acc: 13.1562\n",
      " |~~ train@34880  Loss: 0.003602 Acc: 13.0781\n",
      " |~~ train@34944  Loss: 0.003452 Acc: 13.1875\n",
      " |~~ train@35008  Loss: 0.003257 Acc: 13.2500\n",
      " |~~ train@35072  Loss: 0.003040 Acc: 13.3281\n",
      " |~~ train@35136  Loss: 0.003152 Acc: 13.2500\n",
      " |~~ train@35200  Loss: 0.002889 Acc: 13.3594\n",
      " |~~ train@35264  Loss: 0.003348 Acc: 13.2031\n",
      " |~~ train@35328  Loss: 0.003305 Acc: 13.2188\n",
      " |~~ train@35392  Loss: 0.003158 Acc: 13.2969\n",
      " |~~ train@35456  Loss: 0.002881 Acc: 13.3906\n",
      " |~~ train@35520  Loss: 0.003744 Acc: 13.0156\n",
      " |~~ train@35584  Loss: 0.003068 Acc: 13.3125\n",
      " |~~ train@35648  Loss: 0.003173 Acc: 13.2656\n",
      " |~~ train@35712  Loss: 0.002860 Acc: 13.4219\n",
      " |~~ train@35776  Loss: 0.002782 Acc: 13.4219\n",
      " |~~ train@35840  Loss: 0.003211 Acc: 13.2656\n",
      " |~~ train@35904  Loss: 0.003159 Acc: 13.2344\n",
      " |~~ train@35968  Loss: 0.003096 Acc: 13.2812\n",
      " |~~ train@36032  Loss: 0.002791 Acc: 13.4531\n",
      " |~~ train@36096  Loss: 0.002860 Acc: 13.4219\n",
      " |~~ train@36160  Loss: 0.003304 Acc: 13.2344\n",
      " |~~ train@36224  Loss: 0.003293 Acc: 13.2188\n",
      " |~~ train@36288  Loss: 0.002967 Acc: 13.3750\n",
      " |~~ train@36352  Loss: 0.002958 Acc: 13.3906\n",
      " |~~ train@36416  Loss: 0.002565 Acc: 13.5469\n",
      " |~~ train@36480  Loss: 0.003270 Acc: 13.2188\n",
      " |~~ train@36544  Loss: 0.002732 Acc: 13.4844\n",
      " |~~ train@36608  Loss: 0.002892 Acc: 13.3906\n",
      " |~~ train@36672  Loss: 0.003184 Acc: 13.2969\n",
      " |~~ train@36736  Loss: 0.003222 Acc: 13.2656\n",
      " |~~ train@36800  Loss: 0.003034 Acc: 13.3281\n",
      " |~~ train@36864  Loss: 0.003246 Acc: 13.2344\n",
      " |~~ train@36928  Loss: 0.002975 Acc: 13.3750\n",
      " |~~ train@36992  Loss: 0.003420 Acc: 13.1875\n",
      " |~~ train@37056  Loss: 0.003589 Acc: 13.0781\n",
      " |~~ train@37120  Loss: 0.003353 Acc: 13.1875\n",
      " |~~ train@37184  Loss: 0.003117 Acc: 13.3125\n",
      " |~~ train@37248  Loss: 0.002694 Acc: 13.4219\n",
      " |~~ train@37312  Loss: 0.002675 Acc: 13.4844\n",
      " |~~ train@37376  Loss: 0.003265 Acc: 13.2344\n",
      " |~~ train@37440  Loss: 0.002955 Acc: 13.3438\n",
      " |~~ train@37504  Loss: 0.003280 Acc: 13.2031\n",
      " |~~ train@37568  Loss: 0.002904 Acc: 13.3750\n",
      " |~~ train@37632  Loss: 0.002911 Acc: 13.4062\n",
      " |~~ train@37696  Loss: 0.002920 Acc: 13.3438\n",
      " |~~ train@37760  Loss: 0.002940 Acc: 13.3906\n",
      " |~~ train@37824  Loss: 0.002506 Acc: 13.5312\n",
      " |~~ train@37888  Loss: 0.003525 Acc: 13.1406\n",
      " |~~ train@37952  Loss: 0.003138 Acc: 13.2500\n",
      " |~~ train@38016  Loss: 0.003617 Acc: 13.1406\n",
      " |~~ train@38080  Loss: 0.003260 Acc: 13.2031\n",
      " |~~ train@38144  Loss: 0.003201 Acc: 13.2500\n",
      " |~~ train@38208  Loss: 0.003093 Acc: 13.2969\n",
      " |~~ train@38272  Loss: 0.002607 Acc: 13.4688\n",
      " |~~ train@38336  Loss: 0.002856 Acc: 13.3594\n",
      " |~~ train@38400  Loss: 0.003006 Acc: 13.3125\n",
      " |~~ train@38464  Loss: 0.002666 Acc: 13.4531\n",
      " |~~ train@38528  Loss: 0.002994 Acc: 13.3281\n",
      " |~~ train@38592  Loss: 0.002684 Acc: 13.4531\n",
      " |~~ train@38656  Loss: 0.003193 Acc: 13.2344\n",
      " |~~ train@38720  Loss: 0.002842 Acc: 13.3906\n",
      " |~~ train@38784  Loss: 0.002778 Acc: 13.4219\n",
      " |~~ train@38848  Loss: 0.002915 Acc: 13.3594\n",
      " |~~ train@38912  Loss: 0.002857 Acc: 13.3750\n",
      " |~~ train@38976  Loss: 0.002798 Acc: 13.4062\n",
      " |~~ train@39040  Loss: 0.003063 Acc: 13.3594\n",
      " |~~ train@39104  Loss: 0.002793 Acc: 13.4531\n",
      " |~~ train@39168  Loss: 0.003202 Acc: 13.2500\n",
      " |~~ train@39232  Loss: 0.003376 Acc: 13.1719\n",
      " |~~ train@39296  Loss: 0.003399 Acc: 13.1875\n",
      " |~~ train@39360  Loss: 0.002752 Acc: 13.3906\n",
      " |~~ train@39424  Loss: 0.003461 Acc: 13.1406\n",
      " |~~ train@39488  Loss: 0.003327 Acc: 13.2031\n",
      " |~~ train@39552  Loss: 0.003695 Acc: 13.0625\n",
      " |~~ train@39616  Loss: 0.002904 Acc: 13.3125\n",
      " |~~ train@39680  Loss: 0.003316 Acc: 13.2031\n",
      " |~~ train@39744  Loss: 0.003295 Acc: 13.2031\n",
      " |~~ train@39808  Loss: 0.003265 Acc: 13.2031\n",
      " |~~ train@39872  Loss: 0.003151 Acc: 13.2500\n",
      " |~~ train@39936  Loss: 0.002809 Acc: 13.3906\n",
      " |~~ train@40000  Loss: 0.003437 Acc: 13.1406\n",
      " |~~ train@40064  Loss: 0.003007 Acc: 13.2969\n",
      " |~~ train@40128  Loss: 0.003111 Acc: 13.3125\n",
      " |~~ train@40192  Loss: 0.002926 Acc: 13.3906\n",
      " |~~ train@40256  Loss: 0.003221 Acc: 13.2344\n",
      " |~~ train@40320  Loss: 0.002719 Acc: 13.4375\n",
      " |~~ train@40384  Loss: 0.002940 Acc: 13.3281\n",
      " |~~ train@40448  Loss: 0.003057 Acc: 13.3125\n",
      " |~~ train@40512  Loss: 0.002931 Acc: 13.3594\n",
      " |~~ train@40576  Loss: 0.003252 Acc: 13.2031\n",
      " |~~ train@40640  Loss: 0.002699 Acc: 13.5000\n",
      " |~~ train@40704  Loss: 0.002855 Acc: 13.3594\n",
      " |~~ train@40768  Loss: 0.003312 Acc: 13.1719\n",
      " |~~ train@40832  Loss: 0.003456 Acc: 13.1406\n",
      " |~~ train@40896  Loss: 0.002727 Acc: 13.4219\n",
      " |~~ train@40960  Loss: 0.002982 Acc: 13.3281\n",
      " |~~ train@41024  Loss: 0.002872 Acc: 13.3750\n",
      " |~~ train@41088  Loss: 0.002768 Acc: 13.4062\n",
      " |~~ train@41152  Loss: 0.003563 Acc: 13.0781\n",
      " |~~ train@41216  Loss: 0.003291 Acc: 13.1719\n",
      " |~~ train@41280  Loss: 0.003381 Acc: 13.1250\n",
      " |~~ train@41344  Loss: 0.003502 Acc: 13.0938\n",
      " |~~ train@41408  Loss: 0.002455 Acc: 13.5000\n",
      " |~~ train@41472  Loss: 0.002496 Acc: 13.5156\n",
      " |~~ train@41536  Loss: 0.003071 Acc: 13.2500\n",
      " |~~ train@41600  Loss: 0.003373 Acc: 13.1250\n",
      " |~~ train@41664  Loss: 0.003028 Acc: 13.2344\n",
      " |~~ train@41728  Loss: 0.003583 Acc: 13.0781\n",
      " |~~ train@41792  Loss: 0.002945 Acc: 13.3125\n",
      " |~~ train@41856  Loss: 0.002939 Acc: 13.3125\n",
      " |~~ train@41920  Loss: 0.003182 Acc: 13.2031\n",
      " |~~ train@41984  Loss: 0.003337 Acc: 13.1875\n",
      " |~~ train@42048  Loss: 0.003010 Acc: 13.2812\n",
      " |~~ train@42112  Loss: 0.003191 Acc: 13.1875\n",
      " |~~ train@42176  Loss: 0.003291 Acc: 13.2031\n",
      " |~~ train@42240  Loss: 0.002868 Acc: 13.3594\n",
      " |~~ train@42304  Loss: 0.002882 Acc: 13.3125\n",
      " |~~ train@42368  Loss: 0.003468 Acc: 13.1406\n",
      " |~~ train@42432  Loss: 0.002827 Acc: 13.3594\n",
      " |~~ train@42496  Loss: 0.002692 Acc: 13.4688\n",
      " |~~ train@42560  Loss: 0.002739 Acc: 13.4062\n",
      " |~~ train@42624  Loss: 0.003519 Acc: 13.1094\n",
      " |~~ train@42688  Loss: 0.003073 Acc: 13.2500\n",
      " |~~ train@42752  Loss: 0.003051 Acc: 13.2344\n",
      " |~~ train@42816  Loss: 0.002395 Acc: 13.5938\n",
      " |~~ train@42880  Loss: 0.003532 Acc: 13.0781\n",
      " |~~ train@42944  Loss: 0.003105 Acc: 13.2500\n",
      " |~~ train@43008  Loss: 0.002783 Acc: 13.4219\n",
      " |~~ train@43072  Loss: 0.003145 Acc: 13.2031\n",
      " |~~ train@43136  Loss: 0.003281 Acc: 13.1562\n",
      " |~~ train@43200  Loss: 0.003165 Acc: 13.2188\n",
      " |~~ train@43264  Loss: 0.003227 Acc: 13.2344\n",
      " |~~ train@43328  Loss: 0.002777 Acc: 13.3438\n",
      " |~~ train@43392  Loss: 0.002914 Acc: 13.3125\n",
      " |~~ train@43456  Loss: 0.003203 Acc: 13.2344\n",
      " |~~ train@43520  Loss: 0.003839 Acc: 12.9531\n",
      " |~~ train@43584  Loss: 0.002975 Acc: 13.3125\n",
      " |~~ train@43648  Loss: 0.003472 Acc: 13.0938\n",
      " |~~ train@43712  Loss: 0.003069 Acc: 13.2500\n",
      " |~~ train@43776  Loss: 0.003119 Acc: 13.2969\n",
      " |~~ train@43840  Loss: 0.003597 Acc: 13.0469\n",
      " |~~ train@43904  Loss: 0.003145 Acc: 13.2500\n",
      " |~~ train@43968  Loss: 0.003096 Acc: 13.2344\n",
      " |~~ train@44032  Loss: 0.003303 Acc: 13.1562\n",
      " |~~ train@44096  Loss: 0.002836 Acc: 13.3438\n",
      " |~~ train@44160  Loss: 0.002942 Acc: 13.3125\n",
      " |~~ train@44224  Loss: 0.003268 Acc: 13.1562\n",
      " |~~ train@44288  Loss: 0.003850 Acc: 12.9688\n",
      " |~~ train@44352  Loss: 0.003022 Acc: 13.2969\n",
      " |~~ train@44416  Loss: 0.003437 Acc: 13.1719\n",
      " |~~ train@44480  Loss: 0.002735 Acc: 13.4375\n",
      " |~~ train@44544  Loss: 0.003003 Acc: 13.2812\n",
      " |~~ train@44608  Loss: 0.002620 Acc: 13.4531\n",
      " |~~ train@44672  Loss: 0.003120 Acc: 13.2188\n",
      " |~~ train@44736  Loss: 0.003011 Acc: 13.2969\n",
      " |~~ train@44800  Loss: 0.002439 Acc: 13.5312\n",
      " |~~ train@44864  Loss: 0.003121 Acc: 13.2500\n",
      " |~~ train@44928  Loss: 0.002204 Acc: 13.6250\n",
      " |~~ train@44992  Loss: 0.002497 Acc: 13.5156\n",
      " |~~ train@45056  Loss: 0.002963 Acc: 13.3281\n",
      " |~~ train@45120  Loss: 0.003021 Acc: 13.2812\n",
      " |~~ train@45184  Loss: 0.003262 Acc: 13.2344\n",
      " |~~ train@45248  Loss: 0.003623 Acc: 13.0781\n",
      " |~~ train@45312  Loss: 0.003396 Acc: 13.0938\n",
      " |~~ train@45376  Loss: 0.002671 Acc: 13.4531\n",
      " |~~ train@45440  Loss: 0.003461 Acc: 13.1406\n",
      " |~~ train@45504  Loss: 0.002679 Acc: 13.4219\n",
      " |~~ train@45568  Loss: 0.003127 Acc: 13.2812\n",
      " |~~ train@45632  Loss: 0.003907 Acc: 12.9062\n",
      " |~~ train@45696  Loss: 0.003028 Acc: 13.2656\n",
      " |~~ train@45760  Loss: 0.003255 Acc: 13.2344\n",
      " |~~ train@45824  Loss: 0.003376 Acc: 13.1094\n",
      " |~~ train@45888  Loss: 0.003269 Acc: 13.1719\n",
      " |~~ train@45952  Loss: 0.003368 Acc: 13.1406\n",
      " |~~ train@46016  Loss: 0.003146 Acc: 13.2031\n",
      " |~~ train@46080  Loss: 0.003254 Acc: 13.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@46144  Loss: 0.003093 Acc: 13.2500\n",
      " |~~ train@46208  Loss: 0.002879 Acc: 13.3125\n",
      " |~~ train@46272  Loss: 0.002927 Acc: 13.3281\n",
      " |~~ train@46336  Loss: 0.003637 Acc: 13.0469\n",
      " |~~ train@46400  Loss: 0.003093 Acc: 13.2188\n",
      " |~~ train@46464  Loss: 0.002940 Acc: 13.2969\n",
      " |~~ train@46528  Loss: 0.003200 Acc: 13.2188\n",
      " |~~ train@46592  Loss: 0.003583 Acc: 13.0469\n",
      " |~~ train@46656  Loss: 0.002736 Acc: 13.3906\n",
      " |~~ train@46720  Loss: 0.003439 Acc: 13.1250\n",
      " |~~ train@46784  Loss: 0.003360 Acc: 13.1406\n",
      " |~~ train@46848  Loss: 0.002893 Acc: 13.3438\n",
      " |~~ train@46912  Loss: 0.002779 Acc: 13.3750\n",
      " |~~ train@46976  Loss: 0.003077 Acc: 13.2500\n",
      " |~~ train@47040  Loss: 0.002842 Acc: 13.3281\n",
      " |~~ train@47104  Loss: 0.002911 Acc: 13.3438\n",
      " |~~ train@47168  Loss: 0.003205 Acc: 13.2344\n",
      " |~~ train@47232  Loss: 0.003451 Acc: 13.0938\n",
      " |~~ train@47296  Loss: 0.002975 Acc: 13.2656\n",
      " |~~ train@47360  Loss: 0.002948 Acc: 13.3281\n",
      " |~~ train@47424  Loss: 0.002505 Acc: 13.5156\n",
      " |~~ train@47488  Loss: 0.002778 Acc: 13.3594\n",
      " |~~ train@47552  Loss: 0.002854 Acc: 13.3438\n",
      " |~~ train@47616  Loss: 0.003005 Acc: 13.2656\n",
      " |~~ train@47680  Loss: 0.002715 Acc: 13.3906\n",
      " |~~ train@47744  Loss: 0.003124 Acc: 13.2188\n",
      " |~~ train@47808  Loss: 0.002898 Acc: 13.3438\n",
      " |~~ train@47872  Loss: 0.003718 Acc: 13.0625\n",
      " |~~ train@47936  Loss: 0.003078 Acc: 13.2656\n",
      " |~~ train@48000  Loss: 0.002864 Acc: 13.3281\n",
      " |~~ train@48064  Loss: 0.003135 Acc: 13.2656\n",
      " |~~ train@48128  Loss: 0.002721 Acc: 13.4062\n",
      " |~~ train@48192  Loss: 0.003259 Acc: 13.1875\n",
      " |~~ train@48256  Loss: 0.003059 Acc: 13.2656\n",
      " |~~ train@48320  Loss: 0.003160 Acc: 13.2031\n",
      " |~~ train@48384  Loss: 0.002967 Acc: 13.3125\n",
      " |~~ train@48448  Loss: 0.003187 Acc: 13.2344\n",
      " |~~ train@48512  Loss: 0.003115 Acc: 13.2188\n",
      " |~~ train@48576  Loss: 0.002216 Acc: 13.6094\n",
      " |~~ train@48640  Loss: 0.002989 Acc: 13.2812\n",
      " |~~ train@48704  Loss: 0.003259 Acc: 13.1719\n",
      " |~~ train@48768  Loss: 0.003496 Acc: 13.0469\n",
      " |~~ train@48832  Loss: 0.002749 Acc: 13.3438\n",
      " |~~ train@48896  Loss: 0.003134 Acc: 13.2656\n",
      " |~~ train@48960  Loss: 0.003316 Acc: 13.1406\n",
      " |~~ train@49024  Loss: 0.002940 Acc: 13.3125\n",
      " |~~ train@49088  Loss: 0.003303 Acc: 13.1094\n",
      " |~~ train@49152  Loss: 0.003522 Acc: 13.0781\n",
      " |~~ train@49216  Loss: 0.003093 Acc: 13.3125\n",
      " |~~ train@49280  Loss: 0.003219 Acc: 13.1875\n",
      " |~~ train@49344  Loss: 0.002836 Acc: 13.3750\n",
      " |~~ train@49408  Loss: 0.002923 Acc: 13.3125\n",
      " |~~ train@49472  Loss: 0.003141 Acc: 13.1719\n",
      " |~~ train@49536  Loss: 0.003428 Acc: 13.0625\n",
      " |~~ train@49600  Loss: 0.002751 Acc: 13.3906\n",
      " |~~ train@49664  Loss: 0.002815 Acc: 13.3750\n",
      " |~~ train@49728  Loss: 0.002994 Acc: 13.2500\n",
      " |~~ train@49792  Loss: 0.002906 Acc: 13.3125\n",
      " |~~ train@49856  Loss: 0.002834 Acc: 13.3750\n",
      " |~~ train@49920  Loss: 0.003380 Acc: 13.1094\n",
      " |~~ train@49984  Loss: 0.003203 Acc: 13.2188\n",
      " |~~ train@50048  Loss: 0.003049 Acc: 13.2812\n",
      " |~~ train@50112  Loss: 0.003745 Acc: 12.9375\n",
      " |~~ train@50176  Loss: 0.002767 Acc: 13.3438\n",
      " |~~ train@50240  Loss: 0.002878 Acc: 13.3438\n",
      " |~~ train@50304  Loss: 0.003181 Acc: 13.2031\n",
      " |~~ train@50368  Loss: 0.002438 Acc: 13.5156\n",
      " |~~ train@50432  Loss: 0.003013 Acc: 13.2812\n",
      " |~~ train@50496  Loss: 0.002936 Acc: 13.2812\n",
      " |~~ train@50560  Loss: 0.003291 Acc: 13.1562\n",
      " |~~ train@50624  Loss: 0.003554 Acc: 13.0312\n",
      " |~~ train@50688  Loss: 0.003259 Acc: 13.1875\n",
      " |~~ train@50752  Loss: 0.003257 Acc: 13.1875\n",
      " |~~ train@50816  Loss: 0.002798 Acc: 13.3281\n",
      " |~~ train@50880  Loss: 0.003293 Acc: 13.1719\n",
      " |~~ train@50944  Loss: 0.002538 Acc: 13.4531\n",
      " |~~ train@51008  Loss: 0.003181 Acc: 13.2031\n",
      " |~~ train@51072  Loss: 0.003574 Acc: 13.0625\n",
      " |~~ train@51136  Loss: 0.002764 Acc: 13.3906\n",
      " |~~ train@51200  Loss: 0.002558 Acc: 13.4844\n",
      " |~~ train@51264  Loss: 0.002788 Acc: 13.4062\n",
      " |~~ train@51328  Loss: 0.002775 Acc: 13.3750\n",
      " |~~ train@51392  Loss: 0.003654 Acc: 13.0625\n",
      " |~~ train@51456  Loss: 0.003172 Acc: 13.2188\n",
      " |~~ train@51520  Loss: 0.002852 Acc: 13.3750\n",
      " |~~ train@51584  Loss: 0.003153 Acc: 13.2188\n",
      " |~~ train@51648  Loss: 0.003099 Acc: 13.2656\n",
      " |~~ train@51712  Loss: 0.003225 Acc: 13.2031\n",
      " |~~ train@51776  Loss: 0.003283 Acc: 13.1250\n",
      " |~~ train@51840  Loss: 0.002932 Acc: 13.2500\n",
      " |~~ train@51904  Loss: 0.003086 Acc: 13.1875\n",
      " |~~ train@51968  Loss: 0.002827 Acc: 13.3281\n",
      " |~~ train@52032  Loss: 0.002891 Acc: 13.3125\n",
      " |~~ train@52096  Loss: 0.003078 Acc: 13.2188\n",
      " |~~ train@52160  Loss: 0.002725 Acc: 13.3750\n",
      " |~~ train@52224  Loss: 0.002712 Acc: 13.3750\n",
      " |~~ train@52288  Loss: 0.003480 Acc: 13.0781\n",
      " |~~ train@52352  Loss: 0.002526 Acc: 13.4375\n",
      " |~~ train@52416  Loss: 0.003329 Acc: 13.1562\n",
      " |~~ train@52480  Loss: 0.002860 Acc: 13.3438\n",
      " |~~ train@52544  Loss: 0.003256 Acc: 13.1875\n",
      " |~~ train@52608  Loss: 0.003187 Acc: 13.2031\n",
      " |~~ train@52672  Loss: 0.002575 Acc: 13.4531\n",
      " |~~ train@52736  Loss: 0.003255 Acc: 13.1562\n",
      " |~~ train@52800  Loss: 0.003485 Acc: 13.1094\n",
      " |~~ train@52864  Loss: 0.003112 Acc: 13.1719\n",
      " |~~ train@52928  Loss: 0.002962 Acc: 13.3438\n",
      " |~~ train@52992  Loss: 0.003074 Acc: 13.1875\n",
      " |~~ train@53056  Loss: 0.002912 Acc: 13.3125\n",
      " |~~ train@53120  Loss: 0.002682 Acc: 13.4375\n",
      " |~~ train@53184  Loss: 0.003090 Acc: 13.2500\n",
      " |~~ train@53248  Loss: 0.003167 Acc: 13.2656\n",
      " |~~ train@53312  Loss: 0.003259 Acc: 13.2031\n",
      " |~~ train@53376  Loss: 0.002939 Acc: 13.3281\n",
      " |~~ train@53440  Loss: 0.003173 Acc: 13.2344\n",
      " |~~ train@53504  Loss: 0.002950 Acc: 13.3281\n",
      " |~~ train@53568  Loss: 0.003430 Acc: 13.1094\n",
      " |~~ train@53632  Loss: 0.003048 Acc: 13.2500\n",
      " |~~ train@53696  Loss: 0.002879 Acc: 13.3438\n",
      " |~~ train@53760  Loss: 0.003074 Acc: 13.2656\n",
      " |~~ train@53824  Loss: 0.003295 Acc: 13.2188\n",
      " |~~ train@53888  Loss: 0.002206 Acc: 13.5625\n",
      " |~~ train@53952  Loss: 0.003122 Acc: 13.2500\n",
      " |~~ train@54016  Loss: 0.002832 Acc: 13.3281\n",
      " |~~ train@54080  Loss: 0.002762 Acc: 13.4062\n",
      " |~~ train@54144  Loss: 0.002932 Acc: 13.2500\n",
      " |~~ train@54208  Loss: 0.003064 Acc: 13.2344\n",
      " |~~ train@54272  Loss: 0.002327 Acc: 13.5469\n",
      " |~~ train@54336  Loss: 0.003228 Acc: 13.1406\n",
      " |~~ train@54400  Loss: 0.003062 Acc: 13.2344\n",
      " |~~ train@54464  Loss: 0.002830 Acc: 13.3281\n",
      " |~~ train@54528  Loss: 0.002911 Acc: 13.2500\n",
      " |~~ train@54592  Loss: 0.002754 Acc: 13.3750\n",
      " |~~ train@54656  Loss: 0.002871 Acc: 13.3438\n",
      " |~~ train@54720  Loss: 0.003230 Acc: 13.1094\n",
      " |~~ train@54784  Loss: 0.003089 Acc: 13.2656\n",
      " |~~ train@54848  Loss: 0.003377 Acc: 13.2031\n",
      " |~~ train@54912  Loss: 0.002896 Acc: 13.3125\n",
      " |~~ train@54976  Loss: 0.003316 Acc: 13.1719\n",
      " |~~ train@55040  Loss: 0.003822 Acc: 12.9375\n",
      " |~~ train@55104  Loss: 0.003087 Acc: 13.2656\n",
      " |~~ train@55168  Loss: 0.003194 Acc: 13.2031\n",
      " |~~ train@55232  Loss: 0.002683 Acc: 13.3906\n",
      " |~~ train@55296  Loss: 0.003218 Acc: 13.2031\n",
      " |~~ train@55360  Loss: 0.002818 Acc: 13.3281\n",
      " |~~ train@55424  Loss: 0.003508 Acc: 13.0938\n",
      " |~~ train@55488  Loss: 0.003196 Acc: 13.2031\n",
      " |~~ train@55552  Loss: 0.002906 Acc: 13.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Process Process-7:\n",
      "Process Process-9:\n",
      "Process Process-2:\n",
      "Process Process-3:\n",
      "Process Process-6:\n",
      "Process Process-8:\n",
      "Process Process-5:\n",
      "Process Process-10:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-05078c52fc86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             num_epochs=8)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-99-e3e23468b1d7>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs, outfolder)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-87-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"<ipython-input-87-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"<ipython-input-87-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"<ipython-input-86-4cc34eea5387>\", line 67, in pil_loader\n",
      "    with Image.open(f) as img:\n",
      "  File \"<ipython-input-86-4cc34eea5387>\", line 67, in pil_loader\n",
      "    with Image.open(f) as img:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 2486, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"<ipython-input-86-4cc34eea5387>\", line 67, in pil_loader\n",
      "    with Image.open(f) as img:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 2486, in open\n",
      "    prefix = fp.read(16)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 2486, in open\n",
      "    prefix = fp.read(16)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-87-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"<ipython-input-87-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-86-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"<ipython-input-87-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-86-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"<ipython-input-87-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"<ipython-input-87-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "  File \"<ipython-input-87-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"<ipython-input-86-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 212, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"<ipython-input-86-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 212, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 608, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 212, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"<ipython-input-86-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"<ipython-input-86-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 212, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"<ipython-input-87-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 608, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 608, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 212, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"<ipython-input-86-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 608, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 212, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 608, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 608, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 212, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 608, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "train_model(model_ft,\n",
    "            criterion,\n",
    "            optimizer_ft,\n",
    "            exp_lr_scheduler,\n",
    "            num_epochs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model results to S3\n",
    "\n",
    "aws s3 cp ResNet18PlusFlexibleFC_Epoch9.tar s3://bdh-xrayproj-modelparameters/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.list_buckets()\n",
    "\n",
    "S3 Commands: http://docs.aws.amazon.com/cli/latest/userguide/using-s3-commands.html\n",
    "\n",
    "Boto3 QuickStart: http://boto3.readthedocs.io/en/latest/guide/quickstart.html\n",
    "\n",
    "Key Management: https://aws.amazon.com/blogs/security/a-safer-way-to-distribute-aws-credentials-to-ec2/\n",
    "\n",
    "AWS IAM Rules: http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model results back from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_lr_scheduler.last_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ed2ea89b-99da-4fde-a3ac-91d4d4e3865a"
    }
   },
   "source": [
    "# Analysis of Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TotalSumMeter:\n",
    "    def __init__(self):\n",
    "        self.obs_counter = 0.0\n",
    "        self.total_pred = Variable(torch.FloatTensor(torch.zeros(14)), volatile=True)\n",
    "        self.total_act = Variable(torch.FloatTensor(torch.zeros(14)), volatile=True)\n",
    "        \n",
    "    def update(self, preds, actuals):\n",
    "        self.total_act += actuals.sum(0).cpu()\n",
    "        self.total_pred += preds.sum(0).cpu()\n",
    "        self.obs_counter += len(actuals)\n",
    "        \n",
    "    def get_results(self):\n",
    "        return {\n",
    "            'pred': self.total_pred / self.obs_counter,\n",
    "            'act': self.total_act / self.obs_counter\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassAUCMeter:\n",
    "    \"\"\" Wrapper on the normal AUCMeter to handle multi-class predictions \"\"\"\n",
    "    def __init__(self, num_class):\n",
    "        self.num_class = num_class\n",
    "        self.meters = []\n",
    "        for i in range(self.num_class):\n",
    "            self.meters.append(AUCMeter())\n",
    "\n",
    "    def add(self, output, target):\n",
    "        for i in range(self.num_class):\n",
    "            self.meters[i].add(output[:,i], target[:,i])\n",
    "        \n",
    "    def value(self):\n",
    "        output = []\n",
    "        for i in range(self.num_class):\n",
    "            output.append(self.meters[i].value())\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCMeter:\n",
    "    \"\"\"\n",
    "    SOURCE: https://github.com/pytorch/tnt/blob/master/torchnet/meter/aucmeter.py\n",
    "    The AUCMeter measures the area under the receiver-operating characteristic\n",
    "    (ROC) curve for binary classification problems. The area under the curve (AUC)\n",
    "    can be interpreted as the probability that, given a randomly selected positive\n",
    "    example and a randomly selected negative example, the positive example is\n",
    "    assigned a higher score by the classification model than the negative example.\n",
    "    The AUCMeter is designed to operate on one-dimensional Tensors `output`\n",
    "    and `target`, where (1) the `output` contains model output scores that ought to\n",
    "    be higher when the model is more convinced that the example should be positively\n",
    "    labeled, and smaller when the model believes the example should be negatively\n",
    "    labeled (for instance, the output of a signoid function); and (2) the `target`\n",
    "    contains only values 0 (for negative examples) and 1 (for positive examples).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(AUCMeter, self).__init__()\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.scores = torch.DoubleTensor(torch.DoubleStorage()).numpy()\n",
    "        self.targets = torch.LongTensor(torch.LongStorage()).numpy()\n",
    "\n",
    "    def add(self, output, target):\n",
    "        if torch.is_tensor(output):\n",
    "            output = output.cpu().squeeze().numpy()\n",
    "        if torch.is_tensor(target):\n",
    "            target = target.cpu().squeeze().numpy()\n",
    "        elif isinstance(target, numbers.Number):\n",
    "            target = np.asarray([target])\n",
    "        assert np.ndim(output) == 1, \\\n",
    "            'wrong output size (1D expected)'\n",
    "        assert np.ndim(target) == 1, \\\n",
    "            'wrong target size (1D expected)'\n",
    "        assert output.shape[0] == target.shape[0], \\\n",
    "            'number of outputs and targets does not match'\n",
    "        assert np.all(np.add(np.equal(target, 1), np.equal(target, 0))), \\\n",
    "            'targets should be binary (0, 1)'\n",
    "\n",
    "        self.scores = np.append(self.scores, output)\n",
    "        self.targets = np.append(self.targets, target)\n",
    "\n",
    "    def value(self):\n",
    "        # case when number of elements added are 0\n",
    "        if self.scores.shape[0] == 0:\n",
    "            return 0.5\n",
    "\n",
    "        # sorting the arrays\n",
    "        scores, sortind = torch.sort(torch.from_numpy(self.scores), dim=0, descending=True)\n",
    "        scores = scores.numpy()\n",
    "        sortind = sortind.numpy()\n",
    "\n",
    "        # creating the roc curve\n",
    "        tpr = np.zeros(shape=(scores.size + 1), dtype=np.float64)\n",
    "        fpr = np.zeros(shape=(scores.size + 1), dtype=np.float64)\n",
    "\n",
    "        for i in range(1, scores.size + 1):\n",
    "            if self.targets[sortind[i - 1]] == 1:\n",
    "                tpr[i] = tpr[i - 1] + 1\n",
    "                fpr[i] = fpr[i - 1]\n",
    "            else:\n",
    "                tpr[i] = tpr[i - 1]\n",
    "                fpr[i] = fpr[i - 1] + 1\n",
    "\n",
    "        tpr /= (self.targets.sum() * 1.0)\n",
    "        fpr /= ((self.targets - 1.0).sum() * -1.0)\n",
    "\n",
    "        # calculating area under curve using trapezoidal rule\n",
    "        n = tpr.shape[0]\n",
    "        h = fpr[1:n] - fpr[0:n - 1]\n",
    "        sum_h = np.zeros(fpr.shape)\n",
    "        sum_h[0:n - 1] = h\n",
    "        sum_h[1:n] += h\n",
    "        area = (sum_h * tpr).sum() / 2.0\n",
    "\n",
    "        return (area, tpr, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, dataset, num_classes = 14):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.num_classes = num_classes\n",
    "        self.is_run = False\n",
    "        \n",
    "    def score_obs(self, data_row):\n",
    "        inputs, actuals = data_row\n",
    "\n",
    "        inputs = Variable(inputs.cuda(), volatile=True)\n",
    "        actuals = Variable(actuals.cuda(), volatile=True)\n",
    "\n",
    "        outputs = self.model(inputs)\n",
    "        preds = outputs.sigmoid()\n",
    "        \n",
    "        return preds, actuals\n",
    "    \n",
    "    def run(self, force_rerun = False):\n",
    "        if self.is_run and not force_rerun:\n",
    "            print(\"Already evaluated this...\")\n",
    "            return None\n",
    "        \n",
    "        self.model.train(False)\n",
    "    \n",
    "        self.m_total_sums = TotalSumMeter()\n",
    "        self.m_auc = MultiClassAUCMeter(self.num_classes)\n",
    "\n",
    "        for data in self.dataset:\n",
    "            preds, actuals = self.score_obs(data)\n",
    "\n",
    "            self.m_total_sums.update(preds, actuals)\n",
    "            self.m_auc.add(preds.data, actuals.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = ModelEvaluator(model_ft, dataloaders['val'])\n",
    "model_eval.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.59396145147107915,\n",
       " 0.54863800660529205,\n",
       " 0.63454516711824893,\n",
       " 0.58405013172700737,\n",
       " 0.55974710034767916,\n",
       " 0.50114131862140043,\n",
       " 0.54388536971264378,\n",
       " 0.60523903454437367,\n",
       " 0.51246689735191664,\n",
       " 0.53612436181165068,\n",
       " 0.57815125142066515,\n",
       " 0.53601585618573455,\n",
       " 0.54306412539889526,\n",
       " 0.50420847932546509]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = []\n",
    "for i in range(14):\n",
    "    v, _, _ = model_eval.m_auc.meters[i].value()\n",
    "    output.append(v)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_id = 7\n",
    "p, a = model_eval.score_obs((img_data_train[obs_id][0].unsqueeze(0), img_data_train[obs_id][1].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MultiClassAUCMeter(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add(p.data, a.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_sums(in_data, bar_width = 0.4):\n",
    "    act = in_data['act'].data.numpy()\n",
    "    pred = in_data['pred'].data.numpy()\n",
    "    \n",
    "    indx1 = range(14)\n",
    "    indx2 = [i+bar_width for i in indx1]\n",
    "\n",
    "    plt.bar(indx1, act,  width=bar_width, label=\"Actual\")\n",
    "    plt.bar(indx2, pred, width=bar_width, label=\"Predicted\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sums = compare_sums(model_ft, dataloaders['train'])\n",
    "val_sums = compare_sums(model_ft, dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGeBAMDOz5P8DrgJkt80t2/kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6168dcdd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzAAHgpmZJQ4EMzMDHAhmZpb8fz91mFlSkfw+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6168f6b9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Training Sums\")\n",
    "plot_compare_sums(train_sums)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Validation Sums\")\n",
    "plot_compare_sums(val_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "nbpresent": {
     "id": "9235665b-a758-4c35-a922-55466a19bd44"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING ITERATION...\n",
      "PROCESSING FIRST 750 OBSERVATIONS\n",
      "STARTING ITERATION...\n",
      "PROCESSING FIRST 406 OBSERVATIONS\n"
     ]
    }
   ],
   "source": [
    "out_model_30.train(mode=False)\n",
    "\n",
    "obs_counter = 0\n",
    "total_pred = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "total_act = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "\n",
    "conf_a = {}\n",
    "conf_b = {}\n",
    "conf_c = {}\n",
    "conf_d = {}\n",
    "for i in range(1,10):\n",
    "    conf_a[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_b[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_c[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_d[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "\n",
    "for data in dataloaders['val']:\n",
    "    print(\"STARTING ITERATION...\")\n",
    "    inputs, labels = data\n",
    "    print(\"PROCESSING FIRST {} OBSERVATIONS\".format(len(inputs)))\n",
    "\n",
    "    inputs = Variable(inputs.cuda())\n",
    "    labels = Variable(labels.cuda())\n",
    "\n",
    "    outputs = out_model_30(inputs).sigmoid()\n",
    "    \n",
    "    total_act += labels.sum(0).cpu()\n",
    "    total_pred += outputs.sum(0).cpu()\n",
    "\n",
    "    # Store statistics (convert from autograd.Variable to float/int)\n",
    "    for i in range(1,10):\n",
    "        t = i/10\n",
    "        conf_a[i] += ((outputs.sigmoid()>t) == (labels>0.5)).sum(0).cpu().float()\n",
    "        conf_b[i] += ((outputs.sigmoid()<t) == (labels>0.5)).sum(0).cpu().float()\n",
    "        conf_c[i] += ((outputs.sigmoid()>t) == (labels<0.5)).sum(0).cpu().float()\n",
    "        conf_d[i] += ((outputs.sigmoid()<t) == (labels<0.5)).sum(0).cpu().float()\n",
    "\n",
    "    obs_counter += len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "nbpresent": {
     "id": "82758b84-e7ce-48d3-a3e1-f012ab124eea"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00 -2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00 -2.1475e+09  0.0000e+00 -2.1475e+09  0.0000e+00\n",
      " 6.2634e+06 -1.0000e+00 -2.1475e+09  0.0000e+00 -2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "Columns 6 to 11 \n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00 -6.5460e+04  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "-2.1475e+09  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "-2.1475e+09  0.0000e+00 -2.1475e+09 -2.1475e+09 -2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "Columns 12 to 13 \n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      "-2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      "[torch.IntTensor of size 9x14]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comparison = Variable(torch.FloatTensor(9, 14))\n",
    "for i in range(9):\n",
    "    comparison[0] = conf_a[1] / obs_counter\n",
    "print(comparison.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "nbpresent": {
     "id": "4feafc69-38b0-41e8-b670-92c3aa26bfff"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'state': model.state_dict(),\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "            'val_error': val_error\n",
    "        }, model_out_path)\n",
    "'''\n",
    "test_load = torch.load('/user/xrayproj/output/20171120-01h41m56s_model_9.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'state', 'optimizer', 'scheduler', 'val_error'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_load.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_opt = test_load['optimizer']\n",
    "load_sched = test_load['scheduler']\n",
    "load_state = test_load['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.resnet18(pretrained=True)\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace FC layer\n",
    "model2.fc = nn.Linear(model2.fc.in_features, len(img_data_train.labels))\n",
    "\n",
    "model2_c = DataParallel(model2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_c.load_state_dict(load_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.7873  0.5093  0.2980  0.6386  0.4665  0.3371  0.1614  0.1846  0.1925  0.6630\n",
       "\n",
       "Columns 10 to 13 \n",
       " 0.0288  0.4468  0.3684  0.2549\n",
       "[torch.cuda.FloatTensor of size 1x14 (GPU 0)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_c.forward(Variable(img_data_train[0][0].unsqueeze(0).cuda())).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model_run(model, dataset):\n",
    "    dataset\n",
    "    for data in self.dataset:\n",
    "        inputs, actuals = data\n",
    "\n",
    "        inputs = Variable(inputs.cuda(), volatile=True)\n",
    "        actuals = Variable(actuals.cuda(), volatile=True)\n",
    "\n",
    "        outputs = self.model(inputs)\n",
    "        preds = outputs.sigmoid()\n",
    "\n",
    "        self.m_total_sums.update(preds, actuals)\n",
    "        self.m_auc.add(preds, actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ddb34fde-926f-42f6-8bfc-b1b19cb4881d"
    }
   },
   "source": [
    "# Import and High-Level Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "80e3fe37-bc30-43b7-91c3-474b94a16db6"
    }
   },
   "outputs": [],
   "source": [
    "# General Python Packages\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Torch Packages\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim import lr_scheduler, SGD\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import Module\n",
    "\n",
    "# General Analytics Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization / Image Packages\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Randomization Functions\n",
    "from random import random as randuni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "9b582614-ccd7-4f48-8b66-a49ebe66807f"
    }
   },
   "outputs": [],
   "source": [
    "# Put MatPlotLib in interactive mode\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "97faafc3-219d-4a56-b587-32a9c2550eac"
    }
   },
   "source": [
    "# Define Data Manipulation Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6fed3f3e-b14a-457d-95d2-c3726ce0fb3e"
    }
   },
   "source": [
    "### Helper Utility Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "f962c744-4459-4ca1-851c-a19fe8457118"
    }
   },
   "outputs": [],
   "source": [
    "def is_image_file(fname):\n",
    "    \"\"\"Checks if a file is an image.\n",
    "    Args:\n",
    "        fname (string): path to a file\n",
    "    Returns:\n",
    "        bool: True if the filename ends with a known image extension\n",
    "    \"\"\"\n",
    "    return fname.lower().endswith('.png')\n",
    "\n",
    "def create_label_maps(details_df):\n",
    "    \"\"\" Take a descriptive dataframe and extract the unique labels and map to index values\n",
    "    Args:\n",
    "        details_df: Dataframe with the image details\n",
    "    Returns:\n",
    "        label_list: list of unique labels in the dataframe\n",
    "        label_to_index: map from labels to indices\n",
    "    \"\"\"\n",
    "    \"\"\" TODO: Research paper also excludes these labels but need to figure out how to handle\n",
    "              cases that have these as positive findings (completely exclude?)\n",
    "    excluded_labels = ['Edema','Hernia','Emphysema','Fibrosis','No Finding'\n",
    "                      'Pleural_Thickening','Consolidation']\n",
    "    \"\"\"\n",
    "    excluded_labels = ['No Finding']\n",
    "    \n",
    "    label_groups = details_df['Finding Labels'].unique()\n",
    "    unique_labels = set([label for sublist in label_groups.tolist() for label in sublist.split('|')])\n",
    "    \n",
    "    # Drop some label that we do not want to include\n",
    "    unique_labels = [l for l in unique_labels if l not in excluded_labels]\n",
    "\n",
    "    index_to_label = {idx: val for idx, val in enumerate(unique_labels)}\n",
    "    label_to_index = {val: idx for idx, val in index_to_label.items()}\n",
    "\n",
    "    label_list = list(label_to_index.keys())\n",
    "\n",
    "    return label_list, label_to_index\n",
    "\n",
    "def create_image_list(dir):\n",
    "    \"\"\" Create a full list of images available \n",
    "    Args:\n",
    "        dir (string): root directory of images with subdirectories underneath\n",
    "                      that have the .png images within them\n",
    "    Returns:\n",
    "        image_list: list of tuples with (image_name, full_image_path)\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    dir = os.path.expanduser(dir)\n",
    "    for subfolder in sorted(os.listdir(dir)):\n",
    "        d = os.path.join(dir, subfolder)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        for subfolder_path, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if is_image_file(fname):\n",
    "                    path = os.path.join(subfolder_path, fname)\n",
    "                    image_list.append((fname, path))\n",
    "    return image_list\n",
    "\n",
    "def pil_loader(path):\n",
    "    \"\"\" Opens path as file with Pillow (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    Args:\n",
    "        path (string): File path to the image\n",
    "    Returns:\n",
    "        img: Image in RGB format\n",
    "    \"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "        \n",
    "def imshow(inp, title=None):\n",
    "    \"\"\" Convert tensor array to an image (only use post-dataset transform) \"\"\"\n",
    "    inp = inp[0]\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d5d91972-9d4b-4022-842b-22c823f98fff"
    }
   },
   "source": [
    "### Implementation of Torch's Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "5bf4e82b-13ca-4ac2-bbb6-3081e820ab4e"
    }
   },
   "outputs": [],
   "source": [
    "class XrayImageSet(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image_root (string): root directory of the images in form image/subfolder/*.png\n",
    "        csv_file (string): path to the CSV data file\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an image given its path.\n",
    "     Attributes:\n",
    "        labels (list): list of the possible label names.\n",
    "        label_to_index (dict): look from label name to a label index\n",
    "        imgs (list): List of (filename, image path) tuples\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_root, csv_file, transform=None, target_transform=None, loader = pil_loader):\n",
    "        \"\"\" Create an instance of the Xray Dataset \"\"\"\n",
    "        img_details = pd.read_csv(csv_file)\n",
    "        \n",
    "        labels, label_to_index = create_label_maps(img_details)\n",
    "        imgs = create_image_list(image_root)\n",
    "\n",
    "        self.imgs = imgs\n",
    "        self.image_details = img_details\n",
    "        self.image_root = image_root\n",
    "        self.labels = labels\n",
    "        self.label_to_index = label_to_index\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.max_label_index = max(label_to_index.values())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get image,labels pair by index\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        fname, path = self.imgs[index]\n",
    "        target = self.get_one_hot_labels(fname)\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Calculate length of the dataset (number of images) \"\"\"\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def get_labels(self, fname):\n",
    "        \"\"\" Return the label string for the file \"\"\"\n",
    "        return self.image_details[self.image_details['Image Index'] == fname]['Finding Labels'].values[0]\n",
    "    \n",
    "    def one_hot_labels(self, labels):\n",
    "        \"\"\" Convert the labels string (with each label separated by |) into 1-hot encoding \"\"\"\n",
    "        if labels == None:\n",
    "            return None\n",
    "        \n",
    "        split_label_indices = [self.label_to_index.get(label)\n",
    "                               for label in labels.split('|')\n",
    "                               if label != 'No Finding']\n",
    "        \n",
    "        out = [1 if idx in split_label_indices else 0 for idx in range(self.max_label_index+1)]\n",
    "        # This code UNHOTs the labels:\n",
    "        # out = '|'.join([index_to_label.get(idx) for idx, val in enumerate(one_hot_tuple) if val == 1])\n",
    "        return out\n",
    "\n",
    "    def get_one_hot_labels(self, fname):\n",
    "        \"\"\" Get the 1-hot encoded label array for the provided file \"\"\"\n",
    "        labels = self.get_labels(fname)\n",
    "        one_hot_labels = self.one_hot_labels(labels)\n",
    "        return torch.FloatTensor(one_hot_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b6f705b5-c4e4-4fbd-a517-f0c3b58c4305"
    }
   },
   "source": [
    "### Create the dataset with necessary transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "6716d746-b7b1-4aff-aec0-2bd91632bf28"
    }
   },
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "62d30308-7ecb-40f4-a831-dd0a9274618a"
    }
   },
   "outputs": [],
   "source": [
    "img_data_train = XrayImageSet(image_root = '/user/images/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_train.imgs = [img for i, img in enumerate(img_data_train.imgs) if i % 10 > 0]# and randuni() < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "13f86c44-50f2-4809-8ee1-afb0d8ec0b7a"
    }
   },
   "outputs": [],
   "source": [
    "img_data_val   = XrayImageSet(image_root = '/user/images/',\n",
    "                              csv_file = '/user/img_details.csv',\n",
    "                              transform = img_transforms,\n",
    "                              target_transform = None)\n",
    "\n",
    "img_data_val.imgs = [img for i, img in enumerate(img_data_val.imgs) if i % 10 == 0]# and randuni() < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "09ab4157-ad5b-4602-8b93-85c86bd5a620"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 100908\n",
      "Validation Set Size: 11212\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Size: {}\".format(len(img_data_train)))\n",
    "print(\"Validation Set Size: {}\".format(len(img_data_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1b2e1feb-e832-41c5-8b1d-70384f1fe915"
    }
   },
   "source": [
    "### Put the dataset into a Dataloader to handle batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "nbpresent": {
     "id": "e0484420-b2a8-429b-8da4-368a592db7b8"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU: 1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "num_gpus = torch.cuda.device_count()\n",
    "pin_mem_setting = True\n",
    "\n",
    "print(\"Number of GPU: {}\".format(num_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "nbpresent": {
     "id": "1001fa5d-b820-4da6-9d18-0ee7f4462b90"
    }
   },
   "outputs": [],
   "source": [
    "img_loader_train = DataLoader(img_data_train,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = 10,\n",
    "                              pin_memory = pin_mem_setting)\n",
    "\n",
    "img_loader_val   = DataLoader(img_data_val,\n",
    "                              batch_size = batch_size * num_gpus,\n",
    "                              shuffle = True,\n",
    "                              num_workers = 10,\n",
    "                              pin_memory = pin_mem_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "nbpresent": {
     "id": "0e1d2cb0-4d0f-4ab1-a1cf-cd66a3e298a2"
    }
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': img_loader_train,\n",
    "    'val': img_loader_val\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "350daac2-9c37-42d0-a1ef-de7a8110b38f"
    }
   },
   "source": [
    "# Define model training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbpresent": {
     "id": "166ce9d1-ff17-4047-b9ae-b4903393ad15"
    }
   },
   "outputs": [],
   "source": [
    "class printer_writer:\n",
    "    def __init__(self, output_folder_path):\n",
    "        self.start_time = time.strftime('%Y%m%d-%Hh%Mm%Ss')\n",
    "        \n",
    "        self.outprefix = output_folder_path + '/' + self.start_time\n",
    "        \n",
    "        # Print Output File\n",
    "        self.print_out_path = self.outprefix + '_print.txt'\n",
    "        self.print_out_file = open(self.print_out_path, 'w', 1)\n",
    "        \n",
    "    def printw(self, string):\n",
    "        print(string)\n",
    "        try:\n",
    "            self.print_out_file.write(string + \"\\n\")\n",
    "        except: # Ignore errors\n",
    "            pass\n",
    "        \n",
    "    def save_checkpoint(self, epoch, model, optimizer, scheduler, val_error):\n",
    "        model_out_path = self.outprefix + '_model_' + str(epoch+1) + '.tar'\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'state': model.state_dict(),\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "            'val_error': val_error\n",
    "        }, model_out_path)\n",
    "        \n",
    "    def close(self):\n",
    "        self.print_out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "eb99e6e4-00db-494a-ad27-70005761f49e"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, outfolder = '/user/xrayproj/output/'):\n",
    "    since = time.time()\n",
    "    scribe = printer_writer(outfolder)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        scribe.printw('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        scribe.printw('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            obs_counter = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Store statistics (convert from autograd.Variable to float/int)\n",
    "                loss_val = loss.data[0]\n",
    "                correct_val = torch.sum( ((outputs.sigmoid()>0.5) == (labels>0.5)).long() ).data[0]\n",
    "                \n",
    "                running_loss += loss_val\n",
    "                running_corrects += correct_val\n",
    "                \n",
    "                obs_counter += len(inputs)\n",
    "                \n",
    "                batch_loss = 1.0 * loss_val / len(inputs)\n",
    "                batch_acc = 1.0 * correct_val / len(inputs)\n",
    "                status = ' |~~ {}@{}  Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    phase, obs_counter, batch_loss, batch_acc)\n",
    "                scribe.printw(status)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            scribe.printw('{}  Loss: {:.6f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                scribe.save_checkpoint(epoch, model, optimizer, scheduler, epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    scribe.printw('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    scribe.close()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5e6eebab-809d-4550-b771-135dbf2b893d"
    }
   },
   "source": [
    "# Define Weighted Cost Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "0c520d22-a18b-4e5f-b849-1960820f4d04"
    }
   },
   "outputs": [],
   "source": [
    "def imbalance_weighted_bce_with_logit(input, target, size_average=True):\n",
    "    if not (target.size() == input.size()):\n",
    "        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
    "\n",
    "    max_val = (-input).clamp(min=0)\n",
    "    loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "    # Determine |P| and |N|\n",
    "    positive_labels = target.sum()\n",
    "    negative_labels = (1-target).sum()\n",
    "\n",
    "    # Upweight the less common class (very often the 1s)\n",
    "    beta_p = (positive_labels + negative_labels) / positive_labels\n",
    "    beta_n = (positive_labels + negative_labels) / negative_labels\n",
    "\n",
    "    # Adjust the losses accordingly\n",
    "    loss_weight = target * beta_p + (1-target) * beta_n\n",
    "    \n",
    "    loss = loss * loss_weight\n",
    "\n",
    "    if size_average:\n",
    "        return loss.mean()\n",
    "    else:\n",
    "        return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbpresent": {
     "id": "f66b439c-1f87-4d08-939d-f64d085b846b"
    }
   },
   "outputs": [],
   "source": [
    "class BCEWithLogitsImbalanceWeightedLoss(Module):\n",
    "    def __init__(self, class_weight=None, size_average=True):\n",
    "        super(BCEWithLogitsImbalanceWeightedLoss, self).__init__()\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return imbalance_weighted_bce_with_logit(input, target, size_average=self.size_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8ca6e253-06b7-4a15-ac6c-370629667ad6"
    }
   },
   "source": [
    "# Setup Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18PlusFlexibleFC():\n",
    "    # Create a base ResNet18 model\n",
    "    m = models.resnet18(pretrained=True)\n",
    "    for param in m.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace the final FC layer\n",
    "    m.fc = nn.Linear(m.fc.in_features, len(img_data_train.labels))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18PlusFCFullyFlexible():\n",
    "    # Create a base ResNet18 model\n",
    "    m = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Replace the final FC layer\n",
    "    m.fc = nn.Linear(m.fc.in_features, len(img_data_train.labels))\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5580486c-3807-459c-a02d-68be7ffc7e08"
    }
   },
   "source": [
    "### Pull the ResNet-18 pre-trained model and replace the fully connected layer at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "nbpresent": {
     "id": "91946119-bf67-4871-92af-649559fa9bfd"
    }
   },
   "outputs": [],
   "source": [
    "#model_base = ResNet18PlusFlexibleFC()\n",
    "model_base = ResNet18PlusFCFullyFlexible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b85990f9-2c42-48b1-9e5b-857ebd8c2f30"
    }
   },
   "source": [
    "### Push model to CUDA/GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "nbpresent": {
     "id": "0a904f1f-73ac-418b-86cf-cdafdf0f67b1"
    }
   },
   "outputs": [],
   "source": [
    "model_ft = DataParallel(model_base).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e6851de2-8645-4547-9f00-414ad8a3811a"
    }
   },
   "source": [
    "### Define loss measure and learning rates/procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "nbpresent": {
     "id": "1d61f077-84ec-4d2c-bdb0-82b28f8c4ed9"
    }
   },
   "outputs": [],
   "source": [
    "#criterion = BCEWithLogitsImbalanceWeightedLoss()\n",
    "criterion_base = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = SGD(model_ft.module.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = criterion_base.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future code for allowing optimization of the base layer with a lower learning rate\n",
    "\n",
    "```\n",
    "ignored_params = list(map(id, model.fc.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "                     model.parameters())\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "            {'params': base_params},\n",
    "            {'params': model.fc.parameters(), 'lr': opt.lr}\n",
    "        ], lr=opt.lr*0.1, momentum=0.9)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2f9596b5-a2fc-4e0c-984b-4e13b68dcd6d"
    }
   },
   "source": [
    "# Begin Training Network (Normal Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Variable(img_data_train[0][0].unsqueeze(0))\n",
    "act = Variable(torch.FloatTensor([0,0,0,0,1,0,0,0,0,0,0,0,0,0]).unsqueeze(0).cuda())\n",
    "out = model_ft.forward(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(out, act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "nbpresent": {
     "id": "f1672c30-c299-4265-934b-6af391d9de8c"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      " |~~ train@5  Loss: 0.130731 Acc: 8.8000\n",
      " |~~ train@10  Loss: 0.129181 Acc: 8.6000\n",
      " |~~ train@15  Loss: 0.131137 Acc: 8.8000\n",
      " |~~ train@20  Loss: 0.119419 Acc: 9.8000\n",
      " |~~ train@25  Loss: 0.124706 Acc: 9.4000\n",
      " |~~ train@30  Loss: 0.117774 Acc: 10.4000\n",
      " |~~ train@35  Loss: 0.117114 Acc: 10.8000\n",
      " |~~ train@40  Loss: 0.109142 Acc: 11.6000\n",
      " |~~ train@45  Loss: 0.105148 Acc: 11.0000\n",
      " |~~ train@50  Loss: 0.102704 Acc: 11.2000\n",
      " |~~ train@55  Loss: 0.096036 Acc: 11.8000\n",
      " |~~ train@60  Loss: 0.093051 Acc: 12.0000\n",
      " |~~ train@65  Loss: 0.082448 Acc: 13.0000\n",
      " |~~ train@70  Loss: 0.086912 Acc: 12.4000\n",
      " |~~ train@75  Loss: 0.073407 Acc: 13.4000\n",
      " |~~ train@80  Loss: 0.072460 Acc: 13.2000\n",
      " |~~ train@85  Loss: 0.079333 Acc: 12.6000\n",
      " |~~ train@90  Loss: 0.071389 Acc: 12.8000\n",
      " |~~ train@95  Loss: 0.059408 Acc: 13.8000\n",
      " |~~ train@100  Loss: 0.072374 Acc: 12.6000\n",
      " |~~ train@105  Loss: 0.048388 Acc: 14.0000\n",
      " |~~ train@110  Loss: 0.060040 Acc: 13.2000\n",
      " |~~ train@115  Loss: 0.049411 Acc: 13.6000\n",
      " |~~ train@120  Loss: 0.040411 Acc: 14.0000\n",
      " |~~ train@125  Loss: 0.057951 Acc: 13.2000\n",
      " |~~ train@130  Loss: 0.053785 Acc: 13.4000\n",
      " |~~ train@135  Loss: 0.053324 Acc: 13.2000\n",
      " |~~ train@140  Loss: 0.045886 Acc: 13.4000\n",
      " |~~ train@145  Loss: 0.056558 Acc: 13.0000\n",
      " |~~ train@150  Loss: 0.056872 Acc: 13.0000\n",
      " |~~ train@155  Loss: 0.054451 Acc: 13.0000\n",
      " |~~ train@160  Loss: 0.049259 Acc: 13.2000\n",
      " |~~ train@165  Loss: 0.032208 Acc: 13.8000\n",
      " |~~ train@170  Loss: 0.025108 Acc: 14.0000\n",
      " |~~ train@175  Loss: 0.093687 Acc: 11.6000\n",
      " |~~ train@180  Loss: 0.054639 Acc: 13.0000\n",
      " |~~ train@185  Loss: 0.022691 Acc: 14.0000\n",
      " |~~ train@190  Loss: 0.030674 Acc: 13.6000\n",
      " |~~ train@195  Loss: 0.045682 Acc: 13.2000\n",
      " |~~ train@200  Loss: 0.043460 Acc: 13.2000\n",
      " |~~ train@205  Loss: 0.041246 Acc: 13.2000\n",
      " |~~ train@210  Loss: 0.043879 Acc: 13.2000\n",
      " |~~ train@215  Loss: 0.038684 Acc: 13.4000\n",
      " |~~ train@220  Loss: 0.050936 Acc: 13.0000\n",
      " |~~ train@225  Loss: 0.019245 Acc: 14.0000\n",
      " |~~ train@230  Loss: 0.049484 Acc: 13.0000\n",
      " |~~ train@235  Loss: 0.041265 Acc: 13.4000\n",
      " |~~ train@240  Loss: 0.032456 Acc: 13.6000\n",
      " |~~ train@245  Loss: 0.023816 Acc: 13.8000\n",
      " |~~ train@250  Loss: 0.017543 Acc: 14.0000\n",
      " |~~ train@255  Loss: 0.066465 Acc: 12.6000\n",
      " |~~ train@260  Loss: 0.035397 Acc: 13.4000\n",
      " |~~ train@265  Loss: 0.052674 Acc: 12.8000\n",
      " |~~ train@270  Loss: 0.060055 Acc: 12.8000\n",
      " |~~ train@275  Loss: 0.026130 Acc: 13.8000\n",
      " |~~ train@280  Loss: 0.025848 Acc: 13.6000\n",
      " |~~ train@285  Loss: 0.034499 Acc: 13.4000\n",
      " |~~ train@290  Loss: 0.022375 Acc: 13.8000\n",
      " |~~ train@295  Loss: 0.038208 Acc: 13.4000\n",
      " |~~ train@300  Loss: 0.029208 Acc: 13.6000\n",
      " |~~ train@305  Loss: 0.020101 Acc: 13.8000\n",
      " |~~ train@310  Loss: 0.036964 Acc: 13.4000\n",
      " |~~ train@315  Loss: 0.028765 Acc: 13.4000\n",
      " |~~ train@320  Loss: 0.044465 Acc: 13.0000\n",
      " |~~ train@325  Loss: 0.054499 Acc: 12.8000\n",
      " |~~ train@330  Loss: 0.042586 Acc: 13.2000\n",
      " |~~ train@335  Loss: 0.053551 Acc: 12.8000\n",
      " |~~ train@340  Loss: 0.042387 Acc: 13.2000\n",
      " |~~ train@345  Loss: 0.052366 Acc: 13.0000\n",
      " |~~ train@350  Loss: 0.043232 Acc: 13.2000\n",
      " |~~ train@355  Loss: 0.032511 Acc: 13.4000\n",
      " |~~ train@360  Loss: 0.023292 Acc: 13.6000\n",
      " |~~ train@365  Loss: 0.048786 Acc: 13.0000\n",
      " |~~ train@370  Loss: 0.072131 Acc: 12.4000\n",
      " |~~ train@375  Loss: 0.061093 Acc: 12.8000\n",
      " |~~ train@380  Loss: 0.061420 Acc: 12.4000\n",
      " |~~ train@385  Loss: 0.028256 Acc: 13.6000\n",
      " |~~ train@390  Loss: 0.047419 Acc: 13.0000\n",
      " |~~ train@395  Loss: 0.054161 Acc: 13.0000\n",
      " |~~ train@400  Loss: 0.067500 Acc: 12.4000\n",
      " |~~ train@405  Loss: 0.023246 Acc: 13.8000\n",
      " |~~ train@410  Loss: 0.039844 Acc: 13.2000\n",
      " |~~ train@415  Loss: 0.046420 Acc: 13.0000\n",
      " |~~ train@420  Loss: 0.055311 Acc: 12.8000\n",
      " |~~ train@425  Loss: 0.056065 Acc: 13.0000\n",
      " |~~ train@430  Loss: 0.069013 Acc: 12.4000\n",
      " |~~ train@435  Loss: 0.014518 Acc: 14.0000\n",
      " |~~ train@440  Loss: 0.020749 Acc: 13.6000\n",
      " |~~ train@445  Loss: 0.028318 Acc: 13.6000\n",
      " |~~ train@450  Loss: 0.018015 Acc: 13.8000\n",
      " |~~ train@455  Loss: 0.050562 Acc: 12.8000\n",
      " |~~ train@460  Loss: 0.032474 Acc: 13.4000\n",
      " |~~ train@465  Loss: 0.022659 Acc: 13.8000\n",
      " |~~ train@470  Loss: 0.046548 Acc: 13.0000\n",
      " |~~ train@475  Loss: 0.030717 Acc: 13.6000\n",
      " |~~ train@480  Loss: 0.020959 Acc: 13.8000\n",
      " |~~ train@485  Loss: 0.024329 Acc: 13.8000\n",
      " |~~ train@490  Loss: 0.022836 Acc: 13.8000\n",
      " |~~ train@495  Loss: 0.036897 Acc: 13.4000\n",
      " |~~ train@500  Loss: 0.060690 Acc: 12.6000\n",
      " |~~ train@505  Loss: 0.030712 Acc: 13.4000\n",
      " |~~ train@510  Loss: 0.020923 Acc: 13.8000\n",
      " |~~ train@515  Loss: 0.038964 Acc: 13.2000\n",
      " |~~ train@520  Loss: 0.021153 Acc: 13.8000\n",
      " |~~ train@525  Loss: 0.042421 Acc: 13.0000\n",
      " |~~ train@530  Loss: 0.020344 Acc: 13.8000\n",
      " |~~ train@535  Loss: 0.037548 Acc: 13.2000\n",
      " |~~ train@540  Loss: 0.036644 Acc: 13.4000\n",
      " |~~ train@545  Loss: 0.049601 Acc: 13.0000\n",
      " |~~ train@550  Loss: 0.043112 Acc: 13.2000\n",
      " |~~ train@555  Loss: 0.026614 Acc: 13.6000\n",
      " |~~ train@560  Loss: 0.048462 Acc: 12.8000\n",
      " |~~ train@565  Loss: 0.036586 Acc: 13.2000\n",
      " |~~ train@570  Loss: 0.023033 Acc: 13.6000\n",
      " |~~ train@575  Loss: 0.021964 Acc: 13.8000\n",
      " |~~ train@580  Loss: 0.046955 Acc: 13.2000\n",
      " |~~ train@585  Loss: 0.046601 Acc: 13.2000\n",
      " |~~ train@590  Loss: 0.031663 Acc: 13.2000\n",
      " |~~ train@595  Loss: 0.019004 Acc: 13.8000\n",
      " |~~ train@600  Loss: 0.017878 Acc: 13.8000\n",
      " |~~ train@605  Loss: 0.053609 Acc: 12.6000\n",
      " |~~ train@610  Loss: 0.064690 Acc: 12.8000\n",
      " |~~ train@615  Loss: 0.030240 Acc: 13.4000\n",
      " |~~ train@620  Loss: 0.021185 Acc: 13.6000\n",
      " |~~ train@625  Loss: 0.044898 Acc: 13.2000\n",
      " |~~ train@630  Loss: 0.030190 Acc: 13.4000\n",
      " |~~ train@635  Loss: 0.017876 Acc: 13.8000\n",
      " |~~ train@640  Loss: 0.069079 Acc: 12.6000\n",
      " |~~ train@645  Loss: 0.049567 Acc: 13.0000\n",
      " |~~ train@650  Loss: 0.037382 Acc: 13.2000\n",
      " |~~ train@655  Loss: 0.050886 Acc: 12.8000\n",
      " |~~ train@660  Loss: 0.024241 Acc: 13.6000\n",
      " |~~ train@665  Loss: 0.049836 Acc: 13.0000\n",
      " |~~ train@670  Loss: 0.066075 Acc: 12.6000\n",
      " |~~ train@675  Loss: 0.035114 Acc: 13.2000\n",
      " |~~ train@680  Loss: 0.038592 Acc: 13.2000\n",
      " |~~ train@685  Loss: 0.012344 Acc: 14.0000\n",
      " |~~ train@690  Loss: 0.024119 Acc: 13.6000\n",
      " |~~ train@695  Loss: 0.064137 Acc: 12.8000\n",
      " |~~ train@700  Loss: 0.012150 Acc: 14.0000\n",
      " |~~ train@705  Loss: 0.016396 Acc: 13.8000\n",
      " |~~ train@710  Loss: 0.029295 Acc: 13.2000\n",
      " |~~ train@715  Loss: 0.026597 Acc: 13.6000\n",
      " |~~ train@720  Loss: 0.055443 Acc: 12.8000\n",
      " |~~ train@725  Loss: 0.012122 Acc: 14.0000\n",
      " |~~ train@730  Loss: 0.015620 Acc: 13.8000\n",
      " |~~ train@735  Loss: 0.029774 Acc: 13.6000\n",
      " |~~ train@740  Loss: 0.047561 Acc: 13.0000\n",
      " |~~ train@745  Loss: 0.032740 Acc: 13.4000\n",
      " |~~ train@750  Loss: 0.044805 Acc: 13.0000\n",
      " |~~ train@755  Loss: 0.042876 Acc: 13.2000\n",
      " |~~ train@760  Loss: 0.030798 Acc: 13.4000\n",
      " |~~ train@765  Loss: 0.019370 Acc: 13.8000\n",
      " |~~ train@770  Loss: 0.028806 Acc: 13.4000\n",
      " |~~ train@775  Loss: 0.030321 Acc: 13.4000\n",
      " |~~ train@780  Loss: 0.046826 Acc: 13.0000\n",
      " |~~ train@785  Loss: 0.068312 Acc: 12.4000\n",
      " |~~ train@790  Loss: 0.057243 Acc: 12.8000\n",
      " |~~ train@795  Loss: 0.032349 Acc: 13.6000\n",
      " |~~ train@800  Loss: 0.027487 Acc: 13.6000\n",
      " |~~ train@805  Loss: 0.052808 Acc: 13.0000\n",
      " |~~ train@810  Loss: 0.031903 Acc: 13.4000\n",
      " |~~ train@815  Loss: 0.031727 Acc: 13.4000\n",
      " |~~ train@820  Loss: 0.031627 Acc: 13.4000\n",
      " |~~ train@825  Loss: 0.041454 Acc: 13.4000\n",
      " |~~ train@830  Loss: 0.066773 Acc: 12.6000\n",
      " |~~ train@835  Loss: 0.048325 Acc: 13.2000\n",
      " |~~ train@840  Loss: 0.056602 Acc: 12.6000\n",
      " |~~ train@845  Loss: 0.028805 Acc: 13.4000\n",
      " |~~ train@850  Loss: 0.052297 Acc: 12.8000\n",
      " |~~ train@855  Loss: 0.032403 Acc: 13.4000\n",
      " |~~ train@860  Loss: 0.038407 Acc: 13.0000\n",
      " |~~ train@865  Loss: 0.040468 Acc: 13.2000\n",
      " |~~ train@870  Loss: 0.053313 Acc: 12.8000\n",
      " |~~ train@875  Loss: 0.030289 Acc: 13.4000\n",
      " |~~ train@880  Loss: 0.019953 Acc: 13.8000\n",
      " |~~ train@885  Loss: 0.045851 Acc: 13.0000\n",
      " |~~ train@890  Loss: 0.038429 Acc: 13.2000\n",
      " |~~ train@895  Loss: 0.069109 Acc: 12.4000\n",
      " |~~ train@900  Loss: 0.043040 Acc: 13.2000\n",
      " |~~ train@905  Loss: 0.016928 Acc: 13.8000\n",
      " |~~ train@910  Loss: 0.044999 Acc: 13.2000\n",
      " |~~ train@915  Loss: 0.045171 Acc: 12.8000\n",
      " |~~ train@920  Loss: 0.093599 Acc: 11.8000\n",
      " |~~ train@925  Loss: 0.049450 Acc: 13.0000\n",
      " |~~ train@930  Loss: 0.053809 Acc: 12.8000\n",
      " |~~ train@935  Loss: 0.035278 Acc: 13.2000\n",
      " |~~ train@940  Loss: 0.024770 Acc: 13.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@945  Loss: 0.037917 Acc: 13.4000\n",
      " |~~ train@950  Loss: 0.021500 Acc: 13.8000\n",
      " |~~ train@955  Loss: 0.024782 Acc: 13.4000\n",
      " |~~ train@960  Loss: 0.013406 Acc: 14.0000\n",
      " |~~ train@965  Loss: 0.040621 Acc: 13.0000\n",
      " |~~ train@970  Loss: 0.013110 Acc: 14.0000\n",
      " |~~ train@975  Loss: 0.052959 Acc: 12.8000\n",
      " |~~ train@980  Loss: 0.035436 Acc: 13.2000\n",
      " |~~ train@985  Loss: 0.044536 Acc: 13.0000\n",
      " |~~ train@990  Loss: 0.052441 Acc: 13.0000\n",
      " |~~ train@995  Loss: 0.036882 Acc: 13.0000\n",
      " |~~ train@1000  Loss: 0.020807 Acc: 13.8000\n",
      " |~~ train@1005  Loss: 0.020710 Acc: 13.8000\n",
      " |~~ train@1010  Loss: 0.035231 Acc: 13.4000\n",
      " |~~ train@1015  Loss: 0.044559 Acc: 13.0000\n",
      " |~~ train@1020  Loss: 0.059630 Acc: 12.8000\n",
      " |~~ train@1025  Loss: 0.049210 Acc: 13.0000\n",
      " |~~ train@1030  Loss: 0.038071 Acc: 13.2000\n",
      " |~~ train@1035  Loss: 0.026906 Acc: 13.6000\n",
      " |~~ train@1040  Loss: 0.055385 Acc: 12.8000\n",
      " |~~ train@1045  Loss: 0.020046 Acc: 13.8000\n",
      " |~~ train@1050  Loss: 0.037808 Acc: 13.0000\n",
      " |~~ train@1055  Loss: 0.034318 Acc: 13.4000\n",
      " |~~ train@1060  Loss: 0.022769 Acc: 13.6000\n",
      " |~~ train@1065  Loss: 0.062153 Acc: 13.0000\n",
      " |~~ train@1070  Loss: 0.016739 Acc: 13.8000\n",
      " |~~ train@1075  Loss: 0.032714 Acc: 13.2000\n",
      " |~~ train@1080  Loss: 0.067947 Acc: 12.6000\n",
      " |~~ train@1085  Loss: 0.048670 Acc: 13.0000\n",
      " |~~ train@1090  Loss: 0.040258 Acc: 13.2000\n",
      " |~~ train@1095  Loss: 0.045026 Acc: 13.2000\n",
      " |~~ train@1100  Loss: 0.050635 Acc: 12.8000\n",
      " |~~ train@1105  Loss: 0.056271 Acc: 12.8000\n",
      " |~~ train@1110  Loss: 0.019301 Acc: 13.6000\n",
      " |~~ train@1115  Loss: 0.020906 Acc: 13.6000\n",
      " |~~ train@1120  Loss: 0.027877 Acc: 13.6000\n",
      " |~~ train@1125  Loss: 0.034427 Acc: 13.4000\n",
      " |~~ train@1130  Loss: 0.016006 Acc: 13.8000\n",
      " |~~ train@1135  Loss: 0.029733 Acc: 13.4000\n",
      " |~~ train@1140  Loss: 0.041365 Acc: 13.2000\n",
      " |~~ train@1145  Loss: 0.046198 Acc: 13.0000\n",
      " |~~ train@1150  Loss: 0.036575 Acc: 13.2000\n",
      " |~~ train@1155  Loss: 0.018690 Acc: 13.8000\n",
      " |~~ train@1160  Loss: 0.011958 Acc: 14.0000\n",
      " |~~ train@1165  Loss: 0.032263 Acc: 13.6000\n",
      " |~~ train@1170  Loss: 0.037959 Acc: 13.2000\n",
      " |~~ train@1175  Loss: 0.022735 Acc: 13.8000\n",
      " |~~ train@1180  Loss: 0.022230 Acc: 13.8000\n",
      " |~~ train@1185  Loss: 0.040391 Acc: 13.2000\n",
      " |~~ train@1190  Loss: 0.027058 Acc: 13.4000\n",
      " |~~ train@1195  Loss: 0.044891 Acc: 13.0000\n",
      " |~~ train@1200  Loss: 0.015497 Acc: 13.8000\n",
      " |~~ train@1205  Loss: 0.032619 Acc: 13.4000\n",
      " |~~ train@1210  Loss: 0.033328 Acc: 13.4000\n",
      " |~~ train@1215  Loss: 0.027992 Acc: 13.6000\n",
      " |~~ train@1220  Loss: 0.062347 Acc: 12.4000\n",
      " |~~ train@1225  Loss: 0.074210 Acc: 12.6000\n",
      " |~~ train@1230  Loss: 0.025745 Acc: 13.6000\n",
      " |~~ train@1235  Loss: 0.028736 Acc: 13.4000\n",
      " |~~ train@1240  Loss: 0.019224 Acc: 13.8000\n",
      " |~~ train@1245  Loss: 0.057451 Acc: 12.8000\n",
      " |~~ train@1250  Loss: 0.037387 Acc: 13.2000\n",
      " |~~ train@1255  Loss: 0.039071 Acc: 13.4000\n",
      " |~~ train@1260  Loss: 0.048686 Acc: 13.2000\n",
      " |~~ train@1265  Loss: 0.029378 Acc: 13.6000\n",
      " |~~ train@1270  Loss: 0.024958 Acc: 13.4000\n",
      " |~~ train@1275  Loss: 0.090666 Acc: 11.8000\n",
      " |~~ train@1280  Loss: 0.023479 Acc: 13.6000\n",
      " |~~ train@1285  Loss: 0.041100 Acc: 13.2000\n",
      " |~~ train@1290  Loss: 0.053374 Acc: 12.8000\n",
      " |~~ train@1295  Loss: 0.011072 Acc: 14.0000\n",
      " |~~ train@1300  Loss: 0.051436 Acc: 13.0000\n",
      " |~~ train@1305  Loss: 0.030820 Acc: 13.2000\n",
      " |~~ train@1310  Loss: 0.045124 Acc: 13.2000\n",
      " |~~ train@1315  Loss: 0.020298 Acc: 13.8000\n",
      " |~~ train@1320  Loss: 0.037782 Acc: 13.2000\n",
      " |~~ train@1325  Loss: 0.030229 Acc: 13.6000\n",
      " |~~ train@1330  Loss: 0.010487 Acc: 14.0000\n",
      " |~~ train@1335  Loss: 0.050889 Acc: 13.0000\n",
      " |~~ train@1340  Loss: 0.030460 Acc: 13.2000\n",
      " |~~ train@1345  Loss: 0.038050 Acc: 13.2000\n",
      " |~~ train@1350  Loss: 0.021520 Acc: 13.8000\n",
      " |~~ train@1355  Loss: 0.026416 Acc: 13.4000\n",
      " |~~ train@1360  Loss: 0.031471 Acc: 13.4000\n",
      " |~~ train@1365  Loss: 0.030463 Acc: 13.4000\n",
      " |~~ train@1370  Loss: 0.039262 Acc: 13.2000\n",
      " |~~ train@1375  Loss: 0.026734 Acc: 13.6000\n",
      " |~~ train@1380  Loss: 0.021043 Acc: 13.6000\n",
      " |~~ train@1385  Loss: 0.014983 Acc: 13.8000\n",
      " |~~ train@1390  Loss: 0.025748 Acc: 13.6000\n",
      " |~~ train@1395  Loss: 0.027458 Acc: 13.6000\n",
      " |~~ train@1400  Loss: 0.031865 Acc: 13.4000\n",
      " |~~ train@1405  Loss: 0.048042 Acc: 13.0000\n",
      " |~~ train@1410  Loss: 0.019784 Acc: 13.8000\n",
      " |~~ train@1415  Loss: 0.026709 Acc: 13.6000\n",
      " |~~ train@1420  Loss: 0.048752 Acc: 13.0000\n",
      " |~~ train@1425  Loss: 0.041733 Acc: 13.2000\n",
      " |~~ train@1430  Loss: 0.010927 Acc: 14.0000\n",
      " |~~ train@1435  Loss: 0.010726 Acc: 14.0000\n",
      " |~~ train@1440  Loss: 0.046918 Acc: 13.2000\n",
      " |~~ train@1445  Loss: 0.019687 Acc: 13.8000\n",
      " |~~ train@1450  Loss: 0.021504 Acc: 13.6000\n",
      " |~~ train@1455  Loss: 0.042751 Acc: 13.2000\n",
      " |~~ train@1460  Loss: 0.023848 Acc: 13.6000\n",
      " |~~ train@1465  Loss: 0.040517 Acc: 13.0000\n",
      " |~~ train@1470  Loss: 0.033128 Acc: 13.4000\n",
      " |~~ train@1475  Loss: 0.020726 Acc: 13.8000\n",
      " |~~ train@1480  Loss: 0.009745 Acc: 14.0000\n",
      " |~~ train@1485  Loss: 0.032801 Acc: 13.4000\n",
      " |~~ train@1490  Loss: 0.079070 Acc: 12.4000\n",
      " |~~ train@1495  Loss: 0.054969 Acc: 12.8000\n",
      " |~~ train@1500  Loss: 0.025452 Acc: 13.6000\n",
      " |~~ train@1505  Loss: 0.031205 Acc: 13.4000\n",
      " |~~ train@1510  Loss: 0.039025 Acc: 13.4000\n",
      " |~~ train@1515  Loss: 0.071583 Acc: 12.4000\n",
      " |~~ train@1520  Loss: 0.062484 Acc: 12.8000\n",
      " |~~ train@1525  Loss: 0.029059 Acc: 13.4000\n",
      " |~~ train@1530  Loss: 0.045881 Acc: 13.0000\n",
      " |~~ train@1535  Loss: 0.015208 Acc: 13.8000\n",
      " |~~ train@1540  Loss: 0.024177 Acc: 13.6000\n",
      " |~~ train@1545  Loss: 0.044397 Acc: 13.0000\n",
      " |~~ train@1550  Loss: 0.036541 Acc: 13.2000\n",
      " |~~ train@1555  Loss: 0.040741 Acc: 13.2000\n",
      " |~~ train@1560  Loss: 0.035777 Acc: 13.2000\n",
      " |~~ train@1565  Loss: 0.031599 Acc: 13.4000\n",
      " |~~ train@1570  Loss: 0.010119 Acc: 14.0000\n",
      " |~~ train@1575  Loss: 0.014910 Acc: 13.8000\n",
      " |~~ train@1580  Loss: 0.018203 Acc: 13.8000\n",
      " |~~ train@1585  Loss: 0.067437 Acc: 12.6000\n",
      " |~~ train@1590  Loss: 0.009866 Acc: 14.0000\n",
      " |~~ train@1595  Loss: 0.035093 Acc: 13.4000\n",
      " |~~ train@1600  Loss: 0.024900 Acc: 13.6000\n",
      " |~~ train@1605  Loss: 0.028140 Acc: 13.4000\n",
      " |~~ train@1610  Loss: 0.031171 Acc: 13.4000\n",
      " |~~ train@1615  Loss: 0.052401 Acc: 13.0000\n",
      " |~~ train@1620  Loss: 0.054667 Acc: 13.0000\n",
      " |~~ train@1625  Loss: 0.035363 Acc: 13.2000\n",
      " |~~ train@1630  Loss: 0.074924 Acc: 12.6000\n",
      " |~~ train@1635  Loss: 0.053930 Acc: 13.0000\n",
      " |~~ train@1640  Loss: 0.019783 Acc: 13.8000\n",
      " |~~ train@1645  Loss: 0.047610 Acc: 13.2000\n",
      " |~~ train@1650  Loss: 0.021838 Acc: 13.6000\n",
      " |~~ train@1655  Loss: 0.020956 Acc: 13.6000\n",
      " |~~ train@1660  Loss: 0.032972 Acc: 13.2000\n",
      " |~~ train@1665  Loss: 0.038658 Acc: 13.4000\n",
      " |~~ train@1670  Loss: 0.038549 Acc: 13.4000\n",
      " |~~ train@1675  Loss: 0.043326 Acc: 13.0000\n",
      " |~~ train@1680  Loss: 0.027429 Acc: 13.6000\n",
      " |~~ train@1685  Loss: 0.015120 Acc: 13.8000\n",
      " |~~ train@1690  Loss: 0.059597 Acc: 12.8000\n",
      " |~~ train@1695  Loss: 0.020918 Acc: 13.6000\n",
      " |~~ train@1700  Loss: 0.051661 Acc: 13.0000\n",
      " |~~ train@1705  Loss: 0.032950 Acc: 13.4000\n",
      " |~~ train@1710  Loss: 0.049055 Acc: 13.0000\n",
      " |~~ train@1715  Loss: 0.020707 Acc: 13.8000\n",
      " |~~ train@1720  Loss: 0.033454 Acc: 13.2000\n",
      " |~~ train@1725  Loss: 0.061337 Acc: 12.8000\n",
      " |~~ train@1730  Loss: 0.032602 Acc: 13.4000\n",
      " |~~ train@1735  Loss: 0.043692 Acc: 13.2000\n",
      " |~~ train@1740  Loss: 0.038382 Acc: 13.4000\n",
      " |~~ train@1745  Loss: 0.045357 Acc: 13.0000\n",
      " |~~ train@1750  Loss: 0.038993 Acc: 13.4000\n",
      " |~~ train@1755  Loss: 0.036945 Acc: 13.2000\n",
      " |~~ train@1760  Loss: 0.024718 Acc: 13.4000\n",
      " |~~ train@1765  Loss: 0.027367 Acc: 13.6000\n",
      " |~~ train@1770  Loss: 0.035504 Acc: 13.2000\n",
      " |~~ train@1775  Loss: 0.027892 Acc: 13.4000\n",
      " |~~ train@1780  Loss: 0.038251 Acc: 13.2000\n",
      " |~~ train@1785  Loss: 0.016483 Acc: 13.8000\n",
      " |~~ train@1790  Loss: 0.079910 Acc: 12.4000\n",
      " |~~ train@1795  Loss: 0.044269 Acc: 13.2000\n",
      " |~~ train@1800  Loss: 0.011002 Acc: 14.0000\n",
      " |~~ train@1805  Loss: 0.021089 Acc: 13.8000\n",
      " |~~ train@1810  Loss: 0.079821 Acc: 12.4000\n",
      " |~~ train@1815  Loss: 0.024766 Acc: 13.6000\n",
      " |~~ train@1820  Loss: 0.041252 Acc: 13.2000\n",
      " |~~ train@1825  Loss: 0.040490 Acc: 13.0000\n",
      " |~~ train@1830  Loss: 0.039668 Acc: 13.2000\n",
      " |~~ train@1835  Loss: 0.033172 Acc: 13.2000\n",
      " |~~ train@1840  Loss: 0.022697 Acc: 13.6000\n",
      " |~~ train@1845  Loss: 0.011003 Acc: 14.0000\n",
      " |~~ train@1850  Loss: 0.031758 Acc: 13.6000\n",
      " |~~ train@1855  Loss: 0.060202 Acc: 13.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@1860  Loss: 0.032888 Acc: 13.2000\n",
      " |~~ train@1865  Loss: 0.022463 Acc: 13.6000\n",
      " |~~ train@1870  Loss: 0.014320 Acc: 13.8000\n",
      " |~~ train@1875  Loss: 0.019739 Acc: 13.6000\n",
      " |~~ train@1880  Loss: 0.038914 Acc: 13.2000\n",
      " |~~ train@1885  Loss: 0.024890 Acc: 13.4000\n",
      " |~~ train@1890  Loss: 0.050289 Acc: 13.0000\n",
      " |~~ train@1895  Loss: 0.037360 Acc: 13.2000\n",
      " |~~ train@1900  Loss: 0.041308 Acc: 13.2000\n",
      " |~~ train@1905  Loss: 0.010676 Acc: 14.0000\n",
      " |~~ train@1910  Loss: 0.058453 Acc: 12.8000\n",
      " |~~ train@1915  Loss: 0.050916 Acc: 13.2000\n",
      " |~~ train@1920  Loss: 0.054504 Acc: 13.0000\n",
      " |~~ train@1925  Loss: 0.015961 Acc: 13.8000\n",
      " |~~ train@1930  Loss: 0.017232 Acc: 13.8000\n",
      " |~~ train@1935  Loss: 0.018023 Acc: 13.8000\n",
      " |~~ train@1940  Loss: 0.018406 Acc: 13.8000\n",
      " |~~ train@1945  Loss: 0.027744 Acc: 13.4000\n",
      " |~~ train@1950  Loss: 0.034644 Acc: 13.4000\n",
      " |~~ train@1955  Loss: 0.017766 Acc: 13.8000\n",
      " |~~ train@1960  Loss: 0.041941 Acc: 13.2000\n",
      " |~~ train@1965  Loss: 0.024225 Acc: 13.6000\n",
      " |~~ train@1970  Loss: 0.010219 Acc: 14.0000\n",
      " |~~ train@1975  Loss: 0.032140 Acc: 13.2000\n",
      " |~~ train@1980  Loss: 0.022035 Acc: 13.8000\n",
      " |~~ train@1985  Loss: 0.038226 Acc: 13.6000\n",
      " |~~ train@1990  Loss: 0.031327 Acc: 13.2000\n",
      " |~~ train@1995  Loss: 0.029004 Acc: 13.6000\n",
      " |~~ train@2000  Loss: 0.025759 Acc: 13.6000\n",
      " |~~ train@2005  Loss: 0.031812 Acc: 13.4000\n",
      " |~~ train@2010  Loss: 0.060902 Acc: 12.6000\n",
      " |~~ train@2015  Loss: 0.040794 Acc: 13.2000\n",
      " |~~ train@2020  Loss: 0.010040 Acc: 14.0000\n",
      " |~~ train@2025  Loss: 0.014238 Acc: 13.8000\n",
      " |~~ train@2030  Loss: 0.020954 Acc: 13.6000\n",
      " |~~ train@2035  Loss: 0.031488 Acc: 13.4000\n",
      " |~~ train@2040  Loss: 0.023050 Acc: 13.6000\n",
      " |~~ train@2045  Loss: 0.045594 Acc: 13.2000\n",
      " |~~ train@2050  Loss: 0.068977 Acc: 12.2000\n",
      " |~~ train@2055  Loss: 0.034635 Acc: 13.2000\n",
      " |~~ train@2060  Loss: 0.009126 Acc: 14.0000\n",
      " |~~ train@2065  Loss: 0.009518 Acc: 14.0000\n",
      " |~~ train@2070  Loss: 0.055743 Acc: 12.8000\n",
      " |~~ train@2075  Loss: 0.033599 Acc: 13.2000\n",
      " |~~ train@2080  Loss: 0.028749 Acc: 13.4000\n",
      " |~~ train@2085  Loss: 0.023822 Acc: 13.6000\n",
      " |~~ train@2090  Loss: 0.031564 Acc: 13.4000\n",
      " |~~ train@2095  Loss: 0.076195 Acc: 12.4000\n",
      " |~~ train@2100  Loss: 0.048144 Acc: 13.0000\n",
      " |~~ train@2105  Loss: 0.062316 Acc: 12.6000\n",
      " |~~ train@2110  Loss: 0.042711 Acc: 13.2000\n",
      " |~~ train@2115  Loss: 0.026345 Acc: 13.6000\n",
      " |~~ train@2120  Loss: 0.024595 Acc: 13.6000\n",
      " |~~ train@2125  Loss: 0.018730 Acc: 13.8000\n",
      " |~~ train@2130  Loss: 0.049526 Acc: 13.0000\n",
      " |~~ train@2135  Loss: 0.031038 Acc: 13.4000\n",
      " |~~ train@2140  Loss: 0.020699 Acc: 13.6000\n",
      " |~~ train@2145  Loss: 0.028596 Acc: 13.2000\n",
      " |~~ train@2150  Loss: 0.038723 Acc: 13.0000\n",
      " |~~ train@2155  Loss: 0.043349 Acc: 13.2000\n",
      " |~~ train@2160  Loss: 0.021667 Acc: 13.6000\n",
      " |~~ train@2165  Loss: 0.024091 Acc: 13.6000\n",
      " |~~ train@2170  Loss: 0.056899 Acc: 12.8000\n",
      " |~~ train@2175  Loss: 0.037571 Acc: 13.2000\n",
      " |~~ train@2180  Loss: 0.025226 Acc: 13.6000\n",
      " |~~ train@2185  Loss: 0.034501 Acc: 13.4000\n",
      " |~~ train@2190  Loss: 0.032203 Acc: 13.4000\n",
      " |~~ train@2195  Loss: 0.024338 Acc: 13.4000\n",
      " |~~ train@2200  Loss: 0.035100 Acc: 13.4000\n",
      " |~~ train@2205  Loss: 0.039533 Acc: 13.2000\n",
      " |~~ train@2210  Loss: 0.026462 Acc: 13.4000\n",
      " |~~ train@2215  Loss: 0.054032 Acc: 13.0000\n",
      " |~~ train@2220  Loss: 0.031072 Acc: 13.4000\n",
      " |~~ train@2225  Loss: 0.029258 Acc: 13.4000\n",
      " |~~ train@2230  Loss: 0.046838 Acc: 12.8000\n",
      " |~~ train@2235  Loss: 0.058043 Acc: 13.0000\n",
      " |~~ train@2240  Loss: 0.041632 Acc: 13.2000\n",
      " |~~ train@2245  Loss: 0.068781 Acc: 12.2000\n",
      " |~~ train@2250  Loss: 0.070983 Acc: 12.6000\n",
      " |~~ train@2255  Loss: 0.029273 Acc: 13.6000\n",
      " |~~ train@2260  Loss: 0.030719 Acc: 13.4000\n",
      " |~~ train@2265  Loss: 0.046783 Acc: 13.4000\n",
      " |~~ train@2270  Loss: 0.025788 Acc: 13.6000\n",
      " |~~ train@2275  Loss: 0.065453 Acc: 12.6000\n",
      " |~~ train@2280  Loss: 0.024161 Acc: 13.6000\n",
      " |~~ train@2285  Loss: 0.030102 Acc: 13.4000\n",
      " |~~ train@2290  Loss: 0.016336 Acc: 13.8000\n",
      " |~~ train@2295  Loss: 0.010790 Acc: 14.0000\n",
      " |~~ train@2300  Loss: 0.036705 Acc: 13.2000\n",
      " |~~ train@2305  Loss: 0.017000 Acc: 13.6000\n",
      " |~~ train@2310  Loss: 0.047993 Acc: 13.0000\n",
      " |~~ train@2315  Loss: 0.067161 Acc: 12.6000\n",
      " |~~ train@2320  Loss: 0.046258 Acc: 13.2000\n",
      " |~~ train@2325  Loss: 0.018138 Acc: 13.8000\n",
      " |~~ train@2330  Loss: 0.033926 Acc: 13.2000\n",
      " |~~ train@2335  Loss: 0.030764 Acc: 13.4000\n",
      " |~~ train@2340  Loss: 0.011493 Acc: 14.0000\n",
      " |~~ train@2345  Loss: 0.064143 Acc: 12.2000\n",
      " |~~ train@2350  Loss: 0.070064 Acc: 12.4000\n",
      " |~~ train@2355  Loss: 0.046889 Acc: 13.2000\n",
      " |~~ train@2360  Loss: 0.018603 Acc: 13.8000\n",
      " |~~ train@2365  Loss: 0.016643 Acc: 13.8000\n",
      " |~~ train@2370  Loss: 0.060998 Acc: 12.6000\n",
      " |~~ train@2375  Loss: 0.034635 Acc: 13.4000\n",
      " |~~ train@2380  Loss: 0.030492 Acc: 13.4000\n",
      " |~~ train@2385  Loss: 0.045062 Acc: 13.2000\n",
      " |~~ train@2390  Loss: 0.079792 Acc: 12.4000\n",
      " |~~ train@2395  Loss: 0.011157 Acc: 14.0000\n",
      " |~~ train@2400  Loss: 0.046098 Acc: 13.0000\n",
      " |~~ train@2405  Loss: 0.023874 Acc: 13.6000\n",
      " |~~ train@2410  Loss: 0.032274 Acc: 13.2000\n",
      " |~~ train@2415  Loss: 0.047136 Acc: 13.0000\n",
      " |~~ train@2420  Loss: 0.041829 Acc: 13.4000\n",
      " |~~ train@2425  Loss: 0.035188 Acc: 13.2000\n",
      " |~~ train@2430  Loss: 0.027636 Acc: 13.4000\n",
      " |~~ train@2435  Loss: 0.013992 Acc: 13.8000\n",
      " |~~ train@2440  Loss: 0.017076 Acc: 13.8000\n",
      " |~~ train@2445  Loss: 0.074446 Acc: 12.4000\n",
      " |~~ train@2450  Loss: 0.011590 Acc: 14.0000\n",
      " |~~ train@2455  Loss: 0.062260 Acc: 12.6000\n",
      " |~~ train@2460  Loss: 0.024267 Acc: 13.6000\n",
      " |~~ train@2465  Loss: 0.061716 Acc: 12.6000\n",
      " |~~ train@2470  Loss: 0.080449 Acc: 12.2000\n",
      " |~~ train@2475  Loss: 0.085212 Acc: 12.0000\n",
      " |~~ train@2480  Loss: 0.046883 Acc: 13.0000\n",
      " |~~ train@2485  Loss: 0.032291 Acc: 13.2000\n",
      " |~~ train@2490  Loss: 0.042906 Acc: 13.0000\n",
      " |~~ train@2495  Loss: 0.033297 Acc: 13.4000\n",
      " |~~ train@2500  Loss: 0.045633 Acc: 13.2000\n",
      " |~~ train@2505  Loss: 0.043272 Acc: 13.0000\n",
      " |~~ train@2510  Loss: 0.060318 Acc: 13.0000\n",
      " |~~ train@2515  Loss: 0.040061 Acc: 13.0000\n",
      " |~~ train@2520  Loss: 0.025603 Acc: 13.6000\n",
      " |~~ train@2525  Loss: 0.024688 Acc: 13.6000\n",
      " |~~ train@2530  Loss: 0.030289 Acc: 13.4000\n",
      " |~~ train@2535  Loss: 0.041542 Acc: 13.2000\n",
      " |~~ train@2540  Loss: 0.051051 Acc: 13.0000\n",
      " |~~ train@2545  Loss: 0.015909 Acc: 13.8000\n",
      " |~~ train@2550  Loss: 0.041340 Acc: 13.2000\n",
      " |~~ train@2555  Loss: 0.024080 Acc: 13.8000\n",
      " |~~ train@2560  Loss: 0.031628 Acc: 13.4000\n",
      " |~~ train@2565  Loss: 0.034669 Acc: 13.4000\n",
      " |~~ train@2570  Loss: 0.037531 Acc: 13.2000\n",
      " |~~ train@2575  Loss: 0.029366 Acc: 13.6000\n",
      " |~~ train@2580  Loss: 0.059718 Acc: 12.8000\n",
      " |~~ train@2585  Loss: 0.021290 Acc: 13.6000\n",
      " |~~ train@2590  Loss: 0.017799 Acc: 13.8000\n",
      " |~~ train@2595  Loss: 0.021632 Acc: 13.8000\n",
      " |~~ train@2600  Loss: 0.028644 Acc: 13.4000\n",
      " |~~ train@2605  Loss: 0.044421 Acc: 13.0000\n",
      " |~~ train@2610  Loss: 0.045142 Acc: 12.8000\n",
      " |~~ train@2615  Loss: 0.046285 Acc: 13.0000\n",
      " |~~ train@2620  Loss: 0.022270 Acc: 13.8000\n",
      " |~~ train@2625  Loss: 0.033713 Acc: 13.4000\n",
      " |~~ train@2630  Loss: 0.041412 Acc: 13.2000\n",
      " |~~ train@2635  Loss: 0.042978 Acc: 13.2000\n",
      " |~~ train@2640  Loss: 0.020096 Acc: 13.6000\n",
      " |~~ train@2645  Loss: 0.057203 Acc: 12.8000\n",
      " |~~ train@2650  Loss: 0.035868 Acc: 13.2000\n",
      " |~~ train@2655  Loss: 0.027404 Acc: 13.4000\n",
      " |~~ train@2660  Loss: 0.041271 Acc: 13.2000\n",
      " |~~ train@2665  Loss: 0.033902 Acc: 13.4000\n",
      " |~~ train@2670  Loss: 0.016256 Acc: 13.8000\n",
      " |~~ train@2675  Loss: 0.041224 Acc: 13.2000\n",
      " |~~ train@2680  Loss: 0.026170 Acc: 13.4000\n",
      " |~~ train@2685  Loss: 0.043099 Acc: 13.0000\n",
      " |~~ train@2690  Loss: 0.042502 Acc: 13.0000\n",
      " |~~ train@2695  Loss: 0.042147 Acc: 13.4000\n",
      " |~~ train@2700  Loss: 0.059232 Acc: 12.6000\n",
      " |~~ train@2705  Loss: 0.027150 Acc: 13.6000\n",
      " |~~ train@2710  Loss: 0.044445 Acc: 13.0000\n",
      " |~~ train@2715  Loss: 0.041588 Acc: 13.0000\n",
      " |~~ train@2720  Loss: 0.051586 Acc: 13.2000\n",
      " |~~ train@2725  Loss: 0.030305 Acc: 13.4000\n",
      " |~~ train@2730  Loss: 0.055104 Acc: 13.0000\n",
      " |~~ train@2735  Loss: 0.039707 Acc: 13.2000\n",
      " |~~ train@2740  Loss: 0.014477 Acc: 13.8000\n",
      " |~~ train@2745  Loss: 0.011403 Acc: 14.0000\n",
      " |~~ train@2750  Loss: 0.039647 Acc: 13.2000\n",
      " |~~ train@2755  Loss: 0.037451 Acc: 13.2000\n",
      " |~~ train@2760  Loss: 0.020670 Acc: 13.6000\n",
      " |~~ train@2765  Loss: 0.019601 Acc: 13.8000\n",
      " |~~ train@2770  Loss: 0.043257 Acc: 13.2000\n",
      " |~~ train@2775  Loss: 0.037023 Acc: 13.4000\n",
      " |~~ train@2780  Loss: 0.045240 Acc: 13.2000\n",
      " |~~ train@2785  Loss: 0.016552 Acc: 13.8000\n",
      " |~~ train@2790  Loss: 0.016510 Acc: 13.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@2795  Loss: 0.021227 Acc: 13.6000\n",
      " |~~ train@2800  Loss: 0.050143 Acc: 13.2000\n",
      " |~~ train@2805  Loss: 0.018437 Acc: 13.8000\n",
      " |~~ train@2810  Loss: 0.041060 Acc: 13.2000\n",
      " |~~ train@2815  Loss: 0.062830 Acc: 12.8000\n",
      " |~~ train@2820  Loss: 0.029862 Acc: 13.4000\n",
      " |~~ train@2825  Loss: 0.025088 Acc: 13.4000\n",
      " |~~ train@2830  Loss: 0.022825 Acc: 13.6000\n",
      " |~~ train@2835  Loss: 0.024881 Acc: 13.6000\n",
      " |~~ train@2840  Loss: 0.052559 Acc: 13.0000\n",
      " |~~ train@2845  Loss: 0.055728 Acc: 13.0000\n",
      " |~~ train@2850  Loss: 0.019223 Acc: 13.6000\n",
      " |~~ train@2855  Loss: 0.037188 Acc: 13.2000\n",
      " |~~ train@2860  Loss: 0.027191 Acc: 13.6000\n",
      " |~~ train@2865  Loss: 0.042322 Acc: 13.0000\n",
      " |~~ train@2870  Loss: 0.059598 Acc: 12.6000\n",
      " |~~ train@2875  Loss: 0.016192 Acc: 13.8000\n",
      " |~~ train@2880  Loss: 0.051062 Acc: 13.0000\n",
      " |~~ train@2885  Loss: 0.049392 Acc: 13.0000\n",
      " |~~ train@2890  Loss: 0.047780 Acc: 12.8000\n",
      " |~~ train@2895  Loss: 0.025760 Acc: 13.6000\n",
      " |~~ train@2900  Loss: 0.039874 Acc: 13.4000\n",
      " |~~ train@2905  Loss: 0.041146 Acc: 13.0000\n",
      " |~~ train@2910  Loss: 0.032205 Acc: 13.4000\n",
      " |~~ train@2915  Loss: 0.026423 Acc: 13.4000\n",
      " |~~ train@2920  Loss: 0.063435 Acc: 12.8000\n",
      " |~~ train@2925  Loss: 0.028278 Acc: 13.4000\n",
      " |~~ train@2930  Loss: 0.048985 Acc: 13.0000\n",
      " |~~ train@2935  Loss: 0.036598 Acc: 13.2000\n",
      " |~~ train@2940  Loss: 0.034529 Acc: 13.4000\n",
      " |~~ train@2945  Loss: 0.035083 Acc: 13.4000\n",
      " |~~ train@2950  Loss: 0.024745 Acc: 13.6000\n",
      " |~~ train@2955  Loss: 0.031733 Acc: 13.6000\n",
      " |~~ train@2960  Loss: 0.071544 Acc: 12.6000\n",
      " |~~ train@2965  Loss: 0.039634 Acc: 13.2000\n",
      " |~~ train@2970  Loss: 0.028579 Acc: 13.6000\n",
      " |~~ train@2975  Loss: 0.067359 Acc: 12.2000\n",
      " |~~ train@2980  Loss: 0.034267 Acc: 13.4000\n",
      " |~~ train@2985  Loss: 0.023577 Acc: 13.6000\n",
      " |~~ train@2990  Loss: 0.093953 Acc: 12.0000\n",
      " |~~ train@2995  Loss: 0.028586 Acc: 13.4000\n",
      " |~~ train@3000  Loss: 0.039930 Acc: 13.2000\n",
      " |~~ train@3005  Loss: 0.026603 Acc: 13.6000\n",
      " |~~ train@3010  Loss: 0.055079 Acc: 12.8000\n",
      " |~~ train@3015  Loss: 0.031985 Acc: 13.4000\n",
      " |~~ train@3020  Loss: 0.034849 Acc: 13.4000\n",
      " |~~ train@3025  Loss: 0.054243 Acc: 12.6000\n",
      " |~~ train@3030  Loss: 0.061821 Acc: 12.8000\n",
      " |~~ train@3035  Loss: 0.015123 Acc: 13.8000\n",
      " |~~ train@3040  Loss: 0.020573 Acc: 13.6000\n",
      " |~~ train@3045  Loss: 0.022224 Acc: 13.8000\n",
      " |~~ train@3050  Loss: 0.019009 Acc: 13.8000\n",
      " |~~ train@3055  Loss: 0.040283 Acc: 13.2000\n",
      " |~~ train@3060  Loss: 0.032337 Acc: 13.4000\n",
      " |~~ train@3065  Loss: 0.024639 Acc: 13.6000\n",
      " |~~ train@3070  Loss: 0.054901 Acc: 12.8000\n",
      " |~~ train@3075  Loss: 0.038410 Acc: 13.4000\n",
      " |~~ train@3080  Loss: 0.033491 Acc: 13.4000\n",
      " |~~ train@3085  Loss: 0.061116 Acc: 12.8000\n",
      " |~~ train@3090  Loss: 0.015318 Acc: 13.8000\n",
      " |~~ train@3095  Loss: 0.054886 Acc: 12.8000\n",
      " |~~ train@3100  Loss: 0.015372 Acc: 13.8000\n",
      " |~~ train@3105  Loss: 0.031026 Acc: 13.4000\n",
      " |~~ train@3110  Loss: 0.034376 Acc: 13.2000\n",
      " |~~ train@3115  Loss: 0.028397 Acc: 13.4000\n",
      " |~~ train@3120  Loss: 0.055684 Acc: 13.0000\n",
      " |~~ train@3125  Loss: 0.036934 Acc: 13.4000\n",
      " |~~ train@3130  Loss: 0.015628 Acc: 13.8000\n",
      " |~~ train@3135  Loss: 0.033473 Acc: 13.2000\n",
      " |~~ train@3140  Loss: 0.048454 Acc: 12.6000\n",
      " |~~ train@3145  Loss: 0.050139 Acc: 13.0000\n",
      " |~~ train@3150  Loss: 0.030242 Acc: 13.4000\n",
      " |~~ train@3155  Loss: 0.055510 Acc: 12.8000\n",
      " |~~ train@3160  Loss: 0.020701 Acc: 13.8000\n",
      " |~~ train@3165  Loss: 0.057986 Acc: 12.6000\n",
      " |~~ train@3170  Loss: 0.015609 Acc: 13.8000\n",
      " |~~ train@3175  Loss: 0.055161 Acc: 12.6000\n",
      " |~~ train@3180  Loss: 0.059012 Acc: 12.8000\n",
      " |~~ train@3185  Loss: 0.024872 Acc: 13.6000\n",
      " |~~ train@3190  Loss: 0.036315 Acc: 13.2000\n",
      " |~~ train@3195  Loss: 0.051321 Acc: 13.0000\n",
      " |~~ train@3200  Loss: 0.075894 Acc: 12.4000\n",
      " |~~ train@3205  Loss: 0.031763 Acc: 13.4000\n",
      " |~~ train@3210  Loss: 0.056309 Acc: 13.0000\n",
      " |~~ train@3215  Loss: 0.044686 Acc: 13.2000\n",
      " |~~ train@3220  Loss: 0.031260 Acc: 13.2000\n",
      " |~~ train@3225  Loss: 0.030265 Acc: 13.6000\n",
      " |~~ train@3230  Loss: 0.049909 Acc: 13.2000\n",
      " |~~ train@3235  Loss: 0.034438 Acc: 13.2000\n",
      " |~~ train@3240  Loss: 0.042459 Acc: 13.0000\n",
      " |~~ train@3245  Loss: 0.039273 Acc: 13.0000\n",
      " |~~ train@3250  Loss: 0.022782 Acc: 13.6000\n",
      " |~~ train@3255  Loss: 0.024320 Acc: 13.6000\n",
      " |~~ train@3260  Loss: 0.036143 Acc: 13.2000\n",
      " |~~ train@3265  Loss: 0.032144 Acc: 13.4000\n",
      " |~~ train@3270  Loss: 0.024815 Acc: 13.6000\n",
      " |~~ train@3275  Loss: 0.028728 Acc: 13.4000\n",
      " |~~ train@3280  Loss: 0.028429 Acc: 13.4000\n",
      " |~~ train@3285  Loss: 0.031222 Acc: 13.2000\n",
      " |~~ train@3290  Loss: 0.019050 Acc: 13.6000\n",
      " |~~ train@3295  Loss: 0.047992 Acc: 12.8000\n",
      " |~~ train@3300  Loss: 0.012576 Acc: 14.0000\n",
      " |~~ train@3305  Loss: 0.022848 Acc: 13.6000\n",
      " |~~ train@3310  Loss: 0.011745 Acc: 14.0000\n",
      " |~~ train@3315  Loss: 0.044970 Acc: 13.2000\n",
      " |~~ train@3320  Loss: 0.025091 Acc: 13.6000\n",
      " |~~ train@3325  Loss: 0.029917 Acc: 13.4000\n",
      " |~~ train@3330  Loss: 0.032956 Acc: 13.2000\n",
      " |~~ train@3335  Loss: 0.011869 Acc: 14.0000\n",
      " |~~ train@3340  Loss: 0.061282 Acc: 12.8000\n",
      " |~~ train@3345  Loss: 0.050403 Acc: 13.0000\n",
      " |~~ train@3350  Loss: 0.048628 Acc: 12.8000\n",
      " |~~ train@3355  Loss: 0.025016 Acc: 13.6000\n",
      " |~~ train@3360  Loss: 0.030248 Acc: 13.4000\n",
      " |~~ train@3365  Loss: 0.060529 Acc: 12.6000\n",
      " |~~ train@3370  Loss: 0.034106 Acc: 13.4000\n",
      " |~~ train@3375  Loss: 0.105619 Acc: 11.6000\n",
      " |~~ train@3380  Loss: 0.022759 Acc: 13.6000\n",
      " |~~ train@3385  Loss: 0.059996 Acc: 12.8000\n",
      " |~~ train@3390  Loss: 0.058623 Acc: 12.4000\n",
      " |~~ train@3395  Loss: 0.040553 Acc: 13.2000\n",
      " |~~ train@3400  Loss: 0.054541 Acc: 12.6000\n",
      " |~~ train@3405  Loss: 0.054277 Acc: 13.0000\n",
      " |~~ train@3410  Loss: 0.019675 Acc: 13.8000\n",
      " |~~ train@3415  Loss: 0.030063 Acc: 13.6000\n",
      " |~~ train@3420  Loss: 0.029914 Acc: 13.4000\n",
      " |~~ train@3425  Loss: 0.022617 Acc: 13.6000\n",
      " |~~ train@3430  Loss: 0.049748 Acc: 13.0000\n",
      " |~~ train@3435  Loss: 0.045808 Acc: 13.4000\n",
      " |~~ train@3440  Loss: 0.037084 Acc: 13.0000\n",
      " |~~ train@3445  Loss: 0.026958 Acc: 13.6000\n",
      " |~~ train@3450  Loss: 0.035768 Acc: 13.4000\n",
      " |~~ train@3455  Loss: 0.024470 Acc: 13.6000\n",
      " |~~ train@3460  Loss: 0.037807 Acc: 13.2000\n",
      " |~~ train@3465  Loss: 0.040258 Acc: 13.0000\n",
      " |~~ train@3470  Loss: 0.026178 Acc: 13.6000\n",
      " |~~ train@3475  Loss: 0.069415 Acc: 12.2000\n",
      " |~~ train@3480  Loss: 0.038002 Acc: 13.2000\n",
      " |~~ train@3485  Loss: 0.032481 Acc: 13.4000\n",
      " |~~ train@3490  Loss: 0.044175 Acc: 13.0000\n",
      " |~~ train@3495  Loss: 0.017130 Acc: 13.8000\n",
      " |~~ train@3500  Loss: 0.028255 Acc: 13.4000\n",
      " |~~ train@3505  Loss: 0.039254 Acc: 13.2000\n",
      " |~~ train@3510  Loss: 0.048862 Acc: 13.2000\n",
      " |~~ train@3515  Loss: 0.030164 Acc: 13.4000\n",
      " |~~ train@3520  Loss: 0.034757 Acc: 13.4000\n",
      " |~~ train@3525  Loss: 0.036539 Acc: 13.4000\n",
      " |~~ train@3530  Loss: 0.023297 Acc: 13.6000\n",
      " |~~ train@3535  Loss: 0.038170 Acc: 13.2000\n",
      " |~~ train@3540  Loss: 0.052800 Acc: 13.0000\n",
      " |~~ train@3545  Loss: 0.019875 Acc: 13.8000\n",
      " |~~ train@3550  Loss: 0.032429 Acc: 13.4000\n",
      " |~~ train@3555  Loss: 0.029699 Acc: 13.4000\n",
      " |~~ train@3560  Loss: 0.044284 Acc: 13.0000\n",
      " |~~ train@3565  Loss: 0.039317 Acc: 13.0000\n",
      " |~~ train@3570  Loss: 0.021082 Acc: 13.6000\n",
      " |~~ train@3575  Loss: 0.047125 Acc: 13.0000\n",
      " |~~ train@3580  Loss: 0.045769 Acc: 12.8000\n",
      " |~~ train@3585  Loss: 0.011533 Acc: 14.0000\n",
      " |~~ train@3590  Loss: 0.081994 Acc: 12.0000\n",
      " |~~ train@3595  Loss: 0.047504 Acc: 13.0000\n",
      " |~~ train@3600  Loss: 0.042478 Acc: 13.4000\n",
      " |~~ train@3605  Loss: 0.022898 Acc: 13.8000\n",
      " |~~ train@3610  Loss: 0.049365 Acc: 13.0000\n",
      " |~~ train@3615  Loss: 0.040983 Acc: 12.8000\n",
      " |~~ train@3620  Loss: 0.027756 Acc: 13.2000\n",
      " |~~ train@3625  Loss: 0.031957 Acc: 13.4000\n",
      " |~~ train@3630  Loss: 0.040858 Acc: 13.0000\n",
      " |~~ train@3635  Loss: 0.019978 Acc: 13.8000\n",
      " |~~ train@3640  Loss: 0.034744 Acc: 13.2000\n",
      " |~~ train@3645  Loss: 0.028736 Acc: 13.6000\n",
      " |~~ train@3650  Loss: 0.032962 Acc: 13.4000\n",
      " |~~ train@3655  Loss: 0.027658 Acc: 13.4000\n",
      " |~~ train@3660  Loss: 0.020012 Acc: 13.8000\n",
      " |~~ train@3665  Loss: 0.022102 Acc: 13.6000\n",
      " |~~ train@3670  Loss: 0.045033 Acc: 13.2000\n",
      " |~~ train@3675  Loss: 0.028020 Acc: 13.2000\n",
      " |~~ train@3680  Loss: 0.029618 Acc: 13.6000\n",
      " |~~ train@3685  Loss: 0.032655 Acc: 13.6000\n",
      " |~~ train@3690  Loss: 0.029347 Acc: 13.6000\n",
      " |~~ train@3695  Loss: 0.014955 Acc: 13.8000\n",
      " |~~ train@3700  Loss: 0.011933 Acc: 14.0000\n",
      " |~~ train@3705  Loss: 0.033079 Acc: 13.4000\n",
      " |~~ train@3710  Loss: 0.030055 Acc: 13.4000\n",
      " |~~ train@3715  Loss: 0.011677 Acc: 14.0000\n",
      " |~~ train@3720  Loss: 0.020531 Acc: 13.8000\n",
      " |~~ train@3725  Loss: 0.033654 Acc: 13.6000\n",
      " |~~ train@3730  Loss: 0.021594 Acc: 13.8000\n",
      " |~~ train@3735  Loss: 0.059718 Acc: 12.4000\n",
      " |~~ train@3740  Loss: 0.042313 Acc: 13.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@3745  Loss: 0.019962 Acc: 13.6000\n",
      " |~~ train@3750  Loss: 0.042285 Acc: 13.0000\n",
      " |~~ train@3755  Loss: 0.032067 Acc: 13.2000\n",
      " |~~ train@3760  Loss: 0.024246 Acc: 13.4000\n",
      " |~~ train@3765  Loss: 0.010064 Acc: 14.0000\n",
      " |~~ train@3770  Loss: 0.025117 Acc: 13.6000\n",
      " |~~ train@3775  Loss: 0.018830 Acc: 13.6000\n",
      " |~~ train@3780  Loss: 0.028907 Acc: 13.6000\n",
      " |~~ train@3785  Loss: 0.010196 Acc: 14.0000\n",
      " |~~ train@3790  Loss: 0.069163 Acc: 12.6000\n",
      " |~~ train@3795  Loss: 0.030617 Acc: 13.6000\n",
      " |~~ train@3800  Loss: 0.053657 Acc: 13.0000\n",
      " |~~ train@3805  Loss: 0.025226 Acc: 13.6000\n",
      " |~~ train@3810  Loss: 0.040118 Acc: 13.2000\n",
      " |~~ train@3815  Loss: 0.009613 Acc: 14.0000\n",
      " |~~ train@3820  Loss: 0.027436 Acc: 13.6000\n",
      " |~~ train@3825  Loss: 0.013880 Acc: 13.8000\n",
      " |~~ train@3830  Loss: 0.027754 Acc: 13.6000\n",
      " |~~ train@3835  Loss: 0.026370 Acc: 13.4000\n",
      " |~~ train@3840  Loss: 0.029846 Acc: 13.6000\n",
      " |~~ train@3845  Loss: 0.023835 Acc: 13.6000\n",
      " |~~ train@3850  Loss: 0.022630 Acc: 13.6000\n",
      " |~~ train@3855  Loss: 0.021097 Acc: 13.6000\n",
      " |~~ train@3860  Loss: 0.040779 Acc: 13.0000\n",
      " |~~ train@3865  Loss: 0.032330 Acc: 13.2000\n",
      " |~~ train@3870  Loss: 0.048023 Acc: 13.2000\n",
      " |~~ train@3875  Loss: 0.033905 Acc: 13.4000\n",
      " |~~ train@3880  Loss: 0.033654 Acc: 13.4000\n",
      " |~~ train@3885  Loss: 0.014705 Acc: 13.8000\n",
      " |~~ train@3890  Loss: 0.042791 Acc: 13.2000\n",
      " |~~ train@3895  Loss: 0.034368 Acc: 13.4000\n",
      " |~~ train@3900  Loss: 0.025002 Acc: 13.4000\n",
      " |~~ train@3905  Loss: 0.081948 Acc: 12.2000\n",
      " |~~ train@3910  Loss: 0.041470 Acc: 13.2000\n",
      " |~~ train@3915  Loss: 0.032565 Acc: 13.4000\n",
      " |~~ train@3920  Loss: 0.025637 Acc: 13.6000\n",
      " |~~ train@3925  Loss: 0.041833 Acc: 13.0000\n",
      " |~~ train@3930  Loss: 0.028187 Acc: 13.4000\n",
      " |~~ train@3935  Loss: 0.014957 Acc: 13.8000\n",
      " |~~ train@3940  Loss: 0.031454 Acc: 13.2000\n",
      " |~~ train@3945  Loss: 0.067090 Acc: 12.6000\n",
      " |~~ train@3950  Loss: 0.013666 Acc: 13.8000\n",
      " |~~ train@3955  Loss: 0.032118 Acc: 13.0000\n",
      " |~~ train@3960  Loss: 0.021908 Acc: 13.6000\n",
      " |~~ train@3965  Loss: 0.027948 Acc: 13.4000\n",
      " |~~ train@3970  Loss: 0.061379 Acc: 12.8000\n",
      " |~~ train@3975  Loss: 0.063121 Acc: 12.6000\n",
      " |~~ train@3980  Loss: 0.022889 Acc: 13.6000\n",
      " |~~ train@3985  Loss: 0.019700 Acc: 13.6000\n",
      " |~~ train@3990  Loss: 0.025943 Acc: 13.4000\n",
      " |~~ train@3995  Loss: 0.029552 Acc: 13.2000\n",
      " |~~ train@4000  Loss: 0.039639 Acc: 13.2000\n",
      " |~~ train@4005  Loss: 0.038347 Acc: 13.2000\n",
      " |~~ train@4010  Loss: 0.027230 Acc: 13.2000\n",
      " |~~ train@4015  Loss: 0.027302 Acc: 13.6000\n",
      " |~~ train@4020  Loss: 0.055469 Acc: 13.0000\n",
      " |~~ train@4025  Loss: 0.033598 Acc: 13.4000\n",
      " |~~ train@4030  Loss: 0.030346 Acc: 13.6000\n",
      " |~~ train@4035  Loss: 0.036769 Acc: 13.2000\n",
      " |~~ train@4040  Loss: 0.028037 Acc: 13.4000\n",
      " |~~ train@4045  Loss: 0.020301 Acc: 13.8000\n",
      " |~~ train@4050  Loss: 0.040681 Acc: 13.2000\n",
      " |~~ train@4055  Loss: 0.014348 Acc: 13.8000\n",
      " |~~ train@4060  Loss: 0.026976 Acc: 13.4000\n",
      " |~~ train@4065  Loss: 0.014596 Acc: 13.8000\n",
      " |~~ train@4070  Loss: 0.041976 Acc: 13.0000\n",
      " |~~ train@4075  Loss: 0.022468 Acc: 13.6000\n",
      " |~~ train@4080  Loss: 0.035049 Acc: 13.4000\n",
      " |~~ train@4085  Loss: 0.014633 Acc: 13.8000\n",
      " |~~ train@4090  Loss: 0.100260 Acc: 11.6000\n",
      " |~~ train@4095  Loss: 0.021644 Acc: 13.6000\n",
      " |~~ train@4100  Loss: 0.054025 Acc: 12.8000\n",
      " |~~ train@4105  Loss: 0.047220 Acc: 13.4000\n",
      " |~~ train@4110  Loss: 0.061641 Acc: 12.6000\n",
      " |~~ train@4115  Loss: 0.031144 Acc: 13.2000\n",
      " |~~ train@4120  Loss: 0.039419 Acc: 13.2000\n",
      " |~~ train@4125  Loss: 0.028014 Acc: 13.4000\n",
      " |~~ train@4130  Loss: 0.035228 Acc: 13.4000\n",
      " |~~ train@4135  Loss: 0.023408 Acc: 13.6000\n",
      " |~~ train@4140  Loss: 0.019035 Acc: 13.6000\n",
      " |~~ train@4145  Loss: 0.024692 Acc: 13.6000\n",
      " |~~ train@4150  Loss: 0.026140 Acc: 13.6000\n",
      " |~~ train@4155  Loss: 0.055340 Acc: 12.6000\n",
      " |~~ train@4160  Loss: 0.023181 Acc: 13.4000\n",
      " |~~ train@4165  Loss: 0.056447 Acc: 12.6000\n",
      " |~~ train@4170  Loss: 0.020119 Acc: 13.6000\n",
      " |~~ train@4175  Loss: 0.046262 Acc: 13.0000\n",
      " |~~ train@4180  Loss: 0.030857 Acc: 13.4000\n",
      " |~~ train@4185  Loss: 0.065702 Acc: 12.6000\n",
      " |~~ train@4190  Loss: 0.015654 Acc: 13.6000\n",
      " |~~ train@4195  Loss: 0.063629 Acc: 12.6000\n",
      " |~~ train@4200  Loss: 0.033453 Acc: 13.4000\n",
      " |~~ train@4205  Loss: 0.075629 Acc: 12.4000\n",
      " |~~ train@4210  Loss: 0.034207 Acc: 13.4000\n",
      " |~~ train@4215  Loss: 0.031041 Acc: 13.2000\n",
      " |~~ train@4220  Loss: 0.038958 Acc: 13.2000\n",
      " |~~ train@4225  Loss: 0.053492 Acc: 13.2000\n",
      " |~~ train@4230  Loss: 0.024514 Acc: 13.8000\n",
      " |~~ train@4235  Loss: 0.044193 Acc: 13.0000\n",
      " |~~ train@4240  Loss: 0.053988 Acc: 13.2000\n",
      " |~~ train@4245  Loss: 0.036498 Acc: 13.2000\n",
      " |~~ train@4250  Loss: 0.011438 Acc: 14.0000\n",
      " |~~ train@4255  Loss: 0.014863 Acc: 13.8000\n",
      " |~~ train@4260  Loss: 0.013607 Acc: 13.8000\n",
      " |~~ train@4265  Loss: 0.042408 Acc: 13.0000\n",
      " |~~ train@4270  Loss: 0.021118 Acc: 13.6000\n",
      " |~~ train@4275  Loss: 0.016075 Acc: 13.8000\n",
      " |~~ train@4280  Loss: 0.036645 Acc: 13.2000\n",
      " |~~ train@4285  Loss: 0.072172 Acc: 12.4000\n",
      " |~~ train@4290  Loss: 0.018454 Acc: 13.8000\n",
      " |~~ train@4295  Loss: 0.032795 Acc: 13.4000\n",
      " |~~ train@4300  Loss: 0.035895 Acc: 13.4000\n",
      " |~~ train@4305  Loss: 0.031841 Acc: 13.6000\n",
      " |~~ train@4310  Loss: 0.020627 Acc: 13.8000\n",
      " |~~ train@4315  Loss: 0.046671 Acc: 13.2000\n",
      " |~~ train@4320  Loss: 0.029726 Acc: 13.4000\n",
      " |~~ train@4325  Loss: 0.094942 Acc: 12.2000\n",
      " |~~ train@4330  Loss: 0.027177 Acc: 13.6000\n",
      " |~~ train@4335  Loss: 0.028100 Acc: 13.6000\n",
      " |~~ train@4340  Loss: 0.017112 Acc: 13.8000\n",
      " |~~ train@4345  Loss: 0.021857 Acc: 13.6000\n",
      " |~~ train@4350  Loss: 0.013095 Acc: 13.8000\n",
      " |~~ train@4355  Loss: 0.054618 Acc: 13.0000\n",
      " |~~ train@4360  Loss: 0.009910 Acc: 14.0000\n",
      " |~~ train@4365  Loss: 0.029301 Acc: 13.4000\n",
      " |~~ train@4370  Loss: 0.040768 Acc: 13.2000\n",
      " |~~ train@4375  Loss: 0.025901 Acc: 13.6000\n",
      " |~~ train@4380  Loss: 0.031519 Acc: 13.2000\n",
      " |~~ train@4385  Loss: 0.049353 Acc: 13.0000\n",
      " |~~ train@4390  Loss: 0.025978 Acc: 13.6000\n",
      " |~~ train@4395  Loss: 0.037109 Acc: 13.2000\n",
      " |~~ train@4400  Loss: 0.025747 Acc: 13.6000\n",
      " |~~ train@4405  Loss: 0.030417 Acc: 13.4000\n",
      " |~~ train@4410  Loss: 0.042149 Acc: 13.2000\n",
      " |~~ train@4415  Loss: 0.026550 Acc: 13.4000\n",
      " |~~ train@4420  Loss: 0.020397 Acc: 13.6000\n",
      " |~~ train@4425  Loss: 0.029146 Acc: 13.2000\n",
      " |~~ train@4430  Loss: 0.068503 Acc: 13.0000\n",
      " |~~ train@4435  Loss: 0.042659 Acc: 13.2000\n",
      " |~~ train@4440  Loss: 0.039979 Acc: 13.2000\n",
      " |~~ train@4445  Loss: 0.022421 Acc: 13.6000\n",
      " |~~ train@4450  Loss: 0.029760 Acc: 13.2000\n",
      " |~~ train@4455  Loss: 0.009498 Acc: 14.0000\n",
      " |~~ train@4460  Loss: 0.050326 Acc: 13.0000\n",
      " |~~ train@4465  Loss: 0.034584 Acc: 13.4000\n",
      " |~~ train@4470  Loss: 0.030809 Acc: 13.2000\n",
      " |~~ train@4475  Loss: 0.024740 Acc: 13.6000\n",
      " |~~ train@4480  Loss: 0.036814 Acc: 13.2000\n",
      " |~~ train@4485  Loss: 0.020039 Acc: 13.6000\n",
      " |~~ train@4490  Loss: 0.033704 Acc: 13.2000\n",
      " |~~ train@4495  Loss: 0.026101 Acc: 13.6000\n",
      " |~~ train@4500  Loss: 0.036655 Acc: 13.4000\n",
      " |~~ train@4505  Loss: 0.037628 Acc: 13.4000\n",
      " |~~ train@4510  Loss: 0.037114 Acc: 13.4000\n",
      " |~~ train@4515  Loss: 0.094568 Acc: 12.0000\n",
      " |~~ train@4520  Loss: 0.039837 Acc: 13.2000\n",
      " |~~ train@4525  Loss: 0.067504 Acc: 12.6000\n",
      " |~~ train@4530  Loss: 0.050017 Acc: 13.0000\n",
      " |~~ train@4535  Loss: 0.021925 Acc: 13.6000\n",
      " |~~ train@4540  Loss: 0.049783 Acc: 13.2000\n",
      " |~~ train@4545  Loss: 0.035277 Acc: 13.4000\n",
      " |~~ train@4550  Loss: 0.027420 Acc: 13.6000\n",
      " |~~ train@4555  Loss: 0.032502 Acc: 13.4000\n",
      " |~~ train@4560  Loss: 0.026343 Acc: 13.4000\n",
      " |~~ train@4565  Loss: 0.032183 Acc: 13.6000\n",
      " |~~ train@4570  Loss: 0.016144 Acc: 13.8000\n",
      " |~~ train@4575  Loss: 0.026446 Acc: 13.4000\n",
      " |~~ train@4580  Loss: 0.075364 Acc: 12.4000\n",
      " |~~ train@4585  Loss: 0.098096 Acc: 12.2000\n",
      " |~~ train@4590  Loss: 0.054552 Acc: 12.8000\n",
      " |~~ train@4595  Loss: 0.029440 Acc: 13.4000\n",
      " |~~ train@4600  Loss: 0.040337 Acc: 13.2000\n",
      " |~~ train@4605  Loss: 0.050079 Acc: 13.0000\n",
      " |~~ train@4610  Loss: 0.053325 Acc: 12.8000\n",
      " |~~ train@4615  Loss: 0.034073 Acc: 13.2000\n",
      " |~~ train@4620  Loss: 0.049412 Acc: 13.0000\n",
      " |~~ train@4625  Loss: 0.037365 Acc: 13.2000\n",
      " |~~ train@4630  Loss: 0.023482 Acc: 13.6000\n",
      " |~~ train@4635  Loss: 0.028948 Acc: 13.4000\n",
      " |~~ train@4640  Loss: 0.034353 Acc: 13.4000\n",
      " |~~ train@4645  Loss: 0.021527 Acc: 13.6000\n",
      " |~~ train@4650  Loss: 0.026096 Acc: 13.6000\n",
      " |~~ train@4655  Loss: 0.021149 Acc: 13.6000\n",
      " |~~ train@4660  Loss: 0.043485 Acc: 13.0000\n",
      " |~~ train@4665  Loss: 0.018698 Acc: 13.8000\n",
      " |~~ train@4670  Loss: 0.035008 Acc: 13.2000\n",
      " |~~ train@4675  Loss: 0.044393 Acc: 13.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@4680  Loss: 0.043347 Acc: 13.0000\n",
      " |~~ train@4685  Loss: 0.024695 Acc: 13.6000\n",
      " |~~ train@4690  Loss: 0.062529 Acc: 12.6000\n",
      " |~~ train@4695  Loss: 0.035530 Acc: 13.2000\n",
      " |~~ train@4700  Loss: 0.035881 Acc: 13.6000\n",
      " |~~ train@4705  Loss: 0.046599 Acc: 13.2000\n",
      " |~~ train@4710  Loss: 0.023145 Acc: 13.6000\n",
      " |~~ train@4715  Loss: 0.045524 Acc: 13.0000\n",
      " |~~ train@4720  Loss: 0.027836 Acc: 13.6000\n",
      " |~~ train@4725  Loss: 0.036790 Acc: 13.2000\n",
      " |~~ train@4730  Loss: 0.072203 Acc: 12.4000\n",
      " |~~ train@4735  Loss: 0.019372 Acc: 13.8000\n",
      " |~~ train@4740  Loss: 0.024341 Acc: 13.8000\n",
      " |~~ train@4745  Loss: 0.034947 Acc: 13.2000\n",
      " |~~ train@4750  Loss: 0.035908 Acc: 13.4000\n",
      " |~~ train@4755  Loss: 0.038295 Acc: 13.4000\n",
      " |~~ train@4760  Loss: 0.046537 Acc: 13.0000\n",
      " |~~ train@4765  Loss: 0.017701 Acc: 13.6000\n",
      " |~~ train@4770  Loss: 0.050129 Acc: 13.0000\n",
      " |~~ train@4775  Loss: 0.021150 Acc: 13.6000\n",
      " |~~ train@4780  Loss: 0.044095 Acc: 13.2000\n",
      " |~~ train@4785  Loss: 0.052902 Acc: 13.0000\n",
      " |~~ train@4790  Loss: 0.025922 Acc: 13.6000\n",
      " |~~ train@4795  Loss: 0.035195 Acc: 13.2000\n",
      " |~~ train@4800  Loss: 0.019173 Acc: 13.6000\n",
      " |~~ train@4805  Loss: 0.016098 Acc: 13.8000\n",
      " |~~ train@4810  Loss: 0.046197 Acc: 13.0000\n",
      " |~~ train@4815  Loss: 0.016518 Acc: 13.8000\n",
      " |~~ train@4820  Loss: 0.042001 Acc: 13.2000\n",
      " |~~ train@4825  Loss: 0.082728 Acc: 11.8000\n",
      " |~~ train@4830  Loss: 0.035398 Acc: 13.4000\n",
      " |~~ train@4835  Loss: 0.027816 Acc: 13.6000\n",
      " |~~ train@4840  Loss: 0.056518 Acc: 12.8000\n",
      " |~~ train@4845  Loss: 0.021214 Acc: 13.6000\n",
      " |~~ train@4850  Loss: 0.062473 Acc: 12.8000\n",
      " |~~ train@4855  Loss: 0.026408 Acc: 13.6000\n",
      " |~~ train@4860  Loss: 0.039355 Acc: 13.2000\n",
      " |~~ train@4865  Loss: 0.051421 Acc: 13.2000\n",
      " |~~ train@4870  Loss: 0.031105 Acc: 13.2000\n",
      " |~~ train@4875  Loss: 0.032210 Acc: 13.4000\n",
      " |~~ train@4880  Loss: 0.033491 Acc: 13.2000\n",
      " |~~ train@4885  Loss: 0.037523 Acc: 13.4000\n",
      " |~~ train@4890  Loss: 0.020853 Acc: 13.6000\n",
      " |~~ train@4895  Loss: 0.037331 Acc: 13.2000\n",
      " |~~ train@4900  Loss: 0.039263 Acc: 12.8000\n",
      " |~~ train@4905  Loss: 0.054483 Acc: 13.0000\n",
      " |~~ train@4910  Loss: 0.028785 Acc: 13.4000\n",
      " |~~ train@4915  Loss: 0.059839 Acc: 12.8000\n",
      " |~~ train@4920  Loss: 0.057378 Acc: 12.8000\n",
      " |~~ train@4925  Loss: 0.031674 Acc: 13.4000\n",
      " |~~ train@4930  Loss: 0.031195 Acc: 13.4000\n",
      " |~~ train@4935  Loss: 0.020281 Acc: 13.8000\n",
      " |~~ train@4940  Loss: 0.032584 Acc: 13.4000\n",
      " |~~ train@4945  Loss: 0.018560 Acc: 13.8000\n",
      " |~~ train@4950  Loss: 0.040451 Acc: 13.2000\n",
      " |~~ train@4955  Loss: 0.026719 Acc: 13.6000\n",
      " |~~ train@4960  Loss: 0.060406 Acc: 12.8000\n",
      " |~~ train@4965  Loss: 0.080781 Acc: 12.2000\n",
      " |~~ train@4970  Loss: 0.013817 Acc: 13.8000\n",
      " |~~ train@4975  Loss: 0.026156 Acc: 13.6000\n",
      " |~~ train@4980  Loss: 0.039306 Acc: 13.2000\n",
      " |~~ train@4985  Loss: 0.028686 Acc: 13.2000\n",
      " |~~ train@4990  Loss: 0.045779 Acc: 13.0000\n",
      " |~~ train@4995  Loss: 0.075025 Acc: 12.4000\n",
      " |~~ train@5000  Loss: 0.024736 Acc: 13.6000\n",
      " |~~ train@5005  Loss: 0.042477 Acc: 13.2000\n",
      " |~~ train@5010  Loss: 0.046378 Acc: 12.8000\n",
      " |~~ train@5015  Loss: 0.020316 Acc: 13.8000\n",
      " |~~ train@5020  Loss: 0.035037 Acc: 13.2000\n",
      " |~~ train@5025  Loss: 0.044312 Acc: 13.2000\n",
      " |~~ train@5030  Loss: 0.035096 Acc: 13.2000\n",
      " |~~ train@5035  Loss: 0.018617 Acc: 13.8000\n",
      " |~~ train@5040  Loss: 0.021163 Acc: 13.4000\n",
      " |~~ train@5045  Loss: 0.030867 Acc: 13.4000\n",
      " |~~ train@5050  Loss: 0.035847 Acc: 13.2000\n",
      " |~~ train@5055  Loss: 0.086090 Acc: 12.2000\n",
      " |~~ train@5060  Loss: 0.014161 Acc: 13.8000\n",
      " |~~ train@5065  Loss: 0.020677 Acc: 13.8000\n",
      " |~~ train@5070  Loss: 0.039503 Acc: 13.4000\n",
      " |~~ train@5075  Loss: 0.030420 Acc: 13.4000\n",
      " |~~ train@5080  Loss: 0.061104 Acc: 12.6000\n",
      " |~~ train@5085  Loss: 0.034190 Acc: 13.2000\n",
      " |~~ train@5090  Loss: 0.061711 Acc: 12.8000\n",
      " |~~ train@5095  Loss: 0.021826 Acc: 13.8000\n",
      " |~~ train@5100  Loss: 0.034981 Acc: 13.2000\n",
      " |~~ train@5105  Loss: 0.056253 Acc: 12.8000\n",
      " |~~ train@5110  Loss: 0.018935 Acc: 13.8000\n",
      " |~~ train@5115  Loss: 0.067704 Acc: 12.4000\n",
      " |~~ train@5120  Loss: 0.036398 Acc: 13.0000\n",
      " |~~ train@5125  Loss: 0.075580 Acc: 12.4000\n",
      " |~~ train@5130  Loss: 0.038528 Acc: 13.2000\n",
      " |~~ train@5135  Loss: 0.040253 Acc: 13.2000\n",
      " |~~ train@5140  Loss: 0.017174 Acc: 13.8000\n",
      " |~~ train@5145  Loss: 0.035307 Acc: 13.4000\n",
      " |~~ train@5150  Loss: 0.032687 Acc: 13.4000\n",
      " |~~ train@5155  Loss: 0.017121 Acc: 13.8000\n",
      " |~~ train@5160  Loss: 0.026937 Acc: 13.6000\n",
      " |~~ train@5165  Loss: 0.027901 Acc: 13.4000\n",
      " |~~ train@5170  Loss: 0.021745 Acc: 13.8000\n",
      " |~~ train@5175  Loss: 0.048084 Acc: 12.8000\n",
      " |~~ train@5180  Loss: 0.011652 Acc: 14.0000\n",
      " |~~ train@5185  Loss: 0.049992 Acc: 12.8000\n",
      " |~~ train@5190  Loss: 0.038217 Acc: 13.2000\n",
      " |~~ train@5195  Loss: 0.020005 Acc: 13.8000\n",
      " |~~ train@5200  Loss: 0.021830 Acc: 13.8000\n",
      " |~~ train@5205  Loss: 0.020734 Acc: 13.6000\n",
      " |~~ train@5210  Loss: 0.018691 Acc: 13.6000\n",
      " |~~ train@5215  Loss: 0.011824 Acc: 14.0000\n",
      " |~~ train@5220  Loss: 0.032177 Acc: 13.4000\n",
      " |~~ train@5225  Loss: 0.038097 Acc: 13.2000\n",
      " |~~ train@5230  Loss: 0.044082 Acc: 13.2000\n",
      " |~~ train@5235  Loss: 0.044333 Acc: 13.0000\n",
      " |~~ train@5240  Loss: 0.044920 Acc: 12.8000\n",
      " |~~ train@5245  Loss: 0.021159 Acc: 13.8000\n",
      " |~~ train@5250  Loss: 0.052371 Acc: 13.0000\n",
      " |~~ train@5255  Loss: 0.019636 Acc: 13.6000\n",
      " |~~ train@5260  Loss: 0.015340 Acc: 13.8000\n",
      " |~~ train@5265  Loss: 0.035100 Acc: 13.2000\n",
      " |~~ train@5270  Loss: 0.016403 Acc: 13.8000\n",
      " |~~ train@5275  Loss: 0.038653 Acc: 13.2000\n",
      " |~~ train@5280  Loss: 0.039853 Acc: 13.2000\n",
      " |~~ train@5285  Loss: 0.051024 Acc: 12.8000\n",
      " |~~ train@5290  Loss: 0.021904 Acc: 13.6000\n",
      " |~~ train@5295  Loss: 0.019152 Acc: 13.8000\n",
      " |~~ train@5300  Loss: 0.014228 Acc: 13.8000\n",
      " |~~ train@5305  Loss: 0.046278 Acc: 13.0000\n",
      " |~~ train@5310  Loss: 0.042549 Acc: 13.0000\n",
      " |~~ train@5315  Loss: 0.040158 Acc: 13.4000\n",
      " |~~ train@5320  Loss: 0.046141 Acc: 13.2000\n",
      " |~~ train@5325  Loss: 0.060477 Acc: 12.8000\n",
      " |~~ train@5330  Loss: 0.050394 Acc: 12.8000\n",
      " |~~ train@5335  Loss: 0.042035 Acc: 13.0000\n",
      " |~~ train@5340  Loss: 0.043332 Acc: 13.4000\n",
      " |~~ train@5345  Loss: 0.027498 Acc: 13.4000\n",
      " |~~ train@5350  Loss: 0.041887 Acc: 13.2000\n",
      " |~~ train@5355  Loss: 0.023816 Acc: 13.6000\n",
      " |~~ train@5360  Loss: 0.024941 Acc: 13.6000\n",
      " |~~ train@5365  Loss: 0.044497 Acc: 13.0000\n",
      " |~~ train@5370  Loss: 0.052741 Acc: 12.8000\n",
      " |~~ train@5375  Loss: 0.038760 Acc: 13.0000\n",
      " |~~ train@5380  Loss: 0.044698 Acc: 13.2000\n",
      " |~~ train@5385  Loss: 0.019983 Acc: 13.8000\n",
      " |~~ train@5390  Loss: 0.032402 Acc: 13.2000\n",
      " |~~ train@5395  Loss: 0.032786 Acc: 13.6000\n",
      " |~~ train@5400  Loss: 0.028019 Acc: 13.6000\n",
      " |~~ train@5405  Loss: 0.068750 Acc: 12.2000\n",
      " |~~ train@5410  Loss: 0.034892 Acc: 13.4000\n",
      " |~~ train@5415  Loss: 0.030880 Acc: 13.4000\n",
      " |~~ train@5420  Loss: 0.054338 Acc: 12.8000\n",
      " |~~ train@5425  Loss: 0.024382 Acc: 13.6000\n",
      " |~~ train@5430  Loss: 0.017575 Acc: 13.8000\n",
      " |~~ train@5435  Loss: 0.044531 Acc: 13.0000\n",
      " |~~ train@5440  Loss: 0.041062 Acc: 13.0000\n",
      " |~~ train@5445  Loss: 0.045068 Acc: 13.2000\n",
      " |~~ train@5450  Loss: 0.010485 Acc: 14.0000\n",
      " |~~ train@5455  Loss: 0.030621 Acc: 13.6000\n",
      " |~~ train@5460  Loss: 0.030115 Acc: 13.4000\n",
      " |~~ train@5465  Loss: 0.022668 Acc: 13.6000\n",
      " |~~ train@5470  Loss: 0.016171 Acc: 13.8000\n",
      " |~~ train@5475  Loss: 0.036739 Acc: 13.4000\n",
      " |~~ train@5480  Loss: 0.106600 Acc: 11.6000\n",
      " |~~ train@5485  Loss: 0.047341 Acc: 13.2000\n",
      " |~~ train@5490  Loss: 0.059423 Acc: 12.8000\n",
      " |~~ train@5495  Loss: 0.064469 Acc: 12.8000\n",
      " |~~ train@5500  Loss: 0.027588 Acc: 13.6000\n",
      " |~~ train@5505  Loss: 0.057400 Acc: 12.6000\n",
      " |~~ train@5510  Loss: 0.011111 Acc: 14.0000\n",
      " |~~ train@5515  Loss: 0.035612 Acc: 13.4000\n",
      " |~~ train@5520  Loss: 0.033622 Acc: 13.4000\n",
      " |~~ train@5525  Loss: 0.045485 Acc: 12.8000\n",
      " |~~ train@5530  Loss: 0.024007 Acc: 13.6000\n",
      " |~~ train@5535  Loss: 0.033329 Acc: 13.4000\n",
      " |~~ train@5540  Loss: 0.026320 Acc: 13.4000\n",
      " |~~ train@5545  Loss: 0.045676 Acc: 13.0000\n",
      " |~~ train@5550  Loss: 0.023964 Acc: 13.6000\n",
      " |~~ train@5555  Loss: 0.048888 Acc: 13.0000\n",
      " |~~ train@5560  Loss: 0.035881 Acc: 13.4000\n",
      " |~~ train@5565  Loss: 0.043550 Acc: 13.2000\n",
      " |~~ train@5570  Loss: 0.049061 Acc: 12.8000\n",
      " |~~ train@5575  Loss: 0.022260 Acc: 13.6000\n",
      " |~~ train@5580  Loss: 0.065006 Acc: 12.4000\n",
      " |~~ train@5585  Loss: 0.016954 Acc: 13.8000\n",
      " |~~ train@5590  Loss: 0.018125 Acc: 13.8000\n",
      " |~~ train@5595  Loss: 0.015815 Acc: 13.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@5600  Loss: 0.043391 Acc: 13.0000\n",
      " |~~ train@5605  Loss: 0.026859 Acc: 13.4000\n",
      " |~~ train@5610  Loss: 0.031973 Acc: 13.4000\n",
      " |~~ train@5615  Loss: 0.058781 Acc: 12.8000\n",
      " |~~ train@5620  Loss: 0.031992 Acc: 13.2000\n",
      " |~~ train@5625  Loss: 0.085352 Acc: 12.4000\n",
      " |~~ train@5630  Loss: 0.038598 Acc: 13.2000\n",
      " |~~ train@5635  Loss: 0.037315 Acc: 13.2000\n",
      " |~~ train@5640  Loss: 0.011403 Acc: 14.0000\n",
      " |~~ train@5645  Loss: 0.036237 Acc: 13.2000\n",
      " |~~ train@5650  Loss: 0.019624 Acc: 13.8000\n",
      " |~~ train@5655  Loss: 0.011420 Acc: 14.0000\n",
      " |~~ train@5660  Loss: 0.031485 Acc: 13.2000\n",
      " |~~ train@5665  Loss: 0.043659 Acc: 13.2000\n",
      " |~~ train@5670  Loss: 0.010870 Acc: 14.0000\n",
      " |~~ train@5675  Loss: 0.058153 Acc: 12.6000\n",
      " |~~ train@5680  Loss: 0.052468 Acc: 12.8000\n",
      " |~~ train@5685  Loss: 0.048648 Acc: 13.0000\n",
      " |~~ train@5690  Loss: 0.031620 Acc: 13.4000\n",
      " |~~ train@5695  Loss: 0.080484 Acc: 12.4000\n",
      " |~~ train@5700  Loss: 0.034762 Acc: 13.2000\n",
      " |~~ train@5705  Loss: 0.023255 Acc: 13.6000\n",
      " |~~ train@5710  Loss: 0.040444 Acc: 13.2000\n",
      " |~~ train@5715  Loss: 0.023671 Acc: 13.6000\n",
      " |~~ train@5720  Loss: 0.047757 Acc: 12.8000\n",
      " |~~ train@5725  Loss: 0.048150 Acc: 13.0000\n",
      " |~~ train@5730  Loss: 0.027037 Acc: 13.8000\n",
      " |~~ train@5735  Loss: 0.062621 Acc: 12.4000\n",
      " |~~ train@5740  Loss: 0.037810 Acc: 13.2000\n",
      " |~~ train@5745  Loss: 0.063438 Acc: 12.8000\n",
      " |~~ train@5750  Loss: 0.036309 Acc: 13.2000\n",
      " |~~ train@5755  Loss: 0.051073 Acc: 13.0000\n",
      " |~~ train@5760  Loss: 0.033129 Acc: 13.4000\n",
      " |~~ train@5765  Loss: 0.029165 Acc: 13.6000\n",
      " |~~ train@5770  Loss: 0.038362 Acc: 13.0000\n",
      " |~~ train@5775  Loss: 0.032545 Acc: 13.2000\n",
      " |~~ train@5780  Loss: 0.020306 Acc: 13.8000\n",
      " |~~ train@5785  Loss: 0.026828 Acc: 13.4000\n",
      " |~~ train@5790  Loss: 0.012312 Acc: 14.0000\n",
      " |~~ train@5795  Loss: 0.049293 Acc: 13.0000\n",
      " |~~ train@5800  Loss: 0.026608 Acc: 13.4000\n",
      " |~~ train@5805  Loss: 0.026664 Acc: 13.4000\n",
      " |~~ train@5810  Loss: 0.016787 Acc: 13.8000\n",
      " |~~ train@5815  Loss: 0.033369 Acc: 13.6000\n",
      " |~~ train@5820  Loss: 0.062157 Acc: 12.6000\n",
      " |~~ train@5825  Loss: 0.042377 Acc: 13.0000\n",
      " |~~ train@5830  Loss: 0.104089 Acc: 11.6000\n",
      " |~~ train@5835  Loss: 0.038633 Acc: 13.0000\n",
      " |~~ train@5840  Loss: 0.017391 Acc: 13.8000\n",
      " |~~ train@5845  Loss: 0.038600 Acc: 13.0000\n",
      " |~~ train@5850  Loss: 0.030279 Acc: 13.4000\n",
      " |~~ train@5855  Loss: 0.044327 Acc: 13.2000\n",
      " |~~ train@5860  Loss: 0.048845 Acc: 13.2000\n",
      " |~~ train@5865  Loss: 0.054420 Acc: 13.0000\n",
      " |~~ train@5870  Loss: 0.050135 Acc: 13.0000\n",
      " |~~ train@5875  Loss: 0.017860 Acc: 13.8000\n",
      " |~~ train@5880  Loss: 0.037381 Acc: 13.2000\n",
      " |~~ train@5885  Loss: 0.011752 Acc: 14.0000\n",
      " |~~ train@5890  Loss: 0.031606 Acc: 13.4000\n",
      " |~~ train@5895  Loss: 0.044757 Acc: 13.0000\n",
      " |~~ train@5900  Loss: 0.011995 Acc: 14.0000\n",
      " |~~ train@5905  Loss: 0.022950 Acc: 13.6000\n",
      " |~~ train@5910  Loss: 0.037457 Acc: 13.2000\n",
      " |~~ train@5915  Loss: 0.034008 Acc: 13.2000\n",
      " |~~ train@5920  Loss: 0.034948 Acc: 13.4000\n",
      " |~~ train@5925  Loss: 0.034952 Acc: 13.2000\n",
      " |~~ train@5930  Loss: 0.040749 Acc: 13.2000\n",
      " |~~ train@5935  Loss: 0.049859 Acc: 13.0000\n",
      " |~~ train@5940  Loss: 0.038687 Acc: 13.0000\n",
      " |~~ train@5945  Loss: 0.052246 Acc: 12.6000\n",
      " |~~ train@5950  Loss: 0.021673 Acc: 13.6000\n",
      " |~~ train@5955  Loss: 0.089594 Acc: 12.2000\n",
      " |~~ train@5960  Loss: 0.046671 Acc: 13.0000\n",
      " |~~ train@5965  Loss: 0.031907 Acc: 13.2000\n",
      " |~~ train@5970  Loss: 0.015267 Acc: 13.8000\n",
      " |~~ train@5975  Loss: 0.026774 Acc: 13.4000\n",
      " |~~ train@5980  Loss: 0.017892 Acc: 13.8000\n",
      " |~~ train@5985  Loss: 0.030711 Acc: 13.6000\n",
      " |~~ train@5990  Loss: 0.039047 Acc: 13.2000\n",
      " |~~ train@5995  Loss: 0.046242 Acc: 13.2000\n",
      " |~~ train@6000  Loss: 0.022294 Acc: 13.8000\n",
      " |~~ train@6005  Loss: 0.031786 Acc: 13.6000\n",
      " |~~ train@6010  Loss: 0.091707 Acc: 11.8000\n",
      " |~~ train@6015  Loss: 0.032438 Acc: 13.2000\n",
      " |~~ train@6020  Loss: 0.028278 Acc: 13.2000\n",
      " |~~ train@6025  Loss: 0.055192 Acc: 13.0000\n",
      " |~~ train@6030  Loss: 0.032268 Acc: 13.4000\n",
      " |~~ train@6035  Loss: 0.031320 Acc: 13.4000\n",
      " |~~ train@6040  Loss: 0.039756 Acc: 13.0000\n",
      " |~~ train@6045  Loss: 0.023016 Acc: 13.6000\n",
      " |~~ train@6050  Loss: 0.027899 Acc: 13.4000\n",
      " |~~ train@6055  Loss: 0.043014 Acc: 13.4000\n",
      " |~~ train@6060  Loss: 0.034481 Acc: 13.4000\n",
      " |~~ train@6065  Loss: 0.023817 Acc: 13.4000\n",
      " |~~ train@6070  Loss: 0.029693 Acc: 13.4000\n",
      " |~~ train@6075  Loss: 0.040265 Acc: 13.2000\n",
      " |~~ train@6080  Loss: 0.031921 Acc: 13.2000\n",
      " |~~ train@6085  Loss: 0.020868 Acc: 13.6000\n",
      " |~~ train@6090  Loss: 0.011762 Acc: 14.0000\n",
      " |~~ train@6095  Loss: 0.018106 Acc: 13.6000\n",
      " |~~ train@6100  Loss: 0.047287 Acc: 13.2000\n",
      " |~~ train@6105  Loss: 0.042049 Acc: 13.0000\n",
      " |~~ train@6110  Loss: 0.029240 Acc: 13.6000\n",
      " |~~ train@6115  Loss: 0.029095 Acc: 13.6000\n",
      " |~~ train@6120  Loss: 0.028850 Acc: 13.4000\n",
      " |~~ train@6125  Loss: 0.073237 Acc: 12.4000\n",
      " |~~ train@6130  Loss: 0.070682 Acc: 12.2000\n",
      " |~~ train@6135  Loss: 0.010836 Acc: 14.0000\n",
      " |~~ train@6140  Loss: 0.034006 Acc: 13.4000\n",
      " |~~ train@6145  Loss: 0.040300 Acc: 13.0000\n",
      " |~~ train@6150  Loss: 0.040893 Acc: 13.0000\n",
      " |~~ train@6155  Loss: 0.032049 Acc: 13.4000\n",
      " |~~ train@6160  Loss: 0.042001 Acc: 13.2000\n",
      " |~~ train@6165  Loss: 0.021348 Acc: 13.8000\n",
      " |~~ train@6170  Loss: 0.054622 Acc: 12.8000\n",
      " |~~ train@6175  Loss: 0.018544 Acc: 13.8000\n",
      " |~~ train@6180  Loss: 0.054319 Acc: 12.8000\n",
      " |~~ train@6185  Loss: 0.026659 Acc: 13.6000\n",
      " |~~ train@6190  Loss: 0.065549 Acc: 12.4000\n",
      " |~~ train@6195  Loss: 0.024487 Acc: 13.6000\n",
      " |~~ train@6200  Loss: 0.022056 Acc: 13.6000\n",
      " |~~ train@6205  Loss: 0.011302 Acc: 14.0000\n",
      " |~~ train@6210  Loss: 0.015953 Acc: 13.8000\n",
      " |~~ train@6215  Loss: 0.056576 Acc: 12.8000\n",
      " |~~ train@6220  Loss: 0.011138 Acc: 14.0000\n",
      " |~~ train@6225  Loss: 0.053992 Acc: 12.8000\n",
      " |~~ train@6230  Loss: 0.048708 Acc: 13.2000\n",
      " |~~ train@6235  Loss: 0.047929 Acc: 13.0000\n",
      " |~~ train@6240  Loss: 0.021803 Acc: 13.4000\n",
      " |~~ train@6245  Loss: 0.072237 Acc: 12.4000\n",
      " |~~ train@6250  Loss: 0.058800 Acc: 12.8000\n",
      " |~~ train@6255  Loss: 0.019609 Acc: 13.6000\n",
      " |~~ train@6260  Loss: 0.026272 Acc: 13.6000\n",
      " |~~ train@6265  Loss: 0.037419 Acc: 13.0000\n",
      " |~~ train@6270  Loss: 0.055414 Acc: 12.8000\n",
      " |~~ train@6275  Loss: 0.018868 Acc: 13.6000\n",
      " |~~ train@6280  Loss: 0.037511 Acc: 13.2000\n",
      " |~~ train@6285  Loss: 0.020402 Acc: 13.8000\n",
      " |~~ train@6290  Loss: 0.047834 Acc: 12.8000\n",
      " |~~ train@6295  Loss: 0.017339 Acc: 13.8000\n",
      " |~~ train@6300  Loss: 0.038913 Acc: 13.2000\n",
      " |~~ train@6305  Loss: 0.030225 Acc: 13.4000\n",
      " |~~ train@6310  Loss: 0.030887 Acc: 13.4000\n",
      " |~~ train@6315  Loss: 0.028081 Acc: 13.4000\n",
      " |~~ train@6320  Loss: 0.034157 Acc: 13.2000\n",
      " |~~ train@6325  Loss: 0.024425 Acc: 13.6000\n",
      " |~~ train@6330  Loss: 0.035354 Acc: 13.4000\n",
      " |~~ train@6335  Loss: 0.063947 Acc: 12.6000\n",
      " |~~ train@6340  Loss: 0.037554 Acc: 13.2000\n",
      " |~~ train@6345  Loss: 0.041893 Acc: 13.2000\n",
      " |~~ train@6350  Loss: 0.033482 Acc: 13.0000\n",
      " |~~ train@6355  Loss: 0.064690 Acc: 12.6000\n",
      " |~~ train@6360  Loss: 0.029907 Acc: 13.6000\n",
      " |~~ train@6365  Loss: 0.056994 Acc: 12.8000\n",
      " |~~ train@6370  Loss: 0.034940 Acc: 13.4000\n",
      " |~~ train@6375  Loss: 0.032654 Acc: 13.0000\n",
      " |~~ train@6380  Loss: 0.014885 Acc: 13.8000\n",
      " |~~ train@6385  Loss: 0.022613 Acc: 13.8000\n",
      " |~~ train@6390  Loss: 0.034915 Acc: 13.2000\n",
      " |~~ train@6395  Loss: 0.022777 Acc: 13.6000\n",
      " |~~ train@6400  Loss: 0.031937 Acc: 13.4000\n",
      " |~~ train@6405  Loss: 0.059538 Acc: 12.6000\n",
      " |~~ train@6410  Loss: 0.065660 Acc: 12.4000\n",
      " |~~ train@6415  Loss: 0.016275 Acc: 13.8000\n",
      " |~~ train@6420  Loss: 0.040698 Acc: 13.2000\n",
      " |~~ train@6425  Loss: 0.032968 Acc: 13.4000\n",
      " |~~ train@6430  Loss: 0.049749 Acc: 12.6000\n",
      " |~~ train@6435  Loss: 0.019390 Acc: 13.8000\n",
      " |~~ train@6440  Loss: 0.046089 Acc: 13.0000\n",
      " |~~ train@6445  Loss: 0.049790 Acc: 13.0000\n",
      " |~~ train@6450  Loss: 0.031592 Acc: 13.4000\n",
      " |~~ train@6455  Loss: 0.046901 Acc: 12.6000\n",
      " |~~ train@6460  Loss: 0.035526 Acc: 13.4000\n",
      " |~~ train@6465  Loss: 0.015478 Acc: 13.8000\n",
      " |~~ train@6470  Loss: 0.023244 Acc: 13.6000\n",
      " |~~ train@6475  Loss: 0.075318 Acc: 12.2000\n",
      " |~~ train@6480  Loss: 0.034970 Acc: 13.4000\n",
      " |~~ train@6485  Loss: 0.035165 Acc: 13.4000\n",
      " |~~ train@6490  Loss: 0.031055 Acc: 13.6000\n",
      " |~~ train@6495  Loss: 0.032170 Acc: 13.4000\n",
      " |~~ train@6500  Loss: 0.037429 Acc: 13.2000\n",
      " |~~ train@6505  Loss: 0.031017 Acc: 13.4000\n",
      " |~~ train@6510  Loss: 0.036712 Acc: 13.2000\n",
      " |~~ train@6515  Loss: 0.088677 Acc: 11.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@6520  Loss: 0.053499 Acc: 13.0000\n",
      " |~~ train@6525  Loss: 0.053878 Acc: 13.0000\n",
      " |~~ train@6530  Loss: 0.041228 Acc: 13.0000\n",
      " |~~ train@6535  Loss: 0.033398 Acc: 13.2000\n",
      " |~~ train@6540  Loss: 0.070173 Acc: 12.2000\n",
      " |~~ train@6545  Loss: 0.031552 Acc: 13.4000\n",
      " |~~ train@6550  Loss: 0.053127 Acc: 13.0000\n",
      " |~~ train@6555  Loss: 0.020105 Acc: 13.6000\n",
      " |~~ train@6560  Loss: 0.052830 Acc: 13.0000\n",
      " |~~ train@6565  Loss: 0.043004 Acc: 13.2000\n",
      " |~~ train@6570  Loss: 0.035955 Acc: 13.2000\n",
      " |~~ train@6575  Loss: 0.044035 Acc: 13.0000\n",
      " |~~ train@6580  Loss: 0.047352 Acc: 12.8000\n",
      " |~~ train@6585  Loss: 0.016624 Acc: 13.8000\n",
      " |~~ train@6590  Loss: 0.043219 Acc: 13.2000\n",
      " |~~ train@6595  Loss: 0.058331 Acc: 13.0000\n",
      " |~~ train@6600  Loss: 0.038806 Acc: 13.2000\n",
      " |~~ train@6605  Loss: 0.027308 Acc: 13.6000\n",
      " |~~ train@6610  Loss: 0.029259 Acc: 13.6000\n",
      " |~~ train@6615  Loss: 0.055719 Acc: 13.0000\n",
      " |~~ train@6620  Loss: 0.020240 Acc: 13.8000\n",
      " |~~ train@6625  Loss: 0.021824 Acc: 13.8000\n",
      " |~~ train@6630  Loss: 0.024956 Acc: 13.4000\n",
      " |~~ train@6635  Loss: 0.011896 Acc: 14.0000\n",
      " |~~ train@6640  Loss: 0.028342 Acc: 13.6000\n",
      " |~~ train@6645  Loss: 0.084189 Acc: 12.0000\n",
      " |~~ train@6650  Loss: 0.032018 Acc: 13.4000\n",
      " |~~ train@6655  Loss: 0.059026 Acc: 13.0000\n",
      " |~~ train@6660  Loss: 0.047072 Acc: 12.8000\n",
      " |~~ train@6665  Loss: 0.051445 Acc: 12.6000\n",
      " |~~ train@6670  Loss: 0.020170 Acc: 13.6000\n",
      " |~~ train@6675  Loss: 0.034006 Acc: 13.2000\n",
      " |~~ train@6680  Loss: 0.024535 Acc: 13.6000\n",
      " |~~ train@6685  Loss: 0.032222 Acc: 13.4000\n",
      " |~~ train@6690  Loss: 0.050393 Acc: 12.8000\n",
      " |~~ train@6695  Loss: 0.063491 Acc: 12.6000\n",
      " |~~ train@6700  Loss: 0.025081 Acc: 13.6000\n",
      " |~~ train@6705  Loss: 0.044109 Acc: 13.0000\n",
      " |~~ train@6710  Loss: 0.036764 Acc: 13.0000\n",
      " |~~ train@6715  Loss: 0.035770 Acc: 13.4000\n",
      " |~~ train@6720  Loss: 0.043229 Acc: 13.2000\n",
      " |~~ train@6725  Loss: 0.022564 Acc: 13.6000\n",
      " |~~ train@6730  Loss: 0.018804 Acc: 13.8000\n",
      " |~~ train@6735  Loss: 0.042373 Acc: 13.0000\n",
      " |~~ train@6740  Loss: 0.011796 Acc: 14.0000\n",
      " |~~ train@6745  Loss: 0.012489 Acc: 14.0000\n",
      " |~~ train@6750  Loss: 0.058598 Acc: 13.0000\n",
      " |~~ train@6755  Loss: 0.045607 Acc: 13.0000\n",
      " |~~ train@6760  Loss: 0.059585 Acc: 12.6000\n",
      " |~~ train@6765  Loss: 0.030082 Acc: 13.6000\n",
      " |~~ train@6770  Loss: 0.041551 Acc: 13.0000\n",
      " |~~ train@6775  Loss: 0.050814 Acc: 13.0000\n",
      " |~~ train@6780  Loss: 0.041988 Acc: 13.2000\n",
      " |~~ train@6785  Loss: 0.019020 Acc: 13.6000\n",
      " |~~ train@6790  Loss: 0.031074 Acc: 13.2000\n",
      " |~~ train@6795  Loss: 0.017111 Acc: 13.8000\n",
      " |~~ train@6800  Loss: 0.039257 Acc: 13.2000\n",
      " |~~ train@6805  Loss: 0.022652 Acc: 13.8000\n",
      " |~~ train@6810  Loss: 0.036055 Acc: 13.2000\n",
      " |~~ train@6815  Loss: 0.044823 Acc: 13.4000\n",
      " |~~ train@6820  Loss: 0.017678 Acc: 13.8000\n",
      " |~~ train@6825  Loss: 0.042811 Acc: 13.0000\n",
      " |~~ train@6830  Loss: 0.011388 Acc: 14.0000\n",
      " |~~ train@6835  Loss: 0.018882 Acc: 13.6000\n",
      " |~~ train@6840  Loss: 0.053742 Acc: 13.0000\n",
      " |~~ train@6845  Loss: 0.047443 Acc: 12.8000\n",
      " |~~ train@6850  Loss: 0.054186 Acc: 13.0000\n",
      " |~~ train@6855  Loss: 0.020313 Acc: 13.8000\n",
      " |~~ train@6860  Loss: 0.035433 Acc: 13.2000\n",
      " |~~ train@6865  Loss: 0.010922 Acc: 14.0000\n",
      " |~~ train@6870  Loss: 0.036120 Acc: 13.2000\n",
      " |~~ train@6875  Loss: 0.043570 Acc: 13.2000\n",
      " |~~ train@6880  Loss: 0.061270 Acc: 12.8000\n",
      " |~~ train@6885  Loss: 0.038527 Acc: 13.2000\n",
      " |~~ train@6890  Loss: 0.042120 Acc: 13.2000\n",
      " |~~ train@6895  Loss: 0.085337 Acc: 12.0000\n",
      " |~~ train@6900  Loss: 0.019884 Acc: 13.8000\n",
      " |~~ train@6905  Loss: 0.021388 Acc: 13.6000\n",
      " |~~ train@6910  Loss: 0.023963 Acc: 13.6000\n",
      " |~~ train@6915  Loss: 0.024160 Acc: 13.6000\n",
      " |~~ train@6920  Loss: 0.038626 Acc: 13.2000\n",
      " |~~ train@6925  Loss: 0.047702 Acc: 13.0000\n",
      " |~~ train@6930  Loss: 0.014413 Acc: 13.8000\n",
      " |~~ train@6935  Loss: 0.031138 Acc: 13.4000\n",
      " |~~ train@6940  Loss: 0.022385 Acc: 13.6000\n",
      " |~~ train@6945  Loss: 0.028092 Acc: 13.4000\n",
      " |~~ train@6950  Loss: 0.043476 Acc: 13.0000\n",
      " |~~ train@6955  Loss: 0.019627 Acc: 13.8000\n",
      " |~~ train@6960  Loss: 0.038643 Acc: 13.2000\n",
      " |~~ train@6965  Loss: 0.030456 Acc: 13.4000\n",
      " |~~ train@6970  Loss: 0.033257 Acc: 13.6000\n",
      " |~~ train@6975  Loss: 0.031194 Acc: 13.4000\n",
      " |~~ train@6980  Loss: 0.019947 Acc: 13.8000\n",
      " |~~ train@6985  Loss: 0.030863 Acc: 13.4000\n",
      " |~~ train@6990  Loss: 0.028040 Acc: 13.4000\n",
      " |~~ train@6995  Loss: 0.036076 Acc: 13.2000\n",
      " |~~ train@7000  Loss: 0.076390 Acc: 12.0000\n",
      " |~~ train@7005  Loss: 0.058165 Acc: 12.6000\n",
      " |~~ train@7010  Loss: 0.041496 Acc: 13.2000\n",
      " |~~ train@7015  Loss: 0.028045 Acc: 13.6000\n",
      " |~~ train@7020  Loss: 0.068084 Acc: 12.2000\n",
      " |~~ train@7025  Loss: 0.027885 Acc: 13.4000\n",
      " |~~ train@7030  Loss: 0.065110 Acc: 13.0000\n",
      " |~~ train@7035  Loss: 0.034899 Acc: 13.0000\n",
      " |~~ train@7040  Loss: 0.035982 Acc: 13.2000\n",
      " |~~ train@7045  Loss: 0.031247 Acc: 13.2000\n",
      " |~~ train@7050  Loss: 0.049794 Acc: 13.0000\n",
      " |~~ train@7055  Loss: 0.034724 Acc: 13.2000\n",
      " |~~ train@7060  Loss: 0.033173 Acc: 13.4000\n",
      " |~~ train@7065  Loss: 0.026953 Acc: 13.6000\n",
      " |~~ train@7070  Loss: 0.043584 Acc: 13.0000\n",
      " |~~ train@7075  Loss: 0.092716 Acc: 11.8000\n",
      " |~~ train@7080  Loss: 0.029548 Acc: 13.4000\n",
      " |~~ train@7085  Loss: 0.020048 Acc: 13.8000\n",
      " |~~ train@7090  Loss: 0.014705 Acc: 13.8000\n",
      " |~~ train@7095  Loss: 0.011383 Acc: 14.0000\n",
      " |~~ train@7100  Loss: 0.080068 Acc: 12.2000\n",
      " |~~ train@7105  Loss: 0.034806 Acc: 13.6000\n",
      " |~~ train@7110  Loss: 0.026825 Acc: 13.4000\n",
      " |~~ train@7115  Loss: 0.029148 Acc: 13.6000\n",
      " |~~ train@7120  Loss: 0.034344 Acc: 13.0000\n",
      " |~~ train@7125  Loss: 0.040034 Acc: 13.2000\n",
      " |~~ train@7130  Loss: 0.027383 Acc: 13.4000\n",
      " |~~ train@7135  Loss: 0.040181 Acc: 13.4000\n",
      " |~~ train@7140  Loss: 0.019589 Acc: 13.6000\n",
      " |~~ train@7145  Loss: 0.018301 Acc: 13.8000\n",
      " |~~ train@7150  Loss: 0.030716 Acc: 13.6000\n",
      " |~~ train@7155  Loss: 0.021664 Acc: 13.6000\n",
      " |~~ train@7160  Loss: 0.038532 Acc: 13.0000\n",
      " |~~ train@7165  Loss: 0.040658 Acc: 13.2000\n",
      " |~~ train@7170  Loss: 0.045192 Acc: 13.2000\n",
      " |~~ train@7175  Loss: 0.015406 Acc: 13.8000\n",
      " |~~ train@7180  Loss: 0.038447 Acc: 13.2000\n",
      " |~~ train@7185  Loss: 0.025730 Acc: 13.6000\n",
      " |~~ train@7190  Loss: 0.049784 Acc: 13.0000\n",
      " |~~ train@7195  Loss: 0.049072 Acc: 12.8000\n",
      " |~~ train@7200  Loss: 0.076362 Acc: 12.4000\n",
      " |~~ train@7205  Loss: 0.061955 Acc: 12.4000\n",
      " |~~ train@7210  Loss: 0.015678 Acc: 13.8000\n",
      " |~~ train@7215  Loss: 0.038849 Acc: 13.4000\n",
      " |~~ train@7220  Loss: 0.044979 Acc: 13.2000\n",
      " |~~ train@7225  Loss: 0.026205 Acc: 13.6000\n",
      " |~~ train@7230  Loss: 0.078117 Acc: 12.6000\n",
      " |~~ train@7235  Loss: 0.045272 Acc: 13.0000\n",
      " |~~ train@7240  Loss: 0.038616 Acc: 13.2000\n",
      " |~~ train@7245  Loss: 0.027341 Acc: 13.6000\n",
      " |~~ train@7250  Loss: 0.011298 Acc: 14.0000\n",
      " |~~ train@7255  Loss: 0.022585 Acc: 13.6000\n",
      " |~~ train@7260  Loss: 0.021262 Acc: 13.6000\n",
      " |~~ train@7265  Loss: 0.016531 Acc: 13.8000\n",
      " |~~ train@7270  Loss: 0.028757 Acc: 13.4000\n",
      " |~~ train@7275  Loss: 0.038507 Acc: 13.2000\n",
      " |~~ train@7280  Loss: 0.025837 Acc: 13.6000\n",
      " |~~ train@7285  Loss: 0.019516 Acc: 13.8000\n",
      " |~~ train@7290  Loss: 0.016522 Acc: 13.8000\n",
      " |~~ train@7295  Loss: 0.025479 Acc: 13.6000\n",
      " |~~ train@7300  Loss: 0.035608 Acc: 13.2000\n",
      " |~~ train@7305  Loss: 0.024449 Acc: 13.6000\n",
      " |~~ train@7310  Loss: 0.034925 Acc: 13.4000\n",
      " |~~ train@7315  Loss: 0.015867 Acc: 13.8000\n",
      " |~~ train@7320  Loss: 0.048151 Acc: 13.0000\n",
      " |~~ train@7325  Loss: 0.066124 Acc: 12.8000\n",
      " |~~ train@7330  Loss: 0.017252 Acc: 13.8000\n",
      " |~~ train@7335  Loss: 0.048592 Acc: 12.8000\n",
      " |~~ train@7340  Loss: 0.035208 Acc: 13.2000\n",
      " |~~ train@7345  Loss: 0.037551 Acc: 13.4000\n",
      " |~~ train@7350  Loss: 0.016304 Acc: 13.8000\n",
      " |~~ train@7355  Loss: 0.037730 Acc: 13.4000\n",
      " |~~ train@7360  Loss: 0.055010 Acc: 12.8000\n",
      " |~~ train@7365  Loss: 0.043698 Acc: 13.0000\n",
      " |~~ train@7370  Loss: 0.027808 Acc: 13.4000\n",
      " |~~ train@7375  Loss: 0.010205 Acc: 14.0000\n",
      " |~~ train@7380  Loss: 0.043794 Acc: 12.8000\n",
      " |~~ train@7385  Loss: 0.017389 Acc: 13.8000\n",
      " |~~ train@7390  Loss: 0.029176 Acc: 13.4000\n",
      " |~~ train@7395  Loss: 0.009961 Acc: 14.0000\n",
      " |~~ train@7400  Loss: 0.032471 Acc: 13.4000\n",
      " |~~ train@7405  Loss: 0.020039 Acc: 13.6000\n",
      " |~~ train@7410  Loss: 0.037737 Acc: 13.2000\n",
      " |~~ train@7415  Loss: 0.036996 Acc: 13.2000\n",
      " |~~ train@7420  Loss: 0.009997 Acc: 14.0000\n",
      " |~~ train@7425  Loss: 0.014004 Acc: 13.8000\n",
      " |~~ train@7430  Loss: 0.048352 Acc: 12.8000\n",
      " |~~ train@7435  Loss: 0.033167 Acc: 13.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@7440  Loss: 0.017505 Acc: 13.8000\n",
      " |~~ train@7445  Loss: 0.031220 Acc: 13.2000\n",
      " |~~ train@7450  Loss: 0.022563 Acc: 13.6000\n",
      " |~~ train@7455  Loss: 0.017860 Acc: 13.8000\n",
      " |~~ train@7460  Loss: 0.043900 Acc: 13.2000\n",
      " |~~ train@7465  Loss: 0.045103 Acc: 13.0000\n",
      " |~~ train@7470  Loss: 0.050847 Acc: 13.0000\n",
      " |~~ train@7475  Loss: 0.039368 Acc: 13.2000\n",
      " |~~ train@7480  Loss: 0.024421 Acc: 13.6000\n",
      " |~~ train@7485  Loss: 0.045622 Acc: 13.0000\n",
      " |~~ train@7490  Loss: 0.022574 Acc: 13.4000\n",
      " |~~ train@7495  Loss: 0.060505 Acc: 12.8000\n",
      " |~~ train@7500  Loss: 0.009460 Acc: 14.0000\n",
      " |~~ train@7505  Loss: 0.020457 Acc: 13.6000\n",
      " |~~ train@7510  Loss: 0.021262 Acc: 13.8000\n",
      " |~~ train@7515  Loss: 0.027944 Acc: 13.4000\n",
      " |~~ train@7520  Loss: 0.042384 Acc: 13.2000\n",
      " |~~ train@7525  Loss: 0.035212 Acc: 13.2000\n",
      " |~~ train@7530  Loss: 0.024113 Acc: 13.6000\n",
      " |~~ train@7535  Loss: 0.064178 Acc: 12.8000\n",
      " |~~ train@7540  Loss: 0.045312 Acc: 13.0000\n",
      " |~~ train@7545  Loss: 0.053422 Acc: 12.6000\n",
      " |~~ train@7550  Loss: 0.028369 Acc: 13.2000\n",
      " |~~ train@7555  Loss: 0.064252 Acc: 12.6000\n",
      " |~~ train@7560  Loss: 0.026666 Acc: 13.6000\n",
      " |~~ train@7565  Loss: 0.043299 Acc: 12.8000\n",
      " |~~ train@7570  Loss: 0.028866 Acc: 13.4000\n",
      " |~~ train@7575  Loss: 0.070330 Acc: 12.6000\n",
      " |~~ train@7580  Loss: 0.040816 Acc: 13.0000\n",
      " |~~ train@7585  Loss: 0.061602 Acc: 12.6000\n",
      " |~~ train@7590  Loss: 0.055281 Acc: 12.6000\n",
      " |~~ train@7595  Loss: 0.049510 Acc: 13.0000\n",
      " |~~ train@7600  Loss: 0.023921 Acc: 13.8000\n",
      " |~~ train@7605  Loss: 0.040764 Acc: 13.4000\n",
      " |~~ train@7610  Loss: 0.075666 Acc: 12.4000\n",
      " |~~ train@7615  Loss: 0.067054 Acc: 12.8000\n",
      " |~~ train@7620  Loss: 0.016317 Acc: 13.8000\n",
      " |~~ train@7625  Loss: 0.026522 Acc: 13.6000\n",
      " |~~ train@7630  Loss: 0.021683 Acc: 13.8000\n",
      " |~~ train@7635  Loss: 0.034342 Acc: 13.4000\n",
      " |~~ train@7640  Loss: 0.024502 Acc: 13.4000\n",
      " |~~ train@7645  Loss: 0.027111 Acc: 13.6000\n",
      " |~~ train@7650  Loss: 0.030162 Acc: 13.4000\n",
      " |~~ train@7655  Loss: 0.050792 Acc: 12.8000\n",
      " |~~ train@7660  Loss: 0.027479 Acc: 13.4000\n",
      " |~~ train@7665  Loss: 0.011365 Acc: 14.0000\n",
      " |~~ train@7670  Loss: 0.023032 Acc: 13.6000\n",
      " |~~ train@7675  Loss: 0.032263 Acc: 13.6000\n",
      " |~~ train@7680  Loss: 0.027432 Acc: 13.6000\n",
      " |~~ train@7685  Loss: 0.033144 Acc: 13.2000\n",
      " |~~ train@7690  Loss: 0.042102 Acc: 13.0000\n",
      " |~~ train@7695  Loss: 0.026908 Acc: 13.6000\n",
      " |~~ train@7700  Loss: 0.043601 Acc: 13.2000\n",
      " |~~ train@7705  Loss: 0.046612 Acc: 13.2000\n",
      " |~~ train@7710  Loss: 0.034802 Acc: 13.4000\n",
      " |~~ train@7715  Loss: 0.025831 Acc: 13.6000\n",
      " |~~ train@7720  Loss: 0.055684 Acc: 12.8000\n",
      " |~~ train@7725  Loss: 0.025940 Acc: 13.4000\n",
      " |~~ train@7730  Loss: 0.036839 Acc: 13.2000\n",
      " |~~ train@7735  Loss: 0.015157 Acc: 13.8000\n",
      " |~~ train@7740  Loss: 0.050144 Acc: 12.8000\n",
      " |~~ train@7745  Loss: 0.038649 Acc: 13.4000\n",
      " |~~ train@7750  Loss: 0.060139 Acc: 12.6000\n",
      " |~~ train@7755  Loss: 0.043132 Acc: 13.2000\n",
      " |~~ train@7760  Loss: 0.039936 Acc: 13.2000\n",
      " |~~ train@7765  Loss: 0.036992 Acc: 13.4000\n",
      " |~~ train@7770  Loss: 0.033054 Acc: 13.2000\n",
      " |~~ train@7775  Loss: 0.018163 Acc: 13.8000\n",
      " |~~ train@7780  Loss: 0.065214 Acc: 12.4000\n",
      " |~~ train@7785  Loss: 0.031363 Acc: 13.4000\n",
      " |~~ train@7790  Loss: 0.049211 Acc: 12.8000\n",
      " |~~ train@7795  Loss: 0.020930 Acc: 13.8000\n",
      " |~~ train@7800  Loss: 0.010684 Acc: 14.0000\n",
      " |~~ train@7805  Loss: 0.020051 Acc: 13.8000\n",
      " |~~ train@7810  Loss: 0.028988 Acc: 13.4000\n",
      " |~~ train@7815  Loss: 0.046885 Acc: 13.2000\n",
      " |~~ train@7820  Loss: 0.034282 Acc: 13.4000\n",
      " |~~ train@7825  Loss: 0.074011 Acc: 12.6000\n",
      " |~~ train@7830  Loss: 0.028450 Acc: 13.4000\n",
      " |~~ train@7835  Loss: 0.053196 Acc: 13.0000\n",
      " |~~ train@7840  Loss: 0.040550 Acc: 13.0000\n",
      " |~~ train@7845  Loss: 0.031967 Acc: 13.4000\n",
      " |~~ train@7850  Loss: 0.030929 Acc: 13.4000\n",
      " |~~ train@7855  Loss: 0.026043 Acc: 13.4000\n",
      " |~~ train@7860  Loss: 0.030403 Acc: 13.4000\n",
      " |~~ train@7865  Loss: 0.057550 Acc: 13.0000\n",
      " |~~ train@7870  Loss: 0.047227 Acc: 13.0000\n",
      " |~~ train@7875  Loss: 0.054210 Acc: 12.8000\n",
      " |~~ train@7880  Loss: 0.010515 Acc: 14.0000\n",
      " |~~ train@7885  Loss: 0.061274 Acc: 12.6000\n",
      " |~~ train@7890  Loss: 0.017090 Acc: 13.8000\n",
      " |~~ train@7895  Loss: 0.027285 Acc: 13.6000\n",
      " |~~ train@7900  Loss: 0.037078 Acc: 13.4000\n",
      " |~~ train@7905  Loss: 0.024884 Acc: 13.8000\n",
      " |~~ train@7910  Loss: 0.034673 Acc: 13.4000\n",
      " |~~ train@7915  Loss: 0.029583 Acc: 13.4000\n",
      " |~~ train@7920  Loss: 0.036277 Acc: 13.4000\n",
      " |~~ train@7925  Loss: 0.029870 Acc: 13.4000\n",
      " |~~ train@7930  Loss: 0.040959 Acc: 13.2000\n",
      " |~~ train@7935  Loss: 0.109148 Acc: 11.6000\n",
      " |~~ train@7940  Loss: 0.037603 Acc: 13.4000\n",
      " |~~ train@7945  Loss: 0.036937 Acc: 13.4000\n",
      " |~~ train@7950  Loss: 0.021471 Acc: 13.8000\n",
      " |~~ train@7955  Loss: 0.049557 Acc: 12.8000\n",
      " |~~ train@7960  Loss: 0.030339 Acc: 13.4000\n",
      " |~~ train@7965  Loss: 0.047166 Acc: 13.0000\n",
      " |~~ train@7970  Loss: 0.028379 Acc: 13.6000\n",
      " |~~ train@7975  Loss: 0.025220 Acc: 13.6000\n",
      " |~~ train@7980  Loss: 0.027794 Acc: 13.4000\n",
      " |~~ train@7985  Loss: 0.037842 Acc: 13.2000\n",
      " |~~ train@7990  Loss: 0.030067 Acc: 13.2000\n",
      " |~~ train@7995  Loss: 0.037117 Acc: 13.2000\n",
      " |~~ train@8000  Loss: 0.056628 Acc: 13.0000\n",
      " |~~ train@8005  Loss: 0.023222 Acc: 13.6000\n",
      " |~~ train@8010  Loss: 0.011034 Acc: 14.0000\n",
      " |~~ train@8015  Loss: 0.014462 Acc: 13.8000\n",
      " |~~ train@8020  Loss: 0.058383 Acc: 12.8000\n",
      " |~~ train@8025  Loss: 0.015814 Acc: 13.8000\n",
      " |~~ train@8030  Loss: 0.035223 Acc: 13.2000\n",
      " |~~ train@8035  Loss: 0.022881 Acc: 13.6000\n",
      " |~~ train@8040  Loss: 0.029917 Acc: 13.4000\n",
      " |~~ train@8045  Loss: 0.060408 Acc: 12.8000\n",
      " |~~ train@8050  Loss: 0.018680 Acc: 13.8000\n",
      " |~~ train@8055  Loss: 0.039253 Acc: 13.2000\n",
      " |~~ train@8060  Loss: 0.027202 Acc: 13.6000\n",
      " |~~ train@8065  Loss: 0.010501 Acc: 14.0000\n",
      " |~~ train@8070  Loss: 0.022853 Acc: 13.6000\n",
      " |~~ train@8075  Loss: 0.020466 Acc: 13.8000\n",
      " |~~ train@8080  Loss: 0.057298 Acc: 12.6000\n",
      " |~~ train@8085  Loss: 0.030551 Acc: 13.4000\n",
      " |~~ train@8090  Loss: 0.041112 Acc: 13.4000\n",
      " |~~ train@8095  Loss: 0.058847 Acc: 12.8000\n",
      " |~~ train@8100  Loss: 0.009905 Acc: 14.0000\n",
      " |~~ train@8105  Loss: 0.032951 Acc: 13.4000\n",
      " |~~ train@8110  Loss: 0.038323 Acc: 13.2000\n",
      " |~~ train@8115  Loss: 0.061156 Acc: 12.6000\n",
      " |~~ train@8120  Loss: 0.042248 Acc: 13.0000\n",
      " |~~ train@8125  Loss: 0.042241 Acc: 13.0000\n",
      " |~~ train@8130  Loss: 0.038706 Acc: 13.2000\n",
      " |~~ train@8135  Loss: 0.021535 Acc: 13.6000\n",
      " |~~ train@8140  Loss: 0.026572 Acc: 13.4000\n",
      " |~~ train@8145  Loss: 0.056546 Acc: 13.0000\n",
      " |~~ train@8150  Loss: 0.026590 Acc: 13.6000\n",
      " |~~ train@8155  Loss: 0.040815 Acc: 13.2000\n",
      " |~~ train@8160  Loss: 0.018744 Acc: 13.8000\n",
      " |~~ train@8165  Loss: 0.030973 Acc: 13.4000\n",
      " |~~ train@8170  Loss: 0.040705 Acc: 13.0000\n",
      " |~~ train@8175  Loss: 0.053276 Acc: 12.6000\n",
      " |~~ train@8180  Loss: 0.030032 Acc: 13.4000\n",
      " |~~ train@8185  Loss: 0.048088 Acc: 13.0000\n",
      " |~~ train@8190  Loss: 0.042400 Acc: 13.2000\n",
      " |~~ train@8195  Loss: 0.016289 Acc: 13.8000\n",
      " |~~ train@8200  Loss: 0.010396 Acc: 14.0000\n",
      " |~~ train@8205  Loss: 0.055373 Acc: 12.8000\n",
      " |~~ train@8210  Loss: 0.015388 Acc: 13.8000\n",
      " |~~ train@8215  Loss: 0.027863 Acc: 13.6000\n",
      " |~~ train@8220  Loss: 0.046798 Acc: 13.0000\n",
      " |~~ train@8225  Loss: 0.038693 Acc: 13.4000\n",
      " |~~ train@8230  Loss: 0.040349 Acc: 13.2000\n",
      " |~~ train@8235  Loss: 0.023816 Acc: 13.4000\n",
      " |~~ train@8240  Loss: 0.042442 Acc: 12.8000\n",
      " |~~ train@8245  Loss: 0.045050 Acc: 13.2000\n",
      " |~~ train@8250  Loss: 0.015024 Acc: 13.8000\n",
      " |~~ train@8255  Loss: 0.022205 Acc: 13.8000\n",
      " |~~ train@8260  Loss: 0.026807 Acc: 13.4000\n",
      " |~~ train@8265  Loss: 0.063383 Acc: 12.6000\n",
      " |~~ train@8270  Loss: 0.037432 Acc: 13.4000\n",
      " |~~ train@8275  Loss: 0.033677 Acc: 13.2000\n",
      " |~~ train@8280  Loss: 0.035256 Acc: 13.4000\n",
      " |~~ train@8285  Loss: 0.054461 Acc: 12.8000\n",
      " |~~ train@8290  Loss: 0.036789 Acc: 13.2000\n",
      " |~~ train@8295  Loss: 0.052171 Acc: 13.0000\n",
      " |~~ train@8300  Loss: 0.028381 Acc: 13.6000\n",
      " |~~ train@8305  Loss: 0.027201 Acc: 13.4000\n",
      " |~~ train@8310  Loss: 0.053218 Acc: 12.8000\n",
      " |~~ train@8315  Loss: 0.049728 Acc: 12.8000\n",
      " |~~ train@8320  Loss: 0.043678 Acc: 13.2000\n",
      " |~~ train@8325  Loss: 0.051608 Acc: 13.2000\n",
      " |~~ train@8330  Loss: 0.017311 Acc: 13.8000\n",
      " |~~ train@8335  Loss: 0.016307 Acc: 13.8000\n",
      " |~~ train@8340  Loss: 0.063777 Acc: 12.6000\n",
      " |~~ train@8345  Loss: 0.057868 Acc: 12.8000\n",
      " |~~ train@8350  Loss: 0.056717 Acc: 13.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@8355  Loss: 0.048450 Acc: 12.8000\n",
      " |~~ train@8360  Loss: 0.034169 Acc: 13.4000\n",
      " |~~ train@8365  Loss: 0.042463 Acc: 13.4000\n",
      " |~~ train@8370  Loss: 0.041907 Acc: 13.2000\n",
      " |~~ train@8375  Loss: 0.019039 Acc: 13.8000\n",
      " |~~ train@8380  Loss: 0.015007 Acc: 13.8000\n",
      " |~~ train@8385  Loss: 0.039731 Acc: 13.4000\n",
      " |~~ train@8390  Loss: 0.032638 Acc: 13.6000\n",
      " |~~ train@8395  Loss: 0.034713 Acc: 13.2000\n",
      " |~~ train@8400  Loss: 0.010459 Acc: 14.0000\n",
      " |~~ train@8405  Loss: 0.025933 Acc: 13.6000\n",
      " |~~ train@8410  Loss: 0.070013 Acc: 12.4000\n",
      " |~~ train@8415  Loss: 0.025703 Acc: 13.6000\n",
      " |~~ train@8420  Loss: 0.026782 Acc: 13.6000\n",
      " |~~ train@8425  Loss: 0.041305 Acc: 12.8000\n",
      " |~~ train@8430  Loss: 0.059886 Acc: 12.8000\n",
      " |~~ train@8435  Loss: 0.031188 Acc: 13.4000\n",
      " |~~ train@8440  Loss: 0.032016 Acc: 13.2000\n",
      " |~~ train@8445  Loss: 0.058910 Acc: 12.6000\n",
      " |~~ train@8450  Loss: 0.051707 Acc: 13.0000\n",
      " |~~ train@8455  Loss: 0.021672 Acc: 13.6000\n",
      " |~~ train@8460  Loss: 0.010192 Acc: 14.0000\n",
      " |~~ train@8465  Loss: 0.010779 Acc: 14.0000\n",
      " |~~ train@8470  Loss: 0.016283 Acc: 13.8000\n",
      " |~~ train@8475  Loss: 0.053993 Acc: 12.6000\n",
      " |~~ train@8480  Loss: 0.015838 Acc: 13.8000\n",
      " |~~ train@8485  Loss: 0.021127 Acc: 13.6000\n",
      " |~~ train@8490  Loss: 0.038202 Acc: 13.2000\n",
      " |~~ train@8495  Loss: 0.039546 Acc: 13.4000\n",
      " |~~ train@8500  Loss: 0.010733 Acc: 14.0000\n",
      " |~~ train@8505  Loss: 0.064837 Acc: 12.4000\n",
      " |~~ train@8510  Loss: 0.039191 Acc: 13.2000\n",
      " |~~ train@8515  Loss: 0.043566 Acc: 13.0000\n",
      " |~~ train@8520  Loss: 0.044147 Acc: 13.2000\n",
      " |~~ train@8525  Loss: 0.016578 Acc: 13.8000\n",
      " |~~ train@8530  Loss: 0.038936 Acc: 13.4000\n",
      " |~~ train@8535  Loss: 0.038636 Acc: 13.2000\n",
      " |~~ train@8540  Loss: 0.026253 Acc: 13.4000\n",
      " |~~ train@8545  Loss: 0.045608 Acc: 13.0000\n",
      " |~~ train@8550  Loss: 0.032581 Acc: 13.4000\n",
      " |~~ train@8555  Loss: 0.046699 Acc: 13.0000\n",
      " |~~ train@8560  Loss: 0.065939 Acc: 12.6000\n",
      " |~~ train@8565  Loss: 0.097615 Acc: 12.0000\n",
      " |~~ train@8570  Loss: 0.025735 Acc: 13.6000\n",
      " |~~ train@8575  Loss: 0.052086 Acc: 13.0000\n",
      " |~~ train@8580  Loss: 0.049025 Acc: 13.0000\n",
      " |~~ train@8585  Loss: 0.038691 Acc: 13.2000\n",
      " |~~ train@8590  Loss: 0.019864 Acc: 13.6000\n",
      " |~~ train@8595  Loss: 0.050953 Acc: 12.6000\n",
      " |~~ train@8600  Loss: 0.024491 Acc: 13.4000\n",
      " |~~ train@8605  Loss: 0.038199 Acc: 13.4000\n",
      " |~~ train@8610  Loss: 0.042573 Acc: 13.0000\n",
      " |~~ train@8615  Loss: 0.013505 Acc: 13.8000\n",
      " |~~ train@8620  Loss: 0.011282 Acc: 14.0000\n",
      " |~~ train@8625  Loss: 0.028458 Acc: 13.6000\n",
      " |~~ train@8630  Loss: 0.017925 Acc: 13.8000\n",
      " |~~ train@8635  Loss: 0.048721 Acc: 12.8000\n",
      " |~~ train@8640  Loss: 0.019007 Acc: 13.8000\n",
      " |~~ train@8645  Loss: 0.036618 Acc: 13.4000\n",
      " |~~ train@8650  Loss: 0.044206 Acc: 13.2000\n",
      " |~~ train@8655  Loss: 0.053830 Acc: 12.6000\n",
      " |~~ train@8660  Loss: 0.010962 Acc: 14.0000\n",
      " |~~ train@8665  Loss: 0.048696 Acc: 13.2000\n",
      " |~~ train@8670  Loss: 0.035432 Acc: 13.2000\n",
      " |~~ train@8675  Loss: 0.011196 Acc: 14.0000\n",
      " |~~ train@8680  Loss: 0.046720 Acc: 13.4000\n",
      " |~~ train@8685  Loss: 0.033865 Acc: 13.4000\n",
      " |~~ train@8690  Loss: 0.016779 Acc: 13.8000\n",
      " |~~ train@8695  Loss: 0.058769 Acc: 12.6000\n",
      " |~~ train@8700  Loss: 0.024094 Acc: 13.4000\n",
      " |~~ train@8705  Loss: 0.033799 Acc: 13.4000\n",
      " |~~ train@8710  Loss: 0.056423 Acc: 12.8000\n",
      " |~~ train@8715  Loss: 0.028585 Acc: 13.4000\n",
      " |~~ train@8720  Loss: 0.017638 Acc: 13.8000\n",
      " |~~ train@8725  Loss: 0.045839 Acc: 12.8000\n",
      " |~~ train@8730  Loss: 0.030503 Acc: 13.4000\n",
      " |~~ train@8735  Loss: 0.043295 Acc: 12.8000\n",
      " |~~ train@8740  Loss: 0.022445 Acc: 13.6000\n",
      " |~~ train@8745  Loss: 0.051457 Acc: 12.8000\n",
      " |~~ train@8750  Loss: 0.010785 Acc: 14.0000\n",
      " |~~ train@8755  Loss: 0.056818 Acc: 12.6000\n",
      " |~~ train@8760  Loss: 0.034677 Acc: 13.4000\n",
      " |~~ train@8765  Loss: 0.067368 Acc: 12.6000\n",
      " |~~ train@8770  Loss: 0.030715 Acc: 13.4000\n",
      " |~~ train@8775  Loss: 0.016389 Acc: 13.8000\n",
      " |~~ train@8780  Loss: 0.028260 Acc: 13.4000\n",
      " |~~ train@8785  Loss: 0.022332 Acc: 13.6000\n",
      " |~~ train@8790  Loss: 0.039522 Acc: 13.2000\n",
      " |~~ train@8795  Loss: 0.044426 Acc: 13.0000\n",
      " |~~ train@8800  Loss: 0.031219 Acc: 13.4000\n",
      " |~~ train@8805  Loss: 0.011567 Acc: 14.0000\n",
      " |~~ train@8810  Loss: 0.047597 Acc: 13.2000\n",
      " |~~ train@8815  Loss: 0.015245 Acc: 13.8000\n",
      " |~~ train@8820  Loss: 0.025134 Acc: 13.4000\n",
      " |~~ train@8825  Loss: 0.021149 Acc: 13.6000\n",
      " |~~ train@8830  Loss: 0.027805 Acc: 13.8000\n",
      " |~~ train@8835  Loss: 0.028313 Acc: 13.6000\n",
      " |~~ train@8840  Loss: 0.011427 Acc: 14.0000\n",
      " |~~ train@8845  Loss: 0.027131 Acc: 13.4000\n",
      " |~~ train@8850  Loss: 0.024321 Acc: 13.6000\n",
      " |~~ train@8855  Loss: 0.026259 Acc: 13.4000\n",
      " |~~ train@8860  Loss: 0.065070 Acc: 12.6000\n",
      " |~~ train@8865  Loss: 0.031905 Acc: 13.2000\n",
      " |~~ train@8870  Loss: 0.021565 Acc: 13.6000\n",
      " |~~ train@8875  Loss: 0.042191 Acc: 13.2000\n",
      " |~~ train@8880  Loss: 0.057430 Acc: 12.8000\n",
      " |~~ train@8885  Loss: 0.032912 Acc: 13.4000\n",
      " |~~ train@8890  Loss: 0.017284 Acc: 13.8000\n",
      " |~~ train@8895  Loss: 0.076067 Acc: 12.0000\n",
      " |~~ train@8900  Loss: 0.049810 Acc: 12.8000\n",
      " |~~ train@8905  Loss: 0.036912 Acc: 13.2000\n",
      " |~~ train@8910  Loss: 0.067535 Acc: 12.6000\n",
      " |~~ train@8915  Loss: 0.031220 Acc: 13.4000\n",
      " |~~ train@8920  Loss: 0.016873 Acc: 13.8000\n",
      " |~~ train@8925  Loss: 0.022185 Acc: 13.6000\n",
      " |~~ train@8930  Loss: 0.020889 Acc: 13.6000\n",
      " |~~ train@8935  Loss: 0.054845 Acc: 12.6000\n",
      " |~~ train@8940  Loss: 0.056580 Acc: 12.8000\n",
      " |~~ train@8945  Loss: 0.056449 Acc: 12.6000\n",
      " |~~ train@8950  Loss: 0.038571 Acc: 13.0000\n",
      " |~~ train@8955  Loss: 0.061377 Acc: 12.8000\n",
      " |~~ train@8960  Loss: 0.043153 Acc: 13.4000\n",
      " |~~ train@8965  Loss: 0.011617 Acc: 14.0000\n",
      " |~~ train@8970  Loss: 0.030981 Acc: 13.2000\n",
      " |~~ train@8975  Loss: 0.060694 Acc: 12.6000\n",
      " |~~ train@8980  Loss: 0.043409 Acc: 13.0000\n",
      " |~~ train@8985  Loss: 0.054370 Acc: 13.0000\n",
      " |~~ train@8990  Loss: 0.017067 Acc: 13.8000\n",
      " |~~ train@8995  Loss: 0.068098 Acc: 12.8000\n",
      " |~~ train@9000  Loss: 0.028201 Acc: 13.4000\n",
      " |~~ train@9005  Loss: 0.028136 Acc: 13.4000\n",
      " |~~ train@9010  Loss: 0.060302 Acc: 12.8000\n",
      " |~~ train@9015  Loss: 0.027235 Acc: 13.4000\n",
      " |~~ train@9020  Loss: 0.043077 Acc: 13.0000\n",
      " |~~ train@9025  Loss: 0.023977 Acc: 13.8000\n",
      " |~~ train@9030  Loss: 0.026553 Acc: 13.2000\n",
      " |~~ train@9035  Loss: 0.052049 Acc: 13.0000\n",
      " |~~ train@9040  Loss: 0.064881 Acc: 12.6000\n",
      " |~~ train@9045  Loss: 0.038563 Acc: 13.2000\n",
      " |~~ train@9050  Loss: 0.031903 Acc: 13.4000\n",
      " |~~ train@9055  Loss: 0.041974 Acc: 13.2000\n",
      " |~~ train@9060  Loss: 0.025412 Acc: 13.4000\n",
      " |~~ train@9065  Loss: 0.058757 Acc: 12.8000\n",
      " |~~ train@9070  Loss: 0.053518 Acc: 13.0000\n",
      " |~~ train@9075  Loss: 0.039833 Acc: 13.2000\n",
      " |~~ train@9080  Loss: 0.039177 Acc: 13.4000\n",
      " |~~ train@9085  Loss: 0.089249 Acc: 12.2000\n",
      " |~~ train@9090  Loss: 0.019699 Acc: 13.6000\n",
      " |~~ train@9095  Loss: 0.047545 Acc: 13.0000\n",
      " |~~ train@9100  Loss: 0.011711 Acc: 14.0000\n",
      " |~~ train@9105  Loss: 0.084293 Acc: 12.0000\n",
      " |~~ train@9110  Loss: 0.035293 Acc: 13.2000\n",
      " |~~ train@9115  Loss: 0.064500 Acc: 12.4000\n",
      " |~~ train@9120  Loss: 0.034940 Acc: 13.2000\n",
      " |~~ train@9125  Loss: 0.023644 Acc: 13.4000\n",
      " |~~ train@9130  Loss: 0.029397 Acc: 13.4000\n",
      " |~~ train@9135  Loss: 0.025308 Acc: 13.6000\n",
      " |~~ train@9140  Loss: 0.038864 Acc: 13.2000\n",
      " |~~ train@9145  Loss: 0.049746 Acc: 13.2000\n",
      " |~~ train@9150  Loss: 0.048263 Acc: 13.0000\n",
      " |~~ train@9155  Loss: 0.033219 Acc: 13.2000\n",
      " |~~ train@9160  Loss: 0.029222 Acc: 13.2000\n",
      " |~~ train@9165  Loss: 0.064328 Acc: 12.6000\n",
      " |~~ train@9170  Loss: 0.054927 Acc: 12.6000\n",
      " |~~ train@9175  Loss: 0.019920 Acc: 13.6000\n",
      " |~~ train@9180  Loss: 0.039273 Acc: 13.2000\n",
      " |~~ train@9185  Loss: 0.021296 Acc: 13.8000\n",
      " |~~ train@9190  Loss: 0.032448 Acc: 13.4000\n",
      " |~~ train@9195  Loss: 0.014986 Acc: 13.8000\n",
      " |~~ train@9200  Loss: 0.030531 Acc: 13.4000\n",
      " |~~ train@9205  Loss: 0.012478 Acc: 14.0000\n",
      " |~~ train@9210  Loss: 0.026666 Acc: 13.6000\n",
      " |~~ train@9215  Loss: 0.018009 Acc: 13.8000\n",
      " |~~ train@9220  Loss: 0.029952 Acc: 13.4000\n",
      " |~~ train@9225  Loss: 0.034158 Acc: 13.4000\n",
      " |~~ train@9230  Loss: 0.033301 Acc: 13.2000\n",
      " |~~ train@9235  Loss: 0.031562 Acc: 13.4000\n",
      " |~~ train@9240  Loss: 0.045053 Acc: 13.0000\n",
      " |~~ train@9245  Loss: 0.024652 Acc: 13.4000\n",
      " |~~ train@9250  Loss: 0.034252 Acc: 13.4000\n",
      " |~~ train@9255  Loss: 0.033729 Acc: 13.4000\n",
      " |~~ train@9260  Loss: 0.023678 Acc: 13.4000\n",
      " |~~ train@9265  Loss: 0.015995 Acc: 13.8000\n",
      " |~~ train@9270  Loss: 0.058458 Acc: 12.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@9275  Loss: 0.025639 Acc: 13.4000\n",
      " |~~ train@9280  Loss: 0.034078 Acc: 13.6000\n",
      " |~~ train@9285  Loss: 0.046792 Acc: 13.2000\n",
      " |~~ train@9290  Loss: 0.025204 Acc: 13.6000\n",
      " |~~ train@9295  Loss: 0.014269 Acc: 13.8000\n",
      " |~~ train@9300  Loss: 0.067744 Acc: 12.6000\n",
      " |~~ train@9305  Loss: 0.023537 Acc: 13.4000\n",
      " |~~ train@9310  Loss: 0.055537 Acc: 12.6000\n",
      " |~~ train@9315  Loss: 0.032387 Acc: 13.4000\n",
      " |~~ train@9320  Loss: 0.014700 Acc: 13.8000\n",
      " |~~ train@9325  Loss: 0.032432 Acc: 13.4000\n",
      " |~~ train@9330  Loss: 0.042806 Acc: 13.0000\n",
      " |~~ train@9335  Loss: 0.034977 Acc: 13.4000\n",
      " |~~ train@9340  Loss: 0.043308 Acc: 13.0000\n",
      " |~~ train@9345  Loss: 0.038198 Acc: 13.0000\n",
      " |~~ train@9350  Loss: 0.028530 Acc: 13.6000\n",
      " |~~ train@9355  Loss: 0.048038 Acc: 13.2000\n",
      " |~~ train@9360  Loss: 0.038339 Acc: 13.2000\n",
      " |~~ train@9365  Loss: 0.048114 Acc: 13.0000\n",
      " |~~ train@9370  Loss: 0.026932 Acc: 13.6000\n",
      " |~~ train@9375  Loss: 0.025708 Acc: 13.6000\n",
      " |~~ train@9380  Loss: 0.069934 Acc: 12.6000\n",
      " |~~ train@9385  Loss: 0.037661 Acc: 13.0000\n",
      " |~~ train@9390  Loss: 0.019860 Acc: 13.6000\n",
      " |~~ train@9395  Loss: 0.024565 Acc: 13.6000\n",
      " |~~ train@9400  Loss: 0.021447 Acc: 13.6000\n",
      " |~~ train@9405  Loss: 0.057853 Acc: 12.8000\n",
      " |~~ train@9410  Loss: 0.034042 Acc: 13.4000\n",
      " |~~ train@9415  Loss: 0.032787 Acc: 13.4000\n",
      " |~~ train@9420  Loss: 0.038367 Acc: 13.2000\n",
      " |~~ train@9425  Loss: 0.035055 Acc: 13.2000\n",
      " |~~ train@9430  Loss: 0.032915 Acc: 13.6000\n",
      " |~~ train@9435  Loss: 0.043727 Acc: 13.2000\n",
      " |~~ train@9440  Loss: 0.035533 Acc: 13.6000\n",
      " |~~ train@9445  Loss: 0.047678 Acc: 13.0000\n",
      " |~~ train@9450  Loss: 0.057347 Acc: 12.8000\n",
      " |~~ train@9455  Loss: 0.023330 Acc: 13.6000\n",
      " |~~ train@9460  Loss: 0.025679 Acc: 13.6000\n",
      " |~~ train@9465  Loss: 0.036314 Acc: 13.2000\n",
      " |~~ train@9470  Loss: 0.010530 Acc: 14.0000\n",
      " |~~ train@9475  Loss: 0.036343 Acc: 13.4000\n",
      " |~~ train@9480  Loss: 0.063136 Acc: 12.8000\n",
      " |~~ train@9485  Loss: 0.033063 Acc: 13.0000\n",
      " |~~ train@9490  Loss: 0.027563 Acc: 13.4000\n",
      " |~~ train@9495  Loss: 0.032668 Acc: 13.4000\n",
      " |~~ train@9500  Loss: 0.065445 Acc: 12.4000\n",
      " |~~ train@9505  Loss: 0.068453 Acc: 12.6000\n",
      " |~~ train@9510  Loss: 0.045132 Acc: 13.0000\n",
      " |~~ train@9515  Loss: 0.031156 Acc: 13.4000\n",
      " |~~ train@9520  Loss: 0.027774 Acc: 13.4000\n",
      " |~~ train@9525  Loss: 0.043236 Acc: 13.2000\n",
      " |~~ train@9530  Loss: 0.045031 Acc: 13.2000\n",
      " |~~ train@9535  Loss: 0.023686 Acc: 13.6000\n",
      " |~~ train@9540  Loss: 0.042163 Acc: 13.0000\n",
      " |~~ train@9545  Loss: 0.021184 Acc: 13.8000\n",
      " |~~ train@9550  Loss: 0.033059 Acc: 13.4000\n",
      " |~~ train@9555  Loss: 0.025205 Acc: 13.6000\n",
      " |~~ train@9560  Loss: 0.022002 Acc: 13.6000\n",
      " |~~ train@9565  Loss: 0.037603 Acc: 13.0000\n",
      " |~~ train@9570  Loss: 0.029333 Acc: 13.4000\n",
      " |~~ train@9575  Loss: 0.021583 Acc: 13.6000\n",
      " |~~ train@9580  Loss: 0.052508 Acc: 13.2000\n",
      " |~~ train@9585  Loss: 0.037678 Acc: 13.2000\n",
      " |~~ train@9590  Loss: 0.023277 Acc: 13.6000\n",
      " |~~ train@9595  Loss: 0.054843 Acc: 12.8000\n",
      " |~~ train@9600  Loss: 0.010373 Acc: 14.0000\n",
      " |~~ train@9605  Loss: 0.028446 Acc: 13.4000\n",
      " |~~ train@9610  Loss: 0.051502 Acc: 12.8000\n",
      " |~~ train@9615  Loss: 0.037610 Acc: 13.4000\n",
      " |~~ train@9620  Loss: 0.031392 Acc: 13.4000\n",
      " |~~ train@9625  Loss: 0.036061 Acc: 13.2000\n",
      " |~~ train@9630  Loss: 0.010082 Acc: 14.0000\n",
      " |~~ train@9635  Loss: 0.019921 Acc: 13.8000\n",
      " |~~ train@9640  Loss: 0.019774 Acc: 13.8000\n",
      " |~~ train@9645  Loss: 0.010069 Acc: 14.0000\n",
      " |~~ train@9650  Loss: 0.035393 Acc: 13.2000\n",
      " |~~ train@9655  Loss: 0.029821 Acc: 13.6000\n",
      " |~~ train@9660  Loss: 0.028187 Acc: 13.4000\n",
      " |~~ train@9665  Loss: 0.043813 Acc: 13.0000\n",
      " |~~ train@9670  Loss: 0.028450 Acc: 13.6000\n",
      " |~~ train@9675  Loss: 0.045977 Acc: 12.8000\n",
      " |~~ train@9680  Loss: 0.045087 Acc: 13.2000\n",
      " |~~ train@9685  Loss: 0.054010 Acc: 13.0000\n",
      " |~~ train@9690  Loss: 0.065641 Acc: 12.6000\n",
      " |~~ train@9695  Loss: 0.026063 Acc: 13.4000\n",
      " |~~ train@9700  Loss: 0.033241 Acc: 13.4000\n",
      " |~~ train@9705  Loss: 0.059936 Acc: 12.6000\n",
      " |~~ train@9710  Loss: 0.057016 Acc: 12.8000\n",
      " |~~ train@9715  Loss: 0.020367 Acc: 13.6000\n",
      " |~~ train@9720  Loss: 0.022033 Acc: 13.6000\n",
      " |~~ train@9725  Loss: 0.016543 Acc: 13.8000\n",
      " |~~ train@9730  Loss: 0.052145 Acc: 12.8000\n",
      " |~~ train@9735  Loss: 0.010203 Acc: 14.0000\n",
      " |~~ train@9740  Loss: 0.030034 Acc: 13.6000\n",
      " |~~ train@9745  Loss: 0.017885 Acc: 13.8000\n",
      " |~~ train@9750  Loss: 0.015137 Acc: 13.8000\n",
      " |~~ train@9755  Loss: 0.052383 Acc: 13.0000\n",
      " |~~ train@9760  Loss: 0.010611 Acc: 14.0000\n",
      " |~~ train@9765  Loss: 0.025593 Acc: 13.6000\n",
      " |~~ train@9770  Loss: 0.021592 Acc: 13.6000\n",
      " |~~ train@9775  Loss: 0.050169 Acc: 12.8000\n",
      " |~~ train@9780  Loss: 0.036257 Acc: 13.4000\n",
      " |~~ train@9785  Loss: 0.010219 Acc: 14.0000\n",
      " |~~ train@9790  Loss: 0.034051 Acc: 13.6000\n",
      " |~~ train@9795  Loss: 0.049277 Acc: 13.0000\n",
      " |~~ train@9800  Loss: 0.025630 Acc: 13.6000\n",
      " |~~ train@9805  Loss: 0.036004 Acc: 13.2000\n",
      " |~~ train@9810  Loss: 0.044120 Acc: 13.2000\n",
      " |~~ train@9815  Loss: 0.035255 Acc: 13.2000\n",
      " |~~ train@9820  Loss: 0.034568 Acc: 13.4000\n",
      " |~~ train@9825  Loss: 0.034811 Acc: 13.2000\n",
      " |~~ train@9830  Loss: 0.069567 Acc: 12.2000\n",
      " |~~ train@9835  Loss: 0.025324 Acc: 13.6000\n",
      " |~~ train@9840  Loss: 0.041462 Acc: 13.0000\n",
      " |~~ train@9845  Loss: 0.024135 Acc: 13.6000\n",
      " |~~ train@9850  Loss: 0.053611 Acc: 12.6000\n",
      " |~~ train@9855  Loss: 0.038974 Acc: 13.2000\n",
      " |~~ train@9860  Loss: 0.026657 Acc: 13.6000\n",
      " |~~ train@9865  Loss: 0.050723 Acc: 13.0000\n",
      " |~~ train@9870  Loss: 0.031712 Acc: 13.4000\n",
      " |~~ train@9875  Loss: 0.026699 Acc: 13.2000\n",
      " |~~ train@9880  Loss: 0.044661 Acc: 13.2000\n",
      " |~~ train@9885  Loss: 0.058865 Acc: 12.8000\n",
      " |~~ train@9890  Loss: 0.019888 Acc: 13.6000\n",
      " |~~ train@9895  Loss: 0.044468 Acc: 13.0000\n",
      " |~~ train@9900  Loss: 0.027733 Acc: 13.4000\n",
      " |~~ train@9905  Loss: 0.024283 Acc: 13.6000\n",
      " |~~ train@9910  Loss: 0.017775 Acc: 13.8000\n",
      " |~~ train@9915  Loss: 0.049175 Acc: 12.8000\n",
      " |~~ train@9920  Loss: 0.051142 Acc: 13.0000\n",
      " |~~ train@9925  Loss: 0.014893 Acc: 13.8000\n",
      " |~~ train@9930  Loss: 0.052026 Acc: 13.0000\n",
      " |~~ train@9935  Loss: 0.010207 Acc: 14.0000\n",
      " |~~ train@9940  Loss: 0.044743 Acc: 13.0000\n",
      " |~~ train@9945  Loss: 0.048958 Acc: 13.0000\n",
      " |~~ train@9950  Loss: 0.073587 Acc: 12.4000\n",
      " |~~ train@9955  Loss: 0.030365 Acc: 13.4000\n",
      " |~~ train@9960  Loss: 0.040038 Acc: 13.2000\n",
      " |~~ train@9965  Loss: 0.043936 Acc: 13.0000\n",
      " |~~ train@9970  Loss: 0.043949 Acc: 13.2000\n",
      " |~~ train@9975  Loss: 0.051056 Acc: 12.8000\n",
      " |~~ train@9980  Loss: 0.040975 Acc: 13.0000\n",
      " |~~ train@9985  Loss: 0.024790 Acc: 13.4000\n",
      " |~~ train@9990  Loss: 0.055111 Acc: 12.8000\n",
      " |~~ train@9995  Loss: 0.032290 Acc: 13.4000\n",
      " |~~ train@10000  Loss: 0.051719 Acc: 13.0000\n",
      " |~~ train@10005  Loss: 0.043278 Acc: 13.0000\n",
      " |~~ train@10010  Loss: 0.028305 Acc: 13.6000\n",
      " |~~ train@10015  Loss: 0.024143 Acc: 13.4000\n",
      " |~~ train@10020  Loss: 0.033733 Acc: 13.4000\n",
      " |~~ train@10025  Loss: 0.036596 Acc: 13.4000\n",
      " |~~ train@10030  Loss: 0.020748 Acc: 13.8000\n",
      " |~~ train@10035  Loss: 0.019799 Acc: 13.8000\n",
      " |~~ train@10040  Loss: 0.043976 Acc: 13.4000\n",
      " |~~ train@10045  Loss: 0.085411 Acc: 12.2000\n",
      " |~~ train@10050  Loss: 0.100102 Acc: 11.4000\n",
      " |~~ train@10055  Loss: 0.017658 Acc: 13.6000\n",
      " |~~ train@10060  Loss: 0.113295 Acc: 11.6000\n",
      " |~~ train@10065  Loss: 0.037340 Acc: 13.2000\n",
      " |~~ train@10070  Loss: 0.045147 Acc: 13.2000\n",
      " |~~ train@10075  Loss: 0.085657 Acc: 12.0000\n",
      " |~~ train@10080  Loss: 0.037403 Acc: 13.4000\n",
      " |~~ train@10085  Loss: 0.049807 Acc: 13.0000\n",
      " |~~ train@10090  Loss: 0.028338 Acc: 13.4000\n",
      " |~~ train@10095  Loss: 0.042930 Acc: 13.2000\n",
      " |~~ train@10100  Loss: 0.039870 Acc: 13.2000\n",
      " |~~ train@10105  Loss: 0.016980 Acc: 13.8000\n",
      " |~~ train@10110  Loss: 0.029023 Acc: 13.4000\n",
      " |~~ train@10115  Loss: 0.012124 Acc: 14.0000\n",
      " |~~ train@10120  Loss: 0.056587 Acc: 12.8000\n",
      " |~~ train@10125  Loss: 0.018530 Acc: 13.8000\n",
      " |~~ train@10130  Loss: 0.029288 Acc: 13.4000\n",
      " |~~ train@10135  Loss: 0.074467 Acc: 12.0000\n",
      " |~~ train@10140  Loss: 0.047434 Acc: 13.0000\n",
      " |~~ train@10145  Loss: 0.078231 Acc: 12.0000\n",
      " |~~ train@10150  Loss: 0.018617 Acc: 13.8000\n",
      " |~~ train@10155  Loss: 0.023378 Acc: 13.4000\n",
      " |~~ train@10160  Loss: 0.022131 Acc: 13.6000\n",
      " |~~ train@10165  Loss: 0.061908 Acc: 12.6000\n",
      " |~~ train@10170  Loss: 0.018756 Acc: 13.8000\n",
      " |~~ train@10175  Loss: 0.015114 Acc: 13.8000\n",
      " |~~ train@10180  Loss: 0.044840 Acc: 13.2000\n",
      " |~~ train@10185  Loss: 0.023026 Acc: 13.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@10190  Loss: 0.039551 Acc: 13.4000\n",
      " |~~ train@10195  Loss: 0.017645 Acc: 13.8000\n",
      " |~~ train@10200  Loss: 0.026704 Acc: 13.6000\n",
      " |~~ train@10205  Loss: 0.015577 Acc: 13.8000\n",
      " |~~ train@10210  Loss: 0.052313 Acc: 12.8000\n",
      " |~~ train@10215  Loss: 0.033378 Acc: 13.4000\n",
      " |~~ train@10220  Loss: 0.055179 Acc: 12.6000\n",
      " |~~ train@10225  Loss: 0.032513 Acc: 13.4000\n",
      " |~~ train@10230  Loss: 0.017548 Acc: 13.6000\n",
      " |~~ train@10235  Loss: 0.025270 Acc: 13.6000\n",
      " |~~ train@10240  Loss: 0.026284 Acc: 13.6000\n",
      " |~~ train@10245  Loss: 0.053624 Acc: 12.8000\n",
      " |~~ train@10250  Loss: 0.036226 Acc: 13.0000\n",
      " |~~ train@10255  Loss: 0.024153 Acc: 13.8000\n",
      " |~~ train@10260  Loss: 0.044149 Acc: 13.0000\n",
      " |~~ train@10265  Loss: 0.075656 Acc: 12.0000\n",
      " |~~ train@10270  Loss: 0.053072 Acc: 12.4000\n",
      " |~~ train@10275  Loss: 0.015293 Acc: 13.8000\n",
      " |~~ train@10280  Loss: 0.024687 Acc: 13.6000\n",
      " |~~ train@10285  Loss: 0.040966 Acc: 13.2000\n",
      " |~~ train@10290  Loss: 0.035481 Acc: 13.2000\n",
      " |~~ train@10295  Loss: 0.044237 Acc: 13.0000\n",
      " |~~ train@10300  Loss: 0.026513 Acc: 13.6000\n",
      " |~~ train@10305  Loss: 0.022820 Acc: 13.8000\n",
      " |~~ train@10310  Loss: 0.049985 Acc: 12.6000\n",
      " |~~ train@10315  Loss: 0.033334 Acc: 13.0000\n",
      " |~~ train@10320  Loss: 0.035532 Acc: 13.4000\n",
      " |~~ train@10325  Loss: 0.014161 Acc: 13.8000\n",
      " |~~ train@10330  Loss: 0.033813 Acc: 13.4000\n",
      " |~~ train@10335  Loss: 0.011705 Acc: 14.0000\n",
      " |~~ train@10340  Loss: 0.042102 Acc: 13.2000\n",
      " |~~ train@10345  Loss: 0.032069 Acc: 13.2000\n",
      " |~~ train@10350  Loss: 0.078673 Acc: 12.6000\n",
      " |~~ train@10355  Loss: 0.011480 Acc: 14.0000\n",
      " |~~ train@10360  Loss: 0.032072 Acc: 13.4000\n",
      " |~~ train@10365  Loss: 0.021656 Acc: 13.6000\n",
      " |~~ train@10370  Loss: 0.036061 Acc: 13.2000\n",
      " |~~ train@10375  Loss: 0.037430 Acc: 13.2000\n",
      " |~~ train@10380  Loss: 0.041071 Acc: 13.2000\n",
      " |~~ train@10385  Loss: 0.011459 Acc: 14.0000\n",
      " |~~ train@10390  Loss: 0.037078 Acc: 13.4000\n",
      " |~~ train@10395  Loss: 0.041802 Acc: 13.2000\n",
      " |~~ train@10400  Loss: 0.024423 Acc: 13.6000\n",
      " |~~ train@10405  Loss: 0.023861 Acc: 13.6000\n",
      " |~~ train@10410  Loss: 0.039917 Acc: 12.8000\n",
      " |~~ train@10415  Loss: 0.061331 Acc: 12.8000\n",
      " |~~ train@10420  Loss: 0.046248 Acc: 13.0000\n",
      " |~~ train@10425  Loss: 0.039116 Acc: 13.0000\n",
      " |~~ train@10430  Loss: 0.047590 Acc: 13.2000\n",
      " |~~ train@10435  Loss: 0.050535 Acc: 12.8000\n",
      " |~~ train@10440  Loss: 0.044943 Acc: 13.2000\n",
      " |~~ train@10445  Loss: 0.073966 Acc: 12.4000\n",
      " |~~ train@10450  Loss: 0.028110 Acc: 13.4000\n",
      " |~~ train@10455  Loss: 0.038079 Acc: 13.2000\n",
      " |~~ train@10460  Loss: 0.031930 Acc: 13.6000\n",
      " |~~ train@10465  Loss: 0.061214 Acc: 12.6000\n",
      " |~~ train@10470  Loss: 0.041756 Acc: 13.0000\n",
      " |~~ train@10475  Loss: 0.016635 Acc: 13.8000\n",
      " |~~ train@10480  Loss: 0.020632 Acc: 13.8000\n",
      " |~~ train@10485  Loss: 0.018886 Acc: 13.8000\n",
      " |~~ train@10490  Loss: 0.073676 Acc: 12.2000\n",
      " |~~ train@10495  Loss: 0.011234 Acc: 14.0000\n",
      " |~~ train@10500  Loss: 0.039567 Acc: 13.2000\n",
      " |~~ train@10505  Loss: 0.034159 Acc: 13.2000\n",
      " |~~ train@10510  Loss: 0.023563 Acc: 13.4000\n",
      " |~~ train@10515  Loss: 0.067912 Acc: 12.4000\n",
      " |~~ train@10520  Loss: 0.043731 Acc: 13.4000\n",
      " |~~ train@10525  Loss: 0.054006 Acc: 12.8000\n",
      " |~~ train@10530  Loss: 0.029195 Acc: 13.4000\n",
      " |~~ train@10535  Loss: 0.022604 Acc: 13.8000\n",
      " |~~ train@10540  Loss: 0.034563 Acc: 13.2000\n",
      " |~~ train@10545  Loss: 0.021086 Acc: 13.6000\n",
      " |~~ train@10550  Loss: 0.011161 Acc: 14.0000\n",
      " |~~ train@10555  Loss: 0.054132 Acc: 13.0000\n",
      " |~~ train@10560  Loss: 0.026150 Acc: 13.4000\n",
      " |~~ train@10565  Loss: 0.049820 Acc: 13.0000\n",
      " |~~ train@10570  Loss: 0.040492 Acc: 13.0000\n",
      " |~~ train@10575  Loss: 0.042754 Acc: 13.0000\n",
      " |~~ train@10580  Loss: 0.029821 Acc: 13.2000\n",
      " |~~ train@10585  Loss: 0.017934 Acc: 13.6000\n",
      " |~~ train@10590  Loss: 0.021733 Acc: 13.6000\n",
      " |~~ train@10595  Loss: 0.020051 Acc: 13.8000\n",
      " |~~ train@10600  Loss: 0.041976 Acc: 13.2000\n",
      " |~~ train@10605  Loss: 0.018648 Acc: 13.8000\n",
      " |~~ train@10610  Loss: 0.069359 Acc: 12.4000\n",
      " |~~ train@10615  Loss: 0.024220 Acc: 13.6000\n",
      " |~~ train@10620  Loss: 0.041226 Acc: 13.2000\n",
      " |~~ train@10625  Loss: 0.028354 Acc: 13.4000\n",
      " |~~ train@10630  Loss: 0.036734 Acc: 13.0000\n",
      " |~~ train@10635  Loss: 0.052149 Acc: 12.6000\n",
      " |~~ train@10640  Loss: 0.022426 Acc: 13.8000\n",
      " |~~ train@10645  Loss: 0.058529 Acc: 12.6000\n",
      " |~~ train@10650  Loss: 0.011710 Acc: 14.0000\n",
      " |~~ train@10655  Loss: 0.041154 Acc: 13.2000\n",
      " |~~ train@10660  Loss: 0.016522 Acc: 13.8000\n",
      " |~~ train@10665  Loss: 0.017319 Acc: 13.8000\n",
      " |~~ train@10670  Loss: 0.014412 Acc: 13.8000\n",
      " |~~ train@10675  Loss: 0.040616 Acc: 13.2000\n",
      " |~~ train@10680  Loss: 0.066911 Acc: 12.6000\n",
      " |~~ train@10685  Loss: 0.053669 Acc: 13.0000\n",
      " |~~ train@10690  Loss: 0.035218 Acc: 13.4000\n",
      " |~~ train@10695  Loss: 0.050083 Acc: 13.0000\n",
      " |~~ train@10700  Loss: 0.026234 Acc: 13.4000\n",
      " |~~ train@10705  Loss: 0.011402 Acc: 14.0000\n",
      " |~~ train@10710  Loss: 0.016795 Acc: 13.8000\n",
      " |~~ train@10715  Loss: 0.035624 Acc: 13.2000\n",
      " |~~ train@10720  Loss: 0.054524 Acc: 12.8000\n",
      " |~~ train@10725  Loss: 0.024001 Acc: 13.6000\n",
      " |~~ train@10730  Loss: 0.034652 Acc: 13.4000\n",
      " |~~ train@10735  Loss: 0.026483 Acc: 13.6000\n",
      " |~~ train@10740  Loss: 0.032126 Acc: 13.6000\n",
      " |~~ train@10745  Loss: 0.026788 Acc: 13.6000\n",
      " |~~ train@10750  Loss: 0.047048 Acc: 13.0000\n",
      " |~~ train@10755  Loss: 0.026669 Acc: 13.6000\n",
      " |~~ train@10760  Loss: 0.065135 Acc: 12.8000\n",
      " |~~ train@10765  Loss: 0.068759 Acc: 12.2000\n",
      " |~~ train@10770  Loss: 0.015265 Acc: 13.8000\n",
      " |~~ train@10775  Loss: 0.018656 Acc: 13.8000\n",
      " |~~ train@10780  Loss: 0.015259 Acc: 13.8000\n",
      " |~~ train@10785  Loss: 0.044458 Acc: 12.8000\n",
      " |~~ train@10790  Loss: 0.055438 Acc: 12.8000\n",
      " |~~ train@10795  Loss: 0.033210 Acc: 13.6000\n",
      " |~~ train@10800  Loss: 0.019369 Acc: 13.8000\n",
      " |~~ train@10805  Loss: 0.018103 Acc: 13.8000\n",
      " |~~ train@10810  Loss: 0.021602 Acc: 13.6000\n",
      " |~~ train@10815  Loss: 0.058072 Acc: 12.6000\n",
      " |~~ train@10820  Loss: 0.030590 Acc: 13.6000\n",
      " |~~ train@10825  Loss: 0.069852 Acc: 12.2000\n",
      " |~~ train@10830  Loss: 0.014959 Acc: 13.8000\n",
      " |~~ train@10835  Loss: 0.059883 Acc: 12.8000\n",
      " |~~ train@10840  Loss: 0.050759 Acc: 12.6000\n",
      " |~~ train@10845  Loss: 0.066815 Acc: 12.8000\n",
      " |~~ train@10850  Loss: 0.022248 Acc: 13.6000\n",
      " |~~ train@10855  Loss: 0.034055 Acc: 13.2000\n",
      " |~~ train@10860  Loss: 0.030941 Acc: 13.4000\n",
      " |~~ train@10865  Loss: 0.071120 Acc: 12.4000\n",
      " |~~ train@10870  Loss: 0.014649 Acc: 13.8000\n",
      " |~~ train@10875  Loss: 0.031040 Acc: 13.4000\n",
      " |~~ train@10880  Loss: 0.018692 Acc: 13.8000\n",
      " |~~ train@10885  Loss: 0.043370 Acc: 13.0000\n",
      " |~~ train@10890  Loss: 0.032397 Acc: 13.2000\n",
      " |~~ train@10895  Loss: 0.032055 Acc: 13.4000\n",
      " |~~ train@10900  Loss: 0.049249 Acc: 12.8000\n",
      " |~~ train@10905  Loss: 0.046278 Acc: 13.0000\n",
      " |~~ train@10910  Loss: 0.053030 Acc: 12.8000\n",
      " |~~ train@10915  Loss: 0.057861 Acc: 13.0000\n",
      " |~~ train@10920  Loss: 0.011208 Acc: 14.0000\n",
      " |~~ train@10925  Loss: 0.032985 Acc: 13.4000\n",
      " |~~ train@10930  Loss: 0.068401 Acc: 12.6000\n",
      " |~~ train@10935  Loss: 0.063298 Acc: 12.6000\n",
      " |~~ train@10940  Loss: 0.024584 Acc: 13.4000\n",
      " |~~ train@10945  Loss: 0.037604 Acc: 13.4000\n",
      " |~~ train@10950  Loss: 0.046071 Acc: 13.2000\n",
      " |~~ train@10955  Loss: 0.019736 Acc: 13.6000\n",
      " |~~ train@10960  Loss: 0.050021 Acc: 12.6000\n",
      " |~~ train@10965  Loss: 0.057843 Acc: 12.6000\n",
      " |~~ train@10970  Loss: 0.035144 Acc: 13.2000\n",
      " |~~ train@10975  Loss: 0.029151 Acc: 13.4000\n",
      " |~~ train@10980  Loss: 0.017222 Acc: 13.8000\n",
      " |~~ train@10985  Loss: 0.034443 Acc: 13.4000\n",
      " |~~ train@10990  Loss: 0.023150 Acc: 13.6000\n",
      " |~~ train@10995  Loss: 0.026995 Acc: 13.6000\n",
      " |~~ train@11000  Loss: 0.050008 Acc: 12.8000\n",
      " |~~ train@11005  Loss: 0.041721 Acc: 13.2000\n",
      " |~~ train@11010  Loss: 0.019287 Acc: 13.8000\n",
      " |~~ train@11015  Loss: 0.021213 Acc: 13.6000\n",
      " |~~ train@11020  Loss: 0.041290 Acc: 13.2000\n",
      " |~~ train@11025  Loss: 0.039492 Acc: 13.2000\n",
      " |~~ train@11030  Loss: 0.036553 Acc: 13.2000\n",
      " |~~ train@11035  Loss: 0.034602 Acc: 13.6000\n",
      " |~~ train@11040  Loss: 0.039440 Acc: 13.4000\n",
      " |~~ train@11045  Loss: 0.025311 Acc: 13.6000\n",
      " |~~ train@11050  Loss: 0.045427 Acc: 13.4000\n",
      " |~~ train@11055  Loss: 0.035292 Acc: 13.2000\n",
      " |~~ train@11060  Loss: 0.032179 Acc: 13.4000\n",
      " |~~ train@11065  Loss: 0.015286 Acc: 13.8000\n",
      " |~~ train@11070  Loss: 0.041409 Acc: 13.0000\n",
      " |~~ train@11075  Loss: 0.039688 Acc: 13.2000\n",
      " |~~ train@11080  Loss: 0.010736 Acc: 14.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@11085  Loss: 0.011360 Acc: 14.0000\n",
      " |~~ train@11090  Loss: 0.047273 Acc: 13.0000\n",
      " |~~ train@11095  Loss: 0.036558 Acc: 13.2000\n",
      " |~~ train@11100  Loss: 0.052723 Acc: 13.0000\n",
      " |~~ train@11105  Loss: 0.018794 Acc: 13.8000\n",
      " |~~ train@11110  Loss: 0.038280 Acc: 13.0000\n",
      " |~~ train@11115  Loss: 0.050086 Acc: 13.2000\n",
      " |~~ train@11120  Loss: 0.052067 Acc: 12.8000\n",
      " |~~ train@11125  Loss: 0.027427 Acc: 13.6000\n",
      " |~~ train@11130  Loss: 0.015767 Acc: 13.8000\n",
      " |~~ train@11135  Loss: 0.022011 Acc: 13.6000\n",
      " |~~ train@11140  Loss: 0.054482 Acc: 13.0000\n",
      " |~~ train@11145  Loss: 0.050334 Acc: 12.8000\n",
      " |~~ train@11150  Loss: 0.023038 Acc: 13.6000\n",
      " |~~ train@11155  Loss: 0.080025 Acc: 12.4000\n",
      " |~~ train@11160  Loss: 0.029514 Acc: 13.6000\n",
      " |~~ train@11165  Loss: 0.028680 Acc: 13.6000\n",
      " |~~ train@11170  Loss: 0.024920 Acc: 13.6000\n",
      " |~~ train@11175  Loss: 0.054833 Acc: 12.6000\n",
      " |~~ train@11180  Loss: 0.034044 Acc: 13.4000\n",
      " |~~ train@11185  Loss: 0.034455 Acc: 13.2000\n",
      " |~~ train@11190  Loss: 0.052819 Acc: 13.0000\n",
      " |~~ train@11195  Loss: 0.022247 Acc: 13.6000\n",
      " |~~ train@11200  Loss: 0.022135 Acc: 13.6000\n",
      " |~~ train@11205  Loss: 0.015017 Acc: 13.8000\n",
      " |~~ train@11210  Loss: 0.020501 Acc: 13.6000\n",
      " |~~ train@11215  Loss: 0.056375 Acc: 12.6000\n",
      " |~~ train@11220  Loss: 0.012549 Acc: 13.8000\n",
      " |~~ train@11225  Loss: 0.021988 Acc: 13.6000\n",
      " |~~ train@11230  Loss: 0.018898 Acc: 13.6000\n",
      " |~~ train@11235  Loss: 0.030023 Acc: 13.4000\n",
      " |~~ train@11240  Loss: 0.046696 Acc: 12.8000\n",
      " |~~ train@11245  Loss: 0.049082 Acc: 12.8000\n",
      " |~~ train@11250  Loss: 0.048428 Acc: 13.0000\n",
      " |~~ train@11255  Loss: 0.053444 Acc: 12.8000\n",
      " |~~ train@11260  Loss: 0.027188 Acc: 13.6000\n",
      " |~~ train@11265  Loss: 0.034302 Acc: 13.2000\n",
      " |~~ train@11270  Loss: 0.029686 Acc: 13.4000\n",
      " |~~ train@11275  Loss: 0.034913 Acc: 13.2000\n",
      " |~~ train@11280  Loss: 0.029412 Acc: 13.6000\n",
      " |~~ train@11285  Loss: 0.051994 Acc: 13.0000\n",
      " |~~ train@11290  Loss: 0.031783 Acc: 13.2000\n",
      " |~~ train@11295  Loss: 0.075639 Acc: 12.4000\n",
      " |~~ train@11300  Loss: 0.040983 Acc: 13.2000\n",
      " |~~ train@11305  Loss: 0.041645 Acc: 13.2000\n",
      " |~~ train@11310  Loss: 0.033742 Acc: 13.4000\n",
      " |~~ train@11315  Loss: 0.059725 Acc: 12.6000\n",
      " |~~ train@11320  Loss: 0.023763 Acc: 13.8000\n",
      " |~~ train@11325  Loss: 0.032176 Acc: 13.4000\n",
      " |~~ train@11330  Loss: 0.044261 Acc: 13.0000\n",
      " |~~ train@11335  Loss: 0.027237 Acc: 13.4000\n",
      " |~~ train@11340  Loss: 0.021752 Acc: 13.6000\n",
      " |~~ train@11345  Loss: 0.054008 Acc: 13.0000\n",
      " |~~ train@11350  Loss: 0.044123 Acc: 13.0000\n",
      " |~~ train@11355  Loss: 0.023277 Acc: 13.6000\n",
      " |~~ train@11360  Loss: 0.034499 Acc: 13.2000\n",
      " |~~ train@11365  Loss: 0.040027 Acc: 13.2000\n",
      " |~~ train@11370  Loss: 0.038792 Acc: 13.2000\n",
      " |~~ train@11375  Loss: 0.016547 Acc: 13.8000\n",
      " |~~ train@11380  Loss: 0.046689 Acc: 13.0000\n",
      " |~~ train@11385  Loss: 0.016561 Acc: 13.8000\n",
      " |~~ train@11390  Loss: 0.058610 Acc: 12.8000\n",
      " |~~ train@11395  Loss: 0.027800 Acc: 13.6000\n",
      " |~~ train@11400  Loss: 0.031924 Acc: 13.4000\n",
      " |~~ train@11405  Loss: 0.035340 Acc: 13.4000\n",
      " |~~ train@11410  Loss: 0.061522 Acc: 12.8000\n",
      " |~~ train@11415  Loss: 0.042484 Acc: 13.2000\n",
      " |~~ train@11420  Loss: 0.044805 Acc: 12.8000\n",
      " |~~ train@11425  Loss: 0.025391 Acc: 13.6000\n",
      " |~~ train@11430  Loss: 0.057531 Acc: 13.0000\n",
      " |~~ train@11435  Loss: 0.063362 Acc: 12.8000\n",
      " |~~ train@11440  Loss: 0.049431 Acc: 13.0000\n",
      " |~~ train@11445  Loss: 0.027810 Acc: 13.4000\n",
      " |~~ train@11450  Loss: 0.016984 Acc: 13.8000\n",
      " |~~ train@11455  Loss: 0.034703 Acc: 13.4000\n",
      " |~~ train@11460  Loss: 0.048237 Acc: 12.6000\n",
      " |~~ train@11465  Loss: 0.018612 Acc: 13.8000\n",
      " |~~ train@11470  Loss: 0.042055 Acc: 13.2000\n",
      " |~~ train@11475  Loss: 0.055115 Acc: 12.6000\n",
      " |~~ train@11480  Loss: 0.023029 Acc: 13.6000\n",
      " |~~ train@11485  Loss: 0.023750 Acc: 13.8000\n",
      " |~~ train@11490  Loss: 0.040295 Acc: 13.2000\n",
      " |~~ train@11495  Loss: 0.033077 Acc: 13.4000\n",
      " |~~ train@11500  Loss: 0.044290 Acc: 13.0000\n",
      " |~~ train@11505  Loss: 0.039054 Acc: 13.2000\n",
      " |~~ train@11510  Loss: 0.014636 Acc: 13.8000\n",
      " |~~ train@11515  Loss: 0.034778 Acc: 13.4000\n",
      " |~~ train@11520  Loss: 0.014715 Acc: 13.8000\n",
      " |~~ train@11525  Loss: 0.011008 Acc: 14.0000\n",
      " |~~ train@11530  Loss: 0.013651 Acc: 13.8000\n",
      " |~~ train@11535  Loss: 0.032874 Acc: 13.4000\n",
      " |~~ train@11540  Loss: 0.027620 Acc: 13.4000\n",
      " |~~ train@11545  Loss: 0.048909 Acc: 13.0000\n",
      " |~~ train@11550  Loss: 0.032941 Acc: 13.4000\n",
      " |~~ train@11555  Loss: 0.036706 Acc: 13.0000\n",
      " |~~ train@11560  Loss: 0.031546 Acc: 13.4000\n",
      " |~~ train@11565  Loss: 0.044968 Acc: 12.8000\n",
      " |~~ train@11570  Loss: 0.070805 Acc: 12.8000\n",
      " |~~ train@11575  Loss: 0.028482 Acc: 13.6000\n",
      " |~~ train@11580  Loss: 0.039208 Acc: 13.0000\n",
      " |~~ train@11585  Loss: 0.042454 Acc: 13.0000\n",
      " |~~ train@11590  Loss: 0.026908 Acc: 13.4000\n",
      " |~~ train@11595  Loss: 0.029361 Acc: 13.4000\n",
      " |~~ train@11600  Loss: 0.029662 Acc: 13.4000\n",
      " |~~ train@11605  Loss: 0.011224 Acc: 14.0000\n",
      " |~~ train@11610  Loss: 0.032888 Acc: 13.4000\n",
      " |~~ train@11615  Loss: 0.032913 Acc: 13.2000\n",
      " |~~ train@11620  Loss: 0.018701 Acc: 13.8000\n",
      " |~~ train@11625  Loss: 0.023859 Acc: 13.6000\n",
      " |~~ train@11630  Loss: 0.038907 Acc: 13.0000\n",
      " |~~ train@11635  Loss: 0.040161 Acc: 13.4000\n",
      " |~~ train@11640  Loss: 0.056053 Acc: 13.0000\n",
      " |~~ train@11645  Loss: 0.047607 Acc: 12.8000\n",
      " |~~ train@11650  Loss: 0.063131 Acc: 12.6000\n",
      " |~~ train@11655  Loss: 0.063493 Acc: 12.4000\n",
      " |~~ train@11660  Loss: 0.024578 Acc: 13.6000\n",
      " |~~ train@11665  Loss: 0.029360 Acc: 13.4000\n",
      " |~~ train@11670  Loss: 0.040069 Acc: 13.2000\n",
      " |~~ train@11675  Loss: 0.028050 Acc: 13.4000\n",
      " |~~ train@11680  Loss: 0.036181 Acc: 13.4000\n",
      " |~~ train@11685  Loss: 0.028524 Acc: 13.6000\n",
      " |~~ train@11690  Loss: 0.037601 Acc: 13.2000\n",
      " |~~ train@11695  Loss: 0.030672 Acc: 13.2000\n",
      " |~~ train@11700  Loss: 0.047728 Acc: 13.0000\n",
      " |~~ train@11705  Loss: 0.041754 Acc: 13.2000\n",
      " |~~ train@11710  Loss: 0.036693 Acc: 13.4000\n",
      " |~~ train@11715  Loss: 0.033178 Acc: 13.4000\n",
      " |~~ train@11720  Loss: 0.055488 Acc: 12.4000\n",
      " |~~ train@11725  Loss: 0.033965 Acc: 13.4000\n",
      " |~~ train@11730  Loss: 0.035823 Acc: 13.4000\n",
      " |~~ train@11735  Loss: 0.068867 Acc: 12.6000\n",
      " |~~ train@11740  Loss: 0.020324 Acc: 13.8000\n",
      " |~~ train@11745  Loss: 0.026045 Acc: 13.6000\n",
      " |~~ train@11750  Loss: 0.031417 Acc: 13.4000\n",
      " |~~ train@11755  Loss: 0.046669 Acc: 13.2000\n",
      " |~~ train@11760  Loss: 0.049366 Acc: 12.8000\n",
      " |~~ train@11765  Loss: 0.046188 Acc: 13.0000\n",
      " |~~ train@11770  Loss: 0.039336 Acc: 13.2000\n",
      " |~~ train@11775  Loss: 0.020050 Acc: 13.8000\n",
      " |~~ train@11780  Loss: 0.017393 Acc: 13.6000\n",
      " |~~ train@11785  Loss: 0.024678 Acc: 13.6000\n",
      " |~~ train@11790  Loss: 0.030026 Acc: 13.2000\n",
      " |~~ train@11795  Loss: 0.028442 Acc: 13.6000\n",
      " |~~ train@11800  Loss: 0.035007 Acc: 13.4000\n",
      " |~~ train@11805  Loss: 0.017360 Acc: 13.8000\n",
      " |~~ train@11810  Loss: 0.043878 Acc: 13.0000\n",
      " |~~ train@11815  Loss: 0.035057 Acc: 13.2000\n",
      " |~~ train@11820  Loss: 0.049287 Acc: 13.2000\n",
      " |~~ train@11825  Loss: 0.042658 Acc: 13.0000\n",
      " |~~ train@11830  Loss: 0.050437 Acc: 12.8000\n",
      " |~~ train@11835  Loss: 0.016553 Acc: 13.8000\n",
      " |~~ train@11840  Loss: 0.030478 Acc: 13.4000\n",
      " |~~ train@11845  Loss: 0.015318 Acc: 13.8000\n",
      " |~~ train@11850  Loss: 0.052158 Acc: 13.2000\n",
      " |~~ train@11855  Loss: 0.050957 Acc: 13.0000\n",
      " |~~ train@11860  Loss: 0.038843 Acc: 13.2000\n",
      " |~~ train@11865  Loss: 0.061117 Acc: 12.6000\n",
      " |~~ train@11870  Loss: 0.050999 Acc: 12.6000\n",
      " |~~ train@11875  Loss: 0.034975 Acc: 13.4000\n",
      " |~~ train@11880  Loss: 0.061034 Acc: 12.8000\n",
      " |~~ train@11885  Loss: 0.053343 Acc: 13.0000\n",
      " |~~ train@11890  Loss: 0.044203 Acc: 13.0000\n",
      " |~~ train@11895  Loss: 0.029982 Acc: 13.4000\n",
      " |~~ train@11900  Loss: 0.049755 Acc: 12.6000\n",
      " |~~ train@11905  Loss: 0.056806 Acc: 12.6000\n",
      " |~~ train@11910  Loss: 0.023996 Acc: 13.6000\n",
      " |~~ train@11915  Loss: 0.016784 Acc: 13.8000\n",
      " |~~ train@11920  Loss: 0.017452 Acc: 13.8000\n",
      " |~~ train@11925  Loss: 0.029085 Acc: 13.6000\n",
      " |~~ train@11930  Loss: 0.047719 Acc: 13.0000\n",
      " |~~ train@11935  Loss: 0.029608 Acc: 13.4000\n",
      " |~~ train@11940  Loss: 0.066866 Acc: 12.8000\n",
      " |~~ train@11945  Loss: 0.046411 Acc: 13.2000\n",
      " |~~ train@11950  Loss: 0.038955 Acc: 13.4000\n",
      " |~~ train@11955  Loss: 0.028761 Acc: 13.6000\n",
      " |~~ train@11960  Loss: 0.023384 Acc: 13.6000\n",
      " |~~ train@11965  Loss: 0.025827 Acc: 13.6000\n",
      " |~~ train@11970  Loss: 0.025569 Acc: 13.6000\n",
      " |~~ train@11975  Loss: 0.015388 Acc: 13.8000\n",
      " |~~ train@11980  Loss: 0.023199 Acc: 13.6000\n",
      " |~~ train@11985  Loss: 0.015330 Acc: 13.8000\n",
      " |~~ train@11990  Loss: 0.045063 Acc: 13.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@11995  Loss: 0.027128 Acc: 13.4000\n",
      " |~~ train@12000  Loss: 0.025365 Acc: 13.6000\n",
      " |~~ train@12005  Loss: 0.010782 Acc: 14.0000\n",
      " |~~ train@12010  Loss: 0.040573 Acc: 13.4000\n",
      " |~~ train@12015  Loss: 0.010840 Acc: 14.0000\n",
      " |~~ train@12020  Loss: 0.013273 Acc: 13.8000\n",
      " |~~ train@12025  Loss: 0.028990 Acc: 13.6000\n",
      " |~~ train@12030  Loss: 0.049689 Acc: 12.8000\n",
      " |~~ train@12035  Loss: 0.018846 Acc: 13.6000\n",
      " |~~ train@12040  Loss: 0.048802 Acc: 13.0000\n",
      " |~~ train@12045  Loss: 0.037304 Acc: 13.0000\n",
      " |~~ train@12050  Loss: 0.020810 Acc: 13.6000\n",
      " |~~ train@12055  Loss: 0.026189 Acc: 13.6000\n",
      " |~~ train@12060  Loss: 0.093888 Acc: 12.2000\n",
      " |~~ train@12065  Loss: 0.027438 Acc: 13.6000\n",
      " |~~ train@12070  Loss: 0.039006 Acc: 13.2000\n",
      " |~~ train@12075  Loss: 0.042247 Acc: 13.4000\n",
      " |~~ train@12080  Loss: 0.049283 Acc: 13.0000\n",
      " |~~ train@12085  Loss: 0.026060 Acc: 13.4000\n",
      " |~~ train@12090  Loss: 0.045920 Acc: 13.0000\n",
      " |~~ train@12095  Loss: 0.034382 Acc: 13.4000\n",
      " |~~ train@12100  Loss: 0.016103 Acc: 13.8000\n",
      " |~~ train@12105  Loss: 0.042837 Acc: 13.0000\n",
      " |~~ train@12110  Loss: 0.035333 Acc: 13.4000\n",
      " |~~ train@12115  Loss: 0.009534 Acc: 14.0000\n",
      " |~~ train@12120  Loss: 0.037250 Acc: 13.2000\n",
      " |~~ train@12125  Loss: 0.022604 Acc: 13.4000\n",
      " |~~ train@12130  Loss: 0.031790 Acc: 13.4000\n",
      " |~~ train@12135  Loss: 0.012913 Acc: 13.8000\n",
      " |~~ train@12140  Loss: 0.024753 Acc: 13.6000\n",
      " |~~ train@12145  Loss: 0.047130 Acc: 13.0000\n",
      " |~~ train@12150  Loss: 0.027626 Acc: 13.6000\n",
      " |~~ train@12155  Loss: 0.021724 Acc: 13.6000\n",
      " |~~ train@12160  Loss: 0.062705 Acc: 12.6000\n",
      " |~~ train@12165  Loss: 0.029725 Acc: 13.4000\n",
      " |~~ train@12170  Loss: 0.032348 Acc: 13.4000\n",
      " |~~ train@12175  Loss: 0.026701 Acc: 13.6000\n",
      " |~~ train@12180  Loss: 0.031398 Acc: 13.4000\n",
      " |~~ train@12185  Loss: 0.024356 Acc: 13.6000\n",
      " |~~ train@12190  Loss: 0.040595 Acc: 13.2000\n",
      " |~~ train@12195  Loss: 0.026531 Acc: 13.4000\n",
      " |~~ train@12200  Loss: 0.021124 Acc: 13.6000\n",
      " |~~ train@12205  Loss: 0.020341 Acc: 13.6000\n",
      " |~~ train@12210  Loss: 0.033670 Acc: 13.4000\n",
      " |~~ train@12215  Loss: 0.058020 Acc: 12.6000\n",
      " |~~ train@12220  Loss: 0.024791 Acc: 13.6000\n",
      " |~~ train@12225  Loss: 0.019240 Acc: 13.6000\n",
      " |~~ train@12230  Loss: 0.044032 Acc: 13.0000\n",
      " |~~ train@12235  Loss: 0.015450 Acc: 13.8000\n",
      " |~~ train@12240  Loss: 0.017729 Acc: 13.8000\n",
      " |~~ train@12245  Loss: 0.037502 Acc: 13.2000\n",
      " |~~ train@12250  Loss: 0.015987 Acc: 13.8000\n",
      " |~~ train@12255  Loss: 0.040564 Acc: 13.2000\n",
      " |~~ train@12260  Loss: 0.028198 Acc: 13.4000\n",
      " |~~ train@12265  Loss: 0.009480 Acc: 14.0000\n",
      " |~~ train@12270  Loss: 0.028530 Acc: 13.4000\n",
      " |~~ train@12275  Loss: 0.027117 Acc: 13.4000\n",
      " |~~ train@12280  Loss: 0.009918 Acc: 14.0000\n",
      " |~~ train@12285  Loss: 0.046657 Acc: 13.0000\n",
      " |~~ train@12290  Loss: 0.054179 Acc: 12.8000\n",
      " |~~ train@12295  Loss: 0.019841 Acc: 13.6000\n",
      " |~~ train@12300  Loss: 0.043887 Acc: 13.2000\n",
      " |~~ train@12305  Loss: 0.022140 Acc: 13.6000\n",
      " |~~ train@12310  Loss: 0.105106 Acc: 11.4000\n",
      " |~~ train@12315  Loss: 0.027851 Acc: 13.6000\n",
      " |~~ train@12320  Loss: 0.032583 Acc: 13.6000\n",
      " |~~ train@12325  Loss: 0.043212 Acc: 13.2000\n",
      " |~~ train@12330  Loss: 0.031921 Acc: 13.2000\n",
      " |~~ train@12335  Loss: 0.031508 Acc: 13.4000\n",
      " |~~ train@12340  Loss: 0.060022 Acc: 12.8000\n",
      " |~~ train@12345  Loss: 0.048828 Acc: 13.0000\n",
      " |~~ train@12350  Loss: 0.068985 Acc: 12.6000\n",
      " |~~ train@12355  Loss: 0.030431 Acc: 13.4000\n",
      " |~~ train@12360  Loss: 0.033034 Acc: 13.4000\n",
      " |~~ train@12365  Loss: 0.063434 Acc: 12.6000\n",
      " |~~ train@12370  Loss: 0.032918 Acc: 13.4000\n",
      " |~~ train@12375  Loss: 0.028352 Acc: 13.4000\n",
      " |~~ train@12380  Loss: 0.032481 Acc: 13.2000\n",
      " |~~ train@12385  Loss: 0.010067 Acc: 14.0000\n",
      " |~~ train@12390  Loss: 0.013387 Acc: 13.8000\n",
      " |~~ train@12395  Loss: 0.041340 Acc: 13.2000\n",
      " |~~ train@12400  Loss: 0.034658 Acc: 13.0000\n",
      " |~~ train@12405  Loss: 0.065204 Acc: 12.8000\n",
      " |~~ train@12410  Loss: 0.025205 Acc: 13.4000\n",
      " |~~ train@12415  Loss: 0.019915 Acc: 13.8000\n",
      " |~~ train@12420  Loss: 0.022010 Acc: 13.6000\n",
      " |~~ train@12425  Loss: 0.033322 Acc: 13.2000\n",
      " |~~ train@12430  Loss: 0.028951 Acc: 13.6000\n",
      " |~~ train@12435  Loss: 0.029549 Acc: 13.4000\n",
      " |~~ train@12440  Loss: 0.048062 Acc: 13.2000\n",
      " |~~ train@12445  Loss: 0.027047 Acc: 13.6000\n",
      " |~~ train@12450  Loss: 0.026441 Acc: 13.6000\n",
      " |~~ train@12455  Loss: 0.027992 Acc: 13.4000\n",
      " |~~ train@12460  Loss: 0.017967 Acc: 13.8000\n",
      " |~~ train@12465  Loss: 0.029244 Acc: 13.4000\n",
      " |~~ train@12470  Loss: 0.027927 Acc: 13.4000\n",
      " |~~ train@12475  Loss: 0.027495 Acc: 13.6000\n",
      " |~~ train@12480  Loss: 0.020473 Acc: 13.6000\n",
      " |~~ train@12485  Loss: 0.084712 Acc: 12.4000\n",
      " |~~ train@12490  Loss: 0.045607 Acc: 13.0000\n",
      " |~~ train@12495  Loss: 0.060877 Acc: 12.6000\n",
      " |~~ train@12500  Loss: 0.039561 Acc: 13.4000\n",
      " |~~ train@12505  Loss: 0.044741 Acc: 13.2000\n",
      " |~~ train@12510  Loss: 0.073220 Acc: 12.4000\n",
      " |~~ train@12515  Loss: 0.074151 Acc: 12.2000\n",
      " |~~ train@12520  Loss: 0.045079 Acc: 13.0000\n",
      " |~~ train@12525  Loss: 0.024372 Acc: 13.4000\n",
      " |~~ train@12530  Loss: 0.011214 Acc: 14.0000\n",
      " |~~ train@12535  Loss: 0.027188 Acc: 13.4000\n",
      " |~~ train@12540  Loss: 0.026046 Acc: 13.4000\n",
      " |~~ train@12545  Loss: 0.029359 Acc: 13.4000\n",
      " |~~ train@12550  Loss: 0.057100 Acc: 12.8000\n",
      " |~~ train@12555  Loss: 0.026359 Acc: 13.6000\n",
      " |~~ train@12560  Loss: 0.035381 Acc: 13.2000\n",
      " |~~ train@12565  Loss: 0.034216 Acc: 13.2000\n",
      " |~~ train@12570  Loss: 0.030408 Acc: 13.2000\n",
      " |~~ train@12575  Loss: 0.010545 Acc: 14.0000\n",
      " |~~ train@12580  Loss: 0.042232 Acc: 12.8000\n",
      " |~~ train@12585  Loss: 0.047841 Acc: 13.0000\n",
      " |~~ train@12590  Loss: 0.039010 Acc: 13.4000\n",
      " |~~ train@12595  Loss: 0.026106 Acc: 13.6000\n",
      " |~~ train@12600  Loss: 0.021980 Acc: 13.8000\n",
      " |~~ train@12605  Loss: 0.036910 Acc: 13.4000\n",
      " |~~ train@12610  Loss: 0.044850 Acc: 13.0000\n",
      " |~~ train@12615  Loss: 0.035696 Acc: 13.2000\n",
      " |~~ train@12620  Loss: 0.025258 Acc: 13.2000\n",
      " |~~ train@12625  Loss: 0.014859 Acc: 13.8000\n",
      " |~~ train@12630  Loss: 0.045103 Acc: 12.8000\n",
      " |~~ train@12635  Loss: 0.054039 Acc: 12.8000\n",
      " |~~ train@12640  Loss: 0.022731 Acc: 13.6000\n",
      " |~~ train@12645  Loss: 0.047770 Acc: 12.8000\n",
      " |~~ train@12650  Loss: 0.022116 Acc: 13.6000\n",
      " |~~ train@12655  Loss: 0.043693 Acc: 13.2000\n",
      " |~~ train@12660  Loss: 0.026905 Acc: 13.6000\n",
      " |~~ train@12665  Loss: 0.065480 Acc: 12.6000\n",
      " |~~ train@12670  Loss: 0.039388 Acc: 13.2000\n",
      " |~~ train@12675  Loss: 0.023006 Acc: 13.4000\n",
      " |~~ train@12680  Loss: 0.031923 Acc: 13.0000\n",
      " |~~ train@12685  Loss: 0.024243 Acc: 13.4000\n",
      " |~~ train@12690  Loss: 0.016015 Acc: 13.8000\n",
      " |~~ train@12695  Loss: 0.047936 Acc: 13.0000\n",
      " |~~ train@12700  Loss: 0.021100 Acc: 13.6000\n",
      " |~~ train@12705  Loss: 0.016108 Acc: 13.8000\n",
      " |~~ train@12710  Loss: 0.034800 Acc: 13.4000\n",
      " |~~ train@12715  Loss: 0.076631 Acc: 12.4000\n",
      " |~~ train@12720  Loss: 0.011777 Acc: 14.0000\n",
      " |~~ train@12725  Loss: 0.036515 Acc: 13.2000\n",
      " |~~ train@12730  Loss: 0.030295 Acc: 13.4000\n",
      " |~~ train@12735  Loss: 0.059027 Acc: 13.2000\n",
      " |~~ train@12740  Loss: 0.053969 Acc: 13.2000\n",
      " |~~ train@12745  Loss: 0.050184 Acc: 13.0000\n",
      " |~~ train@12750  Loss: 0.028506 Acc: 13.4000\n",
      " |~~ train@12755  Loss: 0.017424 Acc: 13.8000\n",
      " |~~ train@12760  Loss: 0.035904 Acc: 13.2000\n",
      " |~~ train@12765  Loss: 0.022243 Acc: 13.8000\n",
      " |~~ train@12770  Loss: 0.042613 Acc: 13.2000\n",
      " |~~ train@12775  Loss: 0.020146 Acc: 13.6000\n",
      " |~~ train@12780  Loss: 0.042446 Acc: 12.8000\n",
      " |~~ train@12785  Loss: 0.024185 Acc: 13.6000\n",
      " |~~ train@12790  Loss: 0.015351 Acc: 13.8000\n",
      " |~~ train@12795  Loss: 0.018207 Acc: 13.8000\n",
      " |~~ train@12800  Loss: 0.034329 Acc: 13.2000\n",
      " |~~ train@12805  Loss: 0.045200 Acc: 12.8000\n",
      " |~~ train@12810  Loss: 0.032910 Acc: 13.4000\n",
      " |~~ train@12815  Loss: 0.016111 Acc: 13.8000\n",
      " |~~ train@12820  Loss: 0.030571 Acc: 13.4000\n",
      " |~~ train@12825  Loss: 0.034957 Acc: 13.4000\n",
      " |~~ train@12830  Loss: 0.042559 Acc: 13.2000\n",
      " |~~ train@12835  Loss: 0.034098 Acc: 13.4000\n",
      " |~~ train@12840  Loss: 0.014126 Acc: 13.8000\n",
      " |~~ train@12845  Loss: 0.025831 Acc: 13.6000\n",
      " |~~ train@12850  Loss: 0.027785 Acc: 13.6000\n",
      " |~~ train@12855  Loss: 0.060291 Acc: 12.8000\n",
      " |~~ train@12860  Loss: 0.070857 Acc: 12.6000\n",
      " |~~ train@12865  Loss: 0.033840 Acc: 13.0000\n",
      " |~~ train@12870  Loss: 0.020651 Acc: 13.8000\n",
      " |~~ train@12875  Loss: 0.040397 Acc: 13.2000\n",
      " |~~ train@12880  Loss: 0.029121 Acc: 13.4000\n",
      " |~~ train@12885  Loss: 0.040893 Acc: 13.2000\n",
      " |~~ train@12890  Loss: 0.029685 Acc: 13.6000\n",
      " |~~ train@12895  Loss: 0.024324 Acc: 13.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@12900  Loss: 0.047955 Acc: 13.0000\n",
      " |~~ train@12905  Loss: 0.028310 Acc: 13.2000\n",
      " |~~ train@12910  Loss: 0.078545 Acc: 12.2000\n",
      " |~~ train@12915  Loss: 0.054091 Acc: 13.0000\n",
      " |~~ train@12920  Loss: 0.031531 Acc: 13.4000\n",
      " |~~ train@12925  Loss: 0.026357 Acc: 13.4000\n",
      " |~~ train@12930  Loss: 0.023838 Acc: 13.6000\n",
      " |~~ train@12935  Loss: 0.040102 Acc: 13.2000\n",
      " |~~ train@12940  Loss: 0.013644 Acc: 13.8000\n",
      " |~~ train@12945  Loss: 0.022330 Acc: 13.6000\n",
      " |~~ train@12950  Loss: 0.026461 Acc: 13.6000\n",
      " |~~ train@12955  Loss: 0.010504 Acc: 14.0000\n",
      " |~~ train@12960  Loss: 0.021462 Acc: 13.4000\n",
      " |~~ train@12965  Loss: 0.063534 Acc: 12.8000\n",
      " |~~ train@12970  Loss: 0.025723 Acc: 13.6000\n",
      " |~~ train@12975  Loss: 0.028270 Acc: 13.4000\n",
      " |~~ train@12980  Loss: 0.059515 Acc: 12.8000\n",
      " |~~ train@12985  Loss: 0.047877 Acc: 13.0000\n",
      " |~~ train@12990  Loss: 0.027548 Acc: 13.4000\n",
      " |~~ train@12995  Loss: 0.031135 Acc: 13.4000\n",
      " |~~ train@13000  Loss: 0.014186 Acc: 13.8000\n",
      " |~~ train@13005  Loss: 0.010051 Acc: 14.0000\n",
      " |~~ train@13010  Loss: 0.047414 Acc: 13.0000\n",
      " |~~ train@13015  Loss: 0.028628 Acc: 13.6000\n",
      " |~~ train@13020  Loss: 0.053960 Acc: 13.0000\n",
      " |~~ train@13025  Loss: 0.010036 Acc: 14.0000\n",
      " |~~ train@13030  Loss: 0.031328 Acc: 13.2000\n",
      " |~~ train@13035  Loss: 0.038701 Acc: 13.4000\n",
      " |~~ train@13040  Loss: 0.016579 Acc: 13.8000\n",
      " |~~ train@13045  Loss: 0.020546 Acc: 13.8000\n",
      " |~~ train@13050  Loss: 0.018831 Acc: 13.8000\n",
      " |~~ train@13055  Loss: 0.027718 Acc: 13.6000\n",
      " |~~ train@13060  Loss: 0.026144 Acc: 13.6000\n",
      " |~~ train@13065  Loss: 0.023795 Acc: 13.6000\n",
      " |~~ train@13070  Loss: 0.029468 Acc: 13.4000\n",
      " |~~ train@13075  Loss: 0.061463 Acc: 13.0000\n",
      " |~~ train@13080  Loss: 0.020935 Acc: 13.6000\n",
      " |~~ train@13085  Loss: 0.034740 Acc: 13.4000\n",
      " |~~ train@13090  Loss: 0.029536 Acc: 13.4000\n",
      " |~~ train@13095  Loss: 0.029280 Acc: 13.6000\n",
      " |~~ train@13100  Loss: 0.018985 Acc: 13.6000\n",
      " |~~ train@13105  Loss: 0.038952 Acc: 13.2000\n",
      " |~~ train@13110  Loss: 0.013518 Acc: 13.8000\n",
      " |~~ train@13115  Loss: 0.050068 Acc: 12.6000\n",
      " |~~ train@13120  Loss: 0.051187 Acc: 12.8000\n",
      " |~~ train@13125  Loss: 0.038236 Acc: 13.4000\n",
      " |~~ train@13130  Loss: 0.036035 Acc: 13.4000\n",
      " |~~ train@13135  Loss: 0.027568 Acc: 13.4000\n",
      " |~~ train@13140  Loss: 0.028118 Acc: 13.6000\n",
      " |~~ train@13145  Loss: 0.022302 Acc: 13.6000\n",
      " |~~ train@13150  Loss: 0.035085 Acc: 13.2000\n",
      " |~~ train@13155  Loss: 0.069175 Acc: 12.4000\n",
      " |~~ train@13160  Loss: 0.027045 Acc: 13.6000\n",
      " |~~ train@13165  Loss: 0.051479 Acc: 12.8000\n",
      " |~~ train@13170  Loss: 0.042774 Acc: 13.2000\n",
      " |~~ train@13175  Loss: 0.046515 Acc: 13.0000\n",
      " |~~ train@13180  Loss: 0.036226 Acc: 13.0000\n",
      " |~~ train@13185  Loss: 0.028916 Acc: 13.4000\n",
      " |~~ train@13190  Loss: 0.018215 Acc: 13.8000\n",
      " |~~ train@13195  Loss: 0.038856 Acc: 13.2000\n",
      " |~~ train@13200  Loss: 0.020626 Acc: 13.8000\n",
      " |~~ train@13205  Loss: 0.065796 Acc: 12.8000\n",
      " |~~ train@13210  Loss: 0.042907 Acc: 13.0000\n",
      " |~~ train@13215  Loss: 0.078420 Acc: 12.6000\n",
      " |~~ train@13220  Loss: 0.010211 Acc: 14.0000\n",
      " |~~ train@13225  Loss: 0.025486 Acc: 13.6000\n",
      " |~~ train@13230  Loss: 0.014982 Acc: 13.8000\n",
      " |~~ train@13235  Loss: 0.026323 Acc: 13.4000\n",
      " |~~ train@13240  Loss: 0.035861 Acc: 13.2000\n",
      " |~~ train@13245  Loss: 0.034131 Acc: 13.4000\n",
      " |~~ train@13250  Loss: 0.038872 Acc: 13.4000\n",
      " |~~ train@13255  Loss: 0.021001 Acc: 13.8000\n",
      " |~~ train@13260  Loss: 0.023944 Acc: 13.6000\n",
      " |~~ train@13265  Loss: 0.044051 Acc: 13.2000\n",
      " |~~ train@13270  Loss: 0.009942 Acc: 14.0000\n",
      " |~~ train@13275  Loss: 0.063059 Acc: 12.8000\n",
      " |~~ train@13280  Loss: 0.032517 Acc: 13.4000\n",
      " |~~ train@13285  Loss: 0.062624 Acc: 12.8000\n",
      " |~~ train@13290  Loss: 0.022655 Acc: 13.6000\n",
      " |~~ train@13295  Loss: 0.052521 Acc: 12.8000\n",
      " |~~ train@13300  Loss: 0.020249 Acc: 13.6000\n",
      " |~~ train@13305  Loss: 0.020488 Acc: 13.6000\n",
      " |~~ train@13310  Loss: 0.059872 Acc: 12.8000\n",
      " |~~ train@13315  Loss: 0.022770 Acc: 13.6000\n",
      " |~~ train@13320  Loss: 0.016777 Acc: 13.8000\n",
      " |~~ train@13325  Loss: 0.054784 Acc: 13.0000\n",
      " |~~ train@13330  Loss: 0.016837 Acc: 13.6000\n",
      " |~~ train@13335  Loss: 0.020988 Acc: 13.6000\n",
      " |~~ train@13340  Loss: 0.043918 Acc: 13.2000\n",
      " |~~ train@13345  Loss: 0.018646 Acc: 13.8000\n",
      " |~~ train@13350  Loss: 0.041326 Acc: 13.2000\n",
      " |~~ train@13355  Loss: 0.040582 Acc: 13.2000\n",
      " |~~ train@13360  Loss: 0.032192 Acc: 13.4000\n",
      " |~~ train@13365  Loss: 0.024742 Acc: 13.4000\n",
      " |~~ train@13370  Loss: 0.025539 Acc: 13.4000\n",
      " |~~ train@13375  Loss: 0.075317 Acc: 12.4000\n",
      " |~~ train@13380  Loss: 0.054288 Acc: 12.8000\n",
      " |~~ train@13385  Loss: 0.040839 Acc: 13.0000\n",
      " |~~ train@13390  Loss: 0.032513 Acc: 13.6000\n",
      " |~~ train@13395  Loss: 0.017886 Acc: 13.8000\n",
      " |~~ train@13400  Loss: 0.061719 Acc: 12.6000\n",
      " |~~ train@13405  Loss: 0.044615 Acc: 13.0000\n",
      " |~~ train@13410  Loss: 0.063737 Acc: 12.4000\n",
      " |~~ train@13415  Loss: 0.044156 Acc: 13.0000\n",
      " |~~ train@13420  Loss: 0.043504 Acc: 13.4000\n",
      " |~~ train@13425  Loss: 0.040294 Acc: 13.2000\n",
      " |~~ train@13430  Loss: 0.049786 Acc: 12.8000\n",
      " |~~ train@13435  Loss: 0.011533 Acc: 14.0000\n",
      " |~~ train@13440  Loss: 0.011347 Acc: 14.0000\n",
      " |~~ train@13445  Loss: 0.025490 Acc: 13.6000\n",
      " |~~ train@13450  Loss: 0.052538 Acc: 12.8000\n",
      " |~~ train@13455  Loss: 0.029957 Acc: 13.4000\n",
      " |~~ train@13460  Loss: 0.046416 Acc: 13.0000\n",
      " |~~ train@13465  Loss: 0.030265 Acc: 13.4000\n",
      " |~~ train@13470  Loss: 0.018667 Acc: 13.8000\n",
      " |~~ train@13475  Loss: 0.037561 Acc: 13.2000\n",
      " |~~ train@13480  Loss: 0.034564 Acc: 13.2000\n",
      " |~~ train@13485  Loss: 0.036895 Acc: 13.2000\n",
      " |~~ train@13490  Loss: 0.027141 Acc: 13.4000\n",
      " |~~ train@13495  Loss: 0.046505 Acc: 12.8000\n",
      " |~~ train@13500  Loss: 0.020034 Acc: 13.8000\n",
      " |~~ train@13505  Loss: 0.046243 Acc: 13.0000\n",
      " |~~ train@13510  Loss: 0.053450 Acc: 12.6000\n",
      " |~~ train@13515  Loss: 0.010570 Acc: 14.0000\n",
      " |~~ train@13520  Loss: 0.026754 Acc: 13.4000\n",
      " |~~ train@13525  Loss: 0.051812 Acc: 13.0000\n",
      " |~~ train@13530  Loss: 0.033361 Acc: 13.2000\n",
      " |~~ train@13535  Loss: 0.024879 Acc: 13.4000\n",
      " |~~ train@13540  Loss: 0.022630 Acc: 13.6000\n",
      " |~~ train@13545  Loss: 0.035063 Acc: 13.4000\n",
      " |~~ train@13550  Loss: 0.070673 Acc: 12.8000\n",
      " |~~ train@13555  Loss: 0.082090 Acc: 12.4000\n",
      " |~~ train@13560  Loss: 0.020587 Acc: 13.6000\n",
      " |~~ train@13565  Loss: 0.021823 Acc: 13.6000\n",
      " |~~ train@13570  Loss: 0.044743 Acc: 13.2000\n",
      " |~~ train@13575  Loss: 0.020660 Acc: 13.8000\n",
      " |~~ train@13580  Loss: 0.022846 Acc: 13.6000\n",
      " |~~ train@13585  Loss: 0.072738 Acc: 12.2000\n",
      " |~~ train@13590  Loss: 0.031304 Acc: 13.4000\n",
      " |~~ train@13595  Loss: 0.064090 Acc: 12.6000\n",
      " |~~ train@13600  Loss: 0.026720 Acc: 13.6000\n",
      " |~~ train@13605  Loss: 0.085678 Acc: 12.0000\n",
      " |~~ train@13610  Loss: 0.028323 Acc: 13.6000\n",
      " |~~ train@13615  Loss: 0.023498 Acc: 13.6000\n",
      " |~~ train@13620  Loss: 0.040664 Acc: 13.0000\n",
      " |~~ train@13625  Loss: 0.032422 Acc: 13.4000\n",
      " |~~ train@13630  Loss: 0.023853 Acc: 13.6000\n",
      " |~~ train@13635  Loss: 0.035861 Acc: 13.2000\n",
      " |~~ train@13640  Loss: 0.023433 Acc: 13.4000\n",
      " |~~ train@13645  Loss: 0.026051 Acc: 13.4000\n",
      " |~~ train@13650  Loss: 0.031648 Acc: 13.4000\n",
      " |~~ train@13655  Loss: 0.023428 Acc: 13.6000\n",
      " |~~ train@13660  Loss: 0.054833 Acc: 12.8000\n",
      " |~~ train@13665  Loss: 0.028059 Acc: 13.4000\n",
      " |~~ train@13670  Loss: 0.035743 Acc: 13.2000\n",
      " |~~ train@13675  Loss: 0.071387 Acc: 12.4000\n",
      " |~~ train@13680  Loss: 0.034460 Acc: 13.4000\n",
      " |~~ train@13685  Loss: 0.011114 Acc: 14.0000\n",
      " |~~ train@13690  Loss: 0.032166 Acc: 13.4000\n",
      " |~~ train@13695  Loss: 0.023863 Acc: 13.6000\n",
      " |~~ train@13700  Loss: 0.011122 Acc: 14.0000\n",
      " |~~ train@13705  Loss: 0.030330 Acc: 13.4000\n",
      " |~~ train@13710  Loss: 0.029256 Acc: 13.2000\n",
      " |~~ train@13715  Loss: 0.061810 Acc: 12.6000\n",
      " |~~ train@13720  Loss: 0.021317 Acc: 13.8000\n",
      " |~~ train@13725  Loss: 0.025149 Acc: 13.2000\n",
      " |~~ train@13730  Loss: 0.020692 Acc: 13.6000\n",
      " |~~ train@13735  Loss: 0.034689 Acc: 13.4000\n",
      " |~~ train@13740  Loss: 0.018211 Acc: 13.8000\n",
      " |~~ train@13745  Loss: 0.053851 Acc: 12.8000\n",
      " |~~ train@13750  Loss: 0.070708 Acc: 12.2000\n",
      " |~~ train@13755  Loss: 0.027462 Acc: 13.4000\n",
      " |~~ train@13760  Loss: 0.058893 Acc: 12.6000\n",
      " |~~ train@13765  Loss: 0.071691 Acc: 12.8000\n",
      " |~~ train@13770  Loss: 0.040824 Acc: 13.2000\n",
      " |~~ train@13775  Loss: 0.029228 Acc: 13.4000\n",
      " |~~ train@13780  Loss: 0.050754 Acc: 12.8000\n",
      " |~~ train@13785  Loss: 0.031016 Acc: 13.6000\n",
      " |~~ train@13790  Loss: 0.038039 Acc: 13.2000\n",
      " |~~ train@13795  Loss: 0.019665 Acc: 13.6000\n",
      " |~~ train@13800  Loss: 0.029900 Acc: 13.4000\n",
      " |~~ train@13805  Loss: 0.055037 Acc: 12.6000\n",
      " |~~ train@13810  Loss: 0.044306 Acc: 13.0000\n",
      " |~~ train@13815  Loss: 0.051874 Acc: 12.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@13820  Loss: 0.026435 Acc: 13.6000\n",
      " |~~ train@13825  Loss: 0.039219 Acc: 13.4000\n",
      " |~~ train@13830  Loss: 0.064321 Acc: 12.6000\n",
      " |~~ train@13835  Loss: 0.050096 Acc: 13.0000\n",
      " |~~ train@13840  Loss: 0.028278 Acc: 13.4000\n",
      " |~~ train@13845  Loss: 0.033537 Acc: 13.4000\n",
      " |~~ train@13850  Loss: 0.048632 Acc: 12.8000\n",
      " |~~ train@13855  Loss: 0.044610 Acc: 13.0000\n",
      " |~~ train@13860  Loss: 0.048997 Acc: 13.0000\n",
      " |~~ train@13865  Loss: 0.036574 Acc: 13.0000\n",
      " |~~ train@13870  Loss: 0.038531 Acc: 13.0000\n",
      " |~~ train@13875  Loss: 0.015406 Acc: 13.8000\n",
      " |~~ train@13880  Loss: 0.036357 Acc: 13.2000\n",
      " |~~ train@13885  Loss: 0.048590 Acc: 12.8000\n",
      " |~~ train@13890  Loss: 0.053233 Acc: 12.4000\n",
      " |~~ train@13895  Loss: 0.047904 Acc: 13.0000\n",
      " |~~ train@13900  Loss: 0.018695 Acc: 13.6000\n",
      " |~~ train@13905  Loss: 0.047271 Acc: 13.2000\n",
      " |~~ train@13910  Loss: 0.031486 Acc: 13.4000\n",
      " |~~ train@13915  Loss: 0.023123 Acc: 13.6000\n",
      " |~~ train@13920  Loss: 0.059704 Acc: 12.6000\n",
      " |~~ train@13925  Loss: 0.026263 Acc: 13.4000\n",
      " |~~ train@13930  Loss: 0.058562 Acc: 12.8000\n",
      " |~~ train@13935  Loss: 0.028730 Acc: 13.4000\n",
      " |~~ train@13940  Loss: 0.042079 Acc: 13.2000\n",
      " |~~ train@13945  Loss: 0.043397 Acc: 13.0000\n",
      " |~~ train@13950  Loss: 0.055317 Acc: 13.0000\n",
      " |~~ train@13955  Loss: 0.033981 Acc: 13.4000\n",
      " |~~ train@13960  Loss: 0.038529 Acc: 13.2000\n",
      " |~~ train@13965  Loss: 0.030068 Acc: 13.4000\n",
      " |~~ train@13970  Loss: 0.064031 Acc: 12.6000\n",
      " |~~ train@13975  Loss: 0.035763 Acc: 13.2000\n",
      " |~~ train@13980  Loss: 0.051918 Acc: 12.8000\n",
      " |~~ train@13985  Loss: 0.044054 Acc: 13.0000\n",
      " |~~ train@13990  Loss: 0.021738 Acc: 13.8000\n",
      " |~~ train@13995  Loss: 0.029593 Acc: 13.4000\n",
      " |~~ train@14000  Loss: 0.033606 Acc: 13.4000\n",
      " |~~ train@14005  Loss: 0.032923 Acc: 13.4000\n",
      " |~~ train@14010  Loss: 0.027613 Acc: 13.6000\n",
      " |~~ train@14015  Loss: 0.017123 Acc: 13.8000\n",
      " |~~ train@14020  Loss: 0.028393 Acc: 13.4000\n",
      " |~~ train@14025  Loss: 0.017272 Acc: 13.8000\n",
      " |~~ train@14030  Loss: 0.056433 Acc: 12.8000\n",
      " |~~ train@14035  Loss: 0.056275 Acc: 12.6000\n",
      " |~~ train@14040  Loss: 0.048406 Acc: 12.8000\n",
      " |~~ train@14045  Loss: 0.051174 Acc: 12.8000\n",
      " |~~ train@14050  Loss: 0.045383 Acc: 13.2000\n",
      " |~~ train@14055  Loss: 0.051525 Acc: 13.0000\n",
      " |~~ train@14060  Loss: 0.035574 Acc: 13.2000\n",
      " |~~ train@14065  Loss: 0.043896 Acc: 13.2000\n",
      " |~~ train@14070  Loss: 0.015392 Acc: 13.8000\n",
      " |~~ train@14075  Loss: 0.037186 Acc: 13.2000\n",
      " |~~ train@14080  Loss: 0.031044 Acc: 13.4000\n",
      " |~~ train@14085  Loss: 0.061752 Acc: 12.2000\n",
      " |~~ train@14090  Loss: 0.061795 Acc: 12.8000\n",
      " |~~ train@14095  Loss: 0.064663 Acc: 12.8000\n",
      " |~~ train@14100  Loss: 0.034811 Acc: 13.0000\n",
      " |~~ train@14105  Loss: 0.026214 Acc: 13.6000\n",
      " |~~ train@14110  Loss: 0.016895 Acc: 13.8000\n",
      " |~~ train@14115  Loss: 0.033419 Acc: 13.2000\n",
      " |~~ train@14120  Loss: 0.023363 Acc: 13.6000\n",
      " |~~ train@14125  Loss: 0.017952 Acc: 13.8000\n",
      " |~~ train@14130  Loss: 0.027830 Acc: 13.4000\n",
      " |~~ train@14135  Loss: 0.028893 Acc: 13.6000\n",
      " |~~ train@14140  Loss: 0.041845 Acc: 13.0000\n",
      " |~~ train@14145  Loss: 0.021460 Acc: 13.8000\n",
      " |~~ train@14150  Loss: 0.039035 Acc: 13.0000\n",
      " |~~ train@14155  Loss: 0.050173 Acc: 13.0000\n",
      " |~~ train@14160  Loss: 0.083921 Acc: 12.4000\n",
      " |~~ train@14165  Loss: 0.012310 Acc: 14.0000\n",
      " |~~ train@14170  Loss: 0.032641 Acc: 13.2000\n",
      " |~~ train@14175  Loss: 0.033364 Acc: 13.4000\n",
      " |~~ train@14180  Loss: 0.053520 Acc: 13.0000\n",
      " |~~ train@14185  Loss: 0.045772 Acc: 13.0000\n",
      " |~~ train@14190  Loss: 0.057045 Acc: 13.0000\n",
      " |~~ train@14195  Loss: 0.025410 Acc: 13.4000\n",
      " |~~ train@14200  Loss: 0.019237 Acc: 13.8000\n",
      " |~~ train@14205  Loss: 0.034390 Acc: 13.4000\n",
      " |~~ train@14210  Loss: 0.053809 Acc: 12.6000\n",
      " |~~ train@14215  Loss: 0.062989 Acc: 12.4000\n",
      " |~~ train@14220  Loss: 0.032298 Acc: 13.6000\n",
      " |~~ train@14225  Loss: 0.015988 Acc: 13.8000\n",
      " |~~ train@14230  Loss: 0.039889 Acc: 12.8000\n",
      " |~~ train@14235  Loss: 0.030996 Acc: 13.2000\n",
      " |~~ train@14240  Loss: 0.030708 Acc: 13.4000\n",
      " |~~ train@14245  Loss: 0.011614 Acc: 14.0000\n",
      " |~~ train@14250  Loss: 0.044582 Acc: 13.0000\n",
      " |~~ train@14255  Loss: 0.045815 Acc: 12.8000\n",
      " |~~ train@14260  Loss: 0.044384 Acc: 13.0000\n",
      " |~~ train@14265  Loss: 0.026615 Acc: 13.4000\n",
      " |~~ train@14270  Loss: 0.035753 Acc: 13.4000\n",
      " |~~ train@14275  Loss: 0.037767 Acc: 13.2000\n",
      " |~~ train@14280  Loss: 0.058082 Acc: 12.8000\n",
      " |~~ train@14285  Loss: 0.040486 Acc: 13.2000\n",
      " |~~ train@14290  Loss: 0.034100 Acc: 13.4000\n",
      " |~~ train@14295  Loss: 0.033839 Acc: 13.4000\n",
      " |~~ train@14300  Loss: 0.053412 Acc: 13.0000\n",
      " |~~ train@14305  Loss: 0.020365 Acc: 13.6000\n",
      " |~~ train@14310  Loss: 0.057191 Acc: 12.6000\n",
      " |~~ train@14315  Loss: 0.042601 Acc: 13.0000\n",
      " |~~ train@14320  Loss: 0.031896 Acc: 13.6000\n",
      " |~~ train@14325  Loss: 0.025493 Acc: 13.4000\n",
      " |~~ train@14330  Loss: 0.045831 Acc: 13.2000\n",
      " |~~ train@14335  Loss: 0.044849 Acc: 13.0000\n",
      " |~~ train@14340  Loss: 0.041969 Acc: 13.0000\n",
      " |~~ train@14345  Loss: 0.067899 Acc: 12.4000\n",
      " |~~ train@14350  Loss: 0.045287 Acc: 13.0000\n",
      " |~~ train@14355  Loss: 0.017888 Acc: 13.8000\n",
      " |~~ train@14360  Loss: 0.020756 Acc: 13.8000\n",
      " |~~ train@14365  Loss: 0.034853 Acc: 13.2000\n",
      " |~~ train@14370  Loss: 0.036716 Acc: 13.0000\n",
      " |~~ train@14375  Loss: 0.059751 Acc: 12.6000\n",
      " |~~ train@14380  Loss: 0.022150 Acc: 13.6000\n",
      " |~~ train@14385  Loss: 0.023832 Acc: 13.6000\n",
      " |~~ train@14390  Loss: 0.020506 Acc: 13.6000\n",
      " |~~ train@14395  Loss: 0.042182 Acc: 13.0000\n",
      " |~~ train@14400  Loss: 0.028776 Acc: 13.4000\n",
      " |~~ train@14405  Loss: 0.031318 Acc: 13.4000\n",
      " |~~ train@14410  Loss: 0.017698 Acc: 13.8000\n",
      " |~~ train@14415  Loss: 0.037238 Acc: 13.2000\n",
      " |~~ train@14420  Loss: 0.028879 Acc: 13.4000\n",
      " |~~ train@14425  Loss: 0.012044 Acc: 14.0000\n",
      " |~~ train@14430  Loss: 0.018255 Acc: 13.8000\n",
      " |~~ train@14435  Loss: 0.057473 Acc: 12.8000\n",
      " |~~ train@14440  Loss: 0.020076 Acc: 13.6000\n",
      " |~~ train@14445  Loss: 0.058196 Acc: 12.8000\n",
      " |~~ train@14450  Loss: 0.078142 Acc: 12.0000\n",
      " |~~ train@14455  Loss: 0.011217 Acc: 14.0000\n",
      " |~~ train@14460  Loss: 0.016979 Acc: 13.8000\n",
      " |~~ train@14465  Loss: 0.037960 Acc: 13.2000\n",
      " |~~ train@14470  Loss: 0.055542 Acc: 12.6000\n",
      " |~~ train@14475  Loss: 0.027818 Acc: 13.4000\n",
      " |~~ train@14480  Loss: 0.053242 Acc: 12.8000\n",
      " |~~ train@14485  Loss: 0.042367 Acc: 13.4000\n",
      " |~~ train@14490  Loss: 0.028546 Acc: 13.4000\n",
      " |~~ train@14495  Loss: 0.026042 Acc: 13.6000\n",
      " |~~ train@14500  Loss: 0.050169 Acc: 13.0000\n",
      " |~~ train@14505  Loss: 0.054240 Acc: 12.8000\n",
      " |~~ train@14510  Loss: 0.011190 Acc: 14.0000\n",
      " |~~ train@14515  Loss: 0.034260 Acc: 13.2000\n",
      " |~~ train@14520  Loss: 0.030791 Acc: 13.2000\n",
      " |~~ train@14525  Loss: 0.044044 Acc: 13.2000\n",
      " |~~ train@14530  Loss: 0.043057 Acc: 13.0000\n",
      " |~~ train@14535  Loss: 0.063082 Acc: 12.4000\n",
      " |~~ train@14540  Loss: 0.024541 Acc: 13.8000\n",
      " |~~ train@14545  Loss: 0.047911 Acc: 13.0000\n",
      " |~~ train@14550  Loss: 0.012236 Acc: 14.0000\n",
      " |~~ train@14555  Loss: 0.024403 Acc: 13.4000\n",
      " |~~ train@14560  Loss: 0.023318 Acc: 13.4000\n",
      " |~~ train@14565  Loss: 0.030243 Acc: 13.4000\n",
      " |~~ train@14570  Loss: 0.033112 Acc: 13.4000\n",
      " |~~ train@14575  Loss: 0.034151 Acc: 13.4000\n",
      " |~~ train@14580  Loss: 0.037890 Acc: 13.2000\n",
      " |~~ train@14585  Loss: 0.025889 Acc: 13.6000\n",
      " |~~ train@14590  Loss: 0.020000 Acc: 13.6000\n",
      " |~~ train@14595  Loss: 0.033694 Acc: 13.4000\n",
      " |~~ train@14600  Loss: 0.014321 Acc: 13.8000\n",
      " |~~ train@14605  Loss: 0.051066 Acc: 13.2000\n",
      " |~~ train@14610  Loss: 0.046614 Acc: 12.8000\n",
      " |~~ train@14615  Loss: 0.026601 Acc: 13.4000\n",
      " |~~ train@14620  Loss: 0.025879 Acc: 13.6000\n",
      " |~~ train@14625  Loss: 0.068224 Acc: 12.6000\n",
      " |~~ train@14630  Loss: 0.024179 Acc: 13.6000\n",
      " |~~ train@14635  Loss: 0.032917 Acc: 13.4000\n",
      " |~~ train@14640  Loss: 0.037306 Acc: 13.4000\n",
      " |~~ train@14645  Loss: 0.028353 Acc: 13.4000\n",
      " |~~ train@14650  Loss: 0.086755 Acc: 12.0000\n",
      " |~~ train@14655  Loss: 0.025287 Acc: 13.6000\n",
      " |~~ train@14660  Loss: 0.049508 Acc: 12.8000\n",
      " |~~ train@14665  Loss: 0.039708 Acc: 13.0000\n",
      " |~~ train@14670  Loss: 0.047819 Acc: 12.8000\n",
      " |~~ train@14675  Loss: 0.054094 Acc: 12.8000\n",
      " |~~ train@14680  Loss: 0.027917 Acc: 13.4000\n",
      " |~~ train@14685  Loss: 0.066144 Acc: 12.8000\n",
      " |~~ train@14690  Loss: 0.028178 Acc: 13.6000\n",
      " |~~ train@14695  Loss: 0.027955 Acc: 13.6000\n",
      " |~~ train@14700  Loss: 0.047450 Acc: 13.0000\n",
      " |~~ train@14705  Loss: 0.068813 Acc: 12.6000\n",
      " |~~ train@14710  Loss: 0.042906 Acc: 13.2000\n",
      " |~~ train@14715  Loss: 0.041195 Acc: 13.0000\n",
      " |~~ train@14720  Loss: 0.052638 Acc: 12.8000\n",
      " |~~ train@14725  Loss: 0.025908 Acc: 13.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@14730  Loss: 0.042972 Acc: 13.2000\n",
      " |~~ train@14735  Loss: 0.072798 Acc: 12.6000\n",
      " |~~ train@14740  Loss: 0.034288 Acc: 13.2000\n",
      " |~~ train@14745  Loss: 0.044606 Acc: 13.2000\n",
      " |~~ train@14750  Loss: 0.050516 Acc: 12.8000\n",
      " |~~ train@14755  Loss: 0.028878 Acc: 13.6000\n",
      " |~~ train@14760  Loss: 0.014008 Acc: 13.8000\n",
      " |~~ train@14765  Loss: 0.029590 Acc: 13.4000\n",
      " |~~ train@14770  Loss: 0.038801 Acc: 13.2000\n",
      " |~~ train@14775  Loss: 0.038379 Acc: 13.4000\n",
      " |~~ train@14780  Loss: 0.026950 Acc: 13.6000\n",
      " |~~ train@14785  Loss: 0.083619 Acc: 12.0000\n",
      " |~~ train@14790  Loss: 0.011753 Acc: 14.0000\n",
      " |~~ train@14795  Loss: 0.042447 Acc: 13.2000\n",
      " |~~ train@14800  Loss: 0.059975 Acc: 12.6000\n",
      " |~~ train@14805  Loss: 0.012238 Acc: 14.0000\n",
      " |~~ train@14810  Loss: 0.037706 Acc: 13.2000\n",
      " |~~ train@14815  Loss: 0.040039 Acc: 13.0000\n",
      " |~~ train@14820  Loss: 0.022478 Acc: 13.6000\n",
      " |~~ train@14825  Loss: 0.034982 Acc: 13.2000\n",
      " |~~ train@14830  Loss: 0.072955 Acc: 12.6000\n",
      " |~~ train@14835  Loss: 0.020759 Acc: 13.6000\n",
      " |~~ train@14840  Loss: 0.050919 Acc: 12.8000\n",
      " |~~ train@14845  Loss: 0.020975 Acc: 13.6000\n",
      " |~~ train@14850  Loss: 0.031161 Acc: 13.6000\n",
      " |~~ train@14855  Loss: 0.024760 Acc: 13.6000\n",
      " |~~ train@14860  Loss: 0.039631 Acc: 13.2000\n",
      " |~~ train@14865  Loss: 0.024648 Acc: 13.6000\n",
      " |~~ train@14870  Loss: 0.025179 Acc: 13.6000\n",
      " |~~ train@14875  Loss: 0.050542 Acc: 12.8000\n",
      " |~~ train@14880  Loss: 0.015525 Acc: 13.8000\n",
      " |~~ train@14885  Loss: 0.017021 Acc: 13.8000\n",
      " |~~ train@14890  Loss: 0.038029 Acc: 13.0000\n",
      " |~~ train@14895  Loss: 0.011865 Acc: 14.0000\n",
      " |~~ train@14900  Loss: 0.023664 Acc: 13.6000\n",
      " |~~ train@14905  Loss: 0.045187 Acc: 13.0000\n",
      " |~~ train@14910  Loss: 0.042012 Acc: 13.4000\n",
      " |~~ train@14915  Loss: 0.013470 Acc: 13.8000\n",
      " |~~ train@14920  Loss: 0.021294 Acc: 13.6000\n",
      " |~~ train@14925  Loss: 0.057773 Acc: 13.0000\n",
      " |~~ train@14930  Loss: 0.044901 Acc: 13.0000\n",
      " |~~ train@14935  Loss: 0.035717 Acc: 13.2000\n",
      " |~~ train@14940  Loss: 0.014506 Acc: 13.8000\n",
      " |~~ train@14945  Loss: 0.032368 Acc: 13.2000\n",
      " |~~ train@14950  Loss: 0.055820 Acc: 12.8000\n",
      " |~~ train@14955  Loss: 0.039500 Acc: 13.2000\n",
      " |~~ train@14960  Loss: 0.022902 Acc: 13.6000\n",
      " |~~ train@14965  Loss: 0.042212 Acc: 13.2000\n",
      " |~~ train@14970  Loss: 0.034294 Acc: 13.2000\n",
      " |~~ train@14975  Loss: 0.033649 Acc: 13.4000\n",
      " |~~ train@14980  Loss: 0.025658 Acc: 13.8000\n",
      " |~~ train@14985  Loss: 0.028764 Acc: 13.4000\n",
      " |~~ train@14990  Loss: 0.026778 Acc: 13.6000\n",
      " |~~ train@14995  Loss: 0.024692 Acc: 13.6000\n",
      " |~~ train@15000  Loss: 0.070063 Acc: 12.4000\n",
      " |~~ train@15005  Loss: 0.015229 Acc: 13.8000\n",
      " |~~ train@15010  Loss: 0.018434 Acc: 13.8000\n",
      " |~~ train@15015  Loss: 0.019203 Acc: 13.8000\n",
      " |~~ train@15020  Loss: 0.052796 Acc: 12.8000\n",
      " |~~ train@15025  Loss: 0.046401 Acc: 13.2000\n",
      " |~~ train@15030  Loss: 0.010773 Acc: 14.0000\n",
      " |~~ train@15035  Loss: 0.038205 Acc: 13.0000\n",
      " |~~ train@15040  Loss: 0.022999 Acc: 13.6000\n",
      " |~~ train@15045  Loss: 0.041358 Acc: 13.4000\n",
      " |~~ train@15050  Loss: 0.063354 Acc: 12.6000\n",
      " |~~ train@15055  Loss: 0.030957 Acc: 13.2000\n",
      " |~~ train@15060  Loss: 0.025910 Acc: 13.6000\n",
      " |~~ train@15065  Loss: 0.033294 Acc: 13.4000\n",
      " |~~ train@15070  Loss: 0.037566 Acc: 13.2000\n",
      " |~~ train@15075  Loss: 0.034778 Acc: 13.2000\n",
      " |~~ train@15080  Loss: 0.047869 Acc: 12.8000\n",
      " |~~ train@15085  Loss: 0.029445 Acc: 13.4000\n",
      " |~~ train@15090  Loss: 0.038949 Acc: 13.2000\n",
      " |~~ train@15095  Loss: 0.073012 Acc: 12.4000\n",
      " |~~ train@15100  Loss: 0.040119 Acc: 13.4000\n",
      " |~~ train@15105  Loss: 0.040373 Acc: 13.0000\n",
      " |~~ train@15110  Loss: 0.018550 Acc: 13.8000\n",
      " |~~ train@15115  Loss: 0.048480 Acc: 13.0000\n",
      " |~~ train@15120  Loss: 0.020650 Acc: 13.8000\n",
      " |~~ train@15125  Loss: 0.056787 Acc: 12.6000\n",
      " |~~ train@15130  Loss: 0.015363 Acc: 13.8000\n",
      " |~~ train@15135  Loss: 0.029590 Acc: 13.4000\n",
      " |~~ train@15140  Loss: 0.061800 Acc: 12.6000\n",
      " |~~ train@15145  Loss: 0.029320 Acc: 13.6000\n",
      " |~~ train@15150  Loss: 0.022359 Acc: 13.6000\n",
      " |~~ train@15155  Loss: 0.042213 Acc: 13.2000\n",
      " |~~ train@15160  Loss: 0.045954 Acc: 13.0000\n",
      " |~~ train@15165  Loss: 0.020110 Acc: 13.8000\n",
      " |~~ train@15170  Loss: 0.044112 Acc: 13.0000\n",
      " |~~ train@15175  Loss: 0.056249 Acc: 12.8000\n",
      " |~~ train@15180  Loss: 0.057551 Acc: 12.6000\n",
      " |~~ train@15185  Loss: 0.020577 Acc: 13.6000\n",
      " |~~ train@15190  Loss: 0.032093 Acc: 13.2000\n",
      " |~~ train@15195  Loss: 0.015409 Acc: 13.8000\n",
      " |~~ train@15200  Loss: 0.036355 Acc: 13.4000\n",
      " |~~ train@15205  Loss: 0.072785 Acc: 12.2000\n",
      " |~~ train@15210  Loss: 0.029319 Acc: 13.4000\n",
      " |~~ train@15215  Loss: 0.010918 Acc: 14.0000\n",
      " |~~ train@15220  Loss: 0.018931 Acc: 13.8000\n",
      " |~~ train@15225  Loss: 0.014652 Acc: 13.8000\n",
      " |~~ train@15230  Loss: 0.046568 Acc: 13.2000\n",
      " |~~ train@15235  Loss: 0.042603 Acc: 13.0000\n",
      " |~~ train@15240  Loss: 0.040699 Acc: 13.2000\n",
      " |~~ train@15245  Loss: 0.011234 Acc: 14.0000\n",
      " |~~ train@15250  Loss: 0.040658 Acc: 13.0000\n",
      " |~~ train@15255  Loss: 0.033812 Acc: 13.4000\n",
      " |~~ train@15260  Loss: 0.027043 Acc: 13.6000\n",
      " |~~ train@15265  Loss: 0.025115 Acc: 13.6000\n",
      " |~~ train@15270  Loss: 0.076364 Acc: 12.2000\n",
      " |~~ train@15275  Loss: 0.020010 Acc: 13.6000\n",
      " |~~ train@15280  Loss: 0.025633 Acc: 13.6000\n",
      " |~~ train@15285  Loss: 0.050932 Acc: 12.6000\n",
      " |~~ train@15290  Loss: 0.056879 Acc: 12.8000\n",
      " |~~ train@15295  Loss: 0.037757 Acc: 13.4000\n",
      " |~~ train@15300  Loss: 0.029495 Acc: 13.4000\n",
      " |~~ train@15305  Loss: 0.016647 Acc: 13.8000\n",
      " |~~ train@15310  Loss: 0.072793 Acc: 12.4000\n",
      " |~~ train@15315  Loss: 0.038154 Acc: 13.6000\n",
      " |~~ train@15320  Loss: 0.019771 Acc: 13.6000\n",
      " |~~ train@15325  Loss: 0.019509 Acc: 13.6000\n",
      " |~~ train@15330  Loss: 0.021624 Acc: 13.6000\n",
      " |~~ train@15335  Loss: 0.016824 Acc: 13.8000\n",
      " |~~ train@15340  Loss: 0.030454 Acc: 13.2000\n",
      " |~~ train@15345  Loss: 0.047491 Acc: 13.0000\n",
      " |~~ train@15350  Loss: 0.026918 Acc: 13.4000\n",
      " |~~ train@15355  Loss: 0.022935 Acc: 13.4000\n",
      " |~~ train@15360  Loss: 0.025471 Acc: 13.4000\n",
      " |~~ train@15365  Loss: 0.032770 Acc: 13.4000\n",
      " |~~ train@15370  Loss: 0.033533 Acc: 13.4000\n",
      " |~~ train@15375  Loss: 0.034986 Acc: 13.6000\n",
      " |~~ train@15380  Loss: 0.047738 Acc: 13.0000\n",
      " |~~ train@15385  Loss: 0.041139 Acc: 13.2000\n",
      " |~~ train@15390  Loss: 0.028367 Acc: 13.4000\n",
      " |~~ train@15395  Loss: 0.033313 Acc: 13.6000\n",
      " |~~ train@15400  Loss: 0.021198 Acc: 13.6000\n",
      " |~~ train@15405  Loss: 0.038847 Acc: 13.4000\n",
      " |~~ train@15410  Loss: 0.019192 Acc: 13.8000\n",
      " |~~ train@15415  Loss: 0.029553 Acc: 13.6000\n",
      " |~~ train@15420  Loss: 0.018114 Acc: 13.8000\n",
      " |~~ train@15425  Loss: 0.018160 Acc: 13.8000\n",
      " |~~ train@15430  Loss: 0.053618 Acc: 12.6000\n",
      " |~~ train@15435  Loss: 0.052406 Acc: 12.8000\n",
      " |~~ train@15440  Loss: 0.016231 Acc: 13.8000\n",
      " |~~ train@15445  Loss: 0.039517 Acc: 13.2000\n",
      " |~~ train@15450  Loss: 0.032006 Acc: 13.4000\n",
      " |~~ train@15455  Loss: 0.025851 Acc: 13.8000\n",
      " |~~ train@15460  Loss: 0.015286 Acc: 13.8000\n",
      " |~~ train@15465  Loss: 0.077690 Acc: 12.2000\n",
      " |~~ train@15470  Loss: 0.041494 Acc: 13.0000\n",
      " |~~ train@15475  Loss: 0.059036 Acc: 12.6000\n",
      " |~~ train@15480  Loss: 0.050862 Acc: 12.8000\n",
      " |~~ train@15485  Loss: 0.047885 Acc: 13.2000\n",
      " |~~ train@15490  Loss: 0.015086 Acc: 13.8000\n",
      " |~~ train@15495  Loss: 0.051658 Acc: 12.8000\n",
      " |~~ train@15500  Loss: 0.015174 Acc: 13.8000\n",
      " |~~ train@15505  Loss: 0.029972 Acc: 13.4000\n",
      " |~~ train@15510  Loss: 0.029602 Acc: 13.4000\n",
      " |~~ train@15515  Loss: 0.049266 Acc: 13.0000\n",
      " |~~ train@15520  Loss: 0.031438 Acc: 13.4000\n",
      " |~~ train@15525  Loss: 0.026055 Acc: 13.4000\n",
      " |~~ train@15530  Loss: 0.035215 Acc: 13.2000\n",
      " |~~ train@15535  Loss: 0.024691 Acc: 13.6000\n",
      " |~~ train@15540  Loss: 0.059235 Acc: 13.0000\n",
      " |~~ train@15545  Loss: 0.027768 Acc: 13.4000\n",
      " |~~ train@15550  Loss: 0.061337 Acc: 12.8000\n",
      " |~~ train@15555  Loss: 0.013833 Acc: 13.8000\n",
      " |~~ train@15560  Loss: 0.024989 Acc: 13.6000\n",
      " |~~ train@15565  Loss: 0.055368 Acc: 13.0000\n",
      " |~~ train@15570  Loss: 0.049556 Acc: 13.0000\n",
      " |~~ train@15575  Loss: 0.077723 Acc: 12.4000\n",
      " |~~ train@15580  Loss: 0.060611 Acc: 12.8000\n",
      " |~~ train@15585  Loss: 0.045870 Acc: 13.0000\n",
      " |~~ train@15590  Loss: 0.024190 Acc: 13.4000\n",
      " |~~ train@15595  Loss: 0.020980 Acc: 13.6000\n",
      " |~~ train@15600  Loss: 0.019548 Acc: 13.8000\n",
      " |~~ train@15605  Loss: 0.044608 Acc: 12.8000\n",
      " |~~ train@15610  Loss: 0.018931 Acc: 13.8000\n",
      " |~~ train@15615  Loss: 0.020612 Acc: 13.6000\n",
      " |~~ train@15620  Loss: 0.041014 Acc: 13.0000\n",
      " |~~ train@15625  Loss: 0.022587 Acc: 13.4000\n",
      " |~~ train@15630  Loss: 0.015615 Acc: 13.8000\n",
      " |~~ train@15635  Loss: 0.039290 Acc: 13.2000\n",
      " |~~ train@15640  Loss: 0.026900 Acc: 13.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@15645  Loss: 0.010602 Acc: 14.0000\n",
      " |~~ train@15650  Loss: 0.035043 Acc: 13.2000\n",
      " |~~ train@15655  Loss: 0.027143 Acc: 13.4000\n",
      " |~~ train@15660  Loss: 0.064671 Acc: 12.8000\n",
      " |~~ train@15665  Loss: 0.020068 Acc: 13.8000\n",
      " |~~ train@15670  Loss: 0.010141 Acc: 14.0000\n",
      " |~~ train@15675  Loss: 0.014809 Acc: 13.8000\n",
      " |~~ train@15680  Loss: 0.065829 Acc: 12.4000\n",
      " |~~ train@15685  Loss: 0.050430 Acc: 13.0000\n",
      " |~~ train@15690  Loss: 0.023850 Acc: 13.6000\n",
      " |~~ train@15695  Loss: 0.050824 Acc: 12.8000\n",
      " |~~ train@15700  Loss: 0.032460 Acc: 13.4000\n",
      " |~~ train@15705  Loss: 0.062413 Acc: 13.0000\n",
      " |~~ train@15710  Loss: 0.062675 Acc: 12.6000\n",
      " |~~ train@15715  Loss: 0.034955 Acc: 13.4000\n",
      " |~~ train@15720  Loss: 0.028292 Acc: 13.4000\n",
      " |~~ train@15725  Loss: 0.014078 Acc: 13.8000\n",
      " |~~ train@15730  Loss: 0.039513 Acc: 13.4000\n",
      " |~~ train@15735  Loss: 0.056370 Acc: 13.0000\n",
      " |~~ train@15740  Loss: 0.020082 Acc: 13.8000\n",
      " |~~ train@15745  Loss: 0.027969 Acc: 13.6000\n",
      " |~~ train@15750  Loss: 0.045110 Acc: 12.8000\n",
      " |~~ train@15755  Loss: 0.035515 Acc: 13.4000\n",
      " |~~ train@15760  Loss: 0.025648 Acc: 13.4000\n",
      " |~~ train@15765  Loss: 0.039968 Acc: 13.4000\n",
      " |~~ train@15770  Loss: 0.031979 Acc: 13.4000\n",
      " |~~ train@15775  Loss: 0.037202 Acc: 13.4000\n",
      " |~~ train@15780  Loss: 0.037823 Acc: 13.4000\n",
      " |~~ train@15785  Loss: 0.045572 Acc: 13.2000\n",
      " |~~ train@15790  Loss: 0.023315 Acc: 13.8000\n",
      " |~~ train@15795  Loss: 0.055589 Acc: 12.8000\n",
      " |~~ train@15800  Loss: 0.035527 Acc: 13.4000\n",
      " |~~ train@15805  Loss: 0.044935 Acc: 13.0000\n",
      " |~~ train@15810  Loss: 0.029211 Acc: 13.2000\n",
      " |~~ train@15815  Loss: 0.038274 Acc: 13.4000\n",
      " |~~ train@15820  Loss: 0.043824 Acc: 13.4000\n",
      " |~~ train@15825  Loss: 0.050055 Acc: 12.8000\n",
      " |~~ train@15830  Loss: 0.029307 Acc: 13.4000\n",
      " |~~ train@15835  Loss: 0.035739 Acc: 13.4000\n",
      " |~~ train@15840  Loss: 0.079146 Acc: 12.2000\n",
      " |~~ train@15845  Loss: 0.063733 Acc: 12.8000\n",
      " |~~ train@15850  Loss: 0.029706 Acc: 13.4000\n",
      " |~~ train@15855  Loss: 0.021457 Acc: 13.8000\n",
      " |~~ train@15860  Loss: 0.049379 Acc: 13.2000\n",
      " |~~ train@15865  Loss: 0.028158 Acc: 13.4000\n",
      " |~~ train@15870  Loss: 0.042375 Acc: 13.2000\n",
      " |~~ train@15875  Loss: 0.026915 Acc: 13.4000\n",
      " |~~ train@15880  Loss: 0.027905 Acc: 13.6000\n",
      " |~~ train@15885  Loss: 0.014380 Acc: 13.8000\n",
      " |~~ train@15890  Loss: 0.063799 Acc: 12.8000\n",
      " |~~ train@15895  Loss: 0.022140 Acc: 13.6000\n",
      " |~~ train@15900  Loss: 0.020233 Acc: 13.6000\n",
      " |~~ train@15905  Loss: 0.041507 Acc: 13.0000\n",
      " |~~ train@15910  Loss: 0.037155 Acc: 13.0000\n",
      " |~~ train@15915  Loss: 0.052563 Acc: 12.8000\n",
      " |~~ train@15920  Loss: 0.030655 Acc: 13.4000\n",
      " |~~ train@15925  Loss: 0.041629 Acc: 13.4000\n",
      " |~~ train@15930  Loss: 0.039944 Acc: 13.2000\n",
      " |~~ train@15935  Loss: 0.023988 Acc: 13.6000\n",
      " |~~ train@15940  Loss: 0.043340 Acc: 13.0000\n",
      " |~~ train@15945  Loss: 0.026316 Acc: 13.6000\n",
      " |~~ train@15950  Loss: 0.040775 Acc: 13.2000\n",
      " |~~ train@15955  Loss: 0.043353 Acc: 12.8000\n",
      " |~~ train@15960  Loss: 0.026756 Acc: 13.6000\n",
      " |~~ train@15965  Loss: 0.022744 Acc: 13.6000\n",
      " |~~ train@15970  Loss: 0.016671 Acc: 13.8000\n",
      " |~~ train@15975  Loss: 0.025501 Acc: 13.4000\n",
      " |~~ train@15980  Loss: 0.044913 Acc: 13.0000\n",
      " |~~ train@15985  Loss: 0.019555 Acc: 13.6000\n",
      " |~~ train@15990  Loss: 0.021445 Acc: 13.6000\n",
      " |~~ train@15995  Loss: 0.064992 Acc: 12.6000\n",
      " |~~ train@16000  Loss: 0.033840 Acc: 13.0000\n",
      " |~~ train@16005  Loss: 0.051777 Acc: 12.8000\n",
      " |~~ train@16010  Loss: 0.048333 Acc: 13.0000\n",
      " |~~ train@16015  Loss: 0.040949 Acc: 13.2000\n",
      " |~~ train@16020  Loss: 0.018992 Acc: 13.8000\n",
      " |~~ train@16025  Loss: 0.047792 Acc: 13.0000\n",
      " |~~ train@16030  Loss: 0.032891 Acc: 13.4000\n",
      " |~~ train@16035  Loss: 0.042566 Acc: 13.0000\n",
      " |~~ train@16040  Loss: 0.018324 Acc: 13.8000\n",
      " |~~ train@16045  Loss: 0.021439 Acc: 13.6000\n",
      " |~~ train@16050  Loss: 0.049426 Acc: 12.6000\n",
      " |~~ train@16055  Loss: 0.039247 Acc: 13.2000\n",
      " |~~ train@16060  Loss: 0.027478 Acc: 13.4000\n",
      " |~~ train@16065  Loss: 0.031466 Acc: 13.2000\n",
      " |~~ train@16070  Loss: 0.026396 Acc: 13.6000\n",
      " |~~ train@16075  Loss: 0.021815 Acc: 13.6000\n",
      " |~~ train@16080  Loss: 0.033448 Acc: 13.6000\n",
      " |~~ train@16085  Loss: 0.063198 Acc: 12.2000\n",
      " |~~ train@16090  Loss: 0.051873 Acc: 12.8000\n",
      " |~~ train@16095  Loss: 0.044180 Acc: 13.2000\n",
      " |~~ train@16100  Loss: 0.031508 Acc: 13.4000\n",
      " |~~ train@16105  Loss: 0.028593 Acc: 13.4000\n",
      " |~~ train@16110  Loss: 0.030543 Acc: 13.6000\n",
      " |~~ train@16115  Loss: 0.022039 Acc: 13.6000\n",
      " |~~ train@16120  Loss: 0.015606 Acc: 13.8000\n",
      " |~~ train@16125  Loss: 0.032273 Acc: 13.4000\n",
      " |~~ train@16130  Loss: 0.022530 Acc: 13.8000\n",
      " |~~ train@16135  Loss: 0.059699 Acc: 12.4000\n",
      " |~~ train@16140  Loss: 0.014740 Acc: 13.8000\n",
      " |~~ train@16145  Loss: 0.051583 Acc: 13.0000\n",
      " |~~ train@16150  Loss: 0.039800 Acc: 13.2000\n",
      " |~~ train@16155  Loss: 0.019267 Acc: 13.8000\n",
      " |~~ train@16160  Loss: 0.052832 Acc: 12.8000\n",
      " |~~ train@16165  Loss: 0.045876 Acc: 13.2000\n",
      " |~~ train@16170  Loss: 0.049911 Acc: 13.0000\n",
      " |~~ train@16175  Loss: 0.011082 Acc: 14.0000\n",
      " |~~ train@16180  Loss: 0.037301 Acc: 13.2000\n",
      " |~~ train@16185  Loss: 0.067471 Acc: 12.2000\n",
      " |~~ train@16190  Loss: 0.053143 Acc: 12.6000\n",
      " |~~ train@16195  Loss: 0.056535 Acc: 12.6000\n",
      " |~~ train@16200  Loss: 0.042624 Acc: 13.2000\n",
      " |~~ train@16205  Loss: 0.040456 Acc: 13.0000\n",
      " |~~ train@16210  Loss: 0.042929 Acc: 13.0000\n",
      " |~~ train@16215  Loss: 0.034183 Acc: 13.2000\n",
      " |~~ train@16220  Loss: 0.011197 Acc: 14.0000\n",
      " |~~ train@16225  Loss: 0.011712 Acc: 14.0000\n",
      " |~~ train@16230  Loss: 0.025350 Acc: 13.6000\n",
      " |~~ train@16235  Loss: 0.065179 Acc: 12.6000\n",
      " |~~ train@16240  Loss: 0.011755 Acc: 14.0000\n",
      " |~~ train@16245  Loss: 0.041035 Acc: 13.0000\n",
      " |~~ train@16250  Loss: 0.019060 Acc: 13.8000\n",
      " |~~ train@16255  Loss: 0.033130 Acc: 13.2000\n",
      " |~~ train@16260  Loss: 0.078302 Acc: 12.0000\n",
      " |~~ train@16265  Loss: 0.048243 Acc: 13.0000\n",
      " |~~ train@16270  Loss: 0.022199 Acc: 13.6000\n",
      " |~~ train@16275  Loss: 0.029899 Acc: 13.4000\n",
      " |~~ train@16280  Loss: 0.040141 Acc: 13.2000\n",
      " |~~ train@16285  Loss: 0.045063 Acc: 13.2000\n",
      " |~~ train@16290  Loss: 0.035047 Acc: 13.4000\n",
      " |~~ train@16295  Loss: 0.047963 Acc: 12.8000\n",
      " |~~ train@16300  Loss: 0.031488 Acc: 13.4000\n",
      " |~~ train@16305  Loss: 0.027963 Acc: 13.4000\n",
      " |~~ train@16310  Loss: 0.025038 Acc: 13.6000\n",
      " |~~ train@16315  Loss: 0.034071 Acc: 13.2000\n",
      " |~~ train@16320  Loss: 0.030053 Acc: 13.4000\n",
      " |~~ train@16325  Loss: 0.049283 Acc: 12.8000\n",
      " |~~ train@16330  Loss: 0.038909 Acc: 13.2000\n",
      " |~~ train@16335  Loss: 0.018815 Acc: 13.6000\n",
      " |~~ train@16340  Loss: 0.052382 Acc: 13.0000\n",
      " |~~ train@16345  Loss: 0.026654 Acc: 13.4000\n",
      " |~~ train@16350  Loss: 0.015427 Acc: 13.8000\n",
      " |~~ train@16355  Loss: 0.038068 Acc: 13.2000\n",
      " |~~ train@16360  Loss: 0.058367 Acc: 12.6000\n",
      " |~~ train@16365  Loss: 0.024843 Acc: 13.6000\n",
      " |~~ train@16370  Loss: 0.032172 Acc: 13.4000\n",
      " |~~ train@16375  Loss: 0.055850 Acc: 12.8000\n",
      " |~~ train@16380  Loss: 0.046660 Acc: 13.0000\n",
      " |~~ train@16385  Loss: 0.021221 Acc: 13.8000\n",
      " |~~ train@16390  Loss: 0.017478 Acc: 13.8000\n",
      " |~~ train@16395  Loss: 0.015257 Acc: 13.8000\n",
      " |~~ train@16400  Loss: 0.043348 Acc: 12.8000\n",
      " |~~ train@16405  Loss: 0.028380 Acc: 13.4000\n",
      " |~~ train@16410  Loss: 0.044795 Acc: 12.8000\n",
      " |~~ train@16415  Loss: 0.036996 Acc: 13.4000\n",
      " |~~ train@16420  Loss: 0.030799 Acc: 13.2000\n",
      " |~~ train@16425  Loss: 0.027575 Acc: 13.6000\n",
      " |~~ train@16430  Loss: 0.071519 Acc: 12.6000\n",
      " |~~ train@16435  Loss: 0.021759 Acc: 13.8000\n",
      " |~~ train@16440  Loss: 0.044582 Acc: 12.8000\n",
      " |~~ train@16445  Loss: 0.017352 Acc: 13.8000\n",
      " |~~ train@16450  Loss: 0.053593 Acc: 12.8000\n",
      " |~~ train@16455  Loss: 0.030395 Acc: 13.4000\n",
      " |~~ train@16460  Loss: 0.040639 Acc: 13.0000\n",
      " |~~ train@16465  Loss: 0.038429 Acc: 13.2000\n",
      " |~~ train@16470  Loss: 0.027402 Acc: 13.4000\n",
      " |~~ train@16475  Loss: 0.042689 Acc: 13.0000\n",
      " |~~ train@16480  Loss: 0.040937 Acc: 13.2000\n",
      " |~~ train@16485  Loss: 0.036181 Acc: 13.4000\n",
      " |~~ train@16490  Loss: 0.029673 Acc: 13.4000\n",
      " |~~ train@16495  Loss: 0.030542 Acc: 13.6000\n",
      " |~~ train@16500  Loss: 0.061553 Acc: 12.6000\n",
      " |~~ train@16505  Loss: 0.062095 Acc: 12.8000\n",
      " |~~ train@16510  Loss: 0.051970 Acc: 12.6000\n",
      " |~~ train@16515  Loss: 0.033223 Acc: 13.4000\n",
      " |~~ train@16520  Loss: 0.034366 Acc: 13.4000\n",
      " |~~ train@16525  Loss: 0.031308 Acc: 13.6000\n",
      " |~~ train@16530  Loss: 0.045991 Acc: 13.0000\n",
      " |~~ train@16535  Loss: 0.011090 Acc: 14.0000\n",
      " |~~ train@16540  Loss: 0.055985 Acc: 12.6000\n",
      " |~~ train@16545  Loss: 0.086606 Acc: 12.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@16550  Loss: 0.022335 Acc: 13.6000\n",
      " |~~ train@16555  Loss: 0.042243 Acc: 13.4000\n",
      " |~~ train@16560  Loss: 0.030402 Acc: 13.4000\n",
      " |~~ train@16565  Loss: 0.057499 Acc: 13.0000\n",
      " |~~ train@16570  Loss: 0.022795 Acc: 13.4000\n",
      " |~~ train@16575  Loss: 0.030007 Acc: 13.4000\n",
      " |~~ train@16580  Loss: 0.023650 Acc: 13.6000\n",
      " |~~ train@16585  Loss: 0.021863 Acc: 13.6000\n",
      " |~~ train@16590  Loss: 0.010751 Acc: 14.0000\n",
      " |~~ train@16595  Loss: 0.078184 Acc: 12.4000\n",
      " |~~ train@16600  Loss: 0.034389 Acc: 13.4000\n",
      " |~~ train@16605  Loss: 0.010820 Acc: 14.0000\n",
      " |~~ train@16610  Loss: 0.040681 Acc: 13.2000\n",
      " |~~ train@16615  Loss: 0.028638 Acc: 13.2000\n",
      " |~~ train@16620  Loss: 0.027944 Acc: 13.6000\n",
      " |~~ train@16625  Loss: 0.050343 Acc: 12.6000\n",
      " |~~ train@16630  Loss: 0.033780 Acc: 13.4000\n",
      " |~~ train@16635  Loss: 0.042908 Acc: 13.0000\n",
      " |~~ train@16640  Loss: 0.025946 Acc: 13.6000\n",
      " |~~ train@16645  Loss: 0.075586 Acc: 12.0000\n",
      " |~~ train@16650  Loss: 0.035397 Acc: 13.4000\n",
      " |~~ train@16655  Loss: 0.043994 Acc: 13.0000\n",
      " |~~ train@16660  Loss: 0.045628 Acc: 13.0000\n",
      " |~~ train@16665  Loss: 0.037431 Acc: 13.0000\n",
      " |~~ train@16670  Loss: 0.035316 Acc: 13.4000\n",
      " |~~ train@16675  Loss: 0.042230 Acc: 13.2000\n",
      " |~~ train@16680  Loss: 0.039013 Acc: 13.2000\n",
      " |~~ train@16685  Loss: 0.018911 Acc: 13.6000\n",
      " |~~ train@16690  Loss: 0.031214 Acc: 13.2000\n",
      " |~~ train@16695  Loss: 0.053678 Acc: 12.8000\n",
      " |~~ train@16700  Loss: 0.034424 Acc: 13.2000\n",
      " |~~ train@16705  Loss: 0.066472 Acc: 12.6000\n",
      " |~~ train@16710  Loss: 0.047367 Acc: 13.2000\n",
      " |~~ train@16715  Loss: 0.036939 Acc: 13.2000\n",
      " |~~ train@16720  Loss: 0.035072 Acc: 13.2000\n",
      " |~~ train@16725  Loss: 0.035169 Acc: 13.4000\n",
      " |~~ train@16730  Loss: 0.038532 Acc: 13.0000\n",
      " |~~ train@16735  Loss: 0.034581 Acc: 13.4000\n",
      " |~~ train@16740  Loss: 0.036660 Acc: 13.2000\n",
      " |~~ train@16745  Loss: 0.037460 Acc: 13.2000\n",
      " |~~ train@16750  Loss: 0.052206 Acc: 12.6000\n",
      " |~~ train@16755  Loss: 0.028851 Acc: 13.6000\n",
      " |~~ train@16760  Loss: 0.051903 Acc: 12.6000\n",
      " |~~ train@16765  Loss: 0.033490 Acc: 13.4000\n",
      " |~~ train@16770  Loss: 0.027479 Acc: 13.6000\n",
      " |~~ train@16775  Loss: 0.047377 Acc: 12.8000\n",
      " |~~ train@16780  Loss: 0.047526 Acc: 12.6000\n",
      " |~~ train@16785  Loss: 0.019166 Acc: 13.6000\n",
      " |~~ train@16790  Loss: 0.036276 Acc: 13.4000\n",
      " |~~ train@16795  Loss: 0.030586 Acc: 13.4000\n",
      " |~~ train@16800  Loss: 0.051564 Acc: 13.0000\n",
      " |~~ train@16805  Loss: 0.083759 Acc: 11.6000\n",
      " |~~ train@16810  Loss: 0.027160 Acc: 13.6000\n",
      " |~~ train@16815  Loss: 0.026118 Acc: 13.6000\n",
      " |~~ train@16820  Loss: 0.027371 Acc: 13.4000\n",
      " |~~ train@16825  Loss: 0.041266 Acc: 13.0000\n",
      " |~~ train@16830  Loss: 0.023456 Acc: 13.6000\n",
      " |~~ train@16835  Loss: 0.067589 Acc: 12.4000\n",
      " |~~ train@16840  Loss: 0.059141 Acc: 12.6000\n",
      " |~~ train@16845  Loss: 0.028880 Acc: 13.6000\n",
      " |~~ train@16850  Loss: 0.037150 Acc: 13.4000\n",
      " |~~ train@16855  Loss: 0.033877 Acc: 13.2000\n",
      " |~~ train@16860  Loss: 0.055852 Acc: 12.6000\n",
      " |~~ train@16865  Loss: 0.044731 Acc: 13.2000\n",
      " |~~ train@16870  Loss: 0.038573 Acc: 13.4000\n",
      " |~~ train@16875  Loss: 0.031322 Acc: 13.4000\n",
      " |~~ train@16880  Loss: 0.026693 Acc: 13.6000\n",
      " |~~ train@16885  Loss: 0.034455 Acc: 13.6000\n",
      " |~~ train@16890  Loss: 0.034167 Acc: 13.2000\n",
      " |~~ train@16895  Loss: 0.048554 Acc: 12.8000\n",
      " |~~ train@16900  Loss: 0.031998 Acc: 13.6000\n",
      " |~~ train@16905  Loss: 0.023442 Acc: 13.6000\n",
      " |~~ train@16910  Loss: 0.036827 Acc: 13.2000\n",
      " |~~ train@16915  Loss: 0.029409 Acc: 13.4000\n",
      " |~~ train@16920  Loss: 0.065333 Acc: 12.2000\n",
      " |~~ train@16925  Loss: 0.040748 Acc: 13.0000\n",
      " |~~ train@16930  Loss: 0.029407 Acc: 13.2000\n",
      " |~~ train@16935  Loss: 0.039941 Acc: 13.2000\n",
      " |~~ train@16940  Loss: 0.033983 Acc: 13.2000\n",
      " |~~ train@16945  Loss: 0.032675 Acc: 13.4000\n",
      " |~~ train@16950  Loss: 0.029655 Acc: 13.4000\n",
      " |~~ train@16955  Loss: 0.051080 Acc: 13.4000\n",
      " |~~ train@16960  Loss: 0.041215 Acc: 13.0000\n",
      " |~~ train@16965  Loss: 0.021934 Acc: 13.6000\n",
      " |~~ train@16970  Loss: 0.050577 Acc: 13.0000\n",
      " |~~ train@16975  Loss: 0.032325 Acc: 13.6000\n",
      " |~~ train@16980  Loss: 0.020559 Acc: 13.8000\n",
      " |~~ train@16985  Loss: 0.013930 Acc: 14.0000\n",
      " |~~ train@16990  Loss: 0.025341 Acc: 13.8000\n",
      " |~~ train@16995  Loss: 0.016955 Acc: 13.8000\n",
      " |~~ train@17000  Loss: 0.038876 Acc: 13.0000\n",
      " |~~ train@17005  Loss: 0.056299 Acc: 13.2000\n",
      " |~~ train@17010  Loss: 0.025674 Acc: 13.6000\n",
      " |~~ train@17015  Loss: 0.032595 Acc: 13.2000\n",
      " |~~ train@17020  Loss: 0.026189 Acc: 13.6000\n",
      " |~~ train@17025  Loss: 0.083395 Acc: 12.4000\n",
      " |~~ train@17030  Loss: 0.039174 Acc: 13.4000\n",
      " |~~ train@17035  Loss: 0.031954 Acc: 13.6000\n",
      " |~~ train@17040  Loss: 0.011676 Acc: 14.0000\n",
      " |~~ train@17045  Loss: 0.017660 Acc: 13.8000\n",
      " |~~ train@17050  Loss: 0.032261 Acc: 13.4000\n",
      " |~~ train@17055  Loss: 0.059547 Acc: 12.6000\n",
      " |~~ train@17060  Loss: 0.019349 Acc: 13.8000\n",
      " |~~ train@17065  Loss: 0.017805 Acc: 13.8000\n",
      " |~~ train@17070  Loss: 0.015678 Acc: 13.8000\n",
      " |~~ train@17075  Loss: 0.029303 Acc: 13.4000\n",
      " |~~ train@17080  Loss: 0.052180 Acc: 12.6000\n",
      " |~~ train@17085  Loss: 0.036832 Acc: 13.0000\n",
      " |~~ train@17090  Loss: 0.055198 Acc: 13.0000\n",
      " |~~ train@17095  Loss: 0.032067 Acc: 13.2000\n",
      " |~~ train@17100  Loss: 0.035105 Acc: 13.0000\n",
      " |~~ train@17105  Loss: 0.071386 Acc: 12.4000\n",
      " |~~ train@17110  Loss: 0.029290 Acc: 13.4000\n",
      " |~~ train@17115  Loss: 0.027588 Acc: 13.4000\n",
      " |~~ train@17120  Loss: 0.016412 Acc: 13.8000\n",
      " |~~ train@17125  Loss: 0.050495 Acc: 12.6000\n",
      " |~~ train@17130  Loss: 0.049042 Acc: 12.6000\n",
      " |~~ train@17135  Loss: 0.059647 Acc: 12.6000\n",
      " |~~ train@17140  Loss: 0.035883 Acc: 13.4000\n",
      " |~~ train@17145  Loss: 0.037863 Acc: 13.4000\n",
      " |~~ train@17150  Loss: 0.038819 Acc: 13.4000\n",
      " |~~ train@17155  Loss: 0.028536 Acc: 13.6000\n",
      " |~~ train@17160  Loss: 0.037587 Acc: 13.2000\n",
      " |~~ train@17165  Loss: 0.041965 Acc: 13.4000\n",
      " |~~ train@17170  Loss: 0.011236 Acc: 14.0000\n",
      " |~~ train@17175  Loss: 0.036092 Acc: 13.4000\n",
      " |~~ train@17180  Loss: 0.045800 Acc: 12.8000\n",
      " |~~ train@17185  Loss: 0.032405 Acc: 13.6000\n",
      " |~~ train@17190  Loss: 0.085571 Acc: 11.8000\n",
      " |~~ train@17195  Loss: 0.062469 Acc: 12.8000\n",
      " |~~ train@17200  Loss: 0.016797 Acc: 13.8000\n",
      " |~~ train@17205  Loss: 0.094585 Acc: 12.2000\n",
      " |~~ train@17210  Loss: 0.019009 Acc: 13.8000\n",
      " |~~ train@17215  Loss: 0.030800 Acc: 13.4000\n",
      " |~~ train@17220  Loss: 0.038001 Acc: 13.0000\n",
      " |~~ train@17225  Loss: 0.034036 Acc: 13.2000\n",
      " |~~ train@17230  Loss: 0.059388 Acc: 12.6000\n",
      " |~~ train@17235  Loss: 0.047753 Acc: 13.2000\n",
      " |~~ train@17240  Loss: 0.039392 Acc: 13.2000\n",
      " |~~ train@17245  Loss: 0.028352 Acc: 13.6000\n",
      " |~~ train@17250  Loss: 0.012170 Acc: 14.0000\n",
      " |~~ train@17255  Loss: 0.023011 Acc: 13.4000\n",
      " |~~ train@17260  Loss: 0.049558 Acc: 13.0000\n",
      " |~~ train@17265  Loss: 0.059328 Acc: 12.4000\n",
      " |~~ train@17270  Loss: 0.014347 Acc: 13.8000\n",
      " |~~ train@17275  Loss: 0.023626 Acc: 13.4000\n",
      " |~~ train@17280  Loss: 0.050212 Acc: 12.8000\n",
      " |~~ train@17285  Loss: 0.022960 Acc: 13.6000\n",
      " |~~ train@17290  Loss: 0.034079 Acc: 13.2000\n",
      " |~~ train@17295  Loss: 0.033587 Acc: 13.6000\n",
      " |~~ train@17300  Loss: 0.016181 Acc: 13.8000\n",
      " |~~ train@17305  Loss: 0.027704 Acc: 13.6000\n",
      " |~~ train@17310  Loss: 0.021517 Acc: 13.6000\n",
      " |~~ train@17315  Loss: 0.067150 Acc: 12.4000\n",
      " |~~ train@17320  Loss: 0.043205 Acc: 12.8000\n",
      " |~~ train@17325  Loss: 0.035388 Acc: 13.2000\n",
      " |~~ train@17330  Loss: 0.025107 Acc: 13.6000\n",
      " |~~ train@17335  Loss: 0.100404 Acc: 12.2000\n",
      " |~~ train@17340  Loss: 0.085440 Acc: 12.0000\n",
      " |~~ train@17345  Loss: 0.048465 Acc: 13.0000\n",
      " |~~ train@17350  Loss: 0.034535 Acc: 13.4000\n",
      " |~~ train@17355  Loss: 0.048321 Acc: 13.0000\n",
      " |~~ train@17360  Loss: 0.032994 Acc: 13.2000\n",
      " |~~ train@17365  Loss: 0.037748 Acc: 13.0000\n",
      " |~~ train@17370  Loss: 0.046407 Acc: 13.0000\n",
      " |~~ train@17375  Loss: 0.024372 Acc: 13.4000\n",
      " |~~ train@17380  Loss: 0.015129 Acc: 13.8000\n",
      " |~~ train@17385  Loss: 0.062013 Acc: 12.2000\n",
      " |~~ train@17390  Loss: 0.031110 Acc: 13.4000\n",
      " |~~ train@17395  Loss: 0.059601 Acc: 12.6000\n",
      " |~~ train@17400  Loss: 0.040508 Acc: 13.0000\n",
      " |~~ train@17405  Loss: 0.029176 Acc: 13.4000\n",
      " |~~ train@17410  Loss: 0.053378 Acc: 12.8000\n",
      " |~~ train@17415  Loss: 0.014556 Acc: 13.8000\n",
      " |~~ train@17420  Loss: 0.026485 Acc: 13.4000\n",
      " |~~ train@17425  Loss: 0.016888 Acc: 13.8000\n",
      " |~~ train@17430  Loss: 0.046500 Acc: 13.0000\n",
      " |~~ train@17435  Loss: 0.030522 Acc: 13.4000\n",
      " |~~ train@17440  Loss: 0.032798 Acc: 13.4000\n",
      " |~~ train@17445  Loss: 0.032997 Acc: 13.6000\n",
      " |~~ train@17450  Loss: 0.039770 Acc: 13.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@17455  Loss: 0.037207 Acc: 13.4000\n",
      " |~~ train@17460  Loss: 0.033568 Acc: 13.4000\n",
      " |~~ train@17465  Loss: 0.037855 Acc: 13.2000\n",
      " |~~ train@17470  Loss: 0.033503 Acc: 13.2000\n",
      " |~~ train@17475  Loss: 0.047847 Acc: 13.0000\n",
      " |~~ train@17480  Loss: 0.018714 Acc: 13.6000\n",
      " |~~ train@17485  Loss: 0.020051 Acc: 13.8000\n",
      " |~~ train@17490  Loss: 0.079607 Acc: 12.2000\n",
      " |~~ train@17495  Loss: 0.011751 Acc: 14.0000\n",
      " |~~ train@17500  Loss: 0.047651 Acc: 12.6000\n",
      " |~~ train@17505  Loss: 0.067500 Acc: 12.8000\n",
      " |~~ train@17510  Loss: 0.024547 Acc: 13.4000\n",
      " |~~ train@17515  Loss: 0.028763 Acc: 13.6000\n",
      " |~~ train@17520  Loss: 0.034246 Acc: 13.4000\n",
      " |~~ train@17525  Loss: 0.030631 Acc: 13.4000\n",
      " |~~ train@17530  Loss: 0.044179 Acc: 13.2000\n",
      " |~~ train@17535  Loss: 0.040277 Acc: 13.0000\n",
      " |~~ train@17540  Loss: 0.012373 Acc: 14.0000\n",
      " |~~ train@17545  Loss: 0.018046 Acc: 13.8000\n",
      " |~~ train@17550  Loss: 0.047819 Acc: 13.0000\n",
      " |~~ train@17555  Loss: 0.029638 Acc: 13.4000\n",
      " |~~ train@17560  Loss: 0.025714 Acc: 13.4000\n",
      " |~~ train@17565  Loss: 0.027501 Acc: 13.4000\n",
      " |~~ train@17570  Loss: 0.024776 Acc: 13.8000\n",
      " |~~ train@17575  Loss: 0.057292 Acc: 12.8000\n",
      " |~~ train@17580  Loss: 0.059009 Acc: 12.8000\n",
      " |~~ train@17585  Loss: 0.034525 Acc: 13.4000\n",
      " |~~ train@17590  Loss: 0.051737 Acc: 12.8000\n",
      " |~~ train@17595  Loss: 0.044924 Acc: 13.2000\n",
      " |~~ train@17600  Loss: 0.045416 Acc: 13.4000\n",
      " |~~ train@17605  Loss: 0.041143 Acc: 13.2000\n",
      " |~~ train@17610  Loss: 0.030005 Acc: 13.6000\n",
      " |~~ train@17615  Loss: 0.038399 Acc: 13.4000\n",
      " |~~ train@17620  Loss: 0.061106 Acc: 12.4000\n",
      " |~~ train@17625  Loss: 0.055002 Acc: 12.8000\n",
      " |~~ train@17630  Loss: 0.025760 Acc: 13.4000\n",
      " |~~ train@17635  Loss: 0.050621 Acc: 13.0000\n",
      " |~~ train@17640  Loss: 0.036980 Acc: 13.4000\n",
      " |~~ train@17645  Loss: 0.033063 Acc: 13.2000\n",
      " |~~ train@17650  Loss: 0.021739 Acc: 13.6000\n",
      " |~~ train@17655  Loss: 0.011930 Acc: 14.0000\n",
      " |~~ train@17660  Loss: 0.029713 Acc: 13.4000\n",
      " |~~ train@17665  Loss: 0.014785 Acc: 13.8000\n",
      " |~~ train@17670  Loss: 0.034257 Acc: 13.0000\n",
      " |~~ train@17675  Loss: 0.024921 Acc: 13.4000\n",
      " |~~ train@17680  Loss: 0.051092 Acc: 12.8000\n",
      " |~~ train@17685  Loss: 0.030202 Acc: 13.6000\n",
      " |~~ train@17690  Loss: 0.020709 Acc: 13.8000\n",
      " |~~ train@17695  Loss: 0.049368 Acc: 13.0000\n",
      " |~~ train@17700  Loss: 0.032031 Acc: 13.2000\n",
      " |~~ train@17705  Loss: 0.022776 Acc: 13.6000\n",
      " |~~ train@17710  Loss: 0.066068 Acc: 12.8000\n",
      " |~~ train@17715  Loss: 0.036557 Acc: 13.4000\n",
      " |~~ train@17720  Loss: 0.025758 Acc: 13.4000\n",
      " |~~ train@17725  Loss: 0.045740 Acc: 13.0000\n",
      " |~~ train@17730  Loss: 0.042042 Acc: 13.2000\n",
      " |~~ train@17735  Loss: 0.022726 Acc: 13.6000\n",
      " |~~ train@17740  Loss: 0.067638 Acc: 12.4000\n",
      " |~~ train@17745  Loss: 0.046114 Acc: 12.6000\n",
      " |~~ train@17750  Loss: 0.031033 Acc: 13.2000\n",
      " |~~ train@17755  Loss: 0.043295 Acc: 13.0000\n",
      " |~~ train@17760  Loss: 0.066473 Acc: 12.4000\n",
      " |~~ train@17765  Loss: 0.035074 Acc: 13.4000\n",
      " |~~ train@17770  Loss: 0.027057 Acc: 13.6000\n",
      " |~~ train@17775  Loss: 0.023922 Acc: 13.6000\n",
      " |~~ train@17780  Loss: 0.011302 Acc: 14.0000\n",
      " |~~ train@17785  Loss: 0.030184 Acc: 13.4000\n",
      " |~~ train@17790  Loss: 0.035966 Acc: 13.2000\n",
      " |~~ train@17795  Loss: 0.024067 Acc: 13.6000\n",
      " |~~ train@17800  Loss: 0.042724 Acc: 13.0000\n",
      " |~~ train@17805  Loss: 0.021966 Acc: 13.6000\n",
      " |~~ train@17810  Loss: 0.029583 Acc: 13.4000\n",
      " |~~ train@17815  Loss: 0.017313 Acc: 13.8000\n",
      " |~~ train@17820  Loss: 0.025779 Acc: 13.4000\n",
      " |~~ train@17825  Loss: 0.031965 Acc: 13.4000\n",
      " |~~ train@17830  Loss: 0.031046 Acc: 13.2000\n",
      " |~~ train@17835  Loss: 0.027154 Acc: 13.6000\n",
      " |~~ train@17840  Loss: 0.041285 Acc: 13.0000\n",
      " |~~ train@17845  Loss: 0.033192 Acc: 13.2000\n",
      " |~~ train@17850  Loss: 0.015656 Acc: 13.8000\n",
      " |~~ train@17855  Loss: 0.027371 Acc: 13.4000\n",
      " |~~ train@17860  Loss: 0.041263 Acc: 13.0000\n",
      " |~~ train@17865  Loss: 0.018995 Acc: 13.6000\n",
      " |~~ train@17870  Loss: 0.044293 Acc: 13.0000\n",
      " |~~ train@17875  Loss: 0.050556 Acc: 12.6000\n",
      " |~~ train@17880  Loss: 0.028680 Acc: 13.4000\n",
      " |~~ train@17885  Loss: 0.050953 Acc: 13.0000\n",
      " |~~ train@17890  Loss: 0.033085 Acc: 13.6000\n",
      " |~~ train@17895  Loss: 0.023226 Acc: 13.4000\n",
      " |~~ train@17900  Loss: 0.040410 Acc: 13.2000\n",
      " |~~ train@17905  Loss: 0.073455 Acc: 12.6000\n",
      " |~~ train@17910  Loss: 0.030143 Acc: 13.6000\n",
      " |~~ train@17915  Loss: 0.065010 Acc: 12.8000\n",
      " |~~ train@17920  Loss: 0.011514 Acc: 14.0000\n",
      " |~~ train@17925  Loss: 0.016166 Acc: 13.8000\n",
      " |~~ train@17930  Loss: 0.041594 Acc: 13.2000\n",
      " |~~ train@17935  Loss: 0.025455 Acc: 13.6000\n",
      " |~~ train@17940  Loss: 0.019475 Acc: 13.8000\n",
      " |~~ train@17945  Loss: 0.055866 Acc: 12.8000\n",
      " |~~ train@17950  Loss: 0.045075 Acc: 13.2000\n",
      " |~~ train@17955  Loss: 0.021518 Acc: 13.6000\n",
      " |~~ train@17960  Loss: 0.067834 Acc: 12.6000\n",
      " |~~ train@17965  Loss: 0.019965 Acc: 13.8000\n",
      " |~~ train@17970  Loss: 0.017842 Acc: 13.6000\n",
      " |~~ train@17975  Loss: 0.035633 Acc: 13.4000\n",
      " |~~ train@17980  Loss: 0.054873 Acc: 12.8000\n",
      " |~~ train@17985  Loss: 0.011414 Acc: 14.0000\n",
      " |~~ train@17990  Loss: 0.036505 Acc: 13.4000\n",
      " |~~ train@17995  Loss: 0.027533 Acc: 13.4000\n",
      " |~~ train@18000  Loss: 0.064837 Acc: 12.6000\n",
      " |~~ train@18005  Loss: 0.026527 Acc: 13.6000\n",
      " |~~ train@18010  Loss: 0.036015 Acc: 13.4000\n",
      " |~~ train@18015  Loss: 0.053566 Acc: 12.8000\n",
      " |~~ train@18020  Loss: 0.016093 Acc: 13.8000\n",
      " |~~ train@18025  Loss: 0.015266 Acc: 13.6000\n",
      " |~~ train@18030  Loss: 0.027509 Acc: 13.6000\n",
      " |~~ train@18035  Loss: 0.062585 Acc: 12.8000\n",
      " |~~ train@18040  Loss: 0.027174 Acc: 13.4000\n",
      " |~~ train@18045  Loss: 0.015839 Acc: 13.8000\n",
      " |~~ train@18050  Loss: 0.031102 Acc: 13.4000\n",
      " |~~ train@18055  Loss: 0.032397 Acc: 13.2000\n",
      " |~~ train@18060  Loss: 0.041879 Acc: 13.0000\n",
      " |~~ train@18065  Loss: 0.046541 Acc: 13.0000\n",
      " |~~ train@18070  Loss: 0.029599 Acc: 13.4000\n",
      " |~~ train@18075  Loss: 0.070978 Acc: 12.4000\n",
      " |~~ train@18080  Loss: 0.033719 Acc: 13.4000\n",
      " |~~ train@18085  Loss: 0.055334 Acc: 13.0000\n",
      " |~~ train@18090  Loss: 0.023959 Acc: 13.6000\n",
      " |~~ train@18095  Loss: 0.055236 Acc: 12.8000\n",
      " |~~ train@18100  Loss: 0.058531 Acc: 13.0000\n",
      " |~~ train@18105  Loss: 0.028916 Acc: 13.4000\n",
      " |~~ train@18110  Loss: 0.022087 Acc: 13.6000\n",
      " |~~ train@18115  Loss: 0.014469 Acc: 13.8000\n",
      " |~~ train@18120  Loss: 0.050030 Acc: 12.8000\n",
      " |~~ train@18125  Loss: 0.044192 Acc: 13.0000\n",
      " |~~ train@18130  Loss: 0.028913 Acc: 13.6000\n",
      " |~~ train@18135  Loss: 0.029017 Acc: 13.4000\n",
      " |~~ train@18140  Loss: 0.033947 Acc: 13.4000\n",
      " |~~ train@18145  Loss: 0.023205 Acc: 13.6000\n",
      " |~~ train@18150  Loss: 0.038238 Acc: 13.2000\n",
      " |~~ train@18155  Loss: 0.023975 Acc: 13.6000\n",
      " |~~ train@18160  Loss: 0.066224 Acc: 12.4000\n",
      " |~~ train@18165  Loss: 0.024857 Acc: 13.6000\n",
      " |~~ train@18170  Loss: 0.056053 Acc: 12.8000\n",
      " |~~ train@18175  Loss: 0.033294 Acc: 13.4000\n",
      " |~~ train@18180  Loss: 0.016317 Acc: 13.8000\n",
      " |~~ train@18185  Loss: 0.034190 Acc: 13.2000\n",
      " |~~ train@18190  Loss: 0.043483 Acc: 13.2000\n",
      " |~~ train@18195  Loss: 0.035321 Acc: 13.0000\n",
      " |~~ train@18200  Loss: 0.020371 Acc: 13.6000\n",
      " |~~ train@18205  Loss: 0.028298 Acc: 13.4000\n",
      " |~~ train@18210  Loss: 0.028520 Acc: 13.4000\n",
      " |~~ train@18215  Loss: 0.027146 Acc: 13.4000\n",
      " |~~ train@18220  Loss: 0.047456 Acc: 13.2000\n",
      " |~~ train@18225  Loss: 0.071060 Acc: 12.4000\n",
      " |~~ train@18230  Loss: 0.015723 Acc: 13.8000\n",
      " |~~ train@18235  Loss: 0.027523 Acc: 13.6000\n",
      " |~~ train@18240  Loss: 0.040113 Acc: 13.0000\n",
      " |~~ train@18245  Loss: 0.041310 Acc: 13.2000\n",
      " |~~ train@18250  Loss: 0.022294 Acc: 13.6000\n",
      " |~~ train@18255  Loss: 0.039335 Acc: 13.2000\n",
      " |~~ train@18260  Loss: 0.033540 Acc: 13.0000\n",
      " |~~ train@18265  Loss: 0.062559 Acc: 12.6000\n",
      " |~~ train@18270  Loss: 0.048887 Acc: 12.8000\n",
      " |~~ train@18275  Loss: 0.027314 Acc: 13.6000\n",
      " |~~ train@18280  Loss: 0.010902 Acc: 14.0000\n",
      " |~~ train@18285  Loss: 0.022958 Acc: 13.4000\n",
      " |~~ train@18290  Loss: 0.027498 Acc: 13.6000\n",
      " |~~ train@18295  Loss: 0.035845 Acc: 13.2000\n",
      " |~~ train@18300  Loss: 0.011502 Acc: 14.0000\n",
      " |~~ train@18305  Loss: 0.024734 Acc: 13.6000\n",
      " |~~ train@18310  Loss: 0.032545 Acc: 13.4000\n",
      " |~~ train@18315  Loss: 0.028551 Acc: 13.4000\n",
      " |~~ train@18320  Loss: 0.069440 Acc: 12.6000\n",
      " |~~ train@18325  Loss: 0.043573 Acc: 13.2000\n",
      " |~~ train@18330  Loss: 0.014223 Acc: 13.8000\n",
      " |~~ train@18335  Loss: 0.019925 Acc: 13.6000\n",
      " |~~ train@18340  Loss: 0.026172 Acc: 13.6000\n",
      " |~~ train@18345  Loss: 0.033667 Acc: 13.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@18350  Loss: 0.015027 Acc: 13.8000\n",
      " |~~ train@18355  Loss: 0.040900 Acc: 13.2000\n",
      " |~~ train@18360  Loss: 0.020550 Acc: 13.6000\n",
      " |~~ train@18365  Loss: 0.010477 Acc: 14.0000\n",
      " |~~ train@18370  Loss: 0.029763 Acc: 13.2000\n",
      " |~~ train@18375  Loss: 0.033646 Acc: 13.4000\n",
      " |~~ train@18380  Loss: 0.061653 Acc: 12.4000\n",
      " |~~ train@18385  Loss: 0.013368 Acc: 13.8000\n",
      " |~~ train@18390  Loss: 0.020285 Acc: 13.6000\n",
      " |~~ train@18395  Loss: 0.050909 Acc: 13.0000\n",
      " |~~ train@18400  Loss: 0.013657 Acc: 13.8000\n",
      " |~~ train@18405  Loss: 0.035760 Acc: 13.4000\n",
      " |~~ train@18410  Loss: 0.052749 Acc: 12.6000\n",
      " |~~ train@18415  Loss: 0.048201 Acc: 13.0000\n",
      " |~~ train@18420  Loss: 0.031197 Acc: 13.2000\n",
      " |~~ train@18425  Loss: 0.046158 Acc: 13.0000\n",
      " |~~ train@18430  Loss: 0.036081 Acc: 13.4000\n",
      " |~~ train@18435  Loss: 0.027371 Acc: 13.4000\n",
      " |~~ train@18440  Loss: 0.015158 Acc: 13.8000\n",
      " |~~ train@18445  Loss: 0.026150 Acc: 13.6000\n",
      " |~~ train@18450  Loss: 0.026424 Acc: 13.4000\n",
      " |~~ train@18455  Loss: 0.035522 Acc: 13.2000\n",
      " |~~ train@18460  Loss: 0.048579 Acc: 13.0000\n",
      " |~~ train@18465  Loss: 0.049833 Acc: 13.2000\n",
      " |~~ train@18470  Loss: 0.019835 Acc: 13.8000\n",
      " |~~ train@18475  Loss: 0.014374 Acc: 13.8000\n",
      " |~~ train@18480  Loss: 0.047920 Acc: 12.8000\n",
      " |~~ train@18485  Loss: 0.036119 Acc: 13.4000\n",
      " |~~ train@18490  Loss: 0.015658 Acc: 13.8000\n",
      " |~~ train@18495  Loss: 0.041293 Acc: 13.2000\n",
      " |~~ train@18500  Loss: 0.023171 Acc: 13.6000\n",
      " |~~ train@18505  Loss: 0.029156 Acc: 13.4000\n",
      " |~~ train@18510  Loss: 0.033484 Acc: 13.4000\n",
      " |~~ train@18515  Loss: 0.065991 Acc: 12.6000\n",
      " |~~ train@18520  Loss: 0.024607 Acc: 13.6000\n",
      " |~~ train@18525  Loss: 0.029309 Acc: 13.4000\n",
      " |~~ train@18530  Loss: 0.014949 Acc: 13.8000\n",
      " |~~ train@18535  Loss: 0.024865 Acc: 13.6000\n",
      " |~~ train@18540  Loss: 0.038145 Acc: 13.4000\n",
      " |~~ train@18545  Loss: 0.054425 Acc: 12.8000\n",
      " |~~ train@18550  Loss: 0.022419 Acc: 13.6000\n",
      " |~~ train@18555  Loss: 0.048639 Acc: 13.0000\n",
      " |~~ train@18560  Loss: 0.020203 Acc: 13.8000\n",
      " |~~ train@18565  Loss: 0.038312 Acc: 13.4000\n",
      " |~~ train@18570  Loss: 0.036603 Acc: 13.4000\n",
      " |~~ train@18575  Loss: 0.052068 Acc: 12.8000\n",
      " |~~ train@18580  Loss: 0.031669 Acc: 13.2000\n",
      " |~~ train@18585  Loss: 0.035383 Acc: 13.2000\n",
      " |~~ train@18590  Loss: 0.037487 Acc: 13.2000\n",
      " |~~ train@18595  Loss: 0.024760 Acc: 13.4000\n",
      " |~~ train@18600  Loss: 0.047335 Acc: 13.4000\n",
      " |~~ train@18605  Loss: 0.034356 Acc: 13.4000\n",
      " |~~ train@18610  Loss: 0.041648 Acc: 13.2000\n",
      " |~~ train@18615  Loss: 0.037590 Acc: 13.4000\n",
      " |~~ train@18620  Loss: 0.071648 Acc: 12.2000\n",
      " |~~ train@18625  Loss: 0.039423 Acc: 13.4000\n",
      " |~~ train@18630  Loss: 0.031267 Acc: 13.6000\n",
      " |~~ train@18635  Loss: 0.049990 Acc: 13.0000\n",
      " |~~ train@18640  Loss: 0.028333 Acc: 13.2000\n",
      " |~~ train@18645  Loss: 0.050438 Acc: 13.0000\n",
      " |~~ train@18650  Loss: 0.058614 Acc: 12.8000\n",
      " |~~ train@18655  Loss: 0.040622 Acc: 13.2000\n",
      " |~~ train@18660  Loss: 0.052413 Acc: 12.8000\n",
      " |~~ train@18665  Loss: 0.041890 Acc: 13.0000\n",
      " |~~ train@18670  Loss: 0.064685 Acc: 12.8000\n",
      " |~~ train@18675  Loss: 0.019470 Acc: 13.8000\n",
      " |~~ train@18680  Loss: 0.021028 Acc: 13.6000\n",
      " |~~ train@18685  Loss: 0.065937 Acc: 12.6000\n",
      " |~~ train@18690  Loss: 0.015018 Acc: 13.8000\n",
      " |~~ train@18695  Loss: 0.037356 Acc: 13.4000\n",
      " |~~ train@18700  Loss: 0.032225 Acc: 13.2000\n",
      " |~~ train@18705  Loss: 0.041684 Acc: 13.0000\n",
      " |~~ train@18710  Loss: 0.041339 Acc: 13.2000\n",
      " |~~ train@18715  Loss: 0.037385 Acc: 13.2000\n",
      " |~~ train@18720  Loss: 0.030320 Acc: 13.4000\n",
      " |~~ train@18725  Loss: 0.035165 Acc: 13.4000\n",
      " |~~ train@18730  Loss: 0.020226 Acc: 13.8000\n",
      " |~~ train@18735  Loss: 0.067472 Acc: 12.4000\n",
      " |~~ train@18740  Loss: 0.070873 Acc: 12.4000\n",
      " |~~ train@18745  Loss: 0.022886 Acc: 13.8000\n",
      " |~~ train@18750  Loss: 0.071359 Acc: 12.4000\n",
      " |~~ train@18755  Loss: 0.047608 Acc: 12.8000\n",
      " |~~ train@18760  Loss: 0.019342 Acc: 13.6000\n",
      " |~~ train@18765  Loss: 0.039351 Acc: 13.2000\n",
      " |~~ train@18770  Loss: 0.034763 Acc: 13.2000\n",
      " |~~ train@18775  Loss: 0.017685 Acc: 13.8000\n",
      " |~~ train@18780  Loss: 0.027649 Acc: 13.4000\n",
      " |~~ train@18785  Loss: 0.016616 Acc: 13.8000\n",
      " |~~ train@18790  Loss: 0.075986 Acc: 12.4000\n",
      " |~~ train@18795  Loss: 0.075702 Acc: 12.4000\n",
      " |~~ train@18800  Loss: 0.052746 Acc: 13.2000\n",
      " |~~ train@18805  Loss: 0.046911 Acc: 12.8000\n",
      " |~~ train@18810  Loss: 0.043484 Acc: 13.2000\n",
      " |~~ train@18815  Loss: 0.011597 Acc: 14.0000\n",
      " |~~ train@18820  Loss: 0.040052 Acc: 13.0000\n",
      " |~~ train@18825  Loss: 0.018144 Acc: 13.6000\n",
      " |~~ train@18830  Loss: 0.017221 Acc: 13.8000\n",
      " |~~ train@18835  Loss: 0.064147 Acc: 12.8000\n",
      " |~~ train@18840  Loss: 0.025803 Acc: 13.6000\n",
      " |~~ train@18845  Loss: 0.045893 Acc: 13.0000\n",
      " |~~ train@18850  Loss: 0.017065 Acc: 13.8000\n",
      " |~~ train@18855  Loss: 0.011170 Acc: 14.0000\n",
      " |~~ train@18860  Loss: 0.030031 Acc: 13.6000\n",
      " |~~ train@18865  Loss: 0.027195 Acc: 13.4000\n",
      " |~~ train@18870  Loss: 0.072959 Acc: 12.4000\n",
      " |~~ train@18875  Loss: 0.042542 Acc: 12.8000\n",
      " |~~ train@18880  Loss: 0.028629 Acc: 13.6000\n",
      " |~~ train@18885  Loss: 0.018245 Acc: 13.8000\n",
      " |~~ train@18890  Loss: 0.020653 Acc: 13.6000\n",
      " |~~ train@18895  Loss: 0.045738 Acc: 12.6000\n",
      " |~~ train@18900  Loss: 0.038248 Acc: 13.2000\n",
      " |~~ train@18905  Loss: 0.053359 Acc: 12.6000\n",
      " |~~ train@18910  Loss: 0.023955 Acc: 13.6000\n",
      " |~~ train@18915  Loss: 0.011295 Acc: 14.0000\n",
      " |~~ train@18920  Loss: 0.029563 Acc: 13.4000\n",
      " |~~ train@18925  Loss: 0.043301 Acc: 13.0000\n",
      " |~~ train@18930  Loss: 0.032506 Acc: 13.4000\n",
      " |~~ train@18935  Loss: 0.057386 Acc: 12.8000\n",
      " |~~ train@18940  Loss: 0.028568 Acc: 13.6000\n",
      " |~~ train@18945  Loss: 0.056985 Acc: 12.8000\n",
      " |~~ train@18950  Loss: 0.019990 Acc: 13.8000\n",
      " |~~ train@18955  Loss: 0.015239 Acc: 13.8000\n",
      " |~~ train@18960  Loss: 0.043137 Acc: 13.0000\n",
      " |~~ train@18965  Loss: 0.011135 Acc: 14.0000\n",
      " |~~ train@18970  Loss: 0.060801 Acc: 13.0000\n",
      " |~~ train@18975  Loss: 0.024709 Acc: 13.6000\n",
      " |~~ train@18980  Loss: 0.036804 Acc: 13.2000\n",
      " |~~ train@18985  Loss: 0.034226 Acc: 13.2000\n",
      " |~~ train@18990  Loss: 0.061090 Acc: 12.6000\n",
      " |~~ train@18995  Loss: 0.024636 Acc: 13.6000\n",
      " |~~ train@19000  Loss: 0.010448 Acc: 14.0000\n",
      " |~~ train@19005  Loss: 0.025744 Acc: 13.6000\n",
      " |~~ train@19010  Loss: 0.046144 Acc: 13.0000\n",
      " |~~ train@19015  Loss: 0.043240 Acc: 13.0000\n",
      " |~~ train@19020  Loss: 0.022471 Acc: 13.6000\n",
      " |~~ train@19025  Loss: 0.046684 Acc: 13.0000\n",
      " |~~ train@19030  Loss: 0.020475 Acc: 13.6000\n",
      " |~~ train@19035  Loss: 0.011053 Acc: 14.0000\n",
      " |~~ train@19040  Loss: 0.020983 Acc: 13.6000\n",
      " |~~ train@19045  Loss: 0.025164 Acc: 13.4000\n",
      " |~~ train@19050  Loss: 0.049995 Acc: 12.8000\n",
      " |~~ train@19055  Loss: 0.032103 Acc: 13.2000\n",
      " |~~ train@19060  Loss: 0.039964 Acc: 13.2000\n",
      " |~~ train@19065  Loss: 0.039161 Acc: 13.2000\n",
      " |~~ train@19070  Loss: 0.044928 Acc: 13.0000\n",
      " |~~ train@19075  Loss: 0.039620 Acc: 13.2000\n",
      " |~~ train@19080  Loss: 0.041651 Acc: 13.0000\n",
      " |~~ train@19085  Loss: 0.045770 Acc: 13.2000\n",
      " |~~ train@19090  Loss: 0.047004 Acc: 13.2000\n",
      " |~~ train@19095  Loss: 0.036173 Acc: 13.2000\n",
      " |~~ train@19100  Loss: 0.025142 Acc: 13.6000\n",
      " |~~ train@19105  Loss: 0.065787 Acc: 12.6000\n",
      " |~~ train@19110  Loss: 0.060413 Acc: 12.6000\n",
      " |~~ train@19115  Loss: 0.063491 Acc: 12.8000\n",
      " |~~ train@19120  Loss: 0.027168 Acc: 13.2000\n",
      " |~~ train@19125  Loss: 0.041525 Acc: 13.0000\n",
      " |~~ train@19130  Loss: 0.048981 Acc: 12.8000\n",
      " |~~ train@19135  Loss: 0.044402 Acc: 13.2000\n",
      " |~~ train@19140  Loss: 0.043375 Acc: 13.0000\n",
      " |~~ train@19145  Loss: 0.050404 Acc: 13.0000\n",
      " |~~ train@19150  Loss: 0.035742 Acc: 13.4000\n",
      " |~~ train@19155  Loss: 0.044761 Acc: 12.8000\n",
      " |~~ train@19160  Loss: 0.056869 Acc: 12.8000\n",
      " |~~ train@19165  Loss: 0.019031 Acc: 13.6000\n",
      " |~~ train@19170  Loss: 0.026883 Acc: 13.6000\n",
      " |~~ train@19175  Loss: 0.017046 Acc: 13.8000\n",
      " |~~ train@19180  Loss: 0.042333 Acc: 13.0000\n",
      " |~~ train@19185  Loss: 0.052925 Acc: 12.8000\n",
      " |~~ train@19190  Loss: 0.018507 Acc: 13.8000\n",
      " |~~ train@19195  Loss: 0.039853 Acc: 13.2000\n",
      " |~~ train@19200  Loss: 0.049863 Acc: 13.0000\n",
      " |~~ train@19205  Loss: 0.015852 Acc: 13.8000\n",
      " |~~ train@19210  Loss: 0.040619 Acc: 12.8000\n",
      " |~~ train@19215  Loss: 0.043538 Acc: 13.0000\n",
      " |~~ train@19220  Loss: 0.044649 Acc: 13.2000\n",
      " |~~ train@19225  Loss: 0.013722 Acc: 13.8000\n",
      " |~~ train@19230  Loss: 0.080170 Acc: 12.0000\n",
      " |~~ train@19235  Loss: 0.042833 Acc: 13.0000\n",
      " |~~ train@19240  Loss: 0.027060 Acc: 13.4000\n",
      " |~~ train@19245  Loss: 0.028267 Acc: 13.4000\n",
      " |~~ train@19250  Loss: 0.025625 Acc: 13.6000\n",
      " |~~ train@19255  Loss: 0.059095 Acc: 12.8000\n",
      " |~~ train@19260  Loss: 0.053384 Acc: 13.2000\n",
      " |~~ train@19265  Loss: 0.034044 Acc: 13.4000\n",
      " |~~ train@19270  Loss: 0.029471 Acc: 13.4000\n",
      " |~~ train@19275  Loss: 0.033100 Acc: 13.2000\n",
      " |~~ train@19280  Loss: 0.052427 Acc: 12.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@19285  Loss: 0.040516 Acc: 13.2000\n",
      " |~~ train@19290  Loss: 0.037048 Acc: 13.2000\n",
      " |~~ train@19295  Loss: 0.023556 Acc: 13.6000\n",
      " |~~ train@19300  Loss: 0.026140 Acc: 13.6000\n",
      " |~~ train@19305  Loss: 0.039901 Acc: 13.0000\n",
      " |~~ train@19310  Loss: 0.029063 Acc: 13.4000\n",
      " |~~ train@19315  Loss: 0.042606 Acc: 13.0000\n",
      " |~~ train@19320  Loss: 0.044980 Acc: 12.8000\n",
      " |~~ train@19325  Loss: 0.012529 Acc: 14.0000\n",
      " |~~ train@19330  Loss: 0.026051 Acc: 13.6000\n",
      " |~~ train@19335  Loss: 0.068590 Acc: 12.4000\n",
      " |~~ train@19340  Loss: 0.023240 Acc: 13.6000\n",
      " |~~ train@19345  Loss: 0.039340 Acc: 13.2000\n",
      " |~~ train@19350  Loss: 0.084425 Acc: 12.0000\n",
      " |~~ train@19355  Loss: 0.050464 Acc: 13.0000\n",
      " |~~ train@19360  Loss: 0.020204 Acc: 13.6000\n",
      " |~~ train@19365  Loss: 0.012329 Acc: 14.0000\n",
      " |~~ train@19370  Loss: 0.050051 Acc: 13.0000\n",
      " |~~ train@19375  Loss: 0.037922 Acc: 13.2000\n",
      " |~~ train@19380  Loss: 0.054845 Acc: 13.2000\n",
      " |~~ train@19385  Loss: 0.070166 Acc: 12.2000\n",
      " |~~ train@19390  Loss: 0.042834 Acc: 13.0000\n",
      " |~~ train@19395  Loss: 0.017088 Acc: 13.8000\n",
      " |~~ train@19400  Loss: 0.037708 Acc: 13.0000\n",
      " |~~ train@19405  Loss: 0.049000 Acc: 12.4000\n",
      " |~~ train@19410  Loss: 0.050486 Acc: 13.2000\n",
      " |~~ train@19415  Loss: 0.037234 Acc: 13.2000\n",
      " |~~ train@19420  Loss: 0.028580 Acc: 13.4000\n",
      " |~~ train@19425  Loss: 0.034886 Acc: 13.4000\n",
      " |~~ train@19430  Loss: 0.012266 Acc: 14.0000\n",
      " |~~ train@19435  Loss: 0.012914 Acc: 14.0000\n",
      " |~~ train@19440  Loss: 0.042808 Acc: 13.2000\n",
      " |~~ train@19445  Loss: 0.028827 Acc: 13.4000\n",
      " |~~ train@19450  Loss: 0.028586 Acc: 13.4000\n",
      " |~~ train@19455  Loss: 0.050029 Acc: 13.0000\n",
      " |~~ train@19460  Loss: 0.026761 Acc: 13.4000\n",
      " |~~ train@19465  Loss: 0.023697 Acc: 13.4000\n",
      " |~~ train@19470  Loss: 0.048340 Acc: 13.0000\n",
      " |~~ train@19475  Loss: 0.013270 Acc: 14.0000\n",
      " |~~ train@19480  Loss: 0.039526 Acc: 13.2000\n",
      " |~~ train@19485  Loss: 0.037069 Acc: 13.0000\n",
      " |~~ train@19490  Loss: 0.032278 Acc: 13.0000\n",
      " |~~ train@19495  Loss: 0.024063 Acc: 13.8000\n",
      " |~~ train@19500  Loss: 0.027418 Acc: 13.4000\n",
      " |~~ train@19505  Loss: 0.023630 Acc: 13.6000\n",
      " |~~ train@19510  Loss: 0.036652 Acc: 13.2000\n",
      " |~~ train@19515  Loss: 0.030997 Acc: 13.6000\n",
      " |~~ train@19520  Loss: 0.030246 Acc: 13.6000\n",
      " |~~ train@19525  Loss: 0.011323 Acc: 14.0000\n",
      " |~~ train@19530  Loss: 0.028226 Acc: 13.2000\n",
      " |~~ train@19535  Loss: 0.029176 Acc: 13.4000\n",
      " |~~ train@19540  Loss: 0.055398 Acc: 13.0000\n",
      " |~~ train@19545  Loss: 0.032319 Acc: 13.4000\n",
      " |~~ train@19550  Loss: 0.048733 Acc: 13.0000\n",
      " |~~ train@19555  Loss: 0.029948 Acc: 13.4000\n",
      " |~~ train@19560  Loss: 0.032301 Acc: 13.2000\n",
      " |~~ train@19565  Loss: 0.026004 Acc: 13.6000\n",
      " |~~ train@19570  Loss: 0.032754 Acc: 13.4000\n",
      " |~~ train@19575  Loss: 0.051334 Acc: 12.8000\n",
      " |~~ train@19580  Loss: 0.029901 Acc: 13.2000\n",
      " |~~ train@19585  Loss: 0.022962 Acc: 13.4000\n",
      " |~~ train@19590  Loss: 0.029435 Acc: 13.4000\n",
      " |~~ train@19595  Loss: 0.059197 Acc: 12.8000\n",
      " |~~ train@19600  Loss: 0.029154 Acc: 13.4000\n",
      " |~~ train@19605  Loss: 0.032510 Acc: 13.6000\n",
      " |~~ train@19610  Loss: 0.036266 Acc: 13.2000\n",
      " |~~ train@19615  Loss: 0.030399 Acc: 13.4000\n",
      " |~~ train@19620  Loss: 0.063950 Acc: 12.4000\n",
      " |~~ train@19625  Loss: 0.032289 Acc: 13.4000\n",
      " |~~ train@19630  Loss: 0.015242 Acc: 13.8000\n",
      " |~~ train@19635  Loss: 0.027913 Acc: 13.4000\n",
      " |~~ train@19640  Loss: 0.016609 Acc: 13.8000\n",
      " |~~ train@19645  Loss: 0.044256 Acc: 12.8000\n",
      " |~~ train@19650  Loss: 0.022886 Acc: 13.8000\n",
      " |~~ train@19655  Loss: 0.020055 Acc: 13.8000\n",
      " |~~ train@19660  Loss: 0.018449 Acc: 13.8000\n",
      " |~~ train@19665  Loss: 0.038419 Acc: 13.2000\n",
      " |~~ train@19670  Loss: 0.033299 Acc: 13.2000\n",
      " |~~ train@19675  Loss: 0.019741 Acc: 13.6000\n",
      " |~~ train@19680  Loss: 0.065976 Acc: 12.6000\n",
      " |~~ train@19685  Loss: 0.038782 Acc: 13.2000\n",
      " |~~ train@19690  Loss: 0.028600 Acc: 13.4000\n",
      " |~~ train@19695  Loss: 0.051340 Acc: 12.8000\n",
      " |~~ train@19700  Loss: 0.011028 Acc: 14.0000\n",
      " |~~ train@19705  Loss: 0.046446 Acc: 13.2000\n",
      " |~~ train@19710  Loss: 0.077380 Acc: 12.2000\n",
      " |~~ train@19715  Loss: 0.041134 Acc: 13.0000\n",
      " |~~ train@19720  Loss: 0.044487 Acc: 13.2000\n",
      " |~~ train@19725  Loss: 0.026207 Acc: 13.6000\n",
      " |~~ train@19730  Loss: 0.055153 Acc: 13.0000\n",
      " |~~ train@19735  Loss: 0.024298 Acc: 13.6000\n",
      " |~~ train@19740  Loss: 0.032788 Acc: 13.4000\n",
      " |~~ train@19745  Loss: 0.026623 Acc: 13.6000\n",
      " |~~ train@19750  Loss: 0.040520 Acc: 13.2000\n",
      " |~~ train@19755  Loss: 0.057842 Acc: 12.8000\n",
      " |~~ train@19760  Loss: 0.037008 Acc: 13.2000\n",
      " |~~ train@19765  Loss: 0.038308 Acc: 13.4000\n",
      " |~~ train@19770  Loss: 0.029668 Acc: 13.2000\n",
      " |~~ train@19775  Loss: 0.035081 Acc: 13.2000\n",
      " |~~ train@19780  Loss: 0.038120 Acc: 13.2000\n",
      " |~~ train@19785  Loss: 0.028712 Acc: 13.6000\n",
      " |~~ train@19790  Loss: 0.010450 Acc: 14.0000\n",
      " |~~ train@19795  Loss: 0.069357 Acc: 12.8000\n",
      " |~~ train@19800  Loss: 0.021291 Acc: 13.6000\n",
      " |~~ train@19805  Loss: 0.043383 Acc: 13.0000\n",
      " |~~ train@19810  Loss: 0.038786 Acc: 13.2000\n",
      " |~~ train@19815  Loss: 0.033698 Acc: 13.2000\n",
      " |~~ train@19820  Loss: 0.021734 Acc: 13.6000\n",
      " |~~ train@19825  Loss: 0.035626 Acc: 13.2000\n",
      " |~~ train@19830  Loss: 0.027155 Acc: 13.6000\n",
      " |~~ train@19835  Loss: 0.052108 Acc: 12.8000\n",
      " |~~ train@19840  Loss: 0.041785 Acc: 13.2000\n",
      " |~~ train@19845  Loss: 0.048180 Acc: 12.8000\n",
      " |~~ train@19850  Loss: 0.040775 Acc: 13.0000\n",
      " |~~ train@19855  Loss: 0.038268 Acc: 13.4000\n",
      " |~~ train@19860  Loss: 0.050222 Acc: 12.8000\n",
      " |~~ train@19865  Loss: 0.015002 Acc: 13.8000\n",
      " |~~ train@19870  Loss: 0.015137 Acc: 13.8000\n",
      " |~~ train@19875  Loss: 0.010553 Acc: 14.0000\n",
      " |~~ train@19880  Loss: 0.036885 Acc: 13.2000\n",
      " |~~ train@19885  Loss: 0.031417 Acc: 13.4000\n",
      " |~~ train@19890  Loss: 0.023887 Acc: 13.4000\n",
      " |~~ train@19895  Loss: 0.031947 Acc: 13.4000\n",
      " |~~ train@19900  Loss: 0.043842 Acc: 13.2000\n",
      " |~~ train@19905  Loss: 0.017491 Acc: 13.8000\n",
      " |~~ train@19910  Loss: 0.022883 Acc: 13.6000\n",
      " |~~ train@19915  Loss: 0.032892 Acc: 13.2000\n",
      " |~~ train@19920  Loss: 0.010474 Acc: 14.0000\n",
      " |~~ train@19925  Loss: 0.065685 Acc: 12.8000\n",
      " |~~ train@19930  Loss: 0.046462 Acc: 13.0000\n",
      " |~~ train@19935  Loss: 0.028835 Acc: 13.4000\n",
      " |~~ train@19940  Loss: 0.051217 Acc: 12.8000\n",
      " |~~ train@19945  Loss: 0.043677 Acc: 13.2000\n",
      " |~~ train@19950  Loss: 0.038089 Acc: 13.4000\n",
      " |~~ train@19955  Loss: 0.029194 Acc: 13.6000\n",
      " |~~ train@19960  Loss: 0.015296 Acc: 13.8000\n",
      " |~~ train@19965  Loss: 0.056509 Acc: 12.8000\n",
      " |~~ train@19970  Loss: 0.110579 Acc: 11.6000\n",
      " |~~ train@19975  Loss: 0.060078 Acc: 12.8000\n",
      " |~~ train@19980  Loss: 0.035746 Acc: 13.0000\n",
      " |~~ train@19985  Loss: 0.090085 Acc: 11.6000\n",
      " |~~ train@19990  Loss: 0.042306 Acc: 13.4000\n",
      " |~~ train@19995  Loss: 0.028630 Acc: 13.4000\n",
      " |~~ train@20000  Loss: 0.021368 Acc: 13.6000\n",
      " |~~ train@20005  Loss: 0.035598 Acc: 13.2000\n",
      " |~~ train@20010  Loss: 0.052488 Acc: 13.0000\n",
      " |~~ train@20015  Loss: 0.057587 Acc: 12.6000\n",
      " |~~ train@20020  Loss: 0.046122 Acc: 12.8000\n",
      " |~~ train@20025  Loss: 0.019670 Acc: 13.8000\n",
      " |~~ train@20030  Loss: 0.025663 Acc: 13.4000\n",
      " |~~ train@20035  Loss: 0.036232 Acc: 13.4000\n",
      " |~~ train@20040  Loss: 0.056996 Acc: 12.6000\n",
      " |~~ train@20045  Loss: 0.023364 Acc: 13.4000\n",
      " |~~ train@20050  Loss: 0.060021 Acc: 12.4000\n",
      " |~~ train@20055  Loss: 0.032708 Acc: 13.2000\n",
      " |~~ train@20060  Loss: 0.043368 Acc: 13.2000\n",
      " |~~ train@20065  Loss: 0.025397 Acc: 13.6000\n",
      " |~~ train@20070  Loss: 0.030640 Acc: 13.2000\n",
      " |~~ train@20075  Loss: 0.027222 Acc: 13.6000\n",
      " |~~ train@20080  Loss: 0.023694 Acc: 13.6000\n",
      " |~~ train@20085  Loss: 0.013984 Acc: 13.8000\n",
      " |~~ train@20090  Loss: 0.031858 Acc: 13.4000\n",
      " |~~ train@20095  Loss: 0.032082 Acc: 13.6000\n",
      " |~~ train@20100  Loss: 0.023137 Acc: 13.8000\n",
      " |~~ train@20105  Loss: 0.042419 Acc: 13.0000\n",
      " |~~ train@20110  Loss: 0.034545 Acc: 13.4000\n",
      " |~~ train@20115  Loss: 0.016804 Acc: 13.8000\n",
      " |~~ train@20120  Loss: 0.017165 Acc: 13.8000\n",
      " |~~ train@20125  Loss: 0.040728 Acc: 13.0000\n",
      " |~~ train@20130  Loss: 0.049413 Acc: 13.0000\n",
      " |~~ train@20135  Loss: 0.018719 Acc: 13.6000\n",
      " |~~ train@20140  Loss: 0.026339 Acc: 13.6000\n",
      " |~~ train@20145  Loss: 0.022298 Acc: 13.6000\n",
      " |~~ train@20150  Loss: 0.012102 Acc: 14.0000\n",
      " |~~ train@20155  Loss: 0.069642 Acc: 12.2000\n",
      " |~~ train@20160  Loss: 0.029325 Acc: 13.4000\n",
      " |~~ train@20165  Loss: 0.074877 Acc: 12.2000\n",
      " |~~ train@20170  Loss: 0.053885 Acc: 12.8000\n",
      " |~~ train@20175  Loss: 0.055115 Acc: 12.6000\n",
      " |~~ train@20180  Loss: 0.036216 Acc: 13.4000\n",
      " |~~ train@20185  Loss: 0.026668 Acc: 13.4000\n",
      " |~~ train@20190  Loss: 0.011007 Acc: 14.0000\n",
      " |~~ train@20195  Loss: 0.032044 Acc: 13.4000\n",
      " |~~ train@20200  Loss: 0.037359 Acc: 13.4000\n",
      " |~~ train@20205  Loss: 0.028508 Acc: 13.4000\n",
      " |~~ train@20210  Loss: 0.050432 Acc: 12.8000\n",
      " |~~ train@20215  Loss: 0.010881 Acc: 14.0000\n",
      " |~~ train@20220  Loss: 0.025017 Acc: 13.6000\n",
      " |~~ train@20225  Loss: 0.029152 Acc: 13.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@20230  Loss: 0.023412 Acc: 13.4000\n",
      " |~~ train@20235  Loss: 0.038679 Acc: 13.2000\n",
      " |~~ train@20240  Loss: 0.043429 Acc: 13.0000\n",
      " |~~ train@20245  Loss: 0.020702 Acc: 13.6000\n",
      " |~~ train@20250  Loss: 0.042483 Acc: 13.2000\n",
      " |~~ train@20255  Loss: 0.041324 Acc: 13.0000\n",
      " |~~ train@20260  Loss: 0.045141 Acc: 13.0000\n",
      " |~~ train@20265  Loss: 0.058651 Acc: 12.8000\n",
      " |~~ train@20270  Loss: 0.047873 Acc: 13.0000\n",
      " |~~ train@20275  Loss: 0.046627 Acc: 13.0000\n",
      " |~~ train@20280  Loss: 0.047808 Acc: 13.0000\n",
      " |~~ train@20285  Loss: 0.035948 Acc: 13.0000\n",
      " |~~ train@20290  Loss: 0.039112 Acc: 13.2000\n",
      " |~~ train@20295  Loss: 0.015948 Acc: 13.8000\n",
      " |~~ train@20300  Loss: 0.014686 Acc: 13.8000\n",
      " |~~ train@20305  Loss: 0.010788 Acc: 14.0000\n",
      " |~~ train@20310  Loss: 0.017559 Acc: 13.6000\n",
      " |~~ train@20315  Loss: 0.029427 Acc: 13.4000\n",
      " |~~ train@20320  Loss: 0.022845 Acc: 13.6000\n",
      " |~~ train@20325  Loss: 0.035324 Acc: 13.2000\n",
      " |~~ train@20330  Loss: 0.032240 Acc: 13.4000\n",
      " |~~ train@20335  Loss: 0.032941 Acc: 13.2000\n",
      " |~~ train@20340  Loss: 0.012722 Acc: 14.0000\n",
      " |~~ train@20345  Loss: 0.035955 Acc: 13.4000\n",
      " |~~ train@20350  Loss: 0.034222 Acc: 13.2000\n",
      " |~~ train@20355  Loss: 0.063295 Acc: 12.8000\n",
      " |~~ train@20360  Loss: 0.020262 Acc: 13.6000\n",
      " |~~ train@20365  Loss: 0.021889 Acc: 13.6000\n",
      " |~~ train@20370  Loss: 0.064292 Acc: 12.4000\n",
      " |~~ train@20375  Loss: 0.044327 Acc: 13.2000\n",
      " |~~ train@20380  Loss: 0.028873 Acc: 13.6000\n",
      " |~~ train@20385  Loss: 0.078804 Acc: 12.2000\n",
      " |~~ train@20390  Loss: 0.038917 Acc: 13.4000\n",
      " |~~ train@20395  Loss: 0.050387 Acc: 12.8000\n",
      " |~~ train@20400  Loss: 0.020161 Acc: 13.8000\n",
      " |~~ train@20405  Loss: 0.038234 Acc: 13.2000\n",
      " |~~ train@20410  Loss: 0.030189 Acc: 13.4000\n",
      " |~~ train@20415  Loss: 0.018225 Acc: 13.8000\n",
      " |~~ train@20420  Loss: 0.038912 Acc: 13.0000\n",
      " |~~ train@20425  Loss: 0.026746 Acc: 13.6000\n",
      " |~~ train@20430  Loss: 0.032732 Acc: 13.4000\n",
      " |~~ train@20435  Loss: 0.035888 Acc: 13.4000\n",
      " |~~ train@20440  Loss: 0.056009 Acc: 12.8000\n",
      " |~~ train@20445  Loss: 0.037549 Acc: 13.2000\n",
      " |~~ train@20450  Loss: 0.039004 Acc: 12.8000\n",
      " |~~ train@20455  Loss: 0.016631 Acc: 13.8000\n",
      " |~~ train@20460  Loss: 0.033146 Acc: 13.4000\n",
      " |~~ train@20465  Loss: 0.018421 Acc: 13.8000\n",
      " |~~ train@20470  Loss: 0.054711 Acc: 13.0000\n",
      " |~~ train@20475  Loss: 0.080380 Acc: 12.2000\n",
      " |~~ train@20480  Loss: 0.042658 Acc: 13.2000\n",
      " |~~ train@20485  Loss: 0.065360 Acc: 12.6000\n",
      " |~~ train@20490  Loss: 0.014181 Acc: 13.8000\n",
      " |~~ train@20495  Loss: 0.057620 Acc: 12.6000\n",
      " |~~ train@20500  Loss: 0.030031 Acc: 13.2000\n",
      " |~~ train@20505  Loss: 0.040650 Acc: 13.0000\n",
      " |~~ train@20510  Loss: 0.040609 Acc: 13.0000\n",
      " |~~ train@20515  Loss: 0.021127 Acc: 13.8000\n",
      " |~~ train@20520  Loss: 0.037334 Acc: 13.4000\n",
      " |~~ train@20525  Loss: 0.047314 Acc: 12.8000\n",
      " |~~ train@20530  Loss: 0.033172 Acc: 13.4000\n",
      " |~~ train@20535  Loss: 0.014778 Acc: 13.8000\n",
      " |~~ train@20540  Loss: 0.031571 Acc: 13.4000\n",
      " |~~ train@20545  Loss: 0.027751 Acc: 13.6000\n",
      " |~~ train@20550  Loss: 0.022320 Acc: 13.8000\n",
      " |~~ train@20555  Loss: 0.039713 Acc: 13.0000\n",
      " |~~ train@20560  Loss: 0.039854 Acc: 13.0000\n",
      " |~~ train@20565  Loss: 0.044527 Acc: 12.8000\n",
      " |~~ train@20570  Loss: 0.023377 Acc: 13.6000\n",
      " |~~ train@20575  Loss: 0.050355 Acc: 12.6000\n",
      " |~~ train@20580  Loss: 0.039840 Acc: 13.4000\n",
      " |~~ train@20585  Loss: 0.013776 Acc: 13.8000\n",
      " |~~ train@20590  Loss: 0.039288 Acc: 13.2000\n",
      " |~~ train@20595  Loss: 0.062038 Acc: 12.4000\n",
      " |~~ train@20600  Loss: 0.020551 Acc: 13.6000\n",
      " |~~ train@20605  Loss: 0.031983 Acc: 13.6000\n",
      " |~~ train@20610  Loss: 0.018059 Acc: 13.6000\n",
      " |~~ train@20615  Loss: 0.048342 Acc: 12.8000\n",
      " |~~ train@20620  Loss: 0.027125 Acc: 13.6000\n",
      " |~~ train@20625  Loss: 0.082228 Acc: 12.2000\n",
      " |~~ train@20630  Loss: 0.043064 Acc: 13.0000\n",
      " |~~ train@20635  Loss: 0.025482 Acc: 13.6000\n",
      " |~~ train@20640  Loss: 0.040710 Acc: 13.2000\n",
      " |~~ train@20645  Loss: 0.036443 Acc: 13.2000\n",
      " |~~ train@20650  Loss: 0.016824 Acc: 13.8000\n",
      " |~~ train@20655  Loss: 0.021901 Acc: 13.6000\n",
      " |~~ train@20660  Loss: 0.031947 Acc: 13.4000\n",
      " |~~ train@20665  Loss: 0.033185 Acc: 13.4000\n",
      " |~~ train@20670  Loss: 0.020935 Acc: 13.6000\n",
      " |~~ train@20675  Loss: 0.030238 Acc: 13.4000\n",
      " |~~ train@20680  Loss: 0.023594 Acc: 13.4000\n",
      " |~~ train@20685  Loss: 0.040768 Acc: 13.2000\n",
      " |~~ train@20690  Loss: 0.022772 Acc: 13.6000\n",
      " |~~ train@20695  Loss: 0.066267 Acc: 12.6000\n",
      " |~~ train@20700  Loss: 0.020523 Acc: 13.8000\n",
      " |~~ train@20705  Loss: 0.037979 Acc: 13.0000\n",
      " |~~ train@20710  Loss: 0.048985 Acc: 13.0000\n",
      " |~~ train@20715  Loss: 0.029667 Acc: 13.6000\n",
      " |~~ train@20720  Loss: 0.055434 Acc: 13.0000\n",
      " |~~ train@20725  Loss: 0.047389 Acc: 12.8000\n",
      " |~~ train@20730  Loss: 0.030404 Acc: 13.4000\n",
      " |~~ train@20735  Loss: 0.051708 Acc: 12.6000\n",
      " |~~ train@20740  Loss: 0.054688 Acc: 12.8000\n",
      " |~~ train@20745  Loss: 0.023773 Acc: 13.6000\n",
      " |~~ train@20750  Loss: 0.026937 Acc: 13.6000\n",
      " |~~ train@20755  Loss: 0.045843 Acc: 13.0000\n",
      " |~~ train@20760  Loss: 0.012954 Acc: 13.8000\n",
      " |~~ train@20765  Loss: 0.020016 Acc: 13.6000\n",
      " |~~ train@20770  Loss: 0.045796 Acc: 13.0000\n",
      " |~~ train@20775  Loss: 0.043752 Acc: 13.2000\n",
      " |~~ train@20780  Loss: 0.024625 Acc: 13.4000\n",
      " |~~ train@20785  Loss: 0.019801 Acc: 13.6000\n",
      " |~~ train@20790  Loss: 0.017833 Acc: 13.8000\n",
      " |~~ train@20795  Loss: 0.018212 Acc: 13.6000\n",
      " |~~ train@20800  Loss: 0.031776 Acc: 13.4000\n",
      " |~~ train@20805  Loss: 0.011574 Acc: 14.0000\n",
      " |~~ train@20810  Loss: 0.039888 Acc: 13.2000\n",
      " |~~ train@20815  Loss: 0.023718 Acc: 13.6000\n",
      " |~~ train@20820  Loss: 0.037433 Acc: 13.4000\n",
      " |~~ train@20825  Loss: 0.027301 Acc: 13.6000\n",
      " |~~ train@20830  Loss: 0.010769 Acc: 14.0000\n",
      " |~~ train@20835  Loss: 0.031985 Acc: 13.2000\n",
      " |~~ train@20840  Loss: 0.036850 Acc: 13.2000\n",
      " |~~ train@20845  Loss: 0.039070 Acc: 13.2000\n",
      " |~~ train@20850  Loss: 0.015119 Acc: 13.8000\n",
      " |~~ train@20855  Loss: 0.048160 Acc: 13.2000\n",
      " |~~ train@20860  Loss: 0.018249 Acc: 13.8000\n",
      " |~~ train@20865  Loss: 0.018829 Acc: 13.6000\n",
      " |~~ train@20870  Loss: 0.015701 Acc: 13.8000\n",
      " |~~ train@20875  Loss: 0.043772 Acc: 13.2000\n",
      " |~~ train@20880  Loss: 0.038038 Acc: 13.4000\n",
      " |~~ train@20885  Loss: 0.017443 Acc: 13.8000\n",
      " |~~ train@20890  Loss: 0.037941 Acc: 12.8000\n",
      " |~~ train@20895  Loss: 0.046668 Acc: 13.2000\n",
      " |~~ train@20900  Loss: 0.036949 Acc: 13.4000\n",
      " |~~ train@20905  Loss: 0.036689 Acc: 13.2000\n",
      " |~~ train@20910  Loss: 0.035304 Acc: 13.2000\n",
      " |~~ train@20915  Loss: 0.037145 Acc: 13.4000\n",
      " |~~ train@20920  Loss: 0.031101 Acc: 13.6000\n",
      " |~~ train@20925  Loss: 0.025012 Acc: 13.6000\n",
      " |~~ train@20930  Loss: 0.023359 Acc: 13.6000\n",
      " |~~ train@20935  Loss: 0.065272 Acc: 12.8000\n",
      " |~~ train@20940  Loss: 0.065758 Acc: 12.4000\n",
      " |~~ train@20945  Loss: 0.038497 Acc: 13.0000\n",
      " |~~ train@20950  Loss: 0.043500 Acc: 13.0000\n",
      " |~~ train@20955  Loss: 0.041654 Acc: 13.2000\n",
      " |~~ train@20960  Loss: 0.035263 Acc: 13.2000\n",
      " |~~ train@20965  Loss: 0.059868 Acc: 12.8000\n",
      " |~~ train@20970  Loss: 0.043301 Acc: 13.4000\n",
      " |~~ train@20975  Loss: 0.037930 Acc: 13.0000\n",
      " |~~ train@20980  Loss: 0.019184 Acc: 13.8000\n",
      " |~~ train@20985  Loss: 0.012303 Acc: 13.8000\n",
      " |~~ train@20990  Loss: 0.062067 Acc: 12.4000\n",
      " |~~ train@20995  Loss: 0.030632 Acc: 13.4000\n",
      " |~~ train@21000  Loss: 0.032928 Acc: 13.2000\n",
      " |~~ train@21005  Loss: 0.035311 Acc: 13.2000\n",
      " |~~ train@21010  Loss: 0.035858 Acc: 13.4000\n",
      " |~~ train@21015  Loss: 0.053810 Acc: 12.6000\n",
      " |~~ train@21020  Loss: 0.032216 Acc: 13.4000\n",
      " |~~ train@21025  Loss: 0.055045 Acc: 12.8000\n",
      " |~~ train@21030  Loss: 0.049110 Acc: 12.8000\n",
      " |~~ train@21035  Loss: 0.040917 Acc: 13.0000\n",
      " |~~ train@21040  Loss: 0.043073 Acc: 13.0000\n",
      " |~~ train@21045  Loss: 0.022524 Acc: 13.8000\n",
      " |~~ train@21050  Loss: 0.040644 Acc: 13.2000\n",
      " |~~ train@21055  Loss: 0.028284 Acc: 13.4000\n",
      " |~~ train@21060  Loss: 0.015415 Acc: 13.8000\n",
      " |~~ train@21065  Loss: 0.059590 Acc: 12.8000\n",
      " |~~ train@21070  Loss: 0.021588 Acc: 13.8000\n",
      " |~~ train@21075  Loss: 0.026300 Acc: 13.4000\n",
      " |~~ train@21080  Loss: 0.054629 Acc: 12.6000\n",
      " |~~ train@21085  Loss: 0.038143 Acc: 13.4000\n",
      " |~~ train@21090  Loss: 0.021468 Acc: 13.8000\n",
      " |~~ train@21095  Loss: 0.047992 Acc: 12.8000\n",
      " |~~ train@21100  Loss: 0.029748 Acc: 13.2000\n",
      " |~~ train@21105  Loss: 0.041911 Acc: 13.2000\n",
      " |~~ train@21110  Loss: 0.023085 Acc: 13.6000\n",
      " |~~ train@21115  Loss: 0.033883 Acc: 13.2000\n",
      " |~~ train@21120  Loss: 0.051729 Acc: 12.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@21125  Loss: 0.031197 Acc: 13.6000\n",
      " |~~ train@21130  Loss: 0.016609 Acc: 13.6000\n",
      " |~~ train@21135  Loss: 0.033339 Acc: 13.2000\n",
      " |~~ train@21140  Loss: 0.011890 Acc: 14.0000\n",
      " |~~ train@21145  Loss: 0.042438 Acc: 13.4000\n",
      " |~~ train@21150  Loss: 0.012911 Acc: 13.8000\n",
      " |~~ train@21155  Loss: 0.027568 Acc: 13.4000\n",
      " |~~ train@21160  Loss: 0.016086 Acc: 13.8000\n",
      " |~~ train@21165  Loss: 0.035932 Acc: 13.4000\n",
      " |~~ train@21170  Loss: 0.012173 Acc: 14.0000\n",
      " |~~ train@21175  Loss: 0.011468 Acc: 14.0000\n",
      " |~~ train@21180  Loss: 0.044417 Acc: 13.0000\n",
      " |~~ train@21185  Loss: 0.034500 Acc: 13.4000\n",
      " |~~ train@21190  Loss: 0.024534 Acc: 13.6000\n",
      " |~~ train@21195  Loss: 0.048542 Acc: 13.0000\n",
      " |~~ train@21200  Loss: 0.033424 Acc: 13.4000\n",
      " |~~ train@21205  Loss: 0.031892 Acc: 13.4000\n",
      " |~~ train@21210  Loss: 0.038636 Acc: 13.0000\n",
      " |~~ train@21215  Loss: 0.058419 Acc: 12.8000\n",
      " |~~ train@21220  Loss: 0.031702 Acc: 13.2000\n",
      " |~~ train@21225  Loss: 0.047491 Acc: 12.8000\n",
      " |~~ train@21230  Loss: 0.042591 Acc: 13.2000\n",
      " |~~ train@21235  Loss: 0.029230 Acc: 13.4000\n",
      " |~~ train@21240  Loss: 0.037562 Acc: 13.2000\n",
      " |~~ train@21245  Loss: 0.050527 Acc: 12.8000\n",
      " |~~ train@21250  Loss: 0.026069 Acc: 13.4000\n",
      " |~~ train@21255  Loss: 0.054861 Acc: 12.6000\n",
      " |~~ train@21260  Loss: 0.023925 Acc: 13.4000\n",
      " |~~ train@21265  Loss: 0.042230 Acc: 13.0000\n",
      " |~~ train@21270  Loss: 0.032800 Acc: 13.2000\n",
      " |~~ train@21275  Loss: 0.015167 Acc: 13.8000\n",
      " |~~ train@21280  Loss: 0.035496 Acc: 13.4000\n",
      " |~~ train@21285  Loss: 0.056495 Acc: 12.8000\n",
      " |~~ train@21290  Loss: 0.028637 Acc: 13.6000\n",
      " |~~ train@21295  Loss: 0.015005 Acc: 13.8000\n",
      " |~~ train@21300  Loss: 0.032018 Acc: 13.6000\n",
      " |~~ train@21305  Loss: 0.014785 Acc: 13.8000\n",
      " |~~ train@21310  Loss: 0.038972 Acc: 13.2000\n",
      " |~~ train@21315  Loss: 0.031063 Acc: 13.4000\n",
      " |~~ train@21320  Loss: 0.018610 Acc: 13.8000\n",
      " |~~ train@21325  Loss: 0.113092 Acc: 11.4000\n",
      " |~~ train@21330  Loss: 0.023316 Acc: 13.4000\n",
      " |~~ train@21335  Loss: 0.024957 Acc: 13.4000\n",
      " |~~ train@21340  Loss: 0.027876 Acc: 13.4000\n",
      " |~~ train@21345  Loss: 0.021743 Acc: 13.4000\n",
      " |~~ train@21350  Loss: 0.039632 Acc: 13.2000\n",
      " |~~ train@21355  Loss: 0.038842 Acc: 13.4000\n",
      " |~~ train@21360  Loss: 0.037427 Acc: 13.4000\n",
      " |~~ train@21365  Loss: 0.026707 Acc: 13.4000\n",
      " |~~ train@21370  Loss: 0.039197 Acc: 13.0000\n",
      " |~~ train@21375  Loss: 0.058492 Acc: 12.4000\n",
      " |~~ train@21380  Loss: 0.045709 Acc: 13.0000\n",
      " |~~ train@21385  Loss: 0.036897 Acc: 13.2000\n",
      " |~~ train@21390  Loss: 0.027384 Acc: 13.6000\n",
      " |~~ train@21395  Loss: 0.036550 Acc: 13.2000\n",
      " |~~ train@21400  Loss: 0.036939 Acc: 13.4000\n",
      " |~~ train@21405  Loss: 0.031370 Acc: 13.6000\n",
      " |~~ train@21410  Loss: 0.085171 Acc: 12.0000\n",
      " |~~ train@21415  Loss: 0.032470 Acc: 13.4000\n",
      " |~~ train@21420  Loss: 0.064091 Acc: 12.6000\n",
      " |~~ train@21425  Loss: 0.032960 Acc: 13.4000\n",
      " |~~ train@21430  Loss: 0.016590 Acc: 13.8000\n",
      " |~~ train@21435  Loss: 0.048554 Acc: 12.8000\n",
      " |~~ train@21440  Loss: 0.025666 Acc: 13.4000\n",
      " |~~ train@21445  Loss: 0.041916 Acc: 12.8000\n",
      " |~~ train@21450  Loss: 0.011431 Acc: 14.0000\n",
      " |~~ train@21455  Loss: 0.040739 Acc: 13.0000\n",
      " |~~ train@21460  Loss: 0.027146 Acc: 13.4000\n",
      " |~~ train@21465  Loss: 0.034674 Acc: 13.2000\n",
      " |~~ train@21470  Loss: 0.050634 Acc: 13.0000\n",
      " |~~ train@21475  Loss: 0.041856 Acc: 13.2000\n",
      " |~~ train@21480  Loss: 0.051956 Acc: 12.6000\n",
      " |~~ train@21485  Loss: 0.027020 Acc: 13.6000\n",
      " |~~ train@21490  Loss: 0.032160 Acc: 13.2000\n",
      " |~~ train@21495  Loss: 0.020161 Acc: 13.6000\n",
      " |~~ train@21500  Loss: 0.040728 Acc: 13.0000\n",
      " |~~ train@21505  Loss: 0.077795 Acc: 11.8000\n",
      " |~~ train@21510  Loss: 0.041316 Acc: 13.2000\n",
      " |~~ train@21515  Loss: 0.040570 Acc: 13.2000\n",
      " |~~ train@21520  Loss: 0.045430 Acc: 12.8000\n",
      " |~~ train@21525  Loss: 0.041854 Acc: 13.0000\n",
      " |~~ train@21530  Loss: 0.048487 Acc: 13.0000\n",
      " |~~ train@21535  Loss: 0.020976 Acc: 13.6000\n",
      " |~~ train@21540  Loss: 0.030336 Acc: 13.6000\n",
      " |~~ train@21545  Loss: 0.025812 Acc: 13.6000\n",
      " |~~ train@21550  Loss: 0.063436 Acc: 12.8000\n",
      " |~~ train@21555  Loss: 0.015669 Acc: 13.8000\n",
      " |~~ train@21560  Loss: 0.054408 Acc: 12.6000\n",
      " |~~ train@21565  Loss: 0.036901 Acc: 13.2000\n",
      " |~~ train@21570  Loss: 0.042691 Acc: 13.0000\n",
      " |~~ train@21575  Loss: 0.034528 Acc: 13.4000\n",
      " |~~ train@21580  Loss: 0.045951 Acc: 12.8000\n",
      " |~~ train@21585  Loss: 0.034251 Acc: 13.4000\n",
      " |~~ train@21590  Loss: 0.031944 Acc: 13.4000\n",
      " |~~ train@21595  Loss: 0.065589 Acc: 12.2000\n",
      " |~~ train@21600  Loss: 0.046593 Acc: 13.2000\n",
      " |~~ train@21605  Loss: 0.032060 Acc: 13.2000\n",
      " |~~ train@21610  Loss: 0.026026 Acc: 13.4000\n",
      " |~~ train@21615  Loss: 0.020006 Acc: 13.6000\n",
      " |~~ train@21620  Loss: 0.020054 Acc: 13.6000\n",
      " |~~ train@21625  Loss: 0.042773 Acc: 13.0000\n",
      " |~~ train@21630  Loss: 0.052135 Acc: 13.0000\n",
      " |~~ train@21635  Loss: 0.024154 Acc: 13.2000\n",
      " |~~ train@21640  Loss: 0.027849 Acc: 13.4000\n",
      " |~~ train@21645  Loss: 0.025828 Acc: 13.2000\n",
      " |~~ train@21650  Loss: 0.031458 Acc: 13.4000\n",
      " |~~ train@21655  Loss: 0.032854 Acc: 13.2000\n",
      " |~~ train@21660  Loss: 0.028945 Acc: 13.6000\n",
      " |~~ train@21665  Loss: 0.026660 Acc: 13.6000\n",
      " |~~ train@21670  Loss: 0.028294 Acc: 13.6000\n",
      " |~~ train@21675  Loss: 0.029501 Acc: 13.4000\n",
      " |~~ train@21680  Loss: 0.024735 Acc: 13.8000\n",
      " |~~ train@21685  Loss: 0.066273 Acc: 13.0000\n",
      " |~~ train@21690  Loss: 0.024151 Acc: 13.6000\n",
      " |~~ train@21695  Loss: 0.063862 Acc: 12.6000\n",
      " |~~ train@21700  Loss: 0.082795 Acc: 12.6000\n",
      " |~~ train@21705  Loss: 0.020487 Acc: 13.4000\n",
      " |~~ train@21710  Loss: 0.030937 Acc: 13.4000\n",
      " |~~ train@21715  Loss: 0.031899 Acc: 13.2000\n",
      " |~~ train@21720  Loss: 0.047246 Acc: 12.6000\n",
      " |~~ train@21725  Loss: 0.040000 Acc: 13.0000\n",
      " |~~ train@21730  Loss: 0.025177 Acc: 13.6000\n",
      " |~~ train@21735  Loss: 0.022874 Acc: 13.8000\n",
      " |~~ train@21740  Loss: 0.028644 Acc: 13.4000\n",
      " |~~ train@21745  Loss: 0.042555 Acc: 13.2000\n",
      " |~~ train@21750  Loss: 0.012510 Acc: 14.0000\n",
      " |~~ train@21755  Loss: 0.049888 Acc: 13.0000\n",
      " |~~ train@21760  Loss: 0.061064 Acc: 12.4000\n",
      " |~~ train@21765  Loss: 0.042316 Acc: 13.2000\n",
      " |~~ train@21770  Loss: 0.080868 Acc: 12.2000\n",
      " |~~ train@21775  Loss: 0.019577 Acc: 13.8000\n",
      " |~~ train@21780  Loss: 0.042917 Acc: 12.8000\n",
      " |~~ train@21785  Loss: 0.023144 Acc: 13.8000\n",
      " |~~ train@21790  Loss: 0.064419 Acc: 12.6000\n",
      " |~~ train@21795  Loss: 0.046613 Acc: 13.2000\n",
      " |~~ train@21800  Loss: 0.021254 Acc: 13.6000\n",
      " |~~ train@21805  Loss: 0.026085 Acc: 13.6000\n",
      " |~~ train@21810  Loss: 0.031939 Acc: 13.4000\n",
      " |~~ train@21815  Loss: 0.022382 Acc: 13.8000\n",
      " |~~ train@21820  Loss: 0.024435 Acc: 13.6000\n",
      " |~~ train@21825  Loss: 0.040777 Acc: 13.0000\n",
      " |~~ train@21830  Loss: 0.057493 Acc: 13.0000\n",
      " |~~ train@21835  Loss: 0.024109 Acc: 13.4000\n",
      " |~~ train@21840  Loss: 0.045475 Acc: 13.0000\n",
      " |~~ train@21845  Loss: 0.019956 Acc: 13.8000\n",
      " |~~ train@21850  Loss: 0.015369 Acc: 13.8000\n",
      " |~~ train@21855  Loss: 0.045648 Acc: 13.0000\n",
      " |~~ train@21860  Loss: 0.049579 Acc: 13.2000\n",
      " |~~ train@21865  Loss: 0.029820 Acc: 13.2000\n",
      " |~~ train@21870  Loss: 0.034446 Acc: 13.4000\n",
      " |~~ train@21875  Loss: 0.032959 Acc: 13.4000\n",
      " |~~ train@21880  Loss: 0.028204 Acc: 13.4000\n",
      " |~~ train@21885  Loss: 0.017720 Acc: 13.8000\n",
      " |~~ train@21890  Loss: 0.060006 Acc: 12.8000\n",
      " |~~ train@21895  Loss: 0.033563 Acc: 13.4000\n",
      " |~~ train@21900  Loss: 0.029917 Acc: 13.4000\n",
      " |~~ train@21905  Loss: 0.022324 Acc: 13.6000\n",
      " |~~ train@21910  Loss: 0.016659 Acc: 13.8000\n",
      " |~~ train@21915  Loss: 0.071590 Acc: 12.4000\n",
      " |~~ train@21920  Loss: 0.026596 Acc: 13.4000\n",
      " |~~ train@21925  Loss: 0.062698 Acc: 12.8000\n",
      " |~~ train@21930  Loss: 0.100297 Acc: 11.4000\n",
      " |~~ train@21935  Loss: 0.028408 Acc: 13.6000\n",
      " |~~ train@21940  Loss: 0.029237 Acc: 13.4000\n",
      " |~~ train@21945  Loss: 0.029018 Acc: 13.4000\n",
      " |~~ train@21950  Loss: 0.016841 Acc: 13.8000\n",
      " |~~ train@21955  Loss: 0.052584 Acc: 13.0000\n",
      " |~~ train@21960  Loss: 0.037748 Acc: 13.4000\n",
      " |~~ train@21965  Loss: 0.032389 Acc: 13.4000\n",
      " |~~ train@21970  Loss: 0.034149 Acc: 13.2000\n",
      " |~~ train@21975  Loss: 0.034078 Acc: 13.2000\n",
      " |~~ train@21980  Loss: 0.047035 Acc: 13.0000\n",
      " |~~ train@21985  Loss: 0.013409 Acc: 13.8000\n",
      " |~~ train@21990  Loss: 0.017290 Acc: 13.8000\n",
      " |~~ train@21995  Loss: 0.062669 Acc: 12.8000\n",
      " |~~ train@22000  Loss: 0.092629 Acc: 12.2000\n",
      " |~~ train@22005  Loss: 0.043782 Acc: 13.0000\n",
      " |~~ train@22010  Loss: 0.054762 Acc: 12.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@22015  Loss: 0.036421 Acc: 13.0000\n",
      " |~~ train@22020  Loss: 0.046133 Acc: 12.8000\n",
      " |~~ train@22025  Loss: 0.037396 Acc: 13.4000\n",
      " |~~ train@22030  Loss: 0.042473 Acc: 13.2000\n",
      " |~~ train@22035  Loss: 0.063434 Acc: 12.4000\n",
      " |~~ train@22040  Loss: 0.025697 Acc: 13.6000\n",
      " |~~ train@22045  Loss: 0.024144 Acc: 13.6000\n",
      " |~~ train@22050  Loss: 0.052558 Acc: 12.8000\n",
      " |~~ train@22055  Loss: 0.036768 Acc: 13.2000\n",
      " |~~ train@22060  Loss: 0.026119 Acc: 13.4000\n",
      " |~~ train@22065  Loss: 0.027502 Acc: 13.4000\n",
      " |~~ train@22070  Loss: 0.030439 Acc: 13.6000\n",
      " |~~ train@22075  Loss: 0.036251 Acc: 13.2000\n",
      " |~~ train@22080  Loss: 0.046545 Acc: 13.0000\n",
      " |~~ train@22085  Loss: 0.018820 Acc: 13.8000\n",
      " |~~ train@22090  Loss: 0.035003 Acc: 13.2000\n",
      " |~~ train@22095  Loss: 0.062575 Acc: 12.6000\n",
      " |~~ train@22100  Loss: 0.032737 Acc: 13.4000\n",
      " |~~ train@22105  Loss: 0.029963 Acc: 13.2000\n",
      " |~~ train@22110  Loss: 0.020758 Acc: 13.4000\n",
      " |~~ train@22115  Loss: 0.039769 Acc: 13.2000\n",
      " |~~ train@22120  Loss: 0.045247 Acc: 13.0000\n",
      " |~~ train@22125  Loss: 0.017491 Acc: 13.8000\n",
      " |~~ train@22130  Loss: 0.019983 Acc: 13.8000\n",
      " |~~ train@22135  Loss: 0.069113 Acc: 12.4000\n",
      " |~~ train@22140  Loss: 0.041862 Acc: 13.0000\n",
      " |~~ train@22145  Loss: 0.022065 Acc: 13.6000\n",
      " |~~ train@22150  Loss: 0.019631 Acc: 13.8000\n",
      " |~~ train@22155  Loss: 0.019113 Acc: 13.6000\n",
      " |~~ train@22160  Loss: 0.087929 Acc: 12.0000\n",
      " |~~ train@22165  Loss: 0.026131 Acc: 13.4000\n",
      " |~~ train@22170  Loss: 0.049689 Acc: 12.8000\n",
      " |~~ train@22175  Loss: 0.041403 Acc: 13.4000\n",
      " |~~ train@22180  Loss: 0.019969 Acc: 13.6000\n",
      " |~~ train@22185  Loss: 0.028735 Acc: 13.4000\n",
      " |~~ train@22190  Loss: 0.032932 Acc: 13.4000\n",
      " |~~ train@22195  Loss: 0.020867 Acc: 13.8000\n",
      " |~~ train@22200  Loss: 0.019002 Acc: 13.8000\n",
      " |~~ train@22205  Loss: 0.027363 Acc: 13.4000\n",
      " |~~ train@22210  Loss: 0.024726 Acc: 13.4000\n",
      " |~~ train@22215  Loss: 0.041063 Acc: 13.2000\n",
      " |~~ train@22220  Loss: 0.035137 Acc: 13.4000\n",
      " |~~ train@22225  Loss: 0.057315 Acc: 12.4000\n",
      " |~~ train@22230  Loss: 0.027578 Acc: 13.6000\n",
      " |~~ train@22235  Loss: 0.048457 Acc: 13.0000\n",
      " |~~ train@22240  Loss: 0.029327 Acc: 13.6000\n",
      " |~~ train@22245  Loss: 0.018068 Acc: 13.6000\n",
      " |~~ train@22250  Loss: 0.035588 Acc: 13.4000\n",
      " |~~ train@22255  Loss: 0.032091 Acc: 13.2000\n",
      " |~~ train@22260  Loss: 0.020826 Acc: 13.6000\n",
      " |~~ train@22265  Loss: 0.025872 Acc: 13.6000\n",
      " |~~ train@22270  Loss: 0.025786 Acc: 13.6000\n",
      " |~~ train@22275  Loss: 0.044184 Acc: 13.2000\n",
      " |~~ train@22280  Loss: 0.023025 Acc: 13.8000\n",
      " |~~ train@22285  Loss: 0.038445 Acc: 13.2000\n",
      " |~~ train@22290  Loss: 0.022814 Acc: 13.6000\n",
      " |~~ train@22295  Loss: 0.045655 Acc: 13.2000\n",
      " |~~ train@22300  Loss: 0.036037 Acc: 13.2000\n",
      " |~~ train@22305  Loss: 0.068238 Acc: 12.4000\n",
      " |~~ train@22310  Loss: 0.029059 Acc: 13.6000\n",
      " |~~ train@22315  Loss: 0.049627 Acc: 13.0000\n",
      " |~~ train@22320  Loss: 0.052218 Acc: 13.0000\n",
      " |~~ train@22325  Loss: 0.019952 Acc: 13.8000\n",
      " |~~ train@22330  Loss: 0.036380 Acc: 13.2000\n",
      " |~~ train@22335  Loss: 0.073246 Acc: 12.4000\n",
      " |~~ train@22340  Loss: 0.010851 Acc: 14.0000\n",
      " |~~ train@22345  Loss: 0.052736 Acc: 12.8000\n",
      " |~~ train@22350  Loss: 0.049196 Acc: 13.0000\n",
      " |~~ train@22355  Loss: 0.079505 Acc: 12.6000\n",
      " |~~ train@22360  Loss: 0.032208 Acc: 13.4000\n",
      " |~~ train@22365  Loss: 0.010211 Acc: 14.0000\n",
      " |~~ train@22370  Loss: 0.054228 Acc: 13.0000\n",
      " |~~ train@22375  Loss: 0.038439 Acc: 13.0000\n",
      " |~~ train@22380  Loss: 0.011026 Acc: 14.0000\n",
      " |~~ train@22385  Loss: 0.038504 Acc: 13.2000\n",
      " |~~ train@22390  Loss: 0.030939 Acc: 13.2000\n",
      " |~~ train@22395  Loss: 0.033682 Acc: 13.4000\n",
      " |~~ train@22400  Loss: 0.020746 Acc: 13.6000\n",
      " |~~ train@22405  Loss: 0.043435 Acc: 13.2000\n",
      " |~~ train@22410  Loss: 0.030249 Acc: 13.4000\n",
      " |~~ train@22415  Loss: 0.016821 Acc: 13.8000\n",
      " |~~ train@22420  Loss: 0.021320 Acc: 13.6000\n",
      " |~~ train@22425  Loss: 0.058795 Acc: 12.6000\n",
      " |~~ train@22430  Loss: 0.027981 Acc: 13.4000\n",
      " |~~ train@22435  Loss: 0.020564 Acc: 13.8000\n",
      " |~~ train@22440  Loss: 0.043457 Acc: 13.0000\n",
      " |~~ train@22445  Loss: 0.024324 Acc: 13.4000\n",
      " |~~ train@22450  Loss: 0.020386 Acc: 13.6000\n",
      " |~~ train@22455  Loss: 0.075855 Acc: 12.4000\n",
      " |~~ train@22460  Loss: 0.033699 Acc: 13.2000\n",
      " |~~ train@22465  Loss: 0.040442 Acc: 13.2000\n",
      " |~~ train@22470  Loss: 0.068663 Acc: 12.6000\n",
      " |~~ train@22475  Loss: 0.030729 Acc: 13.4000\n",
      " |~~ train@22480  Loss: 0.024267 Acc: 13.6000\n",
      " |~~ train@22485  Loss: 0.062060 Acc: 12.6000\n",
      " |~~ train@22490  Loss: 0.074788 Acc: 12.2000\n",
      " |~~ train@22495  Loss: 0.020514 Acc: 13.6000\n",
      " |~~ train@22500  Loss: 0.052799 Acc: 12.8000\n",
      " |~~ train@22505  Loss: 0.031919 Acc: 13.2000\n",
      " |~~ train@22510  Loss: 0.039118 Acc: 13.2000\n",
      " |~~ train@22515  Loss: 0.028285 Acc: 13.6000\n",
      " |~~ train@22520  Loss: 0.044151 Acc: 13.0000\n",
      " |~~ train@22525  Loss: 0.057828 Acc: 12.6000\n",
      " |~~ train@22530  Loss: 0.032459 Acc: 13.4000\n",
      " |~~ train@22535  Loss: 0.102304 Acc: 11.6000\n",
      " |~~ train@22540  Loss: 0.030828 Acc: 13.4000\n",
      " |~~ train@22545  Loss: 0.019414 Acc: 13.6000\n",
      " |~~ train@22550  Loss: 0.066950 Acc: 12.8000\n",
      " |~~ train@22555  Loss: 0.057937 Acc: 13.0000\n",
      " |~~ train@22560  Loss: 0.037983 Acc: 13.2000\n",
      " |~~ train@22565  Loss: 0.011783 Acc: 14.0000\n",
      " |~~ train@22570  Loss: 0.051677 Acc: 12.8000\n",
      " |~~ train@22575  Loss: 0.062244 Acc: 12.6000\n",
      " |~~ train@22580  Loss: 0.018843 Acc: 13.6000\n",
      " |~~ train@22585  Loss: 0.040925 Acc: 13.0000\n",
      " |~~ train@22590  Loss: 0.072461 Acc: 12.4000\n",
      " |~~ train@22595  Loss: 0.049738 Acc: 13.0000\n",
      " |~~ train@22600  Loss: 0.032378 Acc: 13.4000\n",
      " |~~ train@22605  Loss: 0.034511 Acc: 13.2000\n",
      " |~~ train@22610  Loss: 0.042815 Acc: 13.0000\n",
      " |~~ train@22615  Loss: 0.022435 Acc: 13.8000\n",
      " |~~ train@22620  Loss: 0.041900 Acc: 12.8000\n",
      " |~~ train@22625  Loss: 0.042898 Acc: 13.0000\n",
      " |~~ train@22630  Loss: 0.016888 Acc: 13.8000\n",
      " |~~ train@22635  Loss: 0.049486 Acc: 13.0000\n",
      " |~~ train@22640  Loss: 0.024364 Acc: 13.4000\n",
      " |~~ train@22645  Loss: 0.046841 Acc: 13.0000\n",
      " |~~ train@22650  Loss: 0.012924 Acc: 14.0000\n",
      " |~~ train@22655  Loss: 0.036113 Acc: 13.0000\n",
      " |~~ train@22660  Loss: 0.031438 Acc: 13.6000\n",
      " |~~ train@22665  Loss: 0.047216 Acc: 13.0000\n",
      " |~~ train@22670  Loss: 0.063788 Acc: 12.6000\n",
      " |~~ train@22675  Loss: 0.045872 Acc: 13.0000\n",
      " |~~ train@22680  Loss: 0.027774 Acc: 13.6000\n",
      " |~~ train@22685  Loss: 0.012466 Acc: 14.0000\n",
      " |~~ train@22690  Loss: 0.068992 Acc: 12.4000\n",
      " |~~ train@22695  Loss: 0.055013 Acc: 13.0000\n",
      " |~~ train@22700  Loss: 0.045383 Acc: 13.0000\n",
      " |~~ train@22705  Loss: 0.036088 Acc: 13.2000\n",
      " |~~ train@22710  Loss: 0.028476 Acc: 13.4000\n",
      " |~~ train@22715  Loss: 0.020880 Acc: 13.8000\n",
      " |~~ train@22720  Loss: 0.043300 Acc: 12.8000\n",
      " |~~ train@22725  Loss: 0.041115 Acc: 13.0000\n",
      " |~~ train@22730  Loss: 0.017196 Acc: 13.8000\n",
      " |~~ train@22735  Loss: 0.018392 Acc: 13.8000\n",
      " |~~ train@22740  Loss: 0.032920 Acc: 13.4000\n",
      " |~~ train@22745  Loss: 0.040744 Acc: 13.2000\n",
      " |~~ train@22750  Loss: 0.035837 Acc: 13.2000\n",
      " |~~ train@22755  Loss: 0.022323 Acc: 13.6000\n",
      " |~~ train@22760  Loss: 0.023930 Acc: 13.8000\n",
      " |~~ train@22765  Loss: 0.041399 Acc: 13.2000\n",
      " |~~ train@22770  Loss: 0.029624 Acc: 13.6000\n",
      " |~~ train@22775  Loss: 0.013426 Acc: 14.0000\n",
      " |~~ train@22780  Loss: 0.047601 Acc: 13.2000\n",
      " |~~ train@22785  Loss: 0.019754 Acc: 13.8000\n",
      " |~~ train@22790  Loss: 0.060747 Acc: 12.6000\n",
      " |~~ train@22795  Loss: 0.052037 Acc: 13.0000\n",
      " |~~ train@22800  Loss: 0.035739 Acc: 13.4000\n",
      " |~~ train@22805  Loss: 0.045272 Acc: 12.8000\n",
      " |~~ train@22810  Loss: 0.053368 Acc: 12.8000\n",
      " |~~ train@22815  Loss: 0.019175 Acc: 13.6000\n",
      " |~~ train@22820  Loss: 0.025026 Acc: 13.4000\n",
      " |~~ train@22825  Loss: 0.018509 Acc: 13.8000\n",
      " |~~ train@22830  Loss: 0.023823 Acc: 13.6000\n",
      " |~~ train@22835  Loss: 0.058580 Acc: 12.8000\n",
      " |~~ train@22840  Loss: 0.029036 Acc: 13.6000\n",
      " |~~ train@22845  Loss: 0.032095 Acc: 13.4000\n",
      " |~~ train@22850  Loss: 0.037552 Acc: 13.2000\n",
      " |~~ train@22855  Loss: 0.036848 Acc: 13.0000\n",
      " |~~ train@22860  Loss: 0.023497 Acc: 13.8000\n",
      " |~~ train@22865  Loss: 0.031947 Acc: 13.6000\n",
      " |~~ train@22870  Loss: 0.015167 Acc: 13.8000\n",
      " |~~ train@22875  Loss: 0.026030 Acc: 13.6000\n",
      " |~~ train@22880  Loss: 0.024321 Acc: 13.6000\n",
      " |~~ train@22885  Loss: 0.088872 Acc: 12.2000\n",
      " |~~ train@22890  Loss: 0.035119 Acc: 13.4000\n",
      " |~~ train@22895  Loss: 0.025432 Acc: 13.6000\n",
      " |~~ train@22900  Loss: 0.010010 Acc: 14.0000\n",
      " |~~ train@22905  Loss: 0.043307 Acc: 13.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@22910  Loss: 0.027332 Acc: 13.4000\n",
      " |~~ train@22915  Loss: 0.019883 Acc: 13.8000\n",
      " |~~ train@22920  Loss: 0.075129 Acc: 12.2000\n",
      " |~~ train@22925  Loss: 0.020952 Acc: 13.6000\n",
      " |~~ train@22930  Loss: 0.009980 Acc: 14.0000\n",
      " |~~ train@22935  Loss: 0.044072 Acc: 12.8000\n",
      " |~~ train@22940  Loss: 0.040043 Acc: 13.2000\n",
      " |~~ train@22945  Loss: 0.039263 Acc: 13.0000\n",
      " |~~ train@22950  Loss: 0.024208 Acc: 13.6000\n",
      " |~~ train@22955  Loss: 0.024112 Acc: 13.6000\n",
      " |~~ train@22960  Loss: 0.028535 Acc: 13.6000\n",
      " |~~ train@22965  Loss: 0.053639 Acc: 13.0000\n",
      " |~~ train@22970  Loss: 0.032921 Acc: 13.4000\n",
      " |~~ train@22975  Loss: 0.030806 Acc: 13.4000\n",
      " |~~ train@22980  Loss: 0.031086 Acc: 13.4000\n",
      " |~~ train@22985  Loss: 0.034519 Acc: 13.2000\n",
      " |~~ train@22990  Loss: 0.034269 Acc: 13.2000\n",
      " |~~ train@22995  Loss: 0.031063 Acc: 13.4000\n",
      " |~~ train@23000  Loss: 0.040894 Acc: 13.2000\n",
      " |~~ train@23005  Loss: 0.066590 Acc: 12.8000\n",
      " |~~ train@23010  Loss: 0.015005 Acc: 13.8000\n",
      " |~~ train@23015  Loss: 0.019561 Acc: 13.6000\n",
      " |~~ train@23020  Loss: 0.010403 Acc: 14.0000\n",
      " |~~ train@23025  Loss: 0.018733 Acc: 13.6000\n",
      " |~~ train@23030  Loss: 0.026834 Acc: 13.6000\n",
      " |~~ train@23035  Loss: 0.036289 Acc: 13.4000\n",
      " |~~ train@23040  Loss: 0.029606 Acc: 13.6000\n",
      " |~~ train@23045  Loss: 0.070060 Acc: 12.4000\n",
      " |~~ train@23050  Loss: 0.023500 Acc: 13.6000\n",
      " |~~ train@23055  Loss: 0.038009 Acc: 13.2000\n",
      " |~~ train@23060  Loss: 0.021096 Acc: 13.8000\n",
      " |~~ train@23065  Loss: 0.044052 Acc: 13.0000\n",
      " |~~ train@23070  Loss: 0.065423 Acc: 12.4000\n",
      " |~~ train@23075  Loss: 0.017670 Acc: 13.6000\n",
      " |~~ train@23080  Loss: 0.054670 Acc: 12.8000\n",
      " |~~ train@23085  Loss: 0.009258 Acc: 14.0000\n",
      " |~~ train@23090  Loss: 0.038561 Acc: 13.2000\n",
      " |~~ train@23095  Loss: 0.036522 Acc: 13.4000\n",
      " |~~ train@23100  Loss: 0.037052 Acc: 13.2000\n",
      " |~~ train@23105  Loss: 0.009884 Acc: 14.0000\n",
      " |~~ train@23110  Loss: 0.023226 Acc: 13.6000\n",
      " |~~ train@23115  Loss: 0.064462 Acc: 12.4000\n",
      " |~~ train@23120  Loss: 0.015007 Acc: 13.8000\n",
      " |~~ train@23125  Loss: 0.032941 Acc: 13.2000\n",
      " |~~ train@23130  Loss: 0.046168 Acc: 13.0000\n",
      " |~~ train@23135  Loss: 0.040942 Acc: 13.2000\n",
      " |~~ train@23140  Loss: 0.037991 Acc: 13.2000\n",
      " |~~ train@23145  Loss: 0.027963 Acc: 13.6000\n",
      " |~~ train@23150  Loss: 0.052725 Acc: 12.8000\n",
      " |~~ train@23155  Loss: 0.011723 Acc: 14.0000\n",
      " |~~ train@23160  Loss: 0.041614 Acc: 13.2000\n",
      " |~~ train@23165  Loss: 0.010709 Acc: 14.0000\n",
      " |~~ train@23170  Loss: 0.045930 Acc: 12.8000\n",
      " |~~ train@23175  Loss: 0.035435 Acc: 13.2000\n",
      " |~~ train@23180  Loss: 0.037655 Acc: 13.2000\n",
      " |~~ train@23185  Loss: 0.033011 Acc: 13.2000\n",
      " |~~ train@23190  Loss: 0.041850 Acc: 13.0000\n",
      " |~~ train@23195  Loss: 0.036799 Acc: 13.2000\n",
      " |~~ train@23200  Loss: 0.020191 Acc: 13.8000\n",
      " |~~ train@23205  Loss: 0.067520 Acc: 12.4000\n",
      " |~~ train@23210  Loss: 0.024574 Acc: 13.6000\n",
      " |~~ train@23215  Loss: 0.024520 Acc: 13.6000\n",
      " |~~ train@23220  Loss: 0.041532 Acc: 13.0000\n",
      " |~~ train@23225  Loss: 0.032005 Acc: 13.4000\n",
      " |~~ train@23230  Loss: 0.043499 Acc: 13.0000\n",
      " |~~ train@23235  Loss: 0.041963 Acc: 13.4000\n",
      " |~~ train@23240  Loss: 0.035771 Acc: 13.4000\n",
      " |~~ train@23245  Loss: 0.059916 Acc: 12.6000\n",
      " |~~ train@23250  Loss: 0.011076 Acc: 14.0000\n",
      " |~~ train@23255  Loss: 0.026872 Acc: 13.4000\n",
      " |~~ train@23260  Loss: 0.037705 Acc: 13.2000\n",
      " |~~ train@23265  Loss: 0.018058 Acc: 13.8000\n",
      " |~~ train@23270  Loss: 0.010393 Acc: 14.0000\n",
      " |~~ train@23275  Loss: 0.036860 Acc: 13.2000\n",
      " |~~ train@23280  Loss: 0.069392 Acc: 12.4000\n",
      " |~~ train@23285  Loss: 0.029170 Acc: 13.4000\n",
      " |~~ train@23290  Loss: 0.043534 Acc: 13.0000\n",
      " |~~ train@23295  Loss: 0.010576 Acc: 14.0000\n",
      " |~~ train@23300  Loss: 0.042153 Acc: 13.2000\n",
      " |~~ train@23305  Loss: 0.021803 Acc: 13.8000\n",
      " |~~ train@23310  Loss: 0.035020 Acc: 13.4000\n",
      " |~~ train@23315  Loss: 0.020960 Acc: 13.6000\n",
      " |~~ train@23320  Loss: 0.043642 Acc: 13.0000\n",
      " |~~ train@23325  Loss: 0.017084 Acc: 13.8000\n",
      " |~~ train@23330  Loss: 0.032239 Acc: 13.4000\n",
      " |~~ train@23335  Loss: 0.047210 Acc: 13.0000\n",
      " |~~ train@23340  Loss: 0.046372 Acc: 12.8000\n",
      " |~~ train@23345  Loss: 0.048647 Acc: 13.0000\n",
      " |~~ train@23350  Loss: 0.033201 Acc: 13.4000\n",
      " |~~ train@23355  Loss: 0.015275 Acc: 13.8000\n",
      " |~~ train@23360  Loss: 0.044596 Acc: 13.0000\n",
      " |~~ train@23365  Loss: 0.039809 Acc: 13.0000\n",
      " |~~ train@23370  Loss: 0.046322 Acc: 13.2000\n",
      " |~~ train@23375  Loss: 0.022143 Acc: 13.6000\n",
      " |~~ train@23380  Loss: 0.031237 Acc: 13.2000\n",
      " |~~ train@23385  Loss: 0.021241 Acc: 13.8000\n",
      " |~~ train@23390  Loss: 0.032844 Acc: 13.6000\n",
      " |~~ train@23395  Loss: 0.040623 Acc: 13.0000\n",
      " |~~ train@23400  Loss: 0.039046 Acc: 13.2000\n",
      " |~~ train@23405  Loss: 0.050056 Acc: 13.0000\n",
      " |~~ train@23410  Loss: 0.011240 Acc: 14.0000\n",
      " |~~ train@23415  Loss: 0.050749 Acc: 12.8000\n",
      " |~~ train@23420  Loss: 0.035838 Acc: 13.2000\n",
      " |~~ train@23425  Loss: 0.045412 Acc: 13.0000\n",
      " |~~ train@23430  Loss: 0.046363 Acc: 13.0000\n",
      " |~~ train@23435  Loss: 0.038190 Acc: 13.2000\n",
      " |~~ train@23440  Loss: 0.021349 Acc: 13.6000\n",
      " |~~ train@23445  Loss: 0.041312 Acc: 13.2000\n",
      " |~~ train@23450  Loss: 0.033489 Acc: 13.4000\n",
      " |~~ train@23455  Loss: 0.050123 Acc: 12.8000\n",
      " |~~ train@23460  Loss: 0.041943 Acc: 13.2000\n",
      " |~~ train@23465  Loss: 0.045379 Acc: 13.2000\n",
      " |~~ train@23470  Loss: 0.039623 Acc: 13.0000\n",
      " |~~ train@23475  Loss: 0.036614 Acc: 13.4000\n",
      " |~~ train@23480  Loss: 0.019080 Acc: 13.8000\n",
      " |~~ train@23485  Loss: 0.043203 Acc: 13.2000\n",
      " |~~ train@23490  Loss: 0.082989 Acc: 12.4000\n",
      " |~~ train@23495  Loss: 0.041502 Acc: 13.2000\n",
      " |~~ train@23500  Loss: 0.023732 Acc: 13.6000\n",
      " |~~ train@23505  Loss: 0.051016 Acc: 13.2000\n",
      " |~~ train@23510  Loss: 0.019677 Acc: 13.6000\n",
      " |~~ train@23515  Loss: 0.035544 Acc: 13.2000\n",
      " |~~ train@23520  Loss: 0.023799 Acc: 13.6000\n",
      " |~~ train@23525  Loss: 0.011013 Acc: 14.0000\n",
      " |~~ train@23530  Loss: 0.032932 Acc: 13.4000\n",
      " |~~ train@23535  Loss: 0.022999 Acc: 13.4000\n",
      " |~~ train@23540  Loss: 0.035471 Acc: 13.0000\n",
      " |~~ train@23545  Loss: 0.049005 Acc: 13.0000\n",
      " |~~ train@23550  Loss: 0.039054 Acc: 13.2000\n",
      " |~~ train@23555  Loss: 0.090360 Acc: 11.8000\n",
      " |~~ train@23560  Loss: 0.010869 Acc: 14.0000\n",
      " |~~ train@23565  Loss: 0.029052 Acc: 13.4000\n",
      " |~~ train@23570  Loss: 0.048611 Acc: 12.8000\n",
      " |~~ train@23575  Loss: 0.061575 Acc: 12.6000\n",
      " |~~ train@23580  Loss: 0.036177 Acc: 13.2000\n",
      " |~~ train@23585  Loss: 0.028363 Acc: 13.6000\n",
      " |~~ train@23590  Loss: 0.016571 Acc: 13.6000\n",
      " |~~ train@23595  Loss: 0.038465 Acc: 13.4000\n",
      " |~~ train@23600  Loss: 0.010384 Acc: 14.0000\n",
      " |~~ train@23605  Loss: 0.038125 Acc: 13.0000\n",
      " |~~ train@23610  Loss: 0.014883 Acc: 13.8000\n",
      " |~~ train@23615  Loss: 0.017402 Acc: 13.8000\n",
      " |~~ train@23620  Loss: 0.052676 Acc: 12.8000\n",
      " |~~ train@23625  Loss: 0.038980 Acc: 13.2000\n",
      " |~~ train@23630  Loss: 0.023647 Acc: 13.6000\n",
      " |~~ train@23635  Loss: 0.041130 Acc: 13.0000\n",
      " |~~ train@23640  Loss: 0.020517 Acc: 13.6000\n",
      " |~~ train@23645  Loss: 0.010916 Acc: 14.0000\n",
      " |~~ train@23650  Loss: 0.010045 Acc: 14.0000\n",
      " |~~ train@23655  Loss: 0.010630 Acc: 14.0000\n",
      " |~~ train@23660  Loss: 0.010798 Acc: 14.0000\n",
      " |~~ train@23665  Loss: 0.015574 Acc: 13.8000\n",
      " |~~ train@23670  Loss: 0.044036 Acc: 13.2000\n",
      " |~~ train@23675  Loss: 0.038734 Acc: 13.2000\n",
      " |~~ train@23680  Loss: 0.036966 Acc: 13.0000\n",
      " |~~ train@23685  Loss: 0.018309 Acc: 13.6000\n",
      " |~~ train@23690  Loss: 0.025023 Acc: 13.4000\n",
      " |~~ train@23695  Loss: 0.047657 Acc: 13.0000\n",
      " |~~ train@23700  Loss: 0.031722 Acc: 13.6000\n",
      " |~~ train@23705  Loss: 0.054567 Acc: 13.0000\n",
      " |~~ train@23710  Loss: 0.041136 Acc: 13.2000\n",
      " |~~ train@23715  Loss: 0.018027 Acc: 13.8000\n",
      " |~~ train@23720  Loss: 0.037651 Acc: 13.2000\n",
      " |~~ train@23725  Loss: 0.056443 Acc: 12.6000\n",
      " |~~ train@23730  Loss: 0.041577 Acc: 13.2000\n",
      " |~~ train@23735  Loss: 0.028645 Acc: 13.4000\n",
      " |~~ train@23740  Loss: 0.036572 Acc: 13.2000\n",
      " |~~ train@23745  Loss: 0.030599 Acc: 13.4000\n",
      " |~~ train@23750  Loss: 0.053385 Acc: 12.6000\n",
      " |~~ train@23755  Loss: 0.047766 Acc: 13.0000\n",
      " |~~ train@23760  Loss: 0.033182 Acc: 13.2000\n",
      " |~~ train@23765  Loss: 0.050928 Acc: 12.6000\n",
      " |~~ train@23770  Loss: 0.024288 Acc: 13.4000\n",
      " |~~ train@23775  Loss: 0.052346 Acc: 13.0000\n",
      " |~~ train@23780  Loss: 0.028221 Acc: 13.6000\n",
      " |~~ train@23785  Loss: 0.044656 Acc: 13.0000\n",
      " |~~ train@23790  Loss: 0.028141 Acc: 13.4000\n",
      " |~~ train@23795  Loss: 0.027356 Acc: 13.4000\n",
      " |~~ train@23800  Loss: 0.068691 Acc: 12.4000\n",
      " |~~ train@23805  Loss: 0.044761 Acc: 13.0000\n",
      " |~~ train@23810  Loss: 0.028085 Acc: 13.6000\n",
      " |~~ train@23815  Loss: 0.035901 Acc: 13.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@23820  Loss: 0.034704 Acc: 13.4000\n",
      " |~~ train@23825  Loss: 0.059524 Acc: 12.6000\n",
      " |~~ train@23830  Loss: 0.040821 Acc: 13.2000\n",
      " |~~ train@23835  Loss: 0.046025 Acc: 13.2000\n",
      " |~~ train@23840  Loss: 0.067326 Acc: 12.6000\n",
      " |~~ train@23845  Loss: 0.011096 Acc: 14.0000\n",
      " |~~ train@23850  Loss: 0.021236 Acc: 13.6000\n",
      " |~~ train@23855  Loss: 0.035262 Acc: 13.0000\n",
      " |~~ train@23860  Loss: 0.038386 Acc: 13.2000\n",
      " |~~ train@23865  Loss: 0.043939 Acc: 13.2000\n",
      " |~~ train@23870  Loss: 0.049334 Acc: 12.8000\n",
      " |~~ train@23875  Loss: 0.023757 Acc: 13.6000\n",
      " |~~ train@23880  Loss: 0.035428 Acc: 13.2000\n",
      " |~~ train@23885  Loss: 0.060032 Acc: 12.6000\n",
      " |~~ train@23890  Loss: 0.029223 Acc: 13.6000\n",
      " |~~ train@23895  Loss: 0.078235 Acc: 11.8000\n",
      " |~~ train@23900  Loss: 0.043321 Acc: 12.8000\n",
      " |~~ train@23905  Loss: 0.055959 Acc: 12.8000\n",
      " |~~ train@23910  Loss: 0.027644 Acc: 13.4000\n",
      " |~~ train@23915  Loss: 0.055485 Acc: 12.6000\n",
      " |~~ train@23920  Loss: 0.022993 Acc: 13.8000\n",
      " |~~ train@23925  Loss: 0.041317 Acc: 13.0000\n",
      " |~~ train@23930  Loss: 0.054139 Acc: 13.0000\n",
      " |~~ train@23935  Loss: 0.050762 Acc: 12.8000\n",
      " |~~ train@23940  Loss: 0.012818 Acc: 14.0000\n",
      " |~~ train@23945  Loss: 0.018801 Acc: 13.8000\n",
      " |~~ train@23950  Loss: 0.039884 Acc: 13.2000\n",
      " |~~ train@23955  Loss: 0.024105 Acc: 13.8000\n",
      " |~~ train@23960  Loss: 0.036864 Acc: 12.8000\n",
      " |~~ train@23965  Loss: 0.061057 Acc: 12.8000\n",
      " |~~ train@23970  Loss: 0.034737 Acc: 13.4000\n",
      " |~~ train@23975  Loss: 0.037151 Acc: 13.2000\n",
      " |~~ train@23980  Loss: 0.027876 Acc: 13.6000\n",
      " |~~ train@23985  Loss: 0.027019 Acc: 13.4000\n",
      " |~~ train@23990  Loss: 0.029933 Acc: 13.2000\n",
      " |~~ train@23995  Loss: 0.038460 Acc: 13.0000\n",
      " |~~ train@24000  Loss: 0.033094 Acc: 13.4000\n",
      " |~~ train@24005  Loss: 0.011990 Acc: 14.0000\n",
      " |~~ train@24010  Loss: 0.049480 Acc: 13.0000\n",
      " |~~ train@24015  Loss: 0.014737 Acc: 13.8000\n",
      " |~~ train@24020  Loss: 0.051575 Acc: 12.8000\n",
      " |~~ train@24025  Loss: 0.031826 Acc: 13.4000\n",
      " |~~ train@24030  Loss: 0.047012 Acc: 13.0000\n",
      " |~~ train@24035  Loss: 0.022174 Acc: 13.6000\n",
      " |~~ train@24040  Loss: 0.030164 Acc: 13.4000\n",
      " |~~ train@24045  Loss: 0.019311 Acc: 13.8000\n",
      " |~~ train@24050  Loss: 0.039129 Acc: 13.2000\n",
      " |~~ train@24055  Loss: 0.061817 Acc: 12.4000\n",
      " |~~ train@24060  Loss: 0.013099 Acc: 13.8000\n",
      " |~~ train@24065  Loss: 0.025028 Acc: 13.6000\n",
      " |~~ train@24070  Loss: 0.020084 Acc: 13.8000\n",
      " |~~ train@24075  Loss: 0.045650 Acc: 13.2000\n",
      " |~~ train@24080  Loss: 0.031494 Acc: 13.4000\n",
      " |~~ train@24085  Loss: 0.059651 Acc: 12.6000\n",
      " |~~ train@24090  Loss: 0.067651 Acc: 12.4000\n",
      " |~~ train@24095  Loss: 0.019091 Acc: 13.8000\n",
      " |~~ train@24100  Loss: 0.018835 Acc: 13.6000\n",
      " |~~ train@24105  Loss: 0.011226 Acc: 14.0000\n",
      " |~~ train@24110  Loss: 0.050024 Acc: 12.6000\n",
      " |~~ train@24115  Loss: 0.035266 Acc: 13.4000\n",
      " |~~ train@24120  Loss: 0.027614 Acc: 13.4000\n",
      " |~~ train@24125  Loss: 0.034005 Acc: 13.4000\n",
      " |~~ train@24130  Loss: 0.031447 Acc: 13.4000\n",
      " |~~ train@24135  Loss: 0.024365 Acc: 13.8000\n",
      " |~~ train@24140  Loss: 0.068285 Acc: 12.4000\n",
      " |~~ train@24145  Loss: 0.041754 Acc: 13.2000\n",
      " |~~ train@24150  Loss: 0.043779 Acc: 13.2000\n",
      " |~~ train@24155  Loss: 0.039027 Acc: 13.2000\n",
      " |~~ train@24160  Loss: 0.029591 Acc: 13.6000\n",
      " |~~ train@24165  Loss: 0.032451 Acc: 13.4000\n",
      " |~~ train@24170  Loss: 0.017370 Acc: 13.6000\n",
      " |~~ train@24175  Loss: 0.024113 Acc: 13.6000\n",
      " |~~ train@24180  Loss: 0.069124 Acc: 12.2000\n",
      " |~~ train@24185  Loss: 0.035778 Acc: 13.0000\n",
      " |~~ train@24190  Loss: 0.035893 Acc: 13.2000\n",
      " |~~ train@24195  Loss: 0.030231 Acc: 13.4000\n",
      " |~~ train@24200  Loss: 0.043756 Acc: 13.0000\n",
      " |~~ train@24205  Loss: 0.020208 Acc: 13.6000\n",
      " |~~ train@24210  Loss: 0.030200 Acc: 13.4000\n",
      " |~~ train@24215  Loss: 0.039230 Acc: 12.8000\n",
      " |~~ train@24220  Loss: 0.030365 Acc: 13.4000\n",
      " |~~ train@24225  Loss: 0.040999 Acc: 13.0000\n",
      " |~~ train@24230  Loss: 0.025463 Acc: 13.6000\n",
      " |~~ train@24235  Loss: 0.039027 Acc: 13.2000\n",
      " |~~ train@24240  Loss: 0.021099 Acc: 13.6000\n",
      " |~~ train@24245  Loss: 0.047815 Acc: 13.2000\n",
      " |~~ train@24250  Loss: 0.042211 Acc: 12.8000\n",
      " |~~ train@24255  Loss: 0.045685 Acc: 13.0000\n",
      " |~~ train@24260  Loss: 0.050145 Acc: 12.8000\n",
      " |~~ train@24265  Loss: 0.034851 Acc: 13.4000\n",
      " |~~ train@24270  Loss: 0.050356 Acc: 12.8000\n",
      " |~~ train@24275  Loss: 0.011716 Acc: 14.0000\n",
      " |~~ train@24280  Loss: 0.067296 Acc: 12.4000\n",
      " |~~ train@24285  Loss: 0.016157 Acc: 13.8000\n",
      " |~~ train@24290  Loss: 0.014489 Acc: 13.8000\n",
      " |~~ train@24295  Loss: 0.030332 Acc: 13.4000\n",
      " |~~ train@24300  Loss: 0.082579 Acc: 12.0000\n",
      " |~~ train@24305  Loss: 0.033311 Acc: 13.4000\n",
      " |~~ train@24310  Loss: 0.029411 Acc: 13.4000\n",
      " |~~ train@24315  Loss: 0.021235 Acc: 13.8000\n",
      " |~~ train@24320  Loss: 0.012138 Acc: 14.0000\n",
      " |~~ train@24325  Loss: 0.023334 Acc: 13.4000\n",
      " |~~ train@24330  Loss: 0.045079 Acc: 13.0000\n",
      " |~~ train@24335  Loss: 0.042265 Acc: 13.0000\n",
      " |~~ train@24340  Loss: 0.044179 Acc: 13.2000\n",
      " |~~ train@24345  Loss: 0.018102 Acc: 13.8000\n",
      " |~~ train@24350  Loss: 0.039392 Acc: 13.2000\n",
      " |~~ train@24355  Loss: 0.040150 Acc: 13.2000\n",
      " |~~ train@24360  Loss: 0.049378 Acc: 12.8000\n",
      " |~~ train@24365  Loss: 0.066440 Acc: 12.8000\n",
      " |~~ train@24370  Loss: 0.050144 Acc: 12.8000\n",
      " |~~ train@24375  Loss: 0.047005 Acc: 13.0000\n",
      " |~~ train@24380  Loss: 0.033179 Acc: 13.0000\n",
      " |~~ train@24385  Loss: 0.046754 Acc: 13.0000\n",
      " |~~ train@24390  Loss: 0.021381 Acc: 13.8000\n",
      " |~~ train@24395  Loss: 0.035977 Acc: 13.4000\n",
      " |~~ train@24400  Loss: 0.010934 Acc: 14.0000\n",
      " |~~ train@24405  Loss: 0.019434 Acc: 13.6000\n",
      " |~~ train@24410  Loss: 0.020567 Acc: 13.6000\n",
      " |~~ train@24415  Loss: 0.041362 Acc: 13.0000\n",
      " |~~ train@24420  Loss: 0.038928 Acc: 13.2000\n",
      " |~~ train@24425  Loss: 0.029558 Acc: 13.4000\n",
      " |~~ train@24430  Loss: 0.024596 Acc: 13.6000\n",
      " |~~ train@24435  Loss: 0.048441 Acc: 13.0000\n",
      " |~~ train@24440  Loss: 0.039369 Acc: 12.8000\n",
      " |~~ train@24445  Loss: 0.055242 Acc: 12.8000\n",
      " |~~ train@24450  Loss: 0.018764 Acc: 13.6000\n",
      " |~~ train@24455  Loss: 0.036807 Acc: 13.2000\n",
      " |~~ train@24460  Loss: 0.052477 Acc: 12.8000\n",
      " |~~ train@24465  Loss: 0.036890 Acc: 13.2000\n",
      " |~~ train@24470  Loss: 0.080753 Acc: 12.0000\n",
      " |~~ train@24475  Loss: 0.031539 Acc: 13.4000\n",
      " |~~ train@24480  Loss: 0.042702 Acc: 13.2000\n",
      " |~~ train@24485  Loss: 0.038360 Acc: 13.2000\n",
      " |~~ train@24490  Loss: 0.024137 Acc: 13.6000\n",
      " |~~ train@24495  Loss: 0.038987 Acc: 13.2000\n",
      " |~~ train@24500  Loss: 0.041250 Acc: 13.0000\n",
      " |~~ train@24505  Loss: 0.017552 Acc: 13.8000\n",
      " |~~ train@24510  Loss: 0.077650 Acc: 12.2000\n",
      " |~~ train@24515  Loss: 0.016790 Acc: 13.8000\n",
      " |~~ train@24520  Loss: 0.044454 Acc: 12.8000\n",
      " |~~ train@24525  Loss: 0.040306 Acc: 13.2000\n",
      " |~~ train@24530  Loss: 0.045999 Acc: 13.0000\n",
      " |~~ train@24535  Loss: 0.021276 Acc: 13.8000\n",
      " |~~ train@24540  Loss: 0.040809 Acc: 13.2000\n",
      " |~~ train@24545  Loss: 0.028738 Acc: 13.4000\n",
      " |~~ train@24550  Loss: 0.011935 Acc: 14.0000\n",
      " |~~ train@24555  Loss: 0.016065 Acc: 13.8000\n",
      " |~~ train@24560  Loss: 0.022714 Acc: 13.6000\n",
      " |~~ train@24565  Loss: 0.046140 Acc: 13.0000\n",
      " |~~ train@24570  Loss: 0.051867 Acc: 12.8000\n",
      " |~~ train@24575  Loss: 0.033205 Acc: 13.4000\n",
      " |~~ train@24580  Loss: 0.055862 Acc: 13.0000\n",
      " |~~ train@24585  Loss: 0.027761 Acc: 13.4000\n",
      " |~~ train@24590  Loss: 0.029384 Acc: 13.4000\n",
      " |~~ train@24595  Loss: 0.016527 Acc: 13.8000\n",
      " |~~ train@24600  Loss: 0.042412 Acc: 13.0000\n",
      " |~~ train@24605  Loss: 0.016007 Acc: 13.6000\n",
      " |~~ train@24610  Loss: 0.016573 Acc: 13.6000\n",
      " |~~ train@24615  Loss: 0.039155 Acc: 13.4000\n",
      " |~~ train@24620  Loss: 0.043734 Acc: 13.0000\n",
      " |~~ train@24625  Loss: 0.025226 Acc: 13.2000\n",
      " |~~ train@24630  Loss: 0.017853 Acc: 13.8000\n",
      " |~~ train@24635  Loss: 0.016624 Acc: 13.8000\n",
      " |~~ train@24640  Loss: 0.040625 Acc: 13.2000\n",
      " |~~ train@24645  Loss: 0.047585 Acc: 13.2000\n",
      " |~~ train@24650  Loss: 0.016373 Acc: 13.8000\n",
      " |~~ train@24655  Loss: 0.040851 Acc: 13.2000\n",
      " |~~ train@24660  Loss: 0.011280 Acc: 14.0000\n",
      " |~~ train@24665  Loss: 0.025855 Acc: 13.6000\n",
      " |~~ train@24670  Loss: 0.025074 Acc: 13.6000\n",
      " |~~ train@24675  Loss: 0.038485 Acc: 13.4000\n",
      " |~~ train@24680  Loss: 0.048765 Acc: 12.8000\n",
      " |~~ train@24685  Loss: 0.013455 Acc: 13.8000\n",
      " |~~ train@24690  Loss: 0.012415 Acc: 13.8000\n",
      " |~~ train@24695  Loss: 0.070820 Acc: 12.6000\n",
      " |~~ train@24700  Loss: 0.057518 Acc: 12.8000\n",
      " |~~ train@24705  Loss: 0.029661 Acc: 13.6000\n",
      " |~~ train@24710  Loss: 0.023483 Acc: 13.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@24715  Loss: 0.041650 Acc: 13.0000\n",
      " |~~ train@24720  Loss: 0.024765 Acc: 13.6000\n",
      " |~~ train@24725  Loss: 0.019158 Acc: 13.8000\n",
      " |~~ train@24730  Loss: 0.014175 Acc: 13.8000\n",
      " |~~ train@24735  Loss: 0.025262 Acc: 13.6000\n",
      " |~~ train@24740  Loss: 0.035500 Acc: 13.2000\n",
      " |~~ train@24745  Loss: 0.047863 Acc: 13.0000\n",
      " |~~ train@24750  Loss: 0.042388 Acc: 13.0000\n",
      " |~~ train@24755  Loss: 0.019683 Acc: 13.8000\n",
      " |~~ train@24760  Loss: 0.033248 Acc: 13.4000\n",
      " |~~ train@24765  Loss: 0.049440 Acc: 13.0000\n",
      " |~~ train@24770  Loss: 0.053392 Acc: 13.0000\n",
      " |~~ train@24775  Loss: 0.025029 Acc: 13.6000\n",
      " |~~ train@24780  Loss: 0.028042 Acc: 13.4000\n",
      " |~~ train@24785  Loss: 0.054072 Acc: 12.8000\n",
      " |~~ train@24790  Loss: 0.049456 Acc: 12.8000\n",
      " |~~ train@24795  Loss: 0.016496 Acc: 13.8000\n",
      " |~~ train@24800  Loss: 0.010030 Acc: 14.0000\n",
      " |~~ train@24805  Loss: 0.030562 Acc: 13.4000\n",
      " |~~ train@24810  Loss: 0.021418 Acc: 13.8000\n",
      " |~~ train@24815  Loss: 0.015973 Acc: 13.8000\n",
      " |~~ train@24820  Loss: 0.009552 Acc: 14.0000\n",
      " |~~ train@24825  Loss: 0.014858 Acc: 13.8000\n",
      " |~~ train@24830  Loss: 0.029001 Acc: 13.4000\n",
      " |~~ train@24835  Loss: 0.013433 Acc: 13.8000\n",
      " |~~ train@24840  Loss: 0.020609 Acc: 13.8000\n",
      " |~~ train@24845  Loss: 0.049483 Acc: 12.8000\n",
      " |~~ train@24850  Loss: 0.017102 Acc: 13.8000\n",
      " |~~ train@24855  Loss: 0.057918 Acc: 13.0000\n",
      " |~~ train@24860  Loss: 0.054361 Acc: 12.8000\n",
      " |~~ train@24865  Loss: 0.029811 Acc: 13.4000\n",
      " |~~ train@24870  Loss: 0.040921 Acc: 13.2000\n",
      " |~~ train@24875  Loss: 0.052987 Acc: 12.8000\n",
      " |~~ train@24880  Loss: 0.035443 Acc: 13.0000\n",
      " |~~ train@24885  Loss: 0.034076 Acc: 13.4000\n",
      " |~~ train@24890  Loss: 0.029460 Acc: 13.4000\n",
      " |~~ train@24895  Loss: 0.039885 Acc: 13.2000\n",
      " |~~ train@24900  Loss: 0.056267 Acc: 13.2000\n",
      " |~~ train@24905  Loss: 0.035497 Acc: 13.4000\n",
      " |~~ train@24910  Loss: 0.040563 Acc: 13.0000\n",
      " |~~ train@24915  Loss: 0.027148 Acc: 13.6000\n",
      " |~~ train@24920  Loss: 0.025212 Acc: 13.4000\n",
      " |~~ train@24925  Loss: 0.026799 Acc: 13.4000\n",
      " |~~ train@24930  Loss: 0.030700 Acc: 13.2000\n",
      " |~~ train@24935  Loss: 0.009824 Acc: 14.0000\n",
      " |~~ train@24940  Loss: 0.037916 Acc: 13.2000\n",
      " |~~ train@24945  Loss: 0.035965 Acc: 13.4000\n",
      " |~~ train@24950  Loss: 0.056863 Acc: 12.8000\n",
      " |~~ train@24955  Loss: 0.051834 Acc: 13.0000\n",
      " |~~ train@24960  Loss: 0.072122 Acc: 12.4000\n",
      " |~~ train@24965  Loss: 0.037017 Acc: 13.2000\n",
      " |~~ train@24970  Loss: 0.058352 Acc: 12.8000\n",
      " |~~ train@24975  Loss: 0.020819 Acc: 13.6000\n",
      " |~~ train@24980  Loss: 0.039886 Acc: 13.0000\n",
      " |~~ train@24985  Loss: 0.021835 Acc: 13.8000\n",
      " |~~ train@24990  Loss: 0.021919 Acc: 13.6000\n",
      " |~~ train@24995  Loss: 0.027407 Acc: 13.4000\n",
      " |~~ train@25000  Loss: 0.029632 Acc: 13.6000\n",
      " |~~ train@25005  Loss: 0.041323 Acc: 12.8000\n",
      " |~~ train@25010  Loss: 0.055227 Acc: 12.8000\n",
      " |~~ train@25015  Loss: 0.055282 Acc: 13.0000\n",
      " |~~ train@25020  Loss: 0.019663 Acc: 13.6000\n",
      " |~~ train@25025  Loss: 0.044297 Acc: 13.0000\n",
      " |~~ train@25030  Loss: 0.048887 Acc: 12.8000\n",
      " |~~ train@25035  Loss: 0.048037 Acc: 12.8000\n",
      " |~~ train@25040  Loss: 0.046432 Acc: 12.8000\n",
      " |~~ train@25045  Loss: 0.010364 Acc: 14.0000\n",
      " |~~ train@25050  Loss: 0.042078 Acc: 13.0000\n",
      " |~~ train@25055  Loss: 0.024630 Acc: 13.4000\n",
      " |~~ train@25060  Loss: 0.030002 Acc: 13.2000\n",
      " |~~ train@25065  Loss: 0.075973 Acc: 12.6000\n",
      " |~~ train@25070  Loss: 0.067120 Acc: 12.8000\n",
      " |~~ train@25075  Loss: 0.040357 Acc: 13.2000\n",
      " |~~ train@25080  Loss: 0.011787 Acc: 14.0000\n",
      " |~~ train@25085  Loss: 0.027691 Acc: 13.4000\n",
      " |~~ train@25090  Loss: 0.030336 Acc: 13.4000\n",
      " |~~ train@25095  Loss: 0.032429 Acc: 13.6000\n",
      " |~~ train@25100  Loss: 0.020345 Acc: 13.6000\n",
      " |~~ train@25105  Loss: 0.080872 Acc: 11.8000\n",
      " |~~ train@25110  Loss: 0.011928 Acc: 14.0000\n",
      " |~~ train@25115  Loss: 0.030752 Acc: 13.4000\n",
      " |~~ train@25120  Loss: 0.023474 Acc: 13.6000\n",
      " |~~ train@25125  Loss: 0.074673 Acc: 12.6000\n",
      " |~~ train@25130  Loss: 0.031720 Acc: 13.4000\n",
      " |~~ train@25135  Loss: 0.048417 Acc: 13.0000\n",
      " |~~ train@25140  Loss: 0.053396 Acc: 12.8000\n",
      " |~~ train@25145  Loss: 0.046318 Acc: 12.8000\n",
      " |~~ train@25150  Loss: 0.010854 Acc: 14.0000\n",
      " |~~ train@25155  Loss: 0.022377 Acc: 13.6000\n",
      " |~~ train@25160  Loss: 0.012044 Acc: 14.0000\n",
      " |~~ train@25165  Loss: 0.016519 Acc: 13.6000\n",
      " |~~ train@25170  Loss: 0.029417 Acc: 13.4000\n",
      " |~~ train@25175  Loss: 0.032870 Acc: 13.2000\n",
      " |~~ train@25180  Loss: 0.027751 Acc: 13.4000\n",
      " |~~ train@25185  Loss: 0.047665 Acc: 12.8000\n",
      " |~~ train@25190  Loss: 0.026053 Acc: 13.4000\n",
      " |~~ train@25195  Loss: 0.029104 Acc: 13.6000\n",
      " |~~ train@25200  Loss: 0.042629 Acc: 13.0000\n",
      " |~~ train@25205  Loss: 0.026402 Acc: 13.6000\n",
      " |~~ train@25210  Loss: 0.019683 Acc: 13.6000\n",
      " |~~ train@25215  Loss: 0.068369 Acc: 12.8000\n",
      " |~~ train@25220  Loss: 0.057982 Acc: 12.8000\n",
      " |~~ train@25225  Loss: 0.047501 Acc: 13.0000\n",
      " |~~ train@25230  Loss: 0.037117 Acc: 12.8000\n",
      " |~~ train@25235  Loss: 0.011252 Acc: 14.0000\n",
      " |~~ train@25240  Loss: 0.037096 Acc: 13.4000\n",
      " |~~ train@25245  Loss: 0.027828 Acc: 13.6000\n",
      " |~~ train@25250  Loss: 0.041770 Acc: 13.0000\n",
      " |~~ train@25255  Loss: 0.031270 Acc: 13.4000\n",
      " |~~ train@25260  Loss: 0.043336 Acc: 12.8000\n",
      " |~~ train@25265  Loss: 0.010829 Acc: 14.0000\n",
      " |~~ train@25270  Loss: 0.031827 Acc: 13.4000\n",
      " |~~ train@25275  Loss: 0.020193 Acc: 13.8000\n",
      " |~~ train@25280  Loss: 0.038972 Acc: 13.0000\n",
      " |~~ train@25285  Loss: 0.032001 Acc: 13.2000\n",
      " |~~ train@25290  Loss: 0.031113 Acc: 13.4000\n",
      " |~~ train@25295  Loss: 0.060984 Acc: 12.8000\n",
      " |~~ train@25300  Loss: 0.023346 Acc: 13.6000\n",
      " |~~ train@25305  Loss: 0.051924 Acc: 12.8000\n",
      " |~~ train@25310  Loss: 0.041464 Acc: 13.2000\n",
      " |~~ train@25315  Loss: 0.044439 Acc: 13.0000\n",
      " |~~ train@25320  Loss: 0.045655 Acc: 12.8000\n",
      " |~~ train@25325  Loss: 0.022500 Acc: 13.8000\n",
      " |~~ train@25330  Loss: 0.025008 Acc: 13.4000\n",
      " |~~ train@25335  Loss: 0.023656 Acc: 13.4000\n",
      " |~~ train@25340  Loss: 0.039645 Acc: 13.4000\n",
      " |~~ train@25345  Loss: 0.037085 Acc: 13.2000\n",
      " |~~ train@25350  Loss: 0.030850 Acc: 13.6000\n",
      " |~~ train@25355  Loss: 0.036276 Acc: 13.0000\n",
      " |~~ train@25360  Loss: 0.064857 Acc: 12.8000\n",
      " |~~ train@25365  Loss: 0.037631 Acc: 13.0000\n",
      " |~~ train@25370  Loss: 0.021029 Acc: 13.8000\n",
      " |~~ train@25375  Loss: 0.055737 Acc: 12.8000\n",
      " |~~ train@25380  Loss: 0.044683 Acc: 13.2000\n",
      " |~~ train@25385  Loss: 0.021439 Acc: 13.6000\n",
      " |~~ train@25390  Loss: 0.043074 Acc: 13.0000\n",
      " |~~ train@25395  Loss: 0.053515 Acc: 12.8000\n",
      " |~~ train@25400  Loss: 0.078924 Acc: 12.4000\n",
      " |~~ train@25405  Loss: 0.020856 Acc: 13.8000\n",
      " |~~ train@25410  Loss: 0.016302 Acc: 13.8000\n",
      " |~~ train@25415  Loss: 0.036392 Acc: 13.2000\n",
      " |~~ train@25420  Loss: 0.032968 Acc: 13.2000\n",
      " |~~ train@25425  Loss: 0.029545 Acc: 13.4000\n",
      " |~~ train@25430  Loss: 0.024696 Acc: 13.2000\n",
      " |~~ train@25435  Loss: 0.022765 Acc: 13.8000\n",
      " |~~ train@25440  Loss: 0.029417 Acc: 13.6000\n",
      " |~~ train@25445  Loss: 0.035566 Acc: 13.4000\n",
      " |~~ train@25450  Loss: 0.022495 Acc: 13.6000\n",
      " |~~ train@25455  Loss: 0.073344 Acc: 12.4000\n",
      " |~~ train@25460  Loss: 0.045693 Acc: 13.0000\n",
      " |~~ train@25465  Loss: 0.017433 Acc: 13.6000\n",
      " |~~ train@25470  Loss: 0.015346 Acc: 13.8000\n",
      " |~~ train@25475  Loss: 0.033789 Acc: 13.0000\n",
      " |~~ train@25480  Loss: 0.032998 Acc: 13.2000\n",
      " |~~ train@25485  Loss: 0.023132 Acc: 13.4000\n",
      " |~~ train@25490  Loss: 0.055970 Acc: 13.0000\n",
      " |~~ train@25495  Loss: 0.019825 Acc: 13.6000\n",
      " |~~ train@25500  Loss: 0.030955 Acc: 13.4000\n",
      " |~~ train@25505  Loss: 0.077510 Acc: 12.4000\n",
      " |~~ train@25510  Loss: 0.036399 Acc: 13.4000\n",
      " |~~ train@25515  Loss: 0.031982 Acc: 13.2000\n",
      " |~~ train@25520  Loss: 0.057264 Acc: 12.8000\n",
      " |~~ train@25525  Loss: 0.034243 Acc: 13.4000\n",
      " |~~ train@25530  Loss: 0.049624 Acc: 13.0000\n",
      " |~~ train@25535  Loss: 0.027774 Acc: 13.4000\n",
      " |~~ train@25540  Loss: 0.051742 Acc: 12.8000\n",
      " |~~ train@25545  Loss: 0.035332 Acc: 13.2000\n",
      " |~~ train@25550  Loss: 0.031718 Acc: 13.4000\n",
      " |~~ train@25555  Loss: 0.011659 Acc: 14.0000\n",
      " |~~ train@25560  Loss: 0.078758 Acc: 11.6000\n",
      " |~~ train@25565  Loss: 0.024098 Acc: 13.8000\n",
      " |~~ train@25570  Loss: 0.046355 Acc: 13.2000\n",
      " |~~ train@25575  Loss: 0.016096 Acc: 13.8000\n",
      " |~~ train@25580  Loss: 0.049524 Acc: 13.0000\n",
      " |~~ train@25585  Loss: 0.026755 Acc: 13.4000\n",
      " |~~ train@25590  Loss: 0.026073 Acc: 13.6000\n",
      " |~~ train@25595  Loss: 0.043440 Acc: 12.8000\n",
      " |~~ train@25600  Loss: 0.013577 Acc: 13.8000\n",
      " |~~ train@25605  Loss: 0.060512 Acc: 12.6000\n",
      " |~~ train@25610  Loss: 0.019008 Acc: 13.8000\n",
      " |~~ train@25615  Loss: 0.031466 Acc: 13.4000\n",
      " |~~ train@25620  Loss: 0.037970 Acc: 13.2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@25625  Loss: 0.054035 Acc: 12.8000\n",
      " |~~ train@25630  Loss: 0.036743 Acc: 13.4000\n",
      " |~~ train@25635  Loss: 0.048336 Acc: 13.0000\n",
      " |~~ train@25640  Loss: 0.021502 Acc: 13.6000\n",
      " |~~ train@25645  Loss: 0.038806 Acc: 13.0000\n",
      " |~~ train@25650  Loss: 0.031913 Acc: 13.2000\n",
      " |~~ train@25655  Loss: 0.027391 Acc: 13.4000\n",
      " |~~ train@25660  Loss: 0.042488 Acc: 13.2000\n",
      " |~~ train@25665  Loss: 0.025941 Acc: 13.4000\n",
      " |~~ train@25670  Loss: 0.014959 Acc: 13.8000\n",
      " |~~ train@25675  Loss: 0.020329 Acc: 13.6000\n",
      " |~~ train@25680  Loss: 0.025496 Acc: 13.6000\n",
      " |~~ train@25685  Loss: 0.044189 Acc: 13.2000\n",
      " |~~ train@25690  Loss: 0.082202 Acc: 12.0000\n",
      " |~~ train@25695  Loss: 0.030150 Acc: 13.4000\n",
      " |~~ train@25700  Loss: 0.031202 Acc: 13.4000\n",
      " |~~ train@25705  Loss: 0.074887 Acc: 12.6000\n",
      " |~~ train@25710  Loss: 0.039567 Acc: 13.2000\n",
      " |~~ train@25715  Loss: 0.051974 Acc: 13.0000\n",
      " |~~ train@25720  Loss: 0.060712 Acc: 12.8000\n",
      " |~~ train@25725  Loss: 0.061181 Acc: 12.6000\n",
      " |~~ train@25730  Loss: 0.011432 Acc: 14.0000\n",
      " |~~ train@25735  Loss: 0.040742 Acc: 13.0000\n",
      " |~~ train@25740  Loss: 0.031416 Acc: 13.2000\n",
      " |~~ train@25745  Loss: 0.017977 Acc: 13.6000\n",
      " |~~ train@25750  Loss: 0.061223 Acc: 12.4000\n",
      " |~~ train@25755  Loss: 0.017470 Acc: 13.6000\n",
      " |~~ train@25760  Loss: 0.036931 Acc: 13.2000\n",
      " |~~ train@25765  Loss: 0.034671 Acc: 13.2000\n",
      " |~~ train@25770  Loss: 0.040804 Acc: 13.2000\n",
      " |~~ train@25775  Loss: 0.030860 Acc: 13.4000\n",
      " |~~ train@25780  Loss: 0.011330 Acc: 14.0000\n",
      " |~~ train@25785  Loss: 0.083992 Acc: 12.2000\n",
      " |~~ train@25790  Loss: 0.022921 Acc: 13.6000\n",
      " |~~ train@25795  Loss: 0.080721 Acc: 12.2000\n",
      " |~~ train@25800  Loss: 0.017852 Acc: 13.6000\n",
      " |~~ train@25805  Loss: 0.029300 Acc: 13.2000\n",
      " |~~ train@25810  Loss: 0.078104 Acc: 12.0000\n",
      " |~~ train@25815  Loss: 0.016244 Acc: 13.8000\n",
      " |~~ train@25820  Loss: 0.061485 Acc: 12.6000\n",
      " |~~ train@25825  Loss: 0.066034 Acc: 12.6000\n",
      " |~~ train@25830  Loss: 0.029451 Acc: 13.4000\n",
      " |~~ train@25835  Loss: 0.033367 Acc: 13.4000\n",
      " |~~ train@25840  Loss: 0.049851 Acc: 12.8000\n",
      " |~~ train@25845  Loss: 0.017097 Acc: 13.8000\n",
      " |~~ train@25850  Loss: 0.034491 Acc: 13.4000\n",
      " |~~ train@25855  Loss: 0.020087 Acc: 13.6000\n",
      " |~~ train@25860  Loss: 0.045748 Acc: 12.8000\n",
      " |~~ train@25865  Loss: 0.039065 Acc: 13.0000\n",
      " |~~ train@25870  Loss: 0.064763 Acc: 12.4000\n",
      " |~~ train@25875  Loss: 0.017408 Acc: 13.8000\n",
      " |~~ train@25880  Loss: 0.026313 Acc: 13.6000\n",
      " |~~ train@25885  Loss: 0.060340 Acc: 12.8000\n",
      " |~~ train@25890  Loss: 0.047598 Acc: 13.2000\n",
      " |~~ train@25895  Loss: 0.022686 Acc: 13.6000\n",
      " |~~ train@25900  Loss: 0.028266 Acc: 13.4000\n",
      " |~~ train@25905  Loss: 0.034904 Acc: 13.4000\n",
      " |~~ train@25910  Loss: 0.012498 Acc: 14.0000\n",
      " |~~ train@25915  Loss: 0.063526 Acc: 12.4000\n",
      " |~~ train@25920  Loss: 0.062854 Acc: 12.6000\n",
      " |~~ train@25925  Loss: 0.054558 Acc: 13.0000\n",
      " |~~ train@25930  Loss: 0.040716 Acc: 13.0000\n",
      " |~~ train@25935  Loss: 0.032574 Acc: 13.4000\n",
      " |~~ train@25940  Loss: 0.038147 Acc: 13.4000\n",
      " |~~ train@25945  Loss: 0.035434 Acc: 13.4000\n",
      " |~~ train@25950  Loss: 0.020809 Acc: 13.6000\n",
      " |~~ train@25955  Loss: 0.055080 Acc: 12.6000\n",
      " |~~ train@25960  Loss: 0.046661 Acc: 12.8000\n",
      " |~~ train@25965  Loss: 0.037373 Acc: 13.4000\n",
      " |~~ train@25970  Loss: 0.027913 Acc: 13.4000\n",
      " |~~ train@25975  Loss: 0.043610 Acc: 12.6000\n",
      " |~~ train@25980  Loss: 0.015278 Acc: 13.8000\n",
      " |~~ train@25985  Loss: 0.033134 Acc: 13.0000\n",
      " |~~ train@25990  Loss: 0.026407 Acc: 13.4000\n",
      " |~~ train@25995  Loss: 0.046736 Acc: 12.8000\n",
      " |~~ train@26000  Loss: 0.043394 Acc: 12.6000\n",
      " |~~ train@26005  Loss: 0.071042 Acc: 12.4000\n",
      " |~~ train@26010  Loss: 0.027354 Acc: 13.6000\n",
      " |~~ train@26015  Loss: 0.023892 Acc: 13.6000\n",
      " |~~ train@26020  Loss: 0.034921 Acc: 13.4000\n",
      " |~~ train@26025  Loss: 0.040303 Acc: 13.0000\n",
      " |~~ train@26030  Loss: 0.046765 Acc: 13.0000\n",
      " |~~ train@26035  Loss: 0.019177 Acc: 13.8000\n",
      " |~~ train@26040  Loss: 0.045717 Acc: 13.0000\n",
      " |~~ train@26045  Loss: 0.012679 Acc: 14.0000\n",
      " |~~ train@26050  Loss: 0.049225 Acc: 13.0000\n",
      " |~~ train@26055  Loss: 0.044823 Acc: 13.0000\n",
      " |~~ train@26060  Loss: 0.030548 Acc: 13.6000\n",
      " |~~ train@26065  Loss: 0.012030 Acc: 14.0000\n",
      " |~~ train@26070  Loss: 0.067852 Acc: 12.4000\n",
      " |~~ train@26075  Loss: 0.099791 Acc: 11.2000\n",
      " |~~ train@26080  Loss: 0.043249 Acc: 13.2000\n",
      " |~~ train@26085  Loss: 0.017939 Acc: 13.8000\n",
      " |~~ train@26090  Loss: 0.028977 Acc: 13.2000\n",
      " |~~ train@26095  Loss: 0.024418 Acc: 13.4000\n",
      " |~~ train@26100  Loss: 0.017263 Acc: 13.8000\n",
      " |~~ train@26105  Loss: 0.035293 Acc: 13.6000\n",
      " |~~ train@26110  Loss: 0.044353 Acc: 13.4000\n",
      " |~~ train@26115  Loss: 0.066378 Acc: 12.2000\n",
      " |~~ train@26120  Loss: 0.016906 Acc: 13.8000\n",
      " |~~ train@26125  Loss: 0.037250 Acc: 13.0000\n",
      " |~~ train@26130  Loss: 0.024277 Acc: 13.4000\n",
      " |~~ train@26135  Loss: 0.036554 Acc: 13.2000\n",
      " |~~ train@26140  Loss: 0.012431 Acc: 14.0000\n",
      " |~~ train@26145  Loss: 0.023225 Acc: 13.6000\n",
      " |~~ train@26150  Loss: 0.029957 Acc: 13.2000\n",
      " |~~ train@26155  Loss: 0.028418 Acc: 13.4000\n",
      " |~~ train@26160  Loss: 0.037134 Acc: 13.2000\n",
      " |~~ train@26165  Loss: 0.053296 Acc: 12.8000\n",
      " |~~ train@26170  Loss: 0.059573 Acc: 12.4000\n",
      " |~~ train@26175  Loss: 0.022728 Acc: 13.8000\n",
      " |~~ train@26180  Loss: 0.024067 Acc: 13.6000\n",
      " |~~ train@26185  Loss: 0.040035 Acc: 13.0000\n",
      " |~~ train@26190  Loss: 0.044857 Acc: 13.0000\n",
      " |~~ train@26195  Loss: 0.036436 Acc: 13.2000\n",
      " |~~ train@26200  Loss: 0.042895 Acc: 12.8000\n",
      " |~~ train@26205  Loss: 0.036175 Acc: 13.2000\n",
      " |~~ train@26210  Loss: 0.034555 Acc: 13.2000\n",
      " |~~ train@26215  Loss: 0.020012 Acc: 13.8000\n",
      " |~~ train@26220  Loss: 0.031096 Acc: 13.4000\n",
      " |~~ train@26225  Loss: 0.073131 Acc: 12.4000\n",
      " |~~ train@26230  Loss: 0.057826 Acc: 12.6000\n",
      " |~~ train@26235  Loss: 0.031233 Acc: 13.2000\n",
      " |~~ train@26240  Loss: 0.022700 Acc: 13.6000\n",
      " |~~ train@26245  Loss: 0.013170 Acc: 14.0000\n",
      " |~~ train@26250  Loss: 0.057403 Acc: 13.0000\n",
      " |~~ train@26255  Loss: 0.065057 Acc: 12.6000\n",
      " |~~ train@26260  Loss: 0.045979 Acc: 13.0000\n",
      " |~~ train@26265  Loss: 0.032935 Acc: 13.4000\n",
      " |~~ train@26270  Loss: 0.043289 Acc: 12.8000\n",
      " |~~ train@26275  Loss: 0.040285 Acc: 13.4000\n",
      " |~~ train@26280  Loss: 0.030519 Acc: 13.6000\n",
      " |~~ train@26285  Loss: 0.034786 Acc: 13.4000\n",
      " |~~ train@26290  Loss: 0.027138 Acc: 13.2000\n",
      " |~~ train@26295  Loss: 0.049435 Acc: 12.6000\n",
      " |~~ train@26300  Loss: 0.020025 Acc: 13.8000\n",
      " |~~ train@26305  Loss: 0.024647 Acc: 13.4000\n",
      " |~~ train@26310  Loss: 0.020704 Acc: 13.6000\n",
      " |~~ train@26315  Loss: 0.080111 Acc: 12.0000\n",
      " |~~ train@26320  Loss: 0.015634 Acc: 13.8000\n",
      " |~~ train@26325  Loss: 0.049442 Acc: 13.0000\n",
      " |~~ train@26330  Loss: 0.035179 Acc: 13.6000\n",
      " |~~ train@26335  Loss: 0.021454 Acc: 13.8000\n",
      " |~~ train@26340  Loss: 0.019865 Acc: 13.6000\n",
      " |~~ train@26345  Loss: 0.037643 Acc: 13.0000\n",
      " |~~ train@26350  Loss: 0.019685 Acc: 13.8000\n",
      " |~~ train@26355  Loss: 0.055645 Acc: 12.8000\n",
      " |~~ train@26360  Loss: 0.026673 Acc: 13.4000\n",
      " |~~ train@26365  Loss: 0.045311 Acc: 13.2000\n",
      " |~~ train@26370  Loss: 0.030897 Acc: 13.4000\n",
      " |~~ train@26375  Loss: 0.042106 Acc: 13.0000\n",
      " |~~ train@26380  Loss: 0.022566 Acc: 13.6000\n",
      " |~~ train@26385  Loss: 0.021084 Acc: 13.6000\n",
      " |~~ train@26390  Loss: 0.061001 Acc: 13.0000\n",
      " |~~ train@26395  Loss: 0.042805 Acc: 13.0000\n",
      " |~~ train@26400  Loss: 0.023136 Acc: 13.4000\n",
      " |~~ train@26405  Loss: 0.055286 Acc: 13.0000\n",
      " |~~ train@26410  Loss: 0.053374 Acc: 12.6000\n",
      " |~~ train@26415  Loss: 0.036008 Acc: 13.2000\n",
      " |~~ train@26420  Loss: 0.021462 Acc: 13.4000\n",
      " |~~ train@26425  Loss: 0.018322 Acc: 13.8000\n",
      " |~~ train@26430  Loss: 0.030099 Acc: 13.4000\n",
      " |~~ train@26435  Loss: 0.034500 Acc: 13.4000\n",
      " |~~ train@26440  Loss: 0.038072 Acc: 13.0000\n",
      " |~~ train@26445  Loss: 0.038191 Acc: 13.4000\n",
      " |~~ train@26450  Loss: 0.034850 Acc: 13.2000\n",
      " |~~ train@26455  Loss: 0.038119 Acc: 13.4000\n",
      " |~~ train@26460  Loss: 0.031084 Acc: 13.6000\n",
      " |~~ train@26465  Loss: 0.015271 Acc: 13.8000\n",
      " |~~ train@26470  Loss: 0.055542 Acc: 13.0000\n",
      " |~~ train@26475  Loss: 0.030508 Acc: 13.4000\n",
      " |~~ train@26480  Loss: 0.016910 Acc: 13.8000\n",
      " |~~ train@26485  Loss: 0.026507 Acc: 13.6000\n",
      " |~~ train@26490  Loss: 0.010517 Acc: 14.0000\n",
      " |~~ train@26495  Loss: 0.015860 Acc: 13.8000\n",
      " |~~ train@26500  Loss: 0.032101 Acc: 13.2000\n",
      " |~~ train@26505  Loss: 0.036113 Acc: 13.6000\n",
      " |~~ train@26510  Loss: 0.034553 Acc: 13.2000\n",
      " |~~ train@26515  Loss: 0.048730 Acc: 12.8000\n",
      " |~~ train@26520  Loss: 0.063690 Acc: 12.6000\n",
      " |~~ train@26525  Loss: 0.046531 Acc: 13.0000\n",
      " |~~ train@26530  Loss: 0.015686 Acc: 13.8000\n",
      " |~~ train@26535  Loss: 0.056293 Acc: 12.8000\n",
      " |~~ train@26540  Loss: 0.069199 Acc: 12.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@26545  Loss: 0.024458 Acc: 13.6000\n",
      " |~~ train@26550  Loss: 0.036951 Acc: 13.4000\n",
      " |~~ train@26555  Loss: 0.023525 Acc: 13.6000\n",
      " |~~ train@26560  Loss: 0.054301 Acc: 13.0000\n",
      " |~~ train@26565  Loss: 0.016585 Acc: 13.8000\n",
      " |~~ train@26570  Loss: 0.056940 Acc: 12.8000\n",
      " |~~ train@26575  Loss: 0.009953 Acc: 14.0000\n",
      " |~~ train@26580  Loss: 0.048950 Acc: 12.8000\n",
      " |~~ train@26585  Loss: 0.039343 Acc: 13.2000\n",
      " |~~ train@26590  Loss: 0.040327 Acc: 13.0000\n",
      " |~~ train@26595  Loss: 0.021376 Acc: 13.6000\n",
      " |~~ train@26600  Loss: 0.010908 Acc: 14.0000\n",
      " |~~ train@26605  Loss: 0.041630 Acc: 13.0000\n",
      " |~~ train@26610  Loss: 0.023989 Acc: 13.6000\n",
      " |~~ train@26615  Loss: 0.064808 Acc: 12.6000\n",
      " |~~ train@26620  Loss: 0.081460 Acc: 12.4000\n",
      " |~~ train@26625  Loss: 0.059616 Acc: 12.6000\n",
      " |~~ train@26630  Loss: 0.029864 Acc: 13.4000\n",
      " |~~ train@26635  Loss: 0.015559 Acc: 13.8000\n",
      " |~~ train@26640  Loss: 0.056171 Acc: 13.0000\n",
      " |~~ train@26645  Loss: 0.046350 Acc: 13.2000\n",
      " |~~ train@26650  Loss: 0.010364 Acc: 14.0000\n",
      " |~~ train@26655  Loss: 0.042035 Acc: 13.0000\n",
      " |~~ train@26660  Loss: 0.060120 Acc: 12.2000\n",
      " |~~ train@26665  Loss: 0.025384 Acc: 13.6000\n",
      " |~~ train@26670  Loss: 0.015740 Acc: 13.8000\n",
      " |~~ train@26675  Loss: 0.026649 Acc: 13.4000\n",
      " |~~ train@26680  Loss: 0.037392 Acc: 13.4000\n",
      " |~~ train@26685  Loss: 0.044021 Acc: 13.0000\n",
      " |~~ train@26690  Loss: 0.037699 Acc: 13.2000\n",
      " |~~ train@26695  Loss: 0.010833 Acc: 14.0000\n",
      " |~~ train@26700  Loss: 0.023159 Acc: 13.4000\n",
      " |~~ train@26705  Loss: 0.027046 Acc: 13.4000\n",
      " |~~ train@26710  Loss: 0.044812 Acc: 13.0000\n",
      " |~~ train@26715  Loss: 0.016606 Acc: 13.8000\n",
      " |~~ train@26720  Loss: 0.037836 Acc: 13.2000\n",
      " |~~ train@26725  Loss: 0.055180 Acc: 12.6000\n",
      " |~~ train@26730  Loss: 0.026906 Acc: 13.2000\n",
      " |~~ train@26735  Loss: 0.025255 Acc: 13.6000\n",
      " |~~ train@26740  Loss: 0.029237 Acc: 13.4000\n",
      " |~~ train@26745  Loss: 0.098227 Acc: 11.8000\n",
      " |~~ train@26750  Loss: 0.050022 Acc: 12.6000\n",
      " |~~ train@26755  Loss: 0.018273 Acc: 13.6000\n",
      " |~~ train@26760  Loss: 0.035442 Acc: 13.0000\n",
      " |~~ train@26765  Loss: 0.040961 Acc: 13.0000\n",
      " |~~ train@26770  Loss: 0.043204 Acc: 13.2000\n",
      " |~~ train@26775  Loss: 0.039635 Acc: 13.4000\n",
      " |~~ train@26780  Loss: 0.045725 Acc: 13.0000\n",
      " |~~ train@26785  Loss: 0.069987 Acc: 12.2000\n",
      " |~~ train@26790  Loss: 0.048177 Acc: 13.0000\n",
      " |~~ train@26795  Loss: 0.027572 Acc: 13.6000\n",
      " |~~ train@26800  Loss: 0.028887 Acc: 13.4000\n",
      " |~~ train@26805  Loss: 0.012326 Acc: 14.0000\n",
      " |~~ train@26810  Loss: 0.031696 Acc: 13.4000\n",
      " |~~ train@26815  Loss: 0.027354 Acc: 13.4000\n",
      " |~~ train@26820  Loss: 0.027874 Acc: 13.4000\n",
      " |~~ train@26825  Loss: 0.026037 Acc: 13.6000\n",
      " |~~ train@26830  Loss: 0.024221 Acc: 13.4000\n",
      " |~~ train@26835  Loss: 0.019911 Acc: 13.8000\n",
      " |~~ train@26840  Loss: 0.039873 Acc: 13.0000\n",
      " |~~ train@26845  Loss: 0.084365 Acc: 12.2000\n",
      " |~~ train@26850  Loss: 0.012959 Acc: 14.0000\n",
      " |~~ train@26855  Loss: 0.011967 Acc: 14.0000\n",
      " |~~ train@26860  Loss: 0.016812 Acc: 13.8000\n",
      " |~~ train@26865  Loss: 0.046306 Acc: 13.2000\n",
      " |~~ train@26870  Loss: 0.026735 Acc: 13.4000\n",
      " |~~ train@26875  Loss: 0.034827 Acc: 13.2000\n",
      " |~~ train@26880  Loss: 0.037146 Acc: 13.2000\n",
      " |~~ train@26885  Loss: 0.030282 Acc: 13.4000\n",
      " |~~ train@26890  Loss: 0.092944 Acc: 12.0000\n",
      " |~~ train@26895  Loss: 0.027979 Acc: 13.4000\n",
      " |~~ train@26900  Loss: 0.026775 Acc: 13.6000\n",
      " |~~ train@26905  Loss: 0.039930 Acc: 13.2000\n",
      " |~~ train@26910  Loss: 0.013748 Acc: 13.8000\n",
      " |~~ train@26915  Loss: 0.047203 Acc: 12.6000\n",
      " |~~ train@26920  Loss: 0.040284 Acc: 13.4000\n",
      " |~~ train@26925  Loss: 0.045238 Acc: 13.0000\n",
      " |~~ train@26930  Loss: 0.032260 Acc: 13.6000\n",
      " |~~ train@26935  Loss: 0.030663 Acc: 13.4000\n",
      " |~~ train@26940  Loss: 0.078126 Acc: 12.2000\n",
      " |~~ train@26945  Loss: 0.053969 Acc: 13.0000\n",
      " |~~ train@26950  Loss: 0.041727 Acc: 13.2000\n",
      " |~~ train@26955  Loss: 0.100995 Acc: 12.0000\n",
      " |~~ train@26960  Loss: 0.072066 Acc: 12.4000\n",
      " |~~ train@26965  Loss: 0.027032 Acc: 13.6000\n",
      " |~~ train@26970  Loss: 0.037366 Acc: 13.0000\n",
      " |~~ train@26975  Loss: 0.060559 Acc: 12.6000\n",
      " |~~ train@26980  Loss: 0.015625 Acc: 13.8000\n",
      " |~~ train@26985  Loss: 0.011836 Acc: 14.0000\n",
      " |~~ train@26990  Loss: 0.037953 Acc: 13.2000\n",
      " |~~ train@26995  Loss: 0.020985 Acc: 13.8000\n",
      " |~~ train@27000  Loss: 0.073466 Acc: 12.6000\n",
      " |~~ train@27005  Loss: 0.024590 Acc: 13.6000\n",
      " |~~ train@27010  Loss: 0.055535 Acc: 12.6000\n",
      " |~~ train@27015  Loss: 0.051421 Acc: 13.0000\n",
      " |~~ train@27020  Loss: 0.037542 Acc: 13.2000\n",
      " |~~ train@27025  Loss: 0.028159 Acc: 13.6000\n",
      " |~~ train@27030  Loss: 0.042940 Acc: 13.0000\n",
      " |~~ train@27035  Loss: 0.028916 Acc: 13.6000\n",
      " |~~ train@27040  Loss: 0.040183 Acc: 13.2000\n",
      " |~~ train@27045  Loss: 0.048568 Acc: 13.2000\n",
      " |~~ train@27050  Loss: 0.024637 Acc: 13.6000\n",
      " |~~ train@27055  Loss: 0.011839 Acc: 14.0000\n",
      " |~~ train@27060  Loss: 0.048542 Acc: 12.8000\n",
      " |~~ train@27065  Loss: 0.015897 Acc: 13.8000\n",
      " |~~ train@27070  Loss: 0.061829 Acc: 12.6000\n",
      " |~~ train@27075  Loss: 0.056568 Acc: 12.8000\n",
      " |~~ train@27080  Loss: 0.040927 Acc: 13.0000\n",
      " |~~ train@27085  Loss: 0.027321 Acc: 13.6000\n",
      " |~~ train@27090  Loss: 0.029927 Acc: 13.4000\n",
      " |~~ train@27095  Loss: 0.061005 Acc: 12.8000\n",
      " |~~ train@27100  Loss: 0.096613 Acc: 12.0000\n",
      " |~~ train@27105  Loss: 0.011224 Acc: 14.0000\n",
      " |~~ train@27110  Loss: 0.019892 Acc: 13.6000\n",
      " |~~ train@27115  Loss: 0.011075 Acc: 14.0000\n",
      " |~~ train@27120  Loss: 0.046585 Acc: 12.8000\n",
      " |~~ train@27125  Loss: 0.011142 Acc: 14.0000\n",
      " |~~ train@27130  Loss: 0.040342 Acc: 13.0000\n",
      " |~~ train@27135  Loss: 0.042423 Acc: 13.2000\n",
      " |~~ train@27140  Loss: 0.044166 Acc: 12.8000\n",
      " |~~ train@27145  Loss: 0.036424 Acc: 13.2000\n",
      " |~~ train@27150  Loss: 0.047902 Acc: 12.8000\n",
      " |~~ train@27155  Loss: 0.015957 Acc: 13.8000\n",
      " |~~ train@27160  Loss: 0.027786 Acc: 13.4000\n",
      " |~~ train@27165  Loss: 0.082254 Acc: 12.2000\n",
      " |~~ train@27170  Loss: 0.039692 Acc: 13.4000\n",
      " |~~ train@27175  Loss: 0.046197 Acc: 13.0000\n",
      " |~~ train@27180  Loss: 0.037508 Acc: 13.2000\n",
      " |~~ train@27185  Loss: 0.036342 Acc: 13.0000\n",
      " |~~ train@27190  Loss: 0.077771 Acc: 12.2000\n",
      " |~~ train@27195  Loss: 0.045724 Acc: 13.0000\n",
      " |~~ train@27200  Loss: 0.073583 Acc: 12.2000\n",
      " |~~ train@27205  Loss: 0.035425 Acc: 13.2000\n",
      " |~~ train@27210  Loss: 0.023605 Acc: 13.4000\n",
      " |~~ train@27215  Loss: 0.030185 Acc: 13.4000\n",
      " |~~ train@27220  Loss: 0.012659 Acc: 14.0000\n",
      " |~~ train@27225  Loss: 0.041019 Acc: 12.8000\n",
      " |~~ train@27230  Loss: 0.053188 Acc: 12.8000\n",
      " |~~ train@27235  Loss: 0.063727 Acc: 12.6000\n",
      " |~~ train@27240  Loss: 0.038203 Acc: 13.4000\n",
      " |~~ train@27245  Loss: 0.032334 Acc: 13.4000\n",
      " |~~ train@27250  Loss: 0.027958 Acc: 13.4000\n",
      " |~~ train@27255  Loss: 0.030212 Acc: 13.6000\n",
      " |~~ train@27260  Loss: 0.041664 Acc: 12.8000\n",
      " |~~ train@27265  Loss: 0.027100 Acc: 13.4000\n",
      " |~~ train@27270  Loss: 0.062753 Acc: 12.4000\n",
      " |~~ train@27275  Loss: 0.013827 Acc: 13.8000\n",
      " |~~ train@27280  Loss: 0.012501 Acc: 14.0000\n",
      " |~~ train@27285  Loss: 0.029104 Acc: 13.4000\n",
      " |~~ train@27290  Loss: 0.022833 Acc: 13.8000\n",
      " |~~ train@27295  Loss: 0.041814 Acc: 13.2000\n",
      " |~~ train@27300  Loss: 0.027158 Acc: 13.6000\n",
      " |~~ train@27305  Loss: 0.013015 Acc: 14.0000\n",
      " |~~ train@27310  Loss: 0.032091 Acc: 13.4000\n",
      " |~~ train@27315  Loss: 0.028082 Acc: 13.4000\n",
      " |~~ train@27320  Loss: 0.038870 Acc: 13.2000\n",
      " |~~ train@27325  Loss: 0.012836 Acc: 14.0000\n",
      " |~~ train@27330  Loss: 0.052549 Acc: 12.8000\n",
      " |~~ train@27335  Loss: 0.027304 Acc: 13.6000\n",
      " |~~ train@27340  Loss: 0.033280 Acc: 13.6000\n",
      " |~~ train@27345  Loss: 0.057201 Acc: 12.8000\n",
      " |~~ train@27350  Loss: 0.022189 Acc: 13.6000\n",
      " |~~ train@27355  Loss: 0.042958 Acc: 13.0000\n",
      " |~~ train@27360  Loss: 0.042179 Acc: 13.2000\n",
      " |~~ train@27365  Loss: 0.026815 Acc: 13.6000\n",
      " |~~ train@27370  Loss: 0.028297 Acc: 13.4000\n",
      " |~~ train@27375  Loss: 0.024152 Acc: 13.6000\n",
      " |~~ train@27380  Loss: 0.047407 Acc: 13.2000\n",
      " |~~ train@27385  Loss: 0.016265 Acc: 13.8000\n",
      " |~~ train@27390  Loss: 0.051424 Acc: 13.0000\n",
      " |~~ train@27395  Loss: 0.021091 Acc: 13.8000\n",
      " |~~ train@27400  Loss: 0.016720 Acc: 13.8000\n",
      " |~~ train@27405  Loss: 0.048705 Acc: 12.8000\n",
      " |~~ train@27410  Loss: 0.010916 Acc: 14.0000\n",
      " |~~ train@27415  Loss: 0.041814 Acc: 13.2000\n",
      " |~~ train@27420  Loss: 0.028381 Acc: 13.2000\n",
      " |~~ train@27425  Loss: 0.041727 Acc: 12.8000\n",
      " |~~ train@27430  Loss: 0.031963 Acc: 13.4000\n",
      " |~~ train@27435  Loss: 0.018810 Acc: 13.6000\n",
      " |~~ train@27440  Loss: 0.054271 Acc: 12.8000\n",
      " |~~ train@27445  Loss: 0.066533 Acc: 12.4000\n",
      " |~~ train@27450  Loss: 0.039954 Acc: 13.2000\n",
      " |~~ train@27455  Loss: 0.035727 Acc: 13.4000\n",
      " |~~ train@27460  Loss: 0.027478 Acc: 13.6000\n",
      " |~~ train@27465  Loss: 0.018220 Acc: 13.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@27470  Loss: 0.054857 Acc: 12.8000\n",
      " |~~ train@27475  Loss: 0.027959 Acc: 13.4000\n",
      " |~~ train@27480  Loss: 0.018879 Acc: 13.8000\n",
      " |~~ train@27485  Loss: 0.036064 Acc: 13.2000\n",
      " |~~ train@27490  Loss: 0.027192 Acc: 13.6000\n",
      " |~~ train@27495  Loss: 0.028923 Acc: 13.4000\n",
      " |~~ train@27500  Loss: 0.019750 Acc: 13.8000\n",
      " |~~ train@27505  Loss: 0.017881 Acc: 13.6000\n",
      " |~~ train@27510  Loss: 0.031405 Acc: 13.4000\n",
      " |~~ train@27515  Loss: 0.054978 Acc: 12.8000\n",
      " |~~ train@27520  Loss: 0.035776 Acc: 13.4000\n",
      " |~~ train@27525  Loss: 0.025541 Acc: 13.6000\n",
      " |~~ train@27530  Loss: 0.033371 Acc: 13.4000\n",
      " |~~ train@27535  Loss: 0.018629 Acc: 13.8000\n",
      " |~~ train@27540  Loss: 0.061954 Acc: 12.8000\n",
      " |~~ train@27545  Loss: 0.061846 Acc: 12.4000\n",
      " |~~ train@27550  Loss: 0.039400 Acc: 13.0000\n",
      " |~~ train@27555  Loss: 0.037325 Acc: 13.4000\n",
      " |~~ train@27560  Loss: 0.028106 Acc: 13.4000\n",
      " |~~ train@27565  Loss: 0.040350 Acc: 13.0000\n",
      " |~~ train@27570  Loss: 0.044349 Acc: 13.0000\n",
      " |~~ train@27575  Loss: 0.029443 Acc: 13.4000\n",
      " |~~ train@27580  Loss: 0.010628 Acc: 14.0000\n",
      " |~~ train@27585  Loss: 0.026089 Acc: 13.6000\n",
      " |~~ train@27590  Loss: 0.024521 Acc: 13.6000\n",
      " |~~ train@27595  Loss: 0.041806 Acc: 13.0000\n",
      " |~~ train@27600  Loss: 0.027168 Acc: 13.4000\n",
      " |~~ train@27605  Loss: 0.033314 Acc: 13.2000\n",
      " |~~ train@27610  Loss: 0.021325 Acc: 13.6000\n",
      " |~~ train@27615  Loss: 0.049323 Acc: 12.8000\n",
      " |~~ train@27620  Loss: 0.024040 Acc: 13.6000\n",
      " |~~ train@27625  Loss: 0.016375 Acc: 13.8000\n",
      " |~~ train@27630  Loss: 0.030261 Acc: 13.4000\n",
      " |~~ train@27635  Loss: 0.066941 Acc: 12.6000\n",
      " |~~ train@27640  Loss: 0.039153 Acc: 13.2000\n",
      " |~~ train@27645  Loss: 0.023419 Acc: 13.6000\n",
      " |~~ train@27650  Loss: 0.041028 Acc: 13.2000\n",
      " |~~ train@27655  Loss: 0.022034 Acc: 13.6000\n",
      " |~~ train@27660  Loss: 0.025439 Acc: 13.6000\n",
      " |~~ train@27665  Loss: 0.014446 Acc: 13.8000\n",
      " |~~ train@27670  Loss: 0.046545 Acc: 13.0000\n",
      " |~~ train@27675  Loss: 0.039769 Acc: 13.0000\n",
      " |~~ train@27680  Loss: 0.056344 Acc: 12.8000\n",
      " |~~ train@27685  Loss: 0.054232 Acc: 12.8000\n",
      " |~~ train@27690  Loss: 0.049042 Acc: 12.8000\n",
      " |~~ train@27695  Loss: 0.041019 Acc: 13.2000\n",
      " |~~ train@27700  Loss: 0.030140 Acc: 13.6000\n",
      " |~~ train@27705  Loss: 0.026550 Acc: 13.6000\n",
      " |~~ train@27710  Loss: 0.019163 Acc: 13.8000\n",
      " |~~ train@27715  Loss: 0.023853 Acc: 13.6000\n",
      " |~~ train@27720  Loss: 0.028828 Acc: 13.4000\n",
      " |~~ train@27725  Loss: 0.046471 Acc: 13.0000\n",
      " |~~ train@27730  Loss: 0.065074 Acc: 12.6000\n",
      " |~~ train@27735  Loss: 0.037374 Acc: 13.4000\n",
      " |~~ train@27740  Loss: 0.028560 Acc: 13.4000\n",
      " |~~ train@27745  Loss: 0.031509 Acc: 13.2000\n",
      " |~~ train@27750  Loss: 0.024787 Acc: 13.6000\n",
      " |~~ train@27755  Loss: 0.011357 Acc: 14.0000\n",
      " |~~ train@27760  Loss: 0.050141 Acc: 12.8000\n",
      " |~~ train@27765  Loss: 0.021784 Acc: 13.6000\n",
      " |~~ train@27770  Loss: 0.048237 Acc: 12.4000\n",
      " |~~ train@27775  Loss: 0.017211 Acc: 13.8000\n",
      " |~~ train@27780  Loss: 0.031788 Acc: 13.4000\n",
      " |~~ train@27785  Loss: 0.013978 Acc: 13.8000\n",
      " |~~ train@27790  Loss: 0.023891 Acc: 13.6000\n",
      " |~~ train@27795  Loss: 0.060444 Acc: 12.6000\n",
      " |~~ train@27800  Loss: 0.025469 Acc: 13.4000\n",
      " |~~ train@27805  Loss: 0.019284 Acc: 13.6000\n",
      " |~~ train@27810  Loss: 0.023908 Acc: 13.6000\n",
      " |~~ train@27815  Loss: 0.084957 Acc: 12.4000\n",
      " |~~ train@27820  Loss: 0.043212 Acc: 12.8000\n",
      " |~~ train@27825  Loss: 0.033658 Acc: 13.2000\n",
      " |~~ train@27830  Loss: 0.062419 Acc: 12.8000\n",
      " |~~ train@27835  Loss: 0.019349 Acc: 13.6000\n",
      " |~~ train@27840  Loss: 0.051263 Acc: 13.0000\n",
      " |~~ train@27845  Loss: 0.038155 Acc: 13.2000\n",
      " |~~ train@27850  Loss: 0.036460 Acc: 13.4000\n",
      " |~~ train@27855  Loss: 0.033217 Acc: 13.4000\n",
      " |~~ train@27860  Loss: 0.011086 Acc: 14.0000\n",
      " |~~ train@27865  Loss: 0.031738 Acc: 13.2000\n",
      " |~~ train@27870  Loss: 0.010519 Acc: 14.0000\n",
      " |~~ train@27875  Loss: 0.029025 Acc: 13.6000\n",
      " |~~ train@27880  Loss: 0.037899 Acc: 13.2000\n",
      " |~~ train@27885  Loss: 0.026501 Acc: 13.4000\n",
      " |~~ train@27890  Loss: 0.037434 Acc: 13.2000\n",
      " |~~ train@27895  Loss: 0.043362 Acc: 13.2000\n",
      " |~~ train@27900  Loss: 0.046538 Acc: 12.8000\n",
      " |~~ train@27905  Loss: 0.028229 Acc: 13.4000\n",
      " |~~ train@27910  Loss: 0.037923 Acc: 13.4000\n",
      " |~~ train@27915  Loss: 0.022060 Acc: 13.6000\n",
      " |~~ train@27920  Loss: 0.014992 Acc: 13.8000\n",
      " |~~ train@27925  Loss: 0.043851 Acc: 13.2000\n",
      " |~~ train@27930  Loss: 0.062563 Acc: 12.8000\n",
      " |~~ train@27935  Loss: 0.066278 Acc: 12.2000\n",
      " |~~ train@27940  Loss: 0.060497 Acc: 12.4000\n",
      " |~~ train@27945  Loss: 0.061598 Acc: 12.8000\n",
      " |~~ train@27950  Loss: 0.018429 Acc: 13.8000\n",
      " |~~ train@27955  Loss: 0.021978 Acc: 13.6000\n",
      " |~~ train@27960  Loss: 0.033460 Acc: 13.4000\n",
      " |~~ train@27965  Loss: 0.031491 Acc: 13.6000\n",
      " |~~ train@27970  Loss: 0.018904 Acc: 13.8000\n",
      " |~~ train@27975  Loss: 0.024625 Acc: 13.6000\n",
      " |~~ train@27980  Loss: 0.076963 Acc: 12.2000\n",
      " |~~ train@27985  Loss: 0.017336 Acc: 13.6000\n",
      " |~~ train@27990  Loss: 0.033969 Acc: 13.2000\n",
      " |~~ train@27995  Loss: 0.038955 Acc: 13.2000\n",
      " |~~ train@28000  Loss: 0.028350 Acc: 13.4000\n",
      " |~~ train@28005  Loss: 0.013337 Acc: 13.8000\n",
      " |~~ train@28010  Loss: 0.041829 Acc: 13.4000\n",
      " |~~ train@28015  Loss: 0.032263 Acc: 13.2000\n",
      " |~~ train@28020  Loss: 0.027723 Acc: 13.4000\n",
      " |~~ train@28025  Loss: 0.062719 Acc: 13.0000\n",
      " |~~ train@28030  Loss: 0.013585 Acc: 13.8000\n",
      " |~~ train@28035  Loss: 0.030116 Acc: 13.4000\n",
      " |~~ train@28040  Loss: 0.034695 Acc: 13.2000\n",
      " |~~ train@28045  Loss: 0.028587 Acc: 13.4000\n",
      " |~~ train@28050  Loss: 0.015108 Acc: 13.8000\n",
      " |~~ train@28055  Loss: 0.034125 Acc: 13.2000\n",
      " |~~ train@28060  Loss: 0.012887 Acc: 13.8000\n",
      " |~~ train@28065  Loss: 0.036187 Acc: 13.0000\n",
      " |~~ train@28070  Loss: 0.025184 Acc: 13.6000\n",
      " |~~ train@28075  Loss: 0.022963 Acc: 13.6000\n",
      " |~~ train@28080  Loss: 0.080517 Acc: 12.4000\n",
      " |~~ train@28085  Loss: 0.054168 Acc: 12.6000\n",
      " |~~ train@28090  Loss: 0.026604 Acc: 13.4000\n",
      " |~~ train@28095  Loss: 0.039461 Acc: 13.0000\n",
      " |~~ train@28100  Loss: 0.023544 Acc: 13.6000\n",
      " |~~ train@28105  Loss: 0.030236 Acc: 13.6000\n",
      " |~~ train@28110  Loss: 0.027570 Acc: 13.4000\n",
      " |~~ train@28115  Loss: 0.063820 Acc: 12.4000\n",
      " |~~ train@28120  Loss: 0.015750 Acc: 13.8000\n",
      " |~~ train@28125  Loss: 0.035137 Acc: 13.4000\n",
      " |~~ train@28130  Loss: 0.040398 Acc: 13.2000\n",
      " |~~ train@28135  Loss: 0.053744 Acc: 12.8000\n",
      " |~~ train@28140  Loss: 0.025774 Acc: 13.4000\n",
      " |~~ train@28145  Loss: 0.034848 Acc: 13.4000\n",
      " |~~ train@28150  Loss: 0.055894 Acc: 13.0000\n",
      " |~~ train@28155  Loss: 0.041041 Acc: 13.0000\n",
      " |~~ train@28160  Loss: 0.027458 Acc: 13.4000\n",
      " |~~ train@28165  Loss: 0.014245 Acc: 13.8000\n",
      " |~~ train@28170  Loss: 0.048697 Acc: 12.8000\n",
      " |~~ train@28175  Loss: 0.061768 Acc: 12.8000\n",
      " |~~ train@28180  Loss: 0.034384 Acc: 13.4000\n",
      " |~~ train@28185  Loss: 0.027694 Acc: 13.6000\n",
      " |~~ train@28190  Loss: 0.092337 Acc: 11.8000\n",
      " |~~ train@28195  Loss: 0.025468 Acc: 13.6000\n",
      " |~~ train@28200  Loss: 0.011211 Acc: 14.0000\n",
      " |~~ train@28205  Loss: 0.027689 Acc: 13.6000\n",
      " |~~ train@28210  Loss: 0.036069 Acc: 13.2000\n",
      " |~~ train@28215  Loss: 0.030987 Acc: 13.4000\n",
      " |~~ train@28220  Loss: 0.021069 Acc: 13.6000\n",
      " |~~ train@28225  Loss: 0.025667 Acc: 13.6000\n",
      " |~~ train@28230  Loss: 0.031775 Acc: 13.2000\n",
      " |~~ train@28235  Loss: 0.055382 Acc: 13.0000\n",
      " |~~ train@28240  Loss: 0.023018 Acc: 13.6000\n",
      " |~~ train@28245  Loss: 0.032848 Acc: 13.4000\n",
      " |~~ train@28250  Loss: 0.026484 Acc: 13.6000\n",
      " |~~ train@28255  Loss: 0.029659 Acc: 13.4000\n",
      " |~~ train@28260  Loss: 0.026033 Acc: 13.6000\n",
      " |~~ train@28265  Loss: 0.024350 Acc: 13.6000\n",
      " |~~ train@28270  Loss: 0.042149 Acc: 13.2000\n",
      " |~~ train@28275  Loss: 0.042468 Acc: 13.0000\n",
      " |~~ train@28280  Loss: 0.036880 Acc: 13.2000\n",
      " |~~ train@28285  Loss: 0.036163 Acc: 13.4000\n",
      " |~~ train@28290  Loss: 0.041485 Acc: 13.0000\n",
      " |~~ train@28295  Loss: 0.042627 Acc: 13.2000\n",
      " |~~ train@28300  Loss: 0.027529 Acc: 13.4000\n",
      " |~~ train@28305  Loss: 0.074445 Acc: 12.4000\n",
      " |~~ train@28310  Loss: 0.039832 Acc: 13.0000\n",
      " |~~ train@28315  Loss: 0.018528 Acc: 13.8000\n",
      " |~~ train@28320  Loss: 0.082790 Acc: 12.2000\n",
      " |~~ train@28325  Loss: 0.020441 Acc: 13.6000\n",
      " |~~ train@28330  Loss: 0.010269 Acc: 14.0000\n",
      " |~~ train@28335  Loss: 0.022435 Acc: 13.6000\n",
      " |~~ train@28340  Loss: 0.035941 Acc: 13.2000\n",
      " |~~ train@28345  Loss: 0.042571 Acc: 13.0000\n",
      " |~~ train@28350  Loss: 0.029159 Acc: 13.4000\n",
      " |~~ train@28355  Loss: 0.044254 Acc: 13.4000\n",
      " |~~ train@28360  Loss: 0.019085 Acc: 13.8000\n",
      " |~~ train@28365  Loss: 0.027019 Acc: 13.6000\n",
      " |~~ train@28370  Loss: 0.025228 Acc: 13.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@28375  Loss: 0.014004 Acc: 13.8000\n",
      " |~~ train@28380  Loss: 0.025891 Acc: 13.6000\n",
      " |~~ train@28385  Loss: 0.027546 Acc: 13.6000\n",
      " |~~ train@28390  Loss: 0.048078 Acc: 13.0000\n",
      " |~~ train@28395  Loss: 0.053516 Acc: 12.8000\n",
      " |~~ train@28400  Loss: 0.057257 Acc: 12.4000\n",
      " |~~ train@28405  Loss: 0.036839 Acc: 13.2000\n",
      " |~~ train@28410  Loss: 0.066007 Acc: 12.6000\n",
      " |~~ train@28415  Loss: 0.030389 Acc: 13.2000\n",
      " |~~ train@28420  Loss: 0.046643 Acc: 13.2000\n",
      " |~~ train@28425  Loss: 0.043497 Acc: 13.2000\n",
      " |~~ train@28430  Loss: 0.044358 Acc: 13.0000\n",
      " |~~ train@28435  Loss: 0.036613 Acc: 13.4000\n",
      " |~~ train@28440  Loss: 0.027974 Acc: 13.4000\n",
      " |~~ train@28445  Loss: 0.019181 Acc: 13.8000\n",
      " |~~ train@28450  Loss: 0.041987 Acc: 13.0000\n",
      " |~~ train@28455  Loss: 0.021859 Acc: 13.8000\n",
      " |~~ train@28460  Loss: 0.033580 Acc: 13.4000\n",
      " |~~ train@28465  Loss: 0.023483 Acc: 13.6000\n",
      " |~~ train@28470  Loss: 0.020896 Acc: 13.6000\n",
      " |~~ train@28475  Loss: 0.012198 Acc: 13.8000\n",
      " |~~ train@28480  Loss: 0.056175 Acc: 12.6000\n",
      " |~~ train@28485  Loss: 0.031637 Acc: 13.4000\n",
      " |~~ train@28490  Loss: 0.025566 Acc: 13.4000\n",
      " |~~ train@28495  Loss: 0.031747 Acc: 13.4000\n",
      " |~~ train@28500  Loss: 0.028309 Acc: 13.4000\n",
      " |~~ train@28505  Loss: 0.030627 Acc: 13.2000\n",
      " |~~ train@28510  Loss: 0.026298 Acc: 13.4000\n",
      " |~~ train@28515  Loss: 0.041922 Acc: 13.2000\n",
      " |~~ train@28520  Loss: 0.016537 Acc: 13.8000\n",
      " |~~ train@28525  Loss: 0.024365 Acc: 13.6000\n",
      " |~~ train@28530  Loss: 0.034399 Acc: 13.4000\n",
      " |~~ train@28535  Loss: 0.059481 Acc: 12.6000\n",
      " |~~ train@28540  Loss: 0.020460 Acc: 13.8000\n",
      " |~~ train@28545  Loss: 0.023207 Acc: 13.6000\n",
      " |~~ train@28550  Loss: 0.013419 Acc: 13.8000\n",
      " |~~ train@28555  Loss: 0.052144 Acc: 12.8000\n",
      " |~~ train@28560  Loss: 0.037860 Acc: 13.0000\n",
      " |~~ train@28565  Loss: 0.035439 Acc: 13.2000\n",
      " |~~ train@28570  Loss: 0.023523 Acc: 13.6000\n",
      " |~~ train@28575  Loss: 0.027060 Acc: 13.6000\n",
      " |~~ train@28580  Loss: 0.036307 Acc: 13.2000\n",
      " |~~ train@28585  Loss: 0.030427 Acc: 13.4000\n",
      " |~~ train@28590  Loss: 0.039035 Acc: 13.2000\n",
      " |~~ train@28595  Loss: 0.020489 Acc: 13.6000\n",
      " |~~ train@28600  Loss: 0.046669 Acc: 13.2000\n",
      " |~~ train@28605  Loss: 0.057540 Acc: 13.0000\n",
      " |~~ train@28610  Loss: 0.036198 Acc: 13.4000\n",
      " |~~ train@28615  Loss: 0.017708 Acc: 13.8000\n",
      " |~~ train@28620  Loss: 0.035315 Acc: 13.4000\n",
      " |~~ train@28625  Loss: 0.051562 Acc: 12.8000\n",
      " |~~ train@28630  Loss: 0.042695 Acc: 12.8000\n",
      " |~~ train@28635  Loss: 0.035666 Acc: 13.2000\n",
      " |~~ train@28640  Loss: 0.033754 Acc: 13.4000\n",
      " |~~ train@28645  Loss: 0.042899 Acc: 13.0000\n",
      " |~~ train@28650  Loss: 0.048846 Acc: 12.8000\n",
      " |~~ train@28655  Loss: 0.059814 Acc: 12.6000\n",
      " |~~ train@28660  Loss: 0.033749 Acc: 13.6000\n",
      " |~~ train@28665  Loss: 0.048115 Acc: 12.8000\n",
      " |~~ train@28670  Loss: 0.054417 Acc: 12.8000\n",
      " |~~ train@28675  Loss: 0.040849 Acc: 13.0000\n",
      " |~~ train@28680  Loss: 0.030002 Acc: 13.6000\n",
      " |~~ train@28685  Loss: 0.046402 Acc: 12.8000\n",
      " |~~ train@28690  Loss: 0.036417 Acc: 13.4000\n",
      " |~~ train@28695  Loss: 0.057728 Acc: 12.4000\n",
      " |~~ train@28700  Loss: 0.060930 Acc: 12.8000\n",
      " |~~ train@28705  Loss: 0.026105 Acc: 13.2000\n",
      " |~~ train@28710  Loss: 0.020829 Acc: 13.6000\n",
      " |~~ train@28715  Loss: 0.061841 Acc: 12.4000\n",
      " |~~ train@28720  Loss: 0.017294 Acc: 13.8000\n",
      " |~~ train@28725  Loss: 0.026447 Acc: 13.6000\n",
      " |~~ train@28730  Loss: 0.029206 Acc: 13.4000\n",
      " |~~ train@28735  Loss: 0.038802 Acc: 13.2000\n",
      " |~~ train@28740  Loss: 0.024170 Acc: 13.6000\n",
      " |~~ train@28745  Loss: 0.032145 Acc: 13.4000\n",
      " |~~ train@28750  Loss: 0.027823 Acc: 13.4000\n",
      " |~~ train@28755  Loss: 0.016442 Acc: 13.8000\n",
      " |~~ train@28760  Loss: 0.028514 Acc: 13.4000\n",
      " |~~ train@28765  Loss: 0.031398 Acc: 13.2000\n",
      " |~~ train@28770  Loss: 0.020953 Acc: 13.6000\n",
      " |~~ train@28775  Loss: 0.053372 Acc: 12.8000\n",
      " |~~ train@28780  Loss: 0.019242 Acc: 13.6000\n",
      " |~~ train@28785  Loss: 0.043748 Acc: 13.0000\n",
      " |~~ train@28790  Loss: 0.045459 Acc: 13.0000\n",
      " |~~ train@28795  Loss: 0.023046 Acc: 13.6000\n",
      " |~~ train@28800  Loss: 0.030812 Acc: 13.2000\n",
      " |~~ train@28805  Loss: 0.044599 Acc: 12.8000\n",
      " |~~ train@28810  Loss: 0.054707 Acc: 13.2000\n",
      " |~~ train@28815  Loss: 0.044264 Acc: 13.0000\n",
      " |~~ train@28820  Loss: 0.022875 Acc: 13.8000\n",
      " |~~ train@28825  Loss: 0.019879 Acc: 13.6000\n",
      " |~~ train@28830  Loss: 0.020413 Acc: 13.8000\n",
      " |~~ train@28835  Loss: 0.032699 Acc: 13.2000\n",
      " |~~ train@28840  Loss: 0.048193 Acc: 12.8000\n",
      " |~~ train@28845  Loss: 0.017243 Acc: 13.8000\n",
      " |~~ train@28850  Loss: 0.039105 Acc: 13.0000\n",
      " |~~ train@28855  Loss: 0.011360 Acc: 14.0000\n",
      " |~~ train@28860  Loss: 0.068841 Acc: 12.4000\n",
      " |~~ train@28865  Loss: 0.035998 Acc: 13.2000\n",
      " |~~ train@28870  Loss: 0.038389 Acc: 13.2000\n",
      " |~~ train@28875  Loss: 0.036557 Acc: 13.4000\n",
      " |~~ train@28880  Loss: 0.036200 Acc: 13.2000\n",
      " |~~ train@28885  Loss: 0.027428 Acc: 13.6000\n",
      " |~~ train@28890  Loss: 0.041450 Acc: 13.2000\n",
      " |~~ train@28895  Loss: 0.011449 Acc: 14.0000\n",
      " |~~ train@28900  Loss: 0.054324 Acc: 12.8000\n",
      " |~~ train@28905  Loss: 0.051842 Acc: 13.2000\n",
      " |~~ train@28910  Loss: 0.075018 Acc: 12.2000\n",
      " |~~ train@28915  Loss: 0.047567 Acc: 13.0000\n",
      " |~~ train@28920  Loss: 0.029335 Acc: 13.4000\n",
      " |~~ train@28925  Loss: 0.023149 Acc: 13.6000\n",
      " |~~ train@28930  Loss: 0.032697 Acc: 13.2000\n",
      " |~~ train@28935  Loss: 0.014464 Acc: 13.8000\n",
      " |~~ train@28940  Loss: 0.029623 Acc: 13.4000\n",
      " |~~ train@28945  Loss: 0.043287 Acc: 12.8000\n",
      " |~~ train@28950  Loss: 0.018578 Acc: 13.8000\n",
      " |~~ train@28955  Loss: 0.027011 Acc: 13.6000\n",
      " |~~ train@28960  Loss: 0.053206 Acc: 12.8000\n",
      " |~~ train@28965  Loss: 0.048794 Acc: 12.8000\n",
      " |~~ train@28970  Loss: 0.020611 Acc: 13.8000\n",
      " |~~ train@28975  Loss: 0.031572 Acc: 13.4000\n",
      " |~~ train@28980  Loss: 0.026146 Acc: 13.6000\n",
      " |~~ train@28985  Loss: 0.017519 Acc: 13.6000\n",
      " |~~ train@28990  Loss: 0.052347 Acc: 13.0000\n",
      " |~~ train@28995  Loss: 0.023612 Acc: 13.6000\n",
      " |~~ train@29000  Loss: 0.062485 Acc: 12.8000\n",
      " |~~ train@29005  Loss: 0.041506 Acc: 13.0000\n",
      " |~~ train@29010  Loss: 0.044728 Acc: 13.2000\n",
      " |~~ train@29015  Loss: 0.023395 Acc: 13.6000\n",
      " |~~ train@29020  Loss: 0.050690 Acc: 12.8000\n",
      " |~~ train@29025  Loss: 0.011285 Acc: 14.0000\n",
      " |~~ train@29030  Loss: 0.011216 Acc: 14.0000\n",
      " |~~ train@29035  Loss: 0.033017 Acc: 13.4000\n",
      " |~~ train@29040  Loss: 0.021220 Acc: 13.8000\n",
      " |~~ train@29045  Loss: 0.022432 Acc: 13.6000\n",
      " |~~ train@29050  Loss: 0.019713 Acc: 13.8000\n",
      " |~~ train@29055  Loss: 0.039672 Acc: 13.2000\n",
      " |~~ train@29060  Loss: 0.031002 Acc: 13.6000\n",
      " |~~ train@29065  Loss: 0.059760 Acc: 12.8000\n",
      " |~~ train@29070  Loss: 0.022591 Acc: 13.6000\n",
      " |~~ train@29075  Loss: 0.084487 Acc: 12.6000\n",
      " |~~ train@29080  Loss: 0.040426 Acc: 12.8000\n",
      " |~~ train@29085  Loss: 0.028560 Acc: 13.4000\n",
      " |~~ train@29090  Loss: 0.025655 Acc: 13.4000\n",
      " |~~ train@29095  Loss: 0.025458 Acc: 13.6000\n",
      " |~~ train@29100  Loss: 0.010449 Acc: 14.0000\n",
      " |~~ train@29105  Loss: 0.027534 Acc: 13.4000\n",
      " |~~ train@29110  Loss: 0.035541 Acc: 13.4000\n",
      " |~~ train@29115  Loss: 0.025547 Acc: 13.6000\n",
      " |~~ train@29120  Loss: 0.033920 Acc: 13.2000\n",
      " |~~ train@29125  Loss: 0.019863 Acc: 13.6000\n",
      " |~~ train@29130  Loss: 0.040301 Acc: 13.2000\n",
      " |~~ train@29135  Loss: 0.032810 Acc: 13.6000\n",
      " |~~ train@29140  Loss: 0.048108 Acc: 13.0000\n",
      " |~~ train@29145  Loss: 0.036671 Acc: 13.0000\n",
      " |~~ train@29150  Loss: 0.032587 Acc: 13.4000\n",
      " |~~ train@29155  Loss: 0.032115 Acc: 13.4000\n",
      " |~~ train@29160  Loss: 0.035912 Acc: 13.4000\n",
      " |~~ train@29165  Loss: 0.033994 Acc: 13.4000\n",
      " |~~ train@29170  Loss: 0.060158 Acc: 12.6000\n",
      " |~~ train@29175  Loss: 0.020886 Acc: 13.4000\n",
      " |~~ train@29180  Loss: 0.028996 Acc: 13.4000\n",
      " |~~ train@29185  Loss: 0.038520 Acc: 13.0000\n",
      " |~~ train@29190  Loss: 0.034741 Acc: 13.2000\n",
      " |~~ train@29195  Loss: 0.015372 Acc: 13.6000\n",
      " |~~ train@29200  Loss: 0.031925 Acc: 13.2000\n",
      " |~~ train@29205  Loss: 0.036036 Acc: 13.0000\n",
      " |~~ train@29210  Loss: 0.029716 Acc: 13.6000\n",
      " |~~ train@29215  Loss: 0.049858 Acc: 12.8000\n",
      " |~~ train@29220  Loss: 0.026090 Acc: 13.4000\n",
      " |~~ train@29225  Loss: 0.057384 Acc: 13.2000\n",
      " |~~ train@29230  Loss: 0.050965 Acc: 13.2000\n",
      " |~~ train@29235  Loss: 0.038228 Acc: 13.4000\n",
      " |~~ train@29240  Loss: 0.062523 Acc: 13.0000\n",
      " |~~ train@29245  Loss: 0.060618 Acc: 12.6000\n",
      " |~~ train@29250  Loss: 0.025512 Acc: 13.6000\n",
      " |~~ train@29255  Loss: 0.068240 Acc: 12.2000\n",
      " |~~ train@29260  Loss: 0.017634 Acc: 13.8000\n",
      " |~~ train@29265  Loss: 0.035831 Acc: 13.2000\n",
      " |~~ train@29270  Loss: 0.013839 Acc: 13.8000\n",
      " |~~ train@29275  Loss: 0.030417 Acc: 13.4000\n",
      " |~~ train@29280  Loss: 0.048144 Acc: 12.6000\n",
      " |~~ train@29285  Loss: 0.041176 Acc: 13.2000\n",
      " |~~ train@29290  Loss: 0.062644 Acc: 12.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@29295  Loss: 0.049505 Acc: 13.0000\n",
      " |~~ train@29300  Loss: 0.046234 Acc: 13.0000\n",
      " |~~ train@29305  Loss: 0.032801 Acc: 13.4000\n",
      " |~~ train@29310  Loss: 0.010880 Acc: 14.0000\n",
      " |~~ train@29315  Loss: 0.067949 Acc: 12.6000\n",
      " |~~ train@29320  Loss: 0.018594 Acc: 13.8000\n",
      " |~~ train@29325  Loss: 0.027895 Acc: 13.6000\n",
      " |~~ train@29330  Loss: 0.014343 Acc: 13.8000\n",
      " |~~ train@29335  Loss: 0.038837 Acc: 13.4000\n",
      " |~~ train@29340  Loss: 0.045979 Acc: 13.2000\n",
      " |~~ train@29345  Loss: 0.022045 Acc: 13.6000\n",
      " |~~ train@29350  Loss: 0.040095 Acc: 13.2000\n",
      " |~~ train@29355  Loss: 0.024336 Acc: 13.6000\n",
      " |~~ train@29360  Loss: 0.019091 Acc: 13.8000\n",
      " |~~ train@29365  Loss: 0.015049 Acc: 13.8000\n",
      " |~~ train@29370  Loss: 0.031486 Acc: 13.4000\n",
      " |~~ train@29375  Loss: 0.059583 Acc: 12.4000\n",
      " |~~ train@29380  Loss: 0.054753 Acc: 12.8000\n",
      " |~~ train@29385  Loss: 0.033875 Acc: 13.4000\n",
      " |~~ train@29390  Loss: 0.027001 Acc: 13.2000\n",
      " |~~ train@29395  Loss: 0.036388 Acc: 13.2000\n",
      " |~~ train@29400  Loss: 0.028932 Acc: 13.4000\n",
      " |~~ train@29405  Loss: 0.062707 Acc: 12.6000\n",
      " |~~ train@29410  Loss: 0.048862 Acc: 13.0000\n",
      " |~~ train@29415  Loss: 0.015947 Acc: 13.8000\n",
      " |~~ train@29420  Loss: 0.068030 Acc: 12.6000\n",
      " |~~ train@29425  Loss: 0.047076 Acc: 13.0000\n",
      " |~~ train@29430  Loss: 0.018976 Acc: 13.6000\n",
      " |~~ train@29435  Loss: 0.033430 Acc: 13.2000\n",
      " |~~ train@29440  Loss: 0.019511 Acc: 13.6000\n",
      " |~~ train@29445  Loss: 0.073988 Acc: 12.4000\n",
      " |~~ train@29450  Loss: 0.035078 Acc: 13.4000\n",
      " |~~ train@29455  Loss: 0.034646 Acc: 13.2000\n",
      " |~~ train@29460  Loss: 0.011179 Acc: 14.0000\n",
      " |~~ train@29465  Loss: 0.014801 Acc: 13.8000\n",
      " |~~ train@29470  Loss: 0.033702 Acc: 13.2000\n",
      " |~~ train@29475  Loss: 0.027440 Acc: 13.4000\n",
      " |~~ train@29480  Loss: 0.018061 Acc: 13.6000\n",
      " |~~ train@29485  Loss: 0.046771 Acc: 13.0000\n",
      " |~~ train@29490  Loss: 0.017449 Acc: 13.8000\n",
      " |~~ train@29495  Loss: 0.016711 Acc: 13.8000\n",
      " |~~ train@29500  Loss: 0.045010 Acc: 13.0000\n",
      " |~~ train@29505  Loss: 0.044388 Acc: 13.2000\n",
      " |~~ train@29510  Loss: 0.024210 Acc: 13.4000\n",
      " |~~ train@29515  Loss: 0.033781 Acc: 13.2000\n",
      " |~~ train@29520  Loss: 0.014349 Acc: 13.8000\n",
      " |~~ train@29525  Loss: 0.043845 Acc: 13.0000\n",
      " |~~ train@29530  Loss: 0.035223 Acc: 13.0000\n",
      " |~~ train@29535  Loss: 0.016414 Acc: 13.8000\n",
      " |~~ train@29540  Loss: 0.021601 Acc: 13.6000\n",
      " |~~ train@29545  Loss: 0.012953 Acc: 14.0000\n",
      " |~~ train@29550  Loss: 0.082137 Acc: 11.8000\n",
      " |~~ train@29555  Loss: 0.043950 Acc: 13.2000\n",
      " |~~ train@29560  Loss: 0.032333 Acc: 13.2000\n",
      " |~~ train@29565  Loss: 0.061468 Acc: 12.8000\n",
      " |~~ train@29570  Loss: 0.038240 Acc: 13.0000\n",
      " |~~ train@29575  Loss: 0.011473 Acc: 14.0000\n",
      " |~~ train@29580  Loss: 0.058702 Acc: 12.8000\n",
      " |~~ train@29585  Loss: 0.033167 Acc: 13.2000\n",
      " |~~ train@29590  Loss: 0.057585 Acc: 12.6000\n",
      " |~~ train@29595  Loss: 0.025155 Acc: 13.6000\n",
      " |~~ train@29600  Loss: 0.013423 Acc: 13.8000\n",
      " |~~ train@29605  Loss: 0.041829 Acc: 13.0000\n",
      " |~~ train@29610  Loss: 0.089806 Acc: 12.2000\n",
      " |~~ train@29615  Loss: 0.018696 Acc: 13.8000\n",
      " |~~ train@29620  Loss: 0.040955 Acc: 13.2000\n",
      " |~~ train@29625  Loss: 0.030380 Acc: 13.6000\n",
      " |~~ train@29630  Loss: 0.079818 Acc: 12.0000\n",
      " |~~ train@29635  Loss: 0.041969 Acc: 13.0000\n",
      " |~~ train@29640  Loss: 0.011771 Acc: 14.0000\n",
      " |~~ train@29645  Loss: 0.040719 Acc: 13.2000\n",
      " |~~ train@29650  Loss: 0.024791 Acc: 13.4000\n",
      " |~~ train@29655  Loss: 0.053806 Acc: 12.6000\n",
      " |~~ train@29660  Loss: 0.014405 Acc: 13.8000\n",
      " |~~ train@29665  Loss: 0.029120 Acc: 13.4000\n",
      " |~~ train@29670  Loss: 0.038421 Acc: 13.0000\n",
      " |~~ train@29675  Loss: 0.037749 Acc: 13.0000\n",
      " |~~ train@29680  Loss: 0.019271 Acc: 13.8000\n",
      " |~~ train@29685  Loss: 0.033875 Acc: 13.2000\n",
      " |~~ train@29690  Loss: 0.060988 Acc: 12.4000\n",
      " |~~ train@29695  Loss: 0.056650 Acc: 12.8000\n",
      " |~~ train@29700  Loss: 0.024499 Acc: 13.6000\n",
      " |~~ train@29705  Loss: 0.018752 Acc: 13.6000\n",
      " |~~ train@29710  Loss: 0.063617 Acc: 12.8000\n",
      " |~~ train@29715  Loss: 0.023381 Acc: 13.6000\n",
      " |~~ train@29720  Loss: 0.011417 Acc: 14.0000\n",
      " |~~ train@29725  Loss: 0.030425 Acc: 13.4000\n",
      " |~~ train@29730  Loss: 0.028596 Acc: 13.4000\n",
      " |~~ train@29735  Loss: 0.039953 Acc: 13.0000\n",
      " |~~ train@29740  Loss: 0.011535 Acc: 14.0000\n",
      " |~~ train@29745  Loss: 0.040932 Acc: 13.2000\n",
      " |~~ train@29750  Loss: 0.044033 Acc: 12.8000\n",
      " |~~ train@29755  Loss: 0.040376 Acc: 13.4000\n",
      " |~~ train@29760  Loss: 0.037214 Acc: 13.4000\n",
      " |~~ train@29765  Loss: 0.028888 Acc: 13.6000\n",
      " |~~ train@29770  Loss: 0.027726 Acc: 13.4000\n",
      " |~~ train@29775  Loss: 0.023303 Acc: 13.8000\n",
      " |~~ train@29780  Loss: 0.011292 Acc: 14.0000\n",
      " |~~ train@29785  Loss: 0.031472 Acc: 13.6000\n",
      " |~~ train@29790  Loss: 0.030591 Acc: 13.2000\n",
      " |~~ train@29795  Loss: 0.024725 Acc: 13.6000\n",
      " |~~ train@29800  Loss: 0.011617 Acc: 14.0000\n",
      " |~~ train@29805  Loss: 0.037332 Acc: 13.0000\n",
      " |~~ train@29810  Loss: 0.045908 Acc: 13.2000\n",
      " |~~ train@29815  Loss: 0.019057 Acc: 13.6000\n",
      " |~~ train@29820  Loss: 0.035147 Acc: 13.2000\n",
      " |~~ train@29825  Loss: 0.026564 Acc: 13.6000\n",
      " |~~ train@29830  Loss: 0.031386 Acc: 13.4000\n",
      " |~~ train@29835  Loss: 0.042430 Acc: 13.2000\n",
      " |~~ train@29840  Loss: 0.047657 Acc: 12.8000\n",
      " |~~ train@29845  Loss: 0.024856 Acc: 13.6000\n",
      " |~~ train@29850  Loss: 0.030097 Acc: 13.4000\n",
      " |~~ train@29855  Loss: 0.050274 Acc: 13.0000\n",
      " |~~ train@29860  Loss: 0.043122 Acc: 13.2000\n",
      " |~~ train@29865  Loss: 0.024946 Acc: 13.6000\n",
      " |~~ train@29870  Loss: 0.055178 Acc: 13.0000\n",
      " |~~ train@29875  Loss: 0.020558 Acc: 13.8000\n",
      " |~~ train@29880  Loss: 0.068621 Acc: 12.0000\n",
      " |~~ train@29885  Loss: 0.021807 Acc: 13.6000\n",
      " |~~ train@29890  Loss: 0.023878 Acc: 13.6000\n",
      " |~~ train@29895  Loss: 0.062115 Acc: 12.6000\n",
      " |~~ train@29900  Loss: 0.036274 Acc: 13.0000\n",
      " |~~ train@29905  Loss: 0.016427 Acc: 13.8000\n",
      " |~~ train@29910  Loss: 0.017914 Acc: 13.6000\n",
      " |~~ train@29915  Loss: 0.058235 Acc: 12.6000\n",
      " |~~ train@29920  Loss: 0.035421 Acc: 13.4000\n",
      " |~~ train@29925  Loss: 0.067190 Acc: 12.4000\n",
      " |~~ train@29930  Loss: 0.058581 Acc: 12.6000\n",
      " |~~ train@29935  Loss: 0.060868 Acc: 12.6000\n",
      " |~~ train@29940  Loss: 0.033095 Acc: 13.4000\n",
      " |~~ train@29945  Loss: 0.047653 Acc: 13.0000\n",
      " |~~ train@29950  Loss: 0.024803 Acc: 13.4000\n",
      " |~~ train@29955  Loss: 0.045388 Acc: 13.2000\n",
      " |~~ train@29960  Loss: 0.022415 Acc: 13.8000\n",
      " |~~ train@29965  Loss: 0.064648 Acc: 12.6000\n",
      " |~~ train@29970  Loss: 0.020167 Acc: 13.6000\n",
      " |~~ train@29975  Loss: 0.052336 Acc: 13.2000\n",
      " |~~ train@29980  Loss: 0.045194 Acc: 13.0000\n",
      " |~~ train@29985  Loss: 0.065249 Acc: 12.6000\n",
      " |~~ train@29990  Loss: 0.086204 Acc: 12.0000\n",
      " |~~ train@29995  Loss: 0.020593 Acc: 13.8000\n",
      " |~~ train@30000  Loss: 0.010943 Acc: 14.0000\n",
      " |~~ train@30005  Loss: 0.048241 Acc: 12.8000\n",
      " |~~ train@30010  Loss: 0.040755 Acc: 13.0000\n",
      " |~~ train@30015  Loss: 0.010432 Acc: 14.0000\n",
      " |~~ train@30020  Loss: 0.039493 Acc: 13.0000\n",
      " |~~ train@30025  Loss: 0.032648 Acc: 13.4000\n",
      " |~~ train@30030  Loss: 0.031585 Acc: 13.4000\n",
      " |~~ train@30035  Loss: 0.026703 Acc: 13.4000\n",
      " |~~ train@30040  Loss: 0.029004 Acc: 13.4000\n",
      " |~~ train@30045  Loss: 0.029793 Acc: 13.4000\n",
      " |~~ train@30050  Loss: 0.017512 Acc: 13.8000\n",
      " |~~ train@30055  Loss: 0.048149 Acc: 13.2000\n",
      " |~~ train@30060  Loss: 0.064535 Acc: 12.8000\n",
      " |~~ train@30065  Loss: 0.010796 Acc: 14.0000\n",
      " |~~ train@30070  Loss: 0.030180 Acc: 13.4000\n",
      " |~~ train@30075  Loss: 0.018392 Acc: 13.6000\n",
      " |~~ train@30080  Loss: 0.039085 Acc: 13.0000\n",
      " |~~ train@30085  Loss: 0.032609 Acc: 13.2000\n",
      " |~~ train@30090  Loss: 0.028937 Acc: 13.6000\n",
      " |~~ train@30095  Loss: 0.057460 Acc: 12.6000\n",
      " |~~ train@30100  Loss: 0.033460 Acc: 13.4000\n",
      " |~~ train@30105  Loss: 0.024471 Acc: 13.6000\n",
      " |~~ train@30110  Loss: 0.021539 Acc: 13.6000\n",
      " |~~ train@30115  Loss: 0.026202 Acc: 13.6000\n",
      " |~~ train@30120  Loss: 0.046332 Acc: 13.0000\n",
      " |~~ train@30125  Loss: 0.037860 Acc: 13.4000\n",
      " |~~ train@30130  Loss: 0.016432 Acc: 13.8000\n",
      " |~~ train@30135  Loss: 0.048552 Acc: 12.8000\n",
      " |~~ train@30140  Loss: 0.027219 Acc: 13.4000\n",
      " |~~ train@30145  Loss: 0.049171 Acc: 13.2000\n",
      " |~~ train@30150  Loss: 0.075566 Acc: 12.4000\n",
      " |~~ train@30155  Loss: 0.056485 Acc: 12.8000\n",
      " |~~ train@30160  Loss: 0.018680 Acc: 13.8000\n",
      " |~~ train@30165  Loss: 0.023975 Acc: 13.6000\n",
      " |~~ train@30170  Loss: 0.010727 Acc: 14.0000\n",
      " |~~ train@30175  Loss: 0.018609 Acc: 13.8000\n",
      " |~~ train@30180  Loss: 0.023650 Acc: 13.6000\n",
      " |~~ train@30185  Loss: 0.031201 Acc: 13.4000\n",
      " |~~ train@30190  Loss: 0.047152 Acc: 12.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@30195  Loss: 0.022308 Acc: 13.6000\n",
      " |~~ train@30200  Loss: 0.043209 Acc: 13.0000\n",
      " |~~ train@30205  Loss: 0.041206 Acc: 13.2000\n",
      " |~~ train@30210  Loss: 0.010309 Acc: 14.0000\n",
      " |~~ train@30215  Loss: 0.032473 Acc: 13.2000\n",
      " |~~ train@30220  Loss: 0.045437 Acc: 13.0000\n",
      " |~~ train@30225  Loss: 0.046532 Acc: 13.0000\n",
      " |~~ train@30230  Loss: 0.018401 Acc: 13.6000\n",
      " |~~ train@30235  Loss: 0.045972 Acc: 13.0000\n",
      " |~~ train@30240  Loss: 0.047842 Acc: 12.8000\n",
      " |~~ train@30245  Loss: 0.043126 Acc: 13.0000\n",
      " |~~ train@30250  Loss: 0.033096 Acc: 13.2000\n",
      " |~~ train@30255  Loss: 0.056741 Acc: 12.4000\n",
      " |~~ train@30260  Loss: 0.044640 Acc: 12.8000\n",
      " |~~ train@30265  Loss: 0.076235 Acc: 12.6000\n",
      " |~~ train@30270  Loss: 0.044978 Acc: 13.0000\n",
      " |~~ train@30275  Loss: 0.025010 Acc: 13.6000\n",
      " |~~ train@30280  Loss: 0.057206 Acc: 12.8000\n",
      " |~~ train@30285  Loss: 0.029356 Acc: 13.6000\n",
      " |~~ train@30290  Loss: 0.033463 Acc: 13.4000\n",
      " |~~ train@30295  Loss: 0.031790 Acc: 13.0000\n",
      " |~~ train@30300  Loss: 0.042811 Acc: 13.2000\n",
      " |~~ train@30305  Loss: 0.042224 Acc: 13.2000\n",
      " |~~ train@30310  Loss: 0.031887 Acc: 13.4000\n",
      " |~~ train@30315  Loss: 0.049637 Acc: 12.8000\n",
      " |~~ train@30320  Loss: 0.025884 Acc: 13.6000\n",
      " |~~ train@30325  Loss: 0.014688 Acc: 13.8000\n",
      " |~~ train@30330  Loss: 0.015789 Acc: 13.8000\n",
      " |~~ train@30335  Loss: 0.023441 Acc: 13.6000\n",
      " |~~ train@30340  Loss: 0.035721 Acc: 13.4000\n",
      " |~~ train@30345  Loss: 0.016707 Acc: 13.8000\n",
      " |~~ train@30350  Loss: 0.055103 Acc: 12.6000\n",
      " |~~ train@30355  Loss: 0.031185 Acc: 13.4000\n",
      " |~~ train@30360  Loss: 0.059487 Acc: 12.6000\n",
      " |~~ train@30365  Loss: 0.031287 Acc: 13.2000\n",
      " |~~ train@30370  Loss: 0.011583 Acc: 14.0000\n",
      " |~~ train@30375  Loss: 0.025679 Acc: 13.6000\n",
      " |~~ train@30380  Loss: 0.028825 Acc: 13.4000\n",
      " |~~ train@30385  Loss: 0.050015 Acc: 13.0000\n",
      " |~~ train@30390  Loss: 0.029943 Acc: 13.6000\n",
      " |~~ train@30395  Loss: 0.026619 Acc: 13.4000\n",
      " |~~ train@30400  Loss: 0.019267 Acc: 13.8000\n",
      " |~~ train@30405  Loss: 0.024693 Acc: 13.6000\n",
      " |~~ train@30410  Loss: 0.063352 Acc: 12.6000\n",
      " |~~ train@30415  Loss: 0.042828 Acc: 13.2000\n",
      " |~~ train@30420  Loss: 0.065569 Acc: 12.6000\n",
      " |~~ train@30425  Loss: 0.025006 Acc: 13.4000\n",
      " |~~ train@30430  Loss: 0.067932 Acc: 12.4000\n",
      " |~~ train@30435  Loss: 0.016129 Acc: 13.8000\n",
      " |~~ train@30440  Loss: 0.057357 Acc: 12.8000\n",
      " |~~ train@30445  Loss: 0.026865 Acc: 13.6000\n",
      " |~~ train@30450  Loss: 0.071752 Acc: 12.4000\n",
      " |~~ train@30455  Loss: 0.047893 Acc: 12.8000\n",
      " |~~ train@30460  Loss: 0.022373 Acc: 13.8000\n",
      " |~~ train@30465  Loss: 0.027712 Acc: 13.6000\n",
      " |~~ train@30470  Loss: 0.024059 Acc: 13.4000\n",
      " |~~ train@30475  Loss: 0.071659 Acc: 12.6000\n",
      " |~~ train@30480  Loss: 0.038115 Acc: 13.2000\n",
      " |~~ train@30485  Loss: 0.031471 Acc: 13.4000\n",
      " |~~ train@30490  Loss: 0.054115 Acc: 12.8000\n",
      " |~~ train@30495  Loss: 0.036055 Acc: 13.4000\n",
      " |~~ train@30500  Loss: 0.044758 Acc: 13.0000\n",
      " |~~ train@30505  Loss: 0.036944 Acc: 13.2000\n",
      " |~~ train@30510  Loss: 0.042209 Acc: 13.0000\n",
      " |~~ train@30515  Loss: 0.028564 Acc: 13.6000\n",
      " |~~ train@30520  Loss: 0.035416 Acc: 13.2000\n",
      " |~~ train@30525  Loss: 0.025273 Acc: 13.8000\n",
      " |~~ train@30530  Loss: 0.018702 Acc: 13.8000\n",
      " |~~ train@30535  Loss: 0.018600 Acc: 13.8000\n",
      " |~~ train@30540  Loss: 0.030933 Acc: 13.2000\n",
      " |~~ train@30545  Loss: 0.037853 Acc: 13.2000\n",
      " |~~ train@30550  Loss: 0.035364 Acc: 13.2000\n",
      " |~~ train@30555  Loss: 0.013876 Acc: 13.8000\n",
      " |~~ train@30560  Loss: 0.054001 Acc: 12.6000\n",
      " |~~ train@30565  Loss: 0.048891 Acc: 13.0000\n",
      " |~~ train@30570  Loss: 0.044396 Acc: 13.0000\n",
      " |~~ train@30575  Loss: 0.027298 Acc: 13.4000\n",
      " |~~ train@30580  Loss: 0.039401 Acc: 13.0000\n",
      " |~~ train@30585  Loss: 0.023860 Acc: 13.6000\n",
      " |~~ train@30590  Loss: 0.034154 Acc: 13.2000\n",
      " |~~ train@30595  Loss: 0.027824 Acc: 13.6000\n",
      " |~~ train@30600  Loss: 0.026637 Acc: 13.6000\n",
      " |~~ train@30605  Loss: 0.018566 Acc: 13.8000\n",
      " |~~ train@30610  Loss: 0.028559 Acc: 13.4000\n",
      " |~~ train@30615  Loss: 0.048401 Acc: 13.2000\n",
      " |~~ train@30620  Loss: 0.028203 Acc: 13.4000\n",
      " |~~ train@30625  Loss: 0.015827 Acc: 13.8000\n",
      " |~~ train@30630  Loss: 0.012812 Acc: 13.8000\n",
      " |~~ train@30635  Loss: 0.034429 Acc: 13.2000\n",
      " |~~ train@30640  Loss: 0.034127 Acc: 13.4000\n",
      " |~~ train@30645  Loss: 0.027762 Acc: 13.6000\n",
      " |~~ train@30650  Loss: 0.058536 Acc: 12.4000\n",
      " |~~ train@30655  Loss: 0.023956 Acc: 13.6000\n",
      " |~~ train@30660  Loss: 0.050419 Acc: 12.8000\n",
      " |~~ train@30665  Loss: 0.041228 Acc: 13.4000\n",
      " |~~ train@30670  Loss: 0.029477 Acc: 13.4000\n",
      " |~~ train@30675  Loss: 0.027027 Acc: 13.4000\n",
      " |~~ train@30680  Loss: 0.043414 Acc: 13.0000\n",
      " |~~ train@30685  Loss: 0.038988 Acc: 13.2000\n",
      " |~~ train@30690  Loss: 0.024452 Acc: 13.4000\n",
      " |~~ train@30695  Loss: 0.040307 Acc: 13.2000\n",
      " |~~ train@30700  Loss: 0.037378 Acc: 13.0000\n",
      " |~~ train@30705  Loss: 0.023543 Acc: 13.6000\n",
      " |~~ train@30710  Loss: 0.036537 Acc: 13.2000\n",
      " |~~ train@30715  Loss: 0.021933 Acc: 13.4000\n",
      " |~~ train@30720  Loss: 0.068732 Acc: 12.4000\n",
      " |~~ train@30725  Loss: 0.033625 Acc: 13.4000\n",
      " |~~ train@30730  Loss: 0.035760 Acc: 13.2000\n",
      " |~~ train@30735  Loss: 0.025274 Acc: 13.4000\n",
      " |~~ train@30740  Loss: 0.061762 Acc: 12.2000\n",
      " |~~ train@30745  Loss: 0.054965 Acc: 12.8000\n",
      " |~~ train@30750  Loss: 0.066097 Acc: 12.6000\n",
      " |~~ train@30755  Loss: 0.043137 Acc: 13.0000\n",
      " |~~ train@30760  Loss: 0.028969 Acc: 13.8000\n",
      " |~~ train@30765  Loss: 0.024710 Acc: 13.4000\n",
      " |~~ train@30770  Loss: 0.035837 Acc: 13.2000\n",
      " |~~ train@30775  Loss: 0.061807 Acc: 12.4000\n",
      " |~~ train@30780  Loss: 0.019381 Acc: 13.8000\n",
      " |~~ train@30785  Loss: 0.034464 Acc: 13.0000\n",
      " |~~ train@30790  Loss: 0.034776 Acc: 13.2000\n",
      " |~~ train@30795  Loss: 0.021779 Acc: 13.6000\n",
      " |~~ train@30800  Loss: 0.083334 Acc: 12.0000\n",
      " |~~ train@30805  Loss: 0.033431 Acc: 13.0000\n",
      " |~~ train@30810  Loss: 0.017747 Acc: 13.8000\n",
      " |~~ train@30815  Loss: 0.027951 Acc: 13.6000\n",
      " |~~ train@30820  Loss: 0.017465 Acc: 13.8000\n",
      " |~~ train@30825  Loss: 0.050508 Acc: 12.6000\n",
      " |~~ train@30830  Loss: 0.038484 Acc: 13.0000\n",
      " |~~ train@30835  Loss: 0.034971 Acc: 13.4000\n",
      " |~~ train@30840  Loss: 0.032034 Acc: 13.4000\n",
      " |~~ train@30845  Loss: 0.047797 Acc: 13.0000\n",
      " |~~ train@30850  Loss: 0.012318 Acc: 14.0000\n",
      " |~~ train@30855  Loss: 0.026525 Acc: 13.6000\n",
      " |~~ train@30860  Loss: 0.020727 Acc: 13.6000\n",
      " |~~ train@30865  Loss: 0.066490 Acc: 12.6000\n",
      " |~~ train@30870  Loss: 0.062258 Acc: 12.8000\n",
      " |~~ train@30875  Loss: 0.055803 Acc: 12.6000\n",
      " |~~ train@30880  Loss: 0.034329 Acc: 13.2000\n",
      " |~~ train@30885  Loss: 0.037931 Acc: 13.0000\n",
      " |~~ train@30890  Loss: 0.014614 Acc: 13.8000\n",
      " |~~ train@30895  Loss: 0.038516 Acc: 13.4000\n",
      " |~~ train@30900  Loss: 0.034478 Acc: 13.0000\n",
      " |~~ train@30905  Loss: 0.024034 Acc: 13.6000\n",
      " |~~ train@30910  Loss: 0.022752 Acc: 13.8000\n",
      " |~~ train@30915  Loss: 0.028425 Acc: 13.6000\n",
      " |~~ train@30920  Loss: 0.019737 Acc: 13.6000\n",
      " |~~ train@30925  Loss: 0.049406 Acc: 12.8000\n",
      " |~~ train@30930  Loss: 0.042922 Acc: 13.4000\n",
      " |~~ train@30935  Loss: 0.025860 Acc: 13.6000\n",
      " |~~ train@30940  Loss: 0.027127 Acc: 13.4000\n",
      " |~~ train@30945  Loss: 0.034995 Acc: 13.4000\n",
      " |~~ train@30950  Loss: 0.026296 Acc: 13.6000\n",
      " |~~ train@30955  Loss: 0.016752 Acc: 13.8000\n",
      " |~~ train@30960  Loss: 0.019582 Acc: 13.6000\n",
      " |~~ train@30965  Loss: 0.033716 Acc: 13.2000\n",
      " |~~ train@30970  Loss: 0.011115 Acc: 14.0000\n",
      " |~~ train@30975  Loss: 0.030658 Acc: 13.4000\n",
      " |~~ train@30980  Loss: 0.052444 Acc: 12.6000\n",
      " |~~ train@30985  Loss: 0.031715 Acc: 13.4000\n",
      " |~~ train@30990  Loss: 0.016419 Acc: 13.8000\n",
      " |~~ train@30995  Loss: 0.054837 Acc: 12.6000\n",
      " |~~ train@31000  Loss: 0.026410 Acc: 13.6000\n",
      " |~~ train@31005  Loss: 0.033451 Acc: 13.4000\n",
      " |~~ train@31010  Loss: 0.030561 Acc: 13.4000\n",
      " |~~ train@31015  Loss: 0.040043 Acc: 13.2000\n",
      " |~~ train@31020  Loss: 0.043489 Acc: 13.0000\n",
      " |~~ train@31025  Loss: 0.025005 Acc: 13.6000\n",
      " |~~ train@31030  Loss: 0.023436 Acc: 13.6000\n",
      " |~~ train@31035  Loss: 0.051431 Acc: 12.8000\n",
      " |~~ train@31040  Loss: 0.026254 Acc: 13.6000\n",
      " |~~ train@31045  Loss: 0.030925 Acc: 13.4000\n",
      " |~~ train@31050  Loss: 0.036176 Acc: 13.4000\n",
      " |~~ train@31055  Loss: 0.010094 Acc: 14.0000\n",
      " |~~ train@31060  Loss: 0.036154 Acc: 13.0000\n",
      " |~~ train@31065  Loss: 0.038136 Acc: 13.0000\n",
      " |~~ train@31070  Loss: 0.037525 Acc: 13.4000\n",
      " |~~ train@31075  Loss: 0.052517 Acc: 13.0000\n",
      " |~~ train@31080  Loss: 0.056870 Acc: 12.6000\n",
      " |~~ train@31085  Loss: 0.018898 Acc: 13.8000\n",
      " |~~ train@31090  Loss: 0.048884 Acc: 13.2000\n",
      " |~~ train@31095  Loss: 0.026035 Acc: 13.6000\n",
      " |~~ train@31100  Loss: 0.038592 Acc: 13.2000\n",
      " |~~ train@31105  Loss: 0.035026 Acc: 13.2000\n",
      " |~~ train@31110  Loss: 0.049358 Acc: 12.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@31115  Loss: 0.016343 Acc: 13.8000\n",
      " |~~ train@31120  Loss: 0.019901 Acc: 13.8000\n",
      " |~~ train@31125  Loss: 0.029257 Acc: 13.4000\n",
      " |~~ train@31130  Loss: 0.044568 Acc: 13.2000\n",
      " |~~ train@31135  Loss: 0.054811 Acc: 12.8000\n",
      " |~~ train@31140  Loss: 0.035189 Acc: 13.4000\n",
      " |~~ train@31145  Loss: 0.027147 Acc: 13.4000\n",
      " |~~ train@31150  Loss: 0.022265 Acc: 13.8000\n",
      " |~~ train@31155  Loss: 0.022514 Acc: 13.6000\n",
      " |~~ train@31160  Loss: 0.043496 Acc: 13.2000\n",
      " |~~ train@31165  Loss: 0.058958 Acc: 12.6000\n",
      " |~~ train@31170  Loss: 0.047868 Acc: 13.2000\n",
      " |~~ train@31175  Loss: 0.059700 Acc: 12.6000\n",
      " |~~ train@31180  Loss: 0.027260 Acc: 13.4000\n",
      " |~~ train@31185  Loss: 0.029453 Acc: 13.6000\n",
      " |~~ train@31190  Loss: 0.034009 Acc: 13.2000\n",
      " |~~ train@31195  Loss: 0.025211 Acc: 13.4000\n",
      " |~~ train@31200  Loss: 0.078673 Acc: 12.0000\n",
      " |~~ train@31205  Loss: 0.022338 Acc: 13.4000\n",
      " |~~ train@31210  Loss: 0.039272 Acc: 13.2000\n",
      " |~~ train@31215  Loss: 0.027295 Acc: 13.4000\n",
      " |~~ train@31220  Loss: 0.047007 Acc: 13.2000\n",
      " |~~ train@31225  Loss: 0.031780 Acc: 13.4000\n",
      " |~~ train@31230  Loss: 0.052498 Acc: 12.8000\n",
      " |~~ train@31235  Loss: 0.045647 Acc: 13.0000\n",
      " |~~ train@31240  Loss: 0.048733 Acc: 13.2000\n",
      " |~~ train@31245  Loss: 0.035297 Acc: 13.2000\n",
      " |~~ train@31250  Loss: 0.025916 Acc: 13.6000\n",
      " |~~ train@31255  Loss: 0.053174 Acc: 13.2000\n",
      " |~~ train@31260  Loss: 0.036637 Acc: 13.6000\n",
      " |~~ train@31265  Loss: 0.038991 Acc: 13.2000\n",
      " |~~ train@31270  Loss: 0.039171 Acc: 13.2000\n",
      " |~~ train@31275  Loss: 0.015030 Acc: 13.8000\n",
      " |~~ train@31280  Loss: 0.016016 Acc: 13.8000\n",
      " |~~ train@31285  Loss: 0.057666 Acc: 12.8000\n",
      " |~~ train@31290  Loss: 0.036135 Acc: 13.2000\n",
      " |~~ train@31295  Loss: 0.032022 Acc: 13.4000\n",
      " |~~ train@31300  Loss: 0.025402 Acc: 13.6000\n",
      " |~~ train@31305  Loss: 0.030036 Acc: 13.4000\n",
      " |~~ train@31310  Loss: 0.034246 Acc: 13.2000\n",
      " |~~ train@31315  Loss: 0.011409 Acc: 14.0000\n",
      " |~~ train@31320  Loss: 0.038198 Acc: 13.4000\n",
      " |~~ train@31325  Loss: 0.031437 Acc: 13.2000\n",
      " |~~ train@31330  Loss: 0.021803 Acc: 13.6000\n",
      " |~~ train@31335  Loss: 0.026367 Acc: 13.4000\n",
      " |~~ train@31340  Loss: 0.038912 Acc: 13.2000\n",
      " |~~ train@31345  Loss: 0.058869 Acc: 12.8000\n",
      " |~~ train@31350  Loss: 0.021746 Acc: 13.6000\n",
      " |~~ train@31355  Loss: 0.054527 Acc: 12.8000\n",
      " |~~ train@31360  Loss: 0.018336 Acc: 13.8000\n",
      " |~~ train@31365  Loss: 0.022932 Acc: 13.6000\n",
      " |~~ train@31370  Loss: 0.045477 Acc: 13.0000\n",
      " |~~ train@31375  Loss: 0.043932 Acc: 13.2000\n",
      " |~~ train@31380  Loss: 0.036698 Acc: 13.2000\n",
      " |~~ train@31385  Loss: 0.055171 Acc: 12.4000\n",
      " |~~ train@31390  Loss: 0.017975 Acc: 13.8000\n",
      " |~~ train@31395  Loss: 0.058842 Acc: 12.8000\n",
      " |~~ train@31400  Loss: 0.021561 Acc: 13.8000\n",
      " |~~ train@31405  Loss: 0.019926 Acc: 13.8000\n",
      " |~~ train@31410  Loss: 0.027669 Acc: 13.6000\n",
      " |~~ train@31415  Loss: 0.016441 Acc: 13.8000\n",
      " |~~ train@31420  Loss: 0.019093 Acc: 13.8000\n",
      " |~~ train@31425  Loss: 0.018337 Acc: 13.6000\n",
      " |~~ train@31430  Loss: 0.027666 Acc: 13.4000\n",
      " |~~ train@31435  Loss: 0.067024 Acc: 12.0000\n",
      " |~~ train@31440  Loss: 0.022534 Acc: 13.6000\n",
      " |~~ train@31445  Loss: 0.033974 Acc: 13.4000\n",
      " |~~ train@31450  Loss: 0.026664 Acc: 13.4000\n",
      " |~~ train@31455  Loss: 0.032434 Acc: 13.2000\n",
      " |~~ train@31460  Loss: 0.063035 Acc: 12.8000\n",
      " |~~ train@31465  Loss: 0.032677 Acc: 13.4000\n",
      " |~~ train@31470  Loss: 0.012416 Acc: 13.8000\n",
      " |~~ train@31475  Loss: 0.032221 Acc: 13.4000\n",
      " |~~ train@31480  Loss: 0.049211 Acc: 13.0000\n",
      " |~~ train@31485  Loss: 0.039316 Acc: 13.2000\n",
      " |~~ train@31490  Loss: 0.020452 Acc: 13.6000\n",
      " |~~ train@31495  Loss: 0.039593 Acc: 13.2000\n",
      " |~~ train@31500  Loss: 0.037457 Acc: 13.2000\n",
      " |~~ train@31505  Loss: 0.038328 Acc: 12.8000\n",
      " |~~ train@31510  Loss: 0.009992 Acc: 14.0000\n",
      " |~~ train@31515  Loss: 0.046774 Acc: 13.2000\n",
      " |~~ train@31520  Loss: 0.032459 Acc: 13.4000\n",
      " |~~ train@31525  Loss: 0.020705 Acc: 13.6000\n",
      " |~~ train@31530  Loss: 0.025732 Acc: 13.6000\n",
      " |~~ train@31535  Loss: 0.040294 Acc: 13.2000\n",
      " |~~ train@31540  Loss: 0.039578 Acc: 13.2000\n",
      " |~~ train@31545  Loss: 0.055781 Acc: 12.6000\n",
      " |~~ train@31550  Loss: 0.050974 Acc: 13.0000\n",
      " |~~ train@31555  Loss: 0.022493 Acc: 13.6000\n",
      " |~~ train@31560  Loss: 0.048959 Acc: 13.0000\n",
      " |~~ train@31565  Loss: 0.039749 Acc: 13.4000\n",
      " |~~ train@31570  Loss: 0.048794 Acc: 12.8000\n",
      " |~~ train@31575  Loss: 0.041476 Acc: 13.2000\n",
      " |~~ train@31580  Loss: 0.035939 Acc: 13.2000\n",
      " |~~ train@31585  Loss: 0.031165 Acc: 13.4000\n",
      " |~~ train@31590  Loss: 0.041863 Acc: 13.2000\n",
      " |~~ train@31595  Loss: 0.036652 Acc: 13.2000\n",
      " |~~ train@31600  Loss: 0.030998 Acc: 13.2000\n",
      " |~~ train@31605  Loss: 0.035347 Acc: 13.4000\n",
      " |~~ train@31610  Loss: 0.049987 Acc: 13.2000\n",
      " |~~ train@31615  Loss: 0.017066 Acc: 13.8000\n",
      " |~~ train@31620  Loss: 0.010378 Acc: 14.0000\n",
      " |~~ train@31625  Loss: 0.026898 Acc: 13.6000\n",
      " |~~ train@31630  Loss: 0.040542 Acc: 13.2000\n",
      " |~~ train@31635  Loss: 0.029995 Acc: 13.2000\n",
      " |~~ train@31640  Loss: 0.061855 Acc: 12.4000\n",
      " |~~ train@31645  Loss: 0.071035 Acc: 12.6000\n",
      " |~~ train@31650  Loss: 0.049607 Acc: 12.8000\n",
      " |~~ train@31655  Loss: 0.066485 Acc: 12.4000\n",
      " |~~ train@31660  Loss: 0.035502 Acc: 13.2000\n",
      " |~~ train@31665  Loss: 0.054361 Acc: 12.8000\n",
      " |~~ train@31670  Loss: 0.012225 Acc: 14.0000\n",
      " |~~ train@31675  Loss: 0.021734 Acc: 13.6000\n",
      " |~~ train@31680  Loss: 0.035401 Acc: 13.4000\n",
      " |~~ train@31685  Loss: 0.033100 Acc: 13.4000\n",
      " |~~ train@31690  Loss: 0.051915 Acc: 13.0000\n",
      " |~~ train@31695  Loss: 0.031014 Acc: 13.2000\n",
      " |~~ train@31700  Loss: 0.039822 Acc: 13.0000\n",
      " |~~ train@31705  Loss: 0.049166 Acc: 13.0000\n",
      " |~~ train@31710  Loss: 0.068249 Acc: 12.4000\n",
      " |~~ train@31715  Loss: 0.024599 Acc: 13.6000\n",
      " |~~ train@31720  Loss: 0.030931 Acc: 13.2000\n",
      " |~~ train@31725  Loss: 0.038873 Acc: 13.4000\n",
      " |~~ train@31730  Loss: 0.035272 Acc: 13.4000\n",
      " |~~ train@31735  Loss: 0.031766 Acc: 13.4000\n",
      " |~~ train@31740  Loss: 0.036045 Acc: 13.4000\n",
      " |~~ train@31745  Loss: 0.076607 Acc: 12.0000\n",
      " |~~ train@31750  Loss: 0.015933 Acc: 13.8000\n",
      " |~~ train@31755  Loss: 0.051201 Acc: 12.8000\n",
      " |~~ train@31760  Loss: 0.040153 Acc: 13.2000\n",
      " |~~ train@31765  Loss: 0.039293 Acc: 13.4000\n",
      " |~~ train@31770  Loss: 0.032994 Acc: 13.2000\n",
      " |~~ train@31775  Loss: 0.040990 Acc: 13.2000\n",
      " |~~ train@31780  Loss: 0.025013 Acc: 13.6000\n",
      " |~~ train@31785  Loss: 0.041918 Acc: 13.2000\n",
      " |~~ train@31790  Loss: 0.029003 Acc: 13.4000\n",
      " |~~ train@31795  Loss: 0.044572 Acc: 13.2000\n",
      " |~~ train@31800  Loss: 0.060661 Acc: 12.6000\n",
      " |~~ train@31805  Loss: 0.011802 Acc: 14.0000\n",
      " |~~ train@31810  Loss: 0.025662 Acc: 13.4000\n",
      " |~~ train@31815  Loss: 0.044492 Acc: 13.0000\n",
      " |~~ train@31820  Loss: 0.021927 Acc: 13.4000\n",
      " |~~ train@31825  Loss: 0.052777 Acc: 12.8000\n",
      " |~~ train@31830  Loss: 0.014291 Acc: 13.8000\n",
      " |~~ train@31835  Loss: 0.018759 Acc: 13.6000\n",
      " |~~ train@31840  Loss: 0.021614 Acc: 13.6000\n",
      " |~~ train@31845  Loss: 0.028915 Acc: 13.4000\n",
      " |~~ train@31850  Loss: 0.045777 Acc: 12.6000\n",
      " |~~ train@31855  Loss: 0.030073 Acc: 13.4000\n",
      " |~~ train@31860  Loss: 0.056530 Acc: 12.8000\n",
      " |~~ train@31865  Loss: 0.041998 Acc: 13.2000\n",
      " |~~ train@31870  Loss: 0.017471 Acc: 13.8000\n",
      " |~~ train@31875  Loss: 0.064877 Acc: 12.4000\n",
      " |~~ train@31880  Loss: 0.041798 Acc: 13.2000\n",
      " |~~ train@31885  Loss: 0.033667 Acc: 13.2000\n",
      " |~~ train@31890  Loss: 0.015491 Acc: 13.8000\n",
      " |~~ train@31895  Loss: 0.011439 Acc: 14.0000\n",
      " |~~ train@31900  Loss: 0.028058 Acc: 13.6000\n",
      " |~~ train@31905  Loss: 0.031696 Acc: 13.4000\n",
      " |~~ train@31910  Loss: 0.034347 Acc: 13.2000\n",
      " |~~ train@31915  Loss: 0.014701 Acc: 13.8000\n",
      " |~~ train@31920  Loss: 0.079237 Acc: 12.2000\n",
      " |~~ train@31925  Loss: 0.011119 Acc: 14.0000\n",
      " |~~ train@31930  Loss: 0.018353 Acc: 13.6000\n",
      " |~~ train@31935  Loss: 0.033596 Acc: 13.4000\n",
      " |~~ train@31940  Loss: 0.054619 Acc: 12.8000\n",
      " |~~ train@31945  Loss: 0.032976 Acc: 13.4000\n",
      " |~~ train@31950  Loss: 0.029006 Acc: 13.2000\n",
      " |~~ train@31955  Loss: 0.048418 Acc: 13.0000\n",
      " |~~ train@31960  Loss: 0.042803 Acc: 13.2000\n",
      " |~~ train@31965  Loss: 0.027732 Acc: 13.6000\n",
      " |~~ train@31970  Loss: 0.038805 Acc: 13.2000\n",
      " |~~ train@31975  Loss: 0.037310 Acc: 13.2000\n",
      " |~~ train@31980  Loss: 0.071981 Acc: 12.6000\n",
      " |~~ train@31985  Loss: 0.026539 Acc: 13.6000\n",
      " |~~ train@31990  Loss: 0.016721 Acc: 13.8000\n",
      " |~~ train@31995  Loss: 0.011195 Acc: 14.0000\n",
      " |~~ train@32000  Loss: 0.042969 Acc: 13.2000\n",
      " |~~ train@32005  Loss: 0.052076 Acc: 12.6000\n",
      " |~~ train@32010  Loss: 0.044405 Acc: 13.0000\n",
      " |~~ train@32015  Loss: 0.027290 Acc: 13.4000\n",
      " |~~ train@32020  Loss: 0.041442 Acc: 12.8000\n",
      " |~~ train@32025  Loss: 0.029698 Acc: 13.4000\n",
      " |~~ train@32030  Loss: 0.018793 Acc: 13.8000\n",
      " |~~ train@32035  Loss: 0.025426 Acc: 13.6000\n",
      " |~~ train@32040  Loss: 0.014139 Acc: 13.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@32045  Loss: 0.019339 Acc: 13.6000\n",
      " |~~ train@32050  Loss: 0.031790 Acc: 13.4000\n",
      " |~~ train@32055  Loss: 0.061067 Acc: 12.6000\n",
      " |~~ train@32060  Loss: 0.038431 Acc: 13.2000\n",
      " |~~ train@32065  Loss: 0.029856 Acc: 13.4000\n",
      " |~~ train@32070  Loss: 0.037003 Acc: 13.2000\n",
      " |~~ train@32075  Loss: 0.037769 Acc: 13.0000\n",
      " |~~ train@32080  Loss: 0.021791 Acc: 13.8000\n",
      " |~~ train@32085  Loss: 0.026906 Acc: 13.6000\n",
      " |~~ train@32090  Loss: 0.075868 Acc: 12.2000\n",
      " |~~ train@32095  Loss: 0.034943 Acc: 13.4000\n",
      " |~~ train@32100  Loss: 0.010146 Acc: 14.0000\n",
      " |~~ train@32105  Loss: 0.023486 Acc: 13.6000\n",
      " |~~ train@32110  Loss: 0.029465 Acc: 13.4000\n",
      " |~~ train@32115  Loss: 0.057254 Acc: 12.6000\n",
      " |~~ train@32120  Loss: 0.017221 Acc: 13.6000\n",
      " |~~ train@32125  Loss: 0.018955 Acc: 13.8000\n",
      " |~~ train@32130  Loss: 0.068940 Acc: 12.6000\n",
      " |~~ train@32135  Loss: 0.033553 Acc: 13.4000\n",
      " |~~ train@32140  Loss: 0.019441 Acc: 13.6000\n",
      " |~~ train@32145  Loss: 0.034368 Acc: 13.2000\n",
      " |~~ train@32150  Loss: 0.020172 Acc: 13.6000\n",
      " |~~ train@32155  Loss: 0.010916 Acc: 14.0000\n",
      " |~~ train@32160  Loss: 0.045615 Acc: 12.6000\n",
      " |~~ train@32165  Loss: 0.037752 Acc: 13.4000\n",
      " |~~ train@32170  Loss: 0.015741 Acc: 13.8000\n",
      " |~~ train@32175  Loss: 0.025483 Acc: 13.6000\n",
      " |~~ train@32180  Loss: 0.038002 Acc: 13.4000\n",
      " |~~ train@32185  Loss: 0.014520 Acc: 13.8000\n",
      " |~~ train@32190  Loss: 0.062928 Acc: 12.8000\n",
      " |~~ train@32195  Loss: 0.073328 Acc: 12.4000\n",
      " |~~ train@32200  Loss: 0.034361 Acc: 13.4000\n",
      " |~~ train@32205  Loss: 0.023384 Acc: 13.4000\n",
      " |~~ train@32210  Loss: 0.027908 Acc: 13.6000\n",
      " |~~ train@32215  Loss: 0.056113 Acc: 12.8000\n",
      " |~~ train@32220  Loss: 0.028334 Acc: 13.2000\n",
      " |~~ train@32225  Loss: 0.025416 Acc: 13.4000\n",
      " |~~ train@32230  Loss: 0.020620 Acc: 13.8000\n",
      " |~~ train@32235  Loss: 0.028467 Acc: 13.6000\n",
      " |~~ train@32240  Loss: 0.019094 Acc: 13.8000\n",
      " |~~ train@32245  Loss: 0.020104 Acc: 13.8000\n",
      " |~~ train@32250  Loss: 0.041824 Acc: 13.0000\n",
      " |~~ train@32255  Loss: 0.041140 Acc: 13.0000\n",
      " |~~ train@32260  Loss: 0.054365 Acc: 12.8000\n",
      " |~~ train@32265  Loss: 0.030767 Acc: 13.6000\n",
      " |~~ train@32270  Loss: 0.045014 Acc: 12.8000\n",
      " |~~ train@32275  Loss: 0.070268 Acc: 12.6000\n",
      " |~~ train@32280  Loss: 0.014369 Acc: 13.8000\n",
      " |~~ train@32285  Loss: 0.018746 Acc: 13.8000\n",
      " |~~ train@32290  Loss: 0.043929 Acc: 13.4000\n",
      " |~~ train@32295  Loss: 0.030065 Acc: 13.4000\n",
      " |~~ train@32300  Loss: 0.036622 Acc: 13.2000\n",
      " |~~ train@32305  Loss: 0.096771 Acc: 11.4000\n",
      " |~~ train@32310  Loss: 0.043132 Acc: 12.8000\n",
      " |~~ train@32315  Loss: 0.032173 Acc: 13.4000\n",
      " |~~ train@32320  Loss: 0.038292 Acc: 13.2000\n",
      " |~~ train@32325  Loss: 0.049061 Acc: 13.0000\n",
      " |~~ train@32330  Loss: 0.021374 Acc: 13.6000\n",
      " |~~ train@32335  Loss: 0.037497 Acc: 13.2000\n",
      " |~~ train@32340  Loss: 0.046721 Acc: 13.2000\n",
      " |~~ train@32345  Loss: 0.035063 Acc: 13.4000\n",
      " |~~ train@32350  Loss: 0.035506 Acc: 13.2000\n",
      " |~~ train@32355  Loss: 0.034919 Acc: 13.4000\n",
      " |~~ train@32360  Loss: 0.073398 Acc: 12.4000\n",
      " |~~ train@32365  Loss: 0.046454 Acc: 13.0000\n",
      " |~~ train@32370  Loss: 0.037785 Acc: 13.2000\n",
      " |~~ train@32375  Loss: 0.043895 Acc: 13.2000\n",
      " |~~ train@32380  Loss: 0.043836 Acc: 13.2000\n",
      " |~~ train@32385  Loss: 0.010834 Acc: 14.0000\n",
      " |~~ train@32390  Loss: 0.030387 Acc: 13.4000\n",
      " |~~ train@32395  Loss: 0.018679 Acc: 13.8000\n",
      " |~~ train@32400  Loss: 0.066162 Acc: 12.8000\n",
      " |~~ train@32405  Loss: 0.035937 Acc: 13.0000\n",
      " |~~ train@32410  Loss: 0.024402 Acc: 13.6000\n",
      " |~~ train@32415  Loss: 0.032217 Acc: 13.4000\n",
      " |~~ train@32420  Loss: 0.016776 Acc: 13.8000\n",
      " |~~ train@32425  Loss: 0.032800 Acc: 13.2000\n",
      " |~~ train@32430  Loss: 0.016903 Acc: 13.8000\n",
      " |~~ train@32435  Loss: 0.031258 Acc: 13.6000\n",
      " |~~ train@32440  Loss: 0.039530 Acc: 12.8000\n",
      " |~~ train@32445  Loss: 0.041633 Acc: 13.0000\n",
      " |~~ train@32450  Loss: 0.011885 Acc: 14.0000\n",
      " |~~ train@32455  Loss: 0.033293 Acc: 13.4000\n",
      " |~~ train@32460  Loss: 0.063668 Acc: 12.8000\n",
      " |~~ train@32465  Loss: 0.045202 Acc: 13.2000\n",
      " |~~ train@32470  Loss: 0.046626 Acc: 12.8000\n",
      " |~~ train@32475  Loss: 0.088740 Acc: 11.8000\n",
      " |~~ train@32480  Loss: 0.022512 Acc: 13.6000\n",
      " |~~ train@32485  Loss: 0.015019 Acc: 13.8000\n",
      " |~~ train@32490  Loss: 0.035756 Acc: 13.2000\n",
      " |~~ train@32495  Loss: 0.038192 Acc: 13.4000\n",
      " |~~ train@32500  Loss: 0.050474 Acc: 12.8000\n",
      " |~~ train@32505  Loss: 0.019469 Acc: 13.6000\n",
      " |~~ train@32510  Loss: 0.047503 Acc: 12.6000\n",
      " |~~ train@32515  Loss: 0.031982 Acc: 13.6000\n",
      " |~~ train@32520  Loss: 0.050523 Acc: 13.0000\n",
      " |~~ train@32525  Loss: 0.041620 Acc: 13.0000\n",
      " |~~ train@32530  Loss: 0.050032 Acc: 12.8000\n",
      " |~~ train@32535  Loss: 0.057132 Acc: 12.8000\n",
      " |~~ train@32540  Loss: 0.044692 Acc: 13.0000\n",
      " |~~ train@32545  Loss: 0.029718 Acc: 13.4000\n",
      " |~~ train@32550  Loss: 0.056130 Acc: 12.8000\n",
      " |~~ train@32555  Loss: 0.036020 Acc: 13.2000\n",
      " |~~ train@32560  Loss: 0.051376 Acc: 13.0000\n",
      " |~~ train@32565  Loss: 0.066410 Acc: 12.6000\n",
      " |~~ train@32570  Loss: 0.020790 Acc: 13.6000\n",
      " |~~ train@32575  Loss: 0.050917 Acc: 13.0000\n",
      " |~~ train@32580  Loss: 0.013978 Acc: 13.8000\n",
      " |~~ train@32585  Loss: 0.029054 Acc: 13.4000\n",
      " |~~ train@32590  Loss: 0.020453 Acc: 13.8000\n",
      " |~~ train@32595  Loss: 0.095066 Acc: 11.8000\n",
      " |~~ train@32600  Loss: 0.012603 Acc: 14.0000\n",
      " |~~ train@32605  Loss: 0.020293 Acc: 13.6000\n",
      " |~~ train@32610  Loss: 0.041999 Acc: 13.2000\n",
      " |~~ train@32615  Loss: 0.026802 Acc: 13.6000\n",
      " |~~ train@32620  Loss: 0.019790 Acc: 13.6000\n",
      " |~~ train@32625  Loss: 0.054111 Acc: 12.8000\n",
      " |~~ train@32630  Loss: 0.031281 Acc: 13.6000\n",
      " |~~ train@32635  Loss: 0.051153 Acc: 12.6000\n",
      " |~~ train@32640  Loss: 0.040895 Acc: 13.0000\n",
      " |~~ train@32645  Loss: 0.050785 Acc: 12.6000\n",
      " |~~ train@32650  Loss: 0.046782 Acc: 12.8000\n",
      " |~~ train@32655  Loss: 0.050618 Acc: 13.0000\n",
      " |~~ train@32660  Loss: 0.034523 Acc: 13.4000\n",
      " |~~ train@32665  Loss: 0.083282 Acc: 11.8000\n",
      " |~~ train@32670  Loss: 0.040929 Acc: 13.2000\n",
      " |~~ train@32675  Loss: 0.014359 Acc: 13.8000\n",
      " |~~ train@32680  Loss: 0.012673 Acc: 14.0000\n",
      " |~~ train@32685  Loss: 0.012125 Acc: 14.0000\n",
      " |~~ train@32690  Loss: 0.039205 Acc: 13.0000\n",
      " |~~ train@32695  Loss: 0.020023 Acc: 13.8000\n",
      " |~~ train@32700  Loss: 0.041412 Acc: 13.2000\n",
      " |~~ train@32705  Loss: 0.027994 Acc: 13.4000\n",
      " |~~ train@32710  Loss: 0.028260 Acc: 13.4000\n",
      " |~~ train@32715  Loss: 0.050371 Acc: 12.8000\n",
      " |~~ train@32720  Loss: 0.026678 Acc: 13.4000\n",
      " |~~ train@32725  Loss: 0.022530 Acc: 13.6000\n",
      " |~~ train@32730  Loss: 0.019374 Acc: 13.8000\n",
      " |~~ train@32735  Loss: 0.056468 Acc: 13.2000\n",
      " |~~ train@32740  Loss: 0.041436 Acc: 13.2000\n",
      " |~~ train@32745  Loss: 0.020713 Acc: 13.8000\n",
      " |~~ train@32750  Loss: 0.029082 Acc: 13.4000\n",
      " |~~ train@32755  Loss: 0.030442 Acc: 13.4000\n",
      " |~~ train@32760  Loss: 0.031524 Acc: 13.4000\n",
      " |~~ train@32765  Loss: 0.019951 Acc: 13.8000\n",
      " |~~ train@32770  Loss: 0.062349 Acc: 12.8000\n",
      " |~~ train@32775  Loss: 0.042847 Acc: 12.8000\n",
      " |~~ train@32780  Loss: 0.023960 Acc: 13.8000\n",
      " |~~ train@32785  Loss: 0.028242 Acc: 13.6000\n",
      " |~~ train@32790  Loss: 0.023843 Acc: 13.6000\n",
      " |~~ train@32795  Loss: 0.029781 Acc: 13.6000\n",
      " |~~ train@32800  Loss: 0.042548 Acc: 13.0000\n",
      " |~~ train@32805  Loss: 0.025278 Acc: 13.6000\n",
      " |~~ train@32810  Loss: 0.058072 Acc: 12.8000\n",
      " |~~ train@32815  Loss: 0.017409 Acc: 13.8000\n",
      " |~~ train@32820  Loss: 0.013825 Acc: 13.8000\n",
      " |~~ train@32825  Loss: 0.028198 Acc: 13.4000\n",
      " |~~ train@32830  Loss: 0.048193 Acc: 12.8000\n",
      " |~~ train@32835  Loss: 0.046906 Acc: 13.0000\n",
      " |~~ train@32840  Loss: 0.025772 Acc: 13.6000\n",
      " |~~ train@32845  Loss: 0.026008 Acc: 13.4000\n",
      " |~~ train@32850  Loss: 0.022015 Acc: 13.6000\n",
      " |~~ train@32855  Loss: 0.041651 Acc: 13.0000\n",
      " |~~ train@32860  Loss: 0.035682 Acc: 13.2000\n",
      " |~~ train@32865  Loss: 0.043078 Acc: 13.4000\n",
      " |~~ train@32870  Loss: 0.027114 Acc: 13.6000\n",
      " |~~ train@32875  Loss: 0.025452 Acc: 13.4000\n",
      " |~~ train@32880  Loss: 0.053878 Acc: 12.6000\n",
      " |~~ train@32885  Loss: 0.057889 Acc: 13.0000\n",
      " |~~ train@32890  Loss: 0.017966 Acc: 13.8000\n",
      " |~~ train@32895  Loss: 0.022898 Acc: 13.6000\n",
      " |~~ train@32900  Loss: 0.023000 Acc: 13.6000\n",
      " |~~ train@32905  Loss: 0.037404 Acc: 13.2000\n",
      " |~~ train@32910  Loss: 0.035818 Acc: 13.4000\n",
      " |~~ train@32915  Loss: 0.043138 Acc: 13.4000\n",
      " |~~ train@32920  Loss: 0.048302 Acc: 12.8000\n",
      " |~~ train@32925  Loss: 0.041093 Acc: 13.2000\n",
      " |~~ train@32930  Loss: 0.057202 Acc: 12.6000\n",
      " |~~ train@32935  Loss: 0.014412 Acc: 13.8000\n",
      " |~~ train@32940  Loss: 0.026637 Acc: 13.6000\n",
      " |~~ train@32945  Loss: 0.019559 Acc: 13.8000\n",
      " |~~ train@32950  Loss: 0.025306 Acc: 13.4000\n",
      " |~~ train@32955  Loss: 0.036174 Acc: 13.4000\n",
      " |~~ train@32960  Loss: 0.031689 Acc: 13.2000\n",
      " |~~ train@32965  Loss: 0.010795 Acc: 14.0000\n",
      " |~~ train@32970  Loss: 0.030775 Acc: 13.6000\n",
      " |~~ train@32975  Loss: 0.041445 Acc: 13.2000\n",
      " |~~ train@32980  Loss: 0.019057 Acc: 13.6000\n",
      " |~~ train@32985  Loss: 0.039733 Acc: 13.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@32990  Loss: 0.045547 Acc: 13.0000\n",
      " |~~ train@32995  Loss: 0.037565 Acc: 13.4000\n",
      " |~~ train@33000  Loss: 0.017152 Acc: 13.8000\n",
      " |~~ train@33005  Loss: 0.024528 Acc: 13.6000\n",
      " |~~ train@33010  Loss: 0.022674 Acc: 13.8000\n",
      " |~~ train@33015  Loss: 0.052868 Acc: 12.8000\n",
      " |~~ train@33020  Loss: 0.050987 Acc: 13.0000\n",
      " |~~ train@33025  Loss: 0.059139 Acc: 12.8000\n",
      " |~~ train@33030  Loss: 0.026815 Acc: 13.4000\n",
      " |~~ train@33035  Loss: 0.019024 Acc: 13.6000\n",
      " |~~ train@33040  Loss: 0.058285 Acc: 12.6000\n",
      " |~~ train@33045  Loss: 0.042158 Acc: 13.2000\n",
      " |~~ train@33050  Loss: 0.061974 Acc: 12.6000\n",
      " |~~ train@33055  Loss: 0.040643 Acc: 13.0000\n",
      " |~~ train@33060  Loss: 0.053935 Acc: 13.0000\n",
      " |~~ train@33065  Loss: 0.037845 Acc: 13.0000\n",
      " |~~ train@33070  Loss: 0.010244 Acc: 14.0000\n",
      " |~~ train@33075  Loss: 0.028230 Acc: 13.4000\n",
      " |~~ train@33080  Loss: 0.022673 Acc: 13.6000\n",
      " |~~ train@33085  Loss: 0.031944 Acc: 13.6000\n",
      " |~~ train@33090  Loss: 0.064767 Acc: 12.6000\n",
      " |~~ train@33095  Loss: 0.018163 Acc: 13.6000\n",
      " |~~ train@33100  Loss: 0.014042 Acc: 13.8000\n",
      " |~~ train@33105  Loss: 0.032183 Acc: 13.4000\n",
      " |~~ train@33110  Loss: 0.078046 Acc: 12.2000\n",
      " |~~ train@33115  Loss: 0.032546 Acc: 13.4000\n",
      " |~~ train@33120  Loss: 0.018474 Acc: 13.8000\n",
      " |~~ train@33125  Loss: 0.046330 Acc: 12.8000\n",
      " |~~ train@33130  Loss: 0.032971 Acc: 13.2000\n",
      " |~~ train@33135  Loss: 0.009967 Acc: 14.0000\n",
      " |~~ train@33140  Loss: 0.052512 Acc: 12.8000\n",
      " |~~ train@33145  Loss: 0.032460 Acc: 13.2000\n",
      " |~~ train@33150  Loss: 0.038319 Acc: 13.2000\n",
      " |~~ train@33155  Loss: 0.025054 Acc: 13.6000\n",
      " |~~ train@33160  Loss: 0.040012 Acc: 13.2000\n",
      " |~~ train@33165  Loss: 0.051003 Acc: 12.8000\n",
      " |~~ train@33170  Loss: 0.016666 Acc: 13.8000\n",
      " |~~ train@33175  Loss: 0.040086 Acc: 13.4000\n",
      " |~~ train@33180  Loss: 0.040882 Acc: 13.2000\n",
      " |~~ train@33185  Loss: 0.025335 Acc: 13.4000\n",
      " |~~ train@33190  Loss: 0.026951 Acc: 13.4000\n",
      " |~~ train@33195  Loss: 0.104830 Acc: 11.6000\n",
      " |~~ train@33200  Loss: 0.011423 Acc: 14.0000\n",
      " |~~ train@33205  Loss: 0.057189 Acc: 12.6000\n",
      " |~~ train@33210  Loss: 0.021502 Acc: 13.6000\n",
      " |~~ train@33215  Loss: 0.071734 Acc: 12.4000\n",
      " |~~ train@33220  Loss: 0.048227 Acc: 13.0000\n",
      " |~~ train@33225  Loss: 0.043744 Acc: 13.2000\n",
      " |~~ train@33230  Loss: 0.051905 Acc: 12.6000\n",
      " |~~ train@33235  Loss: 0.030349 Acc: 13.4000\n",
      " |~~ train@33240  Loss: 0.038032 Acc: 13.4000\n",
      " |~~ train@33245  Loss: 0.026618 Acc: 13.6000\n",
      " |~~ train@33250  Loss: 0.020894 Acc: 13.8000\n",
      " |~~ train@33255  Loss: 0.040954 Acc: 13.2000\n",
      " |~~ train@33260  Loss: 0.028638 Acc: 13.4000\n",
      " |~~ train@33265  Loss: 0.085794 Acc: 11.8000\n",
      " |~~ train@33270  Loss: 0.032787 Acc: 13.4000\n",
      " |~~ train@33275  Loss: 0.022175 Acc: 13.6000\n",
      " |~~ train@33280  Loss: 0.054338 Acc: 13.0000\n",
      " |~~ train@33285  Loss: 0.034669 Acc: 13.4000\n",
      " |~~ train@33290  Loss: 0.023537 Acc: 13.6000\n",
      " |~~ train@33295  Loss: 0.031377 Acc: 13.4000\n",
      " |~~ train@33300  Loss: 0.018171 Acc: 13.8000\n",
      " |~~ train@33305  Loss: 0.037125 Acc: 13.4000\n",
      " |~~ train@33310  Loss: 0.034420 Acc: 13.4000\n",
      " |~~ train@33315  Loss: 0.029038 Acc: 13.6000\n",
      " |~~ train@33320  Loss: 0.020442 Acc: 13.6000\n",
      " |~~ train@33325  Loss: 0.012746 Acc: 14.0000\n",
      " |~~ train@33330  Loss: 0.030076 Acc: 13.6000\n",
      " |~~ train@33335  Loss: 0.055302 Acc: 12.6000\n",
      " |~~ train@33340  Loss: 0.020686 Acc: 13.8000\n",
      " |~~ train@33345  Loss: 0.010483 Acc: 14.0000\n",
      " |~~ train@33350  Loss: 0.011201 Acc: 14.0000\n",
      " |~~ train@33355  Loss: 0.011882 Acc: 14.0000\n",
      " |~~ train@33360  Loss: 0.027106 Acc: 13.6000\n",
      " |~~ train@33365  Loss: 0.076894 Acc: 12.4000\n",
      " |~~ train@33370  Loss: 0.042099 Acc: 13.2000\n",
      " |~~ train@33375  Loss: 0.029971 Acc: 13.4000\n",
      " |~~ train@33380  Loss: 0.041229 Acc: 13.2000\n",
      " |~~ train@33385  Loss: 0.039547 Acc: 13.2000\n",
      " |~~ train@33390  Loss: 0.019646 Acc: 13.8000\n",
      " |~~ train@33395  Loss: 0.059073 Acc: 12.8000\n",
      " |~~ train@33400  Loss: 0.018930 Acc: 13.8000\n",
      " |~~ train@33405  Loss: 0.027930 Acc: 13.4000\n",
      " |~~ train@33410  Loss: 0.015140 Acc: 13.8000\n",
      " |~~ train@33415  Loss: 0.067158 Acc: 12.4000\n",
      " |~~ train@33420  Loss: 0.041184 Acc: 13.0000\n",
      " |~~ train@33425  Loss: 0.033957 Acc: 13.2000\n",
      " |~~ train@33430  Loss: 0.015892 Acc: 13.8000\n",
      " |~~ train@33435  Loss: 0.047051 Acc: 13.2000\n",
      " |~~ train@33440  Loss: 0.050789 Acc: 13.2000\n",
      " |~~ train@33445  Loss: 0.010525 Acc: 14.0000\n",
      " |~~ train@33450  Loss: 0.024678 Acc: 13.6000\n",
      " |~~ train@33455  Loss: 0.064464 Acc: 12.4000\n",
      " |~~ train@33460  Loss: 0.031763 Acc: 13.4000\n",
      " |~~ train@33465  Loss: 0.042478 Acc: 13.0000\n",
      " |~~ train@33470  Loss: 0.009587 Acc: 14.0000\n",
      " |~~ train@33475  Loss: 0.061673 Acc: 12.6000\n",
      " |~~ train@33480  Loss: 0.060034 Acc: 12.6000\n",
      " |~~ train@33485  Loss: 0.025312 Acc: 13.6000\n",
      " |~~ train@33490  Loss: 0.042935 Acc: 13.0000\n",
      " |~~ train@33495  Loss: 0.029054 Acc: 13.6000\n",
      " |~~ train@33500  Loss: 0.030444 Acc: 13.4000\n",
      " |~~ train@33505  Loss: 0.019548 Acc: 13.8000\n",
      " |~~ train@33510  Loss: 0.050108 Acc: 12.8000\n",
      " |~~ train@33515  Loss: 0.020623 Acc: 13.6000\n",
      " |~~ train@33520  Loss: 0.017855 Acc: 13.8000\n",
      " |~~ train@33525  Loss: 0.014847 Acc: 13.8000\n",
      " |~~ train@33530  Loss: 0.018373 Acc: 13.8000\n",
      " |~~ train@33535  Loss: 0.041721 Acc: 13.0000\n",
      " |~~ train@33540  Loss: 0.034110 Acc: 13.4000\n",
      " |~~ train@33545  Loss: 0.014614 Acc: 13.8000\n",
      " |~~ train@33550  Loss: 0.065176 Acc: 12.6000\n",
      " |~~ train@33555  Loss: 0.016161 Acc: 13.8000\n",
      " |~~ train@33560  Loss: 0.039133 Acc: 13.2000\n",
      " |~~ train@33565  Loss: 0.047731 Acc: 12.8000\n",
      " |~~ train@33570  Loss: 0.027581 Acc: 13.4000\n",
      " |~~ train@33575  Loss: 0.052478 Acc: 12.8000\n",
      " |~~ train@33580  Loss: 0.035883 Acc: 13.2000\n",
      " |~~ train@33585  Loss: 0.030022 Acc: 13.4000\n",
      " |~~ train@33590  Loss: 0.061056 Acc: 12.8000\n",
      " |~~ train@33595  Loss: 0.049250 Acc: 13.2000\n",
      " |~~ train@33600  Loss: 0.050748 Acc: 12.8000\n",
      " |~~ train@33605  Loss: 0.065308 Acc: 13.0000\n",
      " |~~ train@33610  Loss: 0.026371 Acc: 13.6000\n",
      " |~~ train@33615  Loss: 0.045052 Acc: 13.0000\n",
      " |~~ train@33620  Loss: 0.018455 Acc: 13.8000\n",
      " |~~ train@33625  Loss: 0.038291 Acc: 13.4000\n",
      " |~~ train@33630  Loss: 0.032350 Acc: 13.4000\n",
      " |~~ train@33635  Loss: 0.019742 Acc: 13.8000\n",
      " |~~ train@33640  Loss: 0.027458 Acc: 13.6000\n",
      " |~~ train@33645  Loss: 0.046404 Acc: 13.0000\n",
      " |~~ train@33650  Loss: 0.054313 Acc: 12.8000\n",
      " |~~ train@33655  Loss: 0.030139 Acc: 13.6000\n",
      " |~~ train@33660  Loss: 0.033245 Acc: 13.2000\n",
      " |~~ train@33665  Loss: 0.038352 Acc: 13.0000\n",
      " |~~ train@33670  Loss: 0.060930 Acc: 12.8000\n",
      " |~~ train@33675  Loss: 0.046165 Acc: 13.0000\n",
      " |~~ train@33680  Loss: 0.033912 Acc: 13.4000\n",
      " |~~ train@33685  Loss: 0.036886 Acc: 13.2000\n",
      " |~~ train@33690  Loss: 0.042066 Acc: 13.0000\n",
      " |~~ train@33695  Loss: 0.022760 Acc: 13.6000\n",
      " |~~ train@33700  Loss: 0.028582 Acc: 13.4000\n",
      " |~~ train@33705  Loss: 0.041316 Acc: 13.2000\n",
      " |~~ train@33710  Loss: 0.022019 Acc: 13.6000\n",
      " |~~ train@33715  Loss: 0.041796 Acc: 13.2000\n",
      " |~~ train@33720  Loss: 0.075738 Acc: 12.2000\n",
      " |~~ train@33725  Loss: 0.059905 Acc: 12.6000\n",
      " |~~ train@33730  Loss: 0.048006 Acc: 13.0000\n",
      " |~~ train@33735  Loss: 0.061570 Acc: 12.8000\n",
      " |~~ train@33740  Loss: 0.033845 Acc: 13.4000\n",
      " |~~ train@33745  Loss: 0.054057 Acc: 12.4000\n",
      " |~~ train@33750  Loss: 0.079290 Acc: 12.0000\n",
      " |~~ train@33755  Loss: 0.021799 Acc: 13.4000\n",
      " |~~ train@33760  Loss: 0.047218 Acc: 12.8000\n",
      " |~~ train@33765  Loss: 0.024145 Acc: 13.6000\n",
      " |~~ train@33770  Loss: 0.031447 Acc: 13.4000\n",
      " |~~ train@33775  Loss: 0.037887 Acc: 13.4000\n",
      " |~~ train@33780  Loss: 0.051494 Acc: 12.8000\n",
      " |~~ train@33785  Loss: 0.028015 Acc: 13.6000\n",
      " |~~ train@33790  Loss: 0.027651 Acc: 13.4000\n",
      " |~~ train@33795  Loss: 0.024741 Acc: 13.8000\n",
      " |~~ train@33800  Loss: 0.012296 Acc: 14.0000\n",
      " |~~ train@33805  Loss: 0.020644 Acc: 13.8000\n",
      " |~~ train@33810  Loss: 0.041138 Acc: 13.0000\n",
      " |~~ train@33815  Loss: 0.018508 Acc: 13.8000\n",
      " |~~ train@33820  Loss: 0.071094 Acc: 12.4000\n",
      " |~~ train@33825  Loss: 0.035654 Acc: 13.2000\n",
      " |~~ train@33830  Loss: 0.019769 Acc: 13.8000\n",
      " |~~ train@33835  Loss: 0.037584 Acc: 13.2000\n",
      " |~~ train@33840  Loss: 0.038816 Acc: 12.8000\n",
      " |~~ train@33845  Loss: 0.020013 Acc: 13.6000\n",
      " |~~ train@33850  Loss: 0.018779 Acc: 13.8000\n",
      " |~~ train@33855  Loss: 0.048724 Acc: 13.0000\n",
      " |~~ train@33860  Loss: 0.028422 Acc: 13.6000\n",
      " |~~ train@33865  Loss: 0.014899 Acc: 13.8000\n",
      " |~~ train@33870  Loss: 0.044047 Acc: 12.8000\n",
      " |~~ train@33875  Loss: 0.045669 Acc: 13.2000\n",
      " |~~ train@33880  Loss: 0.022053 Acc: 13.8000\n",
      " |~~ train@33885  Loss: 0.031267 Acc: 13.4000\n",
      " |~~ train@33890  Loss: 0.026923 Acc: 13.4000\n",
      " |~~ train@33895  Loss: 0.024236 Acc: 13.6000\n",
      " |~~ train@33900  Loss: 0.038426 Acc: 13.0000\n",
      " |~~ train@33905  Loss: 0.038066 Acc: 13.4000\n",
      " |~~ train@33910  Loss: 0.019566 Acc: 13.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@33915  Loss: 0.068512 Acc: 12.8000\n",
      " |~~ train@33920  Loss: 0.019820 Acc: 13.6000\n",
      " |~~ train@33925  Loss: 0.023188 Acc: 13.6000\n",
      " |~~ train@33930  Loss: 0.046499 Acc: 12.8000\n",
      " |~~ train@33935  Loss: 0.028969 Acc: 13.4000\n",
      " |~~ train@33940  Loss: 0.063295 Acc: 12.6000\n",
      " |~~ train@33945  Loss: 0.041941 Acc: 13.0000\n",
      " |~~ train@33950  Loss: 0.043258 Acc: 13.2000\n",
      " |~~ train@33955  Loss: 0.041829 Acc: 13.4000\n",
      " |~~ train@33960  Loss: 0.032292 Acc: 13.4000\n",
      " |~~ train@33965  Loss: 0.010946 Acc: 14.0000\n",
      " |~~ train@33970  Loss: 0.024735 Acc: 13.2000\n",
      " |~~ train@33975  Loss: 0.011561 Acc: 14.0000\n",
      " |~~ train@33980  Loss: 0.014782 Acc: 13.8000\n",
      " |~~ train@33985  Loss: 0.046030 Acc: 13.0000\n",
      " |~~ train@33990  Loss: 0.015669 Acc: 13.8000\n",
      " |~~ train@33995  Loss: 0.019243 Acc: 13.8000\n",
      " |~~ train@34000  Loss: 0.024281 Acc: 13.6000\n",
      " |~~ train@34005  Loss: 0.022898 Acc: 13.6000\n",
      " |~~ train@34010  Loss: 0.061674 Acc: 12.4000\n",
      " |~~ train@34015  Loss: 0.026411 Acc: 13.4000\n",
      " |~~ train@34020  Loss: 0.027660 Acc: 13.6000\n",
      " |~~ train@34025  Loss: 0.040199 Acc: 13.2000\n",
      " |~~ train@34030  Loss: 0.014183 Acc: 13.8000\n",
      " |~~ train@34035  Loss: 0.056346 Acc: 12.8000\n",
      " |~~ train@34040  Loss: 0.045617 Acc: 13.0000\n",
      " |~~ train@34045  Loss: 0.017166 Acc: 13.8000\n",
      " |~~ train@34050  Loss: 0.040922 Acc: 13.0000\n",
      " |~~ train@34055  Loss: 0.042610 Acc: 13.0000\n",
      " |~~ train@34060  Loss: 0.026877 Acc: 13.2000\n",
      " |~~ train@34065  Loss: 0.064449 Acc: 12.6000\n",
      " |~~ train@34070  Loss: 0.068542 Acc: 13.0000\n",
      " |~~ train@34075  Loss: 0.015977 Acc: 13.8000\n",
      " |~~ train@34080  Loss: 0.042452 Acc: 13.0000\n",
      " |~~ train@34085  Loss: 0.045765 Acc: 13.2000\n",
      " |~~ train@34090  Loss: 0.038926 Acc: 13.2000\n",
      " |~~ train@34095  Loss: 0.024051 Acc: 13.6000\n",
      " |~~ train@34100  Loss: 0.039448 Acc: 13.2000\n",
      " |~~ train@34105  Loss: 0.010787 Acc: 14.0000\n",
      " |~~ train@34110  Loss: 0.041607 Acc: 13.2000\n",
      " |~~ train@34115  Loss: 0.033988 Acc: 13.4000\n",
      " |~~ train@34120  Loss: 0.044183 Acc: 13.2000\n",
      " |~~ train@34125  Loss: 0.019242 Acc: 13.6000\n",
      " |~~ train@34130  Loss: 0.066488 Acc: 12.6000\n",
      " |~~ train@34135  Loss: 0.023707 Acc: 13.6000\n",
      " |~~ train@34140  Loss: 0.025630 Acc: 13.6000\n",
      " |~~ train@34145  Loss: 0.028185 Acc: 13.4000\n",
      " |~~ train@34150  Loss: 0.043493 Acc: 13.2000\n",
      " |~~ train@34155  Loss: 0.043230 Acc: 12.8000\n",
      " |~~ train@34160  Loss: 0.028378 Acc: 13.2000\n",
      " |~~ train@34165  Loss: 0.027583 Acc: 13.4000\n",
      " |~~ train@34170  Loss: 0.033139 Acc: 13.4000\n",
      " |~~ train@34175  Loss: 0.031102 Acc: 13.2000\n",
      " |~~ train@34180  Loss: 0.035452 Acc: 13.2000\n",
      " |~~ train@34185  Loss: 0.010979 Acc: 14.0000\n",
      " |~~ train@34190  Loss: 0.047884 Acc: 13.0000\n",
      " |~~ train@34195  Loss: 0.048517 Acc: 12.8000\n",
      " |~~ train@34200  Loss: 0.025343 Acc: 13.4000\n",
      " |~~ train@34205  Loss: 0.019522 Acc: 13.6000\n",
      " |~~ train@34210  Loss: 0.026902 Acc: 13.4000\n",
      " |~~ train@34215  Loss: 0.047804 Acc: 13.2000\n",
      " |~~ train@34220  Loss: 0.011199 Acc: 14.0000\n",
      " |~~ train@34225  Loss: 0.048164 Acc: 12.8000\n",
      " |~~ train@34230  Loss: 0.049939 Acc: 12.8000\n",
      " |~~ train@34235  Loss: 0.059454 Acc: 12.8000\n",
      " |~~ train@34240  Loss: 0.030989 Acc: 13.0000\n",
      " |~~ train@34245  Loss: 0.041614 Acc: 13.2000\n",
      " |~~ train@34250  Loss: 0.046174 Acc: 13.2000\n",
      " |~~ train@34255  Loss: 0.011056 Acc: 14.0000\n",
      " |~~ train@34260  Loss: 0.048849 Acc: 13.0000\n",
      " |~~ train@34265  Loss: 0.079313 Acc: 12.4000\n",
      " |~~ train@34270  Loss: 0.036174 Acc: 13.4000\n",
      " |~~ train@34275  Loss: 0.015104 Acc: 13.8000\n",
      " |~~ train@34280  Loss: 0.011103 Acc: 14.0000\n",
      " |~~ train@34285  Loss: 0.024971 Acc: 13.6000\n",
      " |~~ train@34290  Loss: 0.010952 Acc: 14.0000\n",
      " |~~ train@34295  Loss: 0.042184 Acc: 13.0000\n",
      " |~~ train@34300  Loss: 0.043330 Acc: 13.0000\n",
      " |~~ train@34305  Loss: 0.033446 Acc: 13.4000\n",
      " |~~ train@34310  Loss: 0.063541 Acc: 12.4000\n",
      " |~~ train@34315  Loss: 0.029670 Acc: 13.2000\n",
      " |~~ train@34320  Loss: 0.017817 Acc: 13.6000\n",
      " |~~ train@34325  Loss: 0.037107 Acc: 13.2000\n",
      " |~~ train@34330  Loss: 0.023991 Acc: 13.6000\n",
      " |~~ train@34335  Loss: 0.010626 Acc: 14.0000\n",
      " |~~ train@34340  Loss: 0.064726 Acc: 12.8000\n",
      " |~~ train@34345  Loss: 0.011703 Acc: 14.0000\n",
      " |~~ train@34350  Loss: 0.046169 Acc: 13.4000\n",
      " |~~ train@34355  Loss: 0.073952 Acc: 12.4000\n",
      " |~~ train@34360  Loss: 0.020928 Acc: 13.6000\n",
      " |~~ train@34365  Loss: 0.046852 Acc: 13.0000\n",
      " |~~ train@34370  Loss: 0.025823 Acc: 13.6000\n",
      " |~~ train@34375  Loss: 0.015567 Acc: 13.8000\n",
      " |~~ train@34380  Loss: 0.010988 Acc: 14.0000\n",
      " |~~ train@34385  Loss: 0.031773 Acc: 13.4000\n",
      " |~~ train@34390  Loss: 0.040682 Acc: 13.2000\n",
      " |~~ train@34395  Loss: 0.037974 Acc: 13.2000\n",
      " |~~ train@34400  Loss: 0.026353 Acc: 13.6000\n",
      " |~~ train@34405  Loss: 0.049562 Acc: 13.0000\n",
      " |~~ train@34410  Loss: 0.009620 Acc: 14.0000\n",
      " |~~ train@34415  Loss: 0.035287 Acc: 13.4000\n",
      " |~~ train@34420  Loss: 0.027236 Acc: 13.4000\n",
      " |~~ train@34425  Loss: 0.013746 Acc: 13.8000\n",
      " |~~ train@34430  Loss: 0.045021 Acc: 13.2000\n",
      " |~~ train@34435  Loss: 0.027163 Acc: 13.4000\n",
      " |~~ train@34440  Loss: 0.054953 Acc: 12.4000\n",
      " |~~ train@34445  Loss: 0.019327 Acc: 13.6000\n",
      " |~~ train@34450  Loss: 0.050085 Acc: 12.8000\n",
      " |~~ train@34455  Loss: 0.010771 Acc: 14.0000\n",
      " |~~ train@34460  Loss: 0.023417 Acc: 13.4000\n",
      " |~~ train@34465  Loss: 0.052583 Acc: 13.0000\n",
      " |~~ train@34470  Loss: 0.050046 Acc: 12.8000\n",
      " |~~ train@34475  Loss: 0.027882 Acc: 13.2000\n",
      " |~~ train@34480  Loss: 0.029015 Acc: 13.4000\n",
      " |~~ train@34485  Loss: 0.032121 Acc: 13.4000\n",
      " |~~ train@34490  Loss: 0.066994 Acc: 12.4000\n",
      " |~~ train@34495  Loss: 0.024297 Acc: 13.6000\n",
      " |~~ train@34500  Loss: 0.031438 Acc: 13.4000\n",
      " |~~ train@34505  Loss: 0.038106 Acc: 13.2000\n",
      " |~~ train@34510  Loss: 0.048999 Acc: 12.8000\n",
      " |~~ train@34515  Loss: 0.049224 Acc: 13.0000\n",
      " |~~ train@34520  Loss: 0.071464 Acc: 12.2000\n",
      " |~~ train@34525  Loss: 0.035381 Acc: 13.4000\n",
      " |~~ train@34530  Loss: 0.056100 Acc: 13.0000\n",
      " |~~ train@34535  Loss: 0.037991 Acc: 13.2000\n",
      " |~~ train@34540  Loss: 0.031713 Acc: 13.4000\n",
      " |~~ train@34545  Loss: 0.020707 Acc: 13.6000\n",
      " |~~ train@34550  Loss: 0.010720 Acc: 14.0000\n",
      " |~~ train@34555  Loss: 0.030020 Acc: 13.4000\n",
      " |~~ train@34560  Loss: 0.036421 Acc: 13.2000\n",
      " |~~ train@34565  Loss: 0.018234 Acc: 13.6000\n",
      " |~~ train@34570  Loss: 0.046302 Acc: 12.6000\n",
      " |~~ train@34575  Loss: 0.010884 Acc: 14.0000\n",
      " |~~ train@34580  Loss: 0.032665 Acc: 13.4000\n",
      " |~~ train@34585  Loss: 0.037212 Acc: 13.4000\n",
      " |~~ train@34590  Loss: 0.035882 Acc: 12.8000\n",
      " |~~ train@34595  Loss: 0.022872 Acc: 13.8000\n",
      " |~~ train@34600  Loss: 0.032542 Acc: 13.4000\n",
      " |~~ train@34605  Loss: 0.031121 Acc: 13.2000\n",
      " |~~ train@34610  Loss: 0.032330 Acc: 13.2000\n",
      " |~~ train@34615  Loss: 0.091595 Acc: 12.4000\n",
      " |~~ train@34620  Loss: 0.014453 Acc: 13.8000\n",
      " |~~ train@34625  Loss: 0.047755 Acc: 12.8000\n",
      " |~~ train@34630  Loss: 0.044649 Acc: 13.0000\n",
      " |~~ train@34635  Loss: 0.042674 Acc: 13.0000\n",
      " |~~ train@34640  Loss: 0.016627 Acc: 13.6000\n",
      " |~~ train@34645  Loss: 0.067460 Acc: 12.8000\n",
      " |~~ train@34650  Loss: 0.032405 Acc: 13.0000\n",
      " |~~ train@34655  Loss: 0.016038 Acc: 13.8000\n",
      " |~~ train@34660  Loss: 0.019428 Acc: 13.6000\n",
      " |~~ train@34665  Loss: 0.013252 Acc: 13.8000\n",
      " |~~ train@34670  Loss: 0.029727 Acc: 13.6000\n",
      " |~~ train@34675  Loss: 0.031348 Acc: 13.2000\n",
      " |~~ train@34680  Loss: 0.011560 Acc: 14.0000\n",
      " |~~ train@34685  Loss: 0.043456 Acc: 13.0000\n",
      " |~~ train@34690  Loss: 0.046007 Acc: 13.0000\n",
      " |~~ train@34695  Loss: 0.040849 Acc: 13.0000\n",
      " |~~ train@34700  Loss: 0.056538 Acc: 12.6000\n",
      " |~~ train@34705  Loss: 0.028939 Acc: 13.4000\n",
      " |~~ train@34710  Loss: 0.028414 Acc: 13.4000\n",
      " |~~ train@34715  Loss: 0.042714 Acc: 12.8000\n",
      " |~~ train@34720  Loss: 0.027936 Acc: 13.6000\n",
      " |~~ train@34725  Loss: 0.054821 Acc: 12.8000\n",
      " |~~ train@34730  Loss: 0.022794 Acc: 13.6000\n",
      " |~~ train@34735  Loss: 0.019443 Acc: 13.8000\n",
      " |~~ train@34740  Loss: 0.031879 Acc: 13.2000\n",
      " |~~ train@34745  Loss: 0.052428 Acc: 12.8000\n",
      " |~~ train@34750  Loss: 0.026965 Acc: 13.4000\n",
      " |~~ train@34755  Loss: 0.042780 Acc: 13.2000\n",
      " |~~ train@34760  Loss: 0.063395 Acc: 13.0000\n",
      " |~~ train@34765  Loss: 0.038632 Acc: 13.2000\n",
      " |~~ train@34770  Loss: 0.041360 Acc: 13.2000\n",
      " |~~ train@34775  Loss: 0.046467 Acc: 12.6000\n",
      " |~~ train@34780  Loss: 0.034564 Acc: 13.4000\n",
      " |~~ train@34785  Loss: 0.023806 Acc: 13.6000\n",
      " |~~ train@34790  Loss: 0.041901 Acc: 13.4000\n",
      " |~~ train@34795  Loss: 0.019269 Acc: 13.4000\n",
      " |~~ train@34800  Loss: 0.039739 Acc: 13.2000\n",
      " |~~ train@34805  Loss: 0.037333 Acc: 13.2000\n",
      " |~~ train@34810  Loss: 0.022333 Acc: 13.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@34815  Loss: 0.041389 Acc: 12.8000\n",
      " |~~ train@34820  Loss: 0.034507 Acc: 13.2000\n",
      " |~~ train@34825  Loss: 0.046818 Acc: 12.8000\n",
      " |~~ train@34830  Loss: 0.039818 Acc: 13.2000\n",
      " |~~ train@34835  Loss: 0.039496 Acc: 13.6000\n",
      " |~~ train@34840  Loss: 0.052180 Acc: 12.8000\n",
      " |~~ train@34845  Loss: 0.041330 Acc: 13.0000\n",
      " |~~ train@34850  Loss: 0.012222 Acc: 14.0000\n",
      " |~~ train@34855  Loss: 0.014300 Acc: 13.8000\n",
      " |~~ train@34860  Loss: 0.034801 Acc: 13.2000\n",
      " |~~ train@34865  Loss: 0.016960 Acc: 13.8000\n",
      " |~~ train@34870  Loss: 0.068152 Acc: 12.6000\n",
      " |~~ train@34875  Loss: 0.056910 Acc: 12.6000\n",
      " |~~ train@34880  Loss: 0.015745 Acc: 13.8000\n",
      " |~~ train@34885  Loss: 0.054153 Acc: 13.0000\n",
      " |~~ train@34890  Loss: 0.045380 Acc: 13.0000\n",
      " |~~ train@34895  Loss: 0.022239 Acc: 13.8000\n",
      " |~~ train@34900  Loss: 0.034346 Acc: 13.2000\n",
      " |~~ train@34905  Loss: 0.033464 Acc: 13.4000\n",
      " |~~ train@34910  Loss: 0.010502 Acc: 14.0000\n",
      " |~~ train@34915  Loss: 0.026050 Acc: 13.4000\n",
      " |~~ train@34920  Loss: 0.051399 Acc: 12.8000\n",
      " |~~ train@34925  Loss: 0.020975 Acc: 13.6000\n",
      " |~~ train@34930  Loss: 0.066177 Acc: 12.8000\n",
      " |~~ train@34935  Loss: 0.027673 Acc: 13.4000\n",
      " |~~ train@34940  Loss: 0.031486 Acc: 13.4000\n",
      " |~~ train@34945  Loss: 0.065383 Acc: 12.4000\n",
      " |~~ train@34950  Loss: 0.057495 Acc: 12.8000\n",
      " |~~ train@34955  Loss: 0.019275 Acc: 13.6000\n",
      " |~~ train@34960  Loss: 0.029872 Acc: 13.4000\n",
      " |~~ train@34965  Loss: 0.033522 Acc: 13.4000\n",
      " |~~ train@34970  Loss: 0.034141 Acc: 13.4000\n",
      " |~~ train@34975  Loss: 0.024431 Acc: 13.6000\n",
      " |~~ train@34980  Loss: 0.036708 Acc: 13.4000\n",
      " |~~ train@34985  Loss: 0.031259 Acc: 13.4000\n",
      " |~~ train@34990  Loss: 0.047546 Acc: 13.0000\n",
      " |~~ train@34995  Loss: 0.034676 Acc: 13.4000\n",
      " |~~ train@35000  Loss: 0.016098 Acc: 13.6000\n",
      " |~~ train@35005  Loss: 0.058336 Acc: 12.8000\n",
      " |~~ train@35010  Loss: 0.042085 Acc: 12.8000\n",
      " |~~ train@35015  Loss: 0.062474 Acc: 12.4000\n",
      " |~~ train@35020  Loss: 0.031321 Acc: 13.4000\n",
      " |~~ train@35025  Loss: 0.037395 Acc: 13.2000\n",
      " |~~ train@35030  Loss: 0.023529 Acc: 13.6000\n",
      " |~~ train@35035  Loss: 0.030269 Acc: 13.4000\n",
      " |~~ train@35040  Loss: 0.032767 Acc: 13.2000\n",
      " |~~ train@35045  Loss: 0.032592 Acc: 13.2000\n",
      " |~~ train@35050  Loss: 0.033499 Acc: 13.4000\n",
      " |~~ train@35055  Loss: 0.018495 Acc: 13.6000\n",
      " |~~ train@35060  Loss: 0.014262 Acc: 13.8000\n",
      " |~~ train@35065  Loss: 0.037185 Acc: 13.0000\n",
      " |~~ train@35070  Loss: 0.064178 Acc: 12.6000\n",
      " |~~ train@35075  Loss: 0.051434 Acc: 12.8000\n",
      " |~~ train@35080  Loss: 0.043248 Acc: 13.0000\n",
      " |~~ train@35085  Loss: 0.047856 Acc: 13.0000\n",
      " |~~ train@35090  Loss: 0.027071 Acc: 13.4000\n",
      " |~~ train@35095  Loss: 0.036481 Acc: 13.2000\n",
      " |~~ train@35100  Loss: 0.046204 Acc: 12.8000\n",
      " |~~ train@35105  Loss: 0.026815 Acc: 13.6000\n",
      " |~~ train@35110  Loss: 0.035487 Acc: 13.4000\n",
      " |~~ train@35115  Loss: 0.013524 Acc: 13.8000\n",
      " |~~ train@35120  Loss: 0.020159 Acc: 13.6000\n",
      " |~~ train@35125  Loss: 0.015913 Acc: 13.8000\n",
      " |~~ train@35130  Loss: 0.043159 Acc: 13.2000\n",
      " |~~ train@35135  Loss: 0.024741 Acc: 13.4000\n",
      " |~~ train@35140  Loss: 0.020447 Acc: 13.6000\n",
      " |~~ train@35145  Loss: 0.015808 Acc: 13.8000\n",
      " |~~ train@35150  Loss: 0.036260 Acc: 13.0000\n",
      " |~~ train@35155  Loss: 0.030748 Acc: 13.4000\n",
      " |~~ train@35160  Loss: 0.067902 Acc: 12.2000\n",
      " |~~ train@35165  Loss: 0.020805 Acc: 13.8000\n",
      " |~~ train@35170  Loss: 0.054784 Acc: 12.6000\n",
      " |~~ train@35175  Loss: 0.078211 Acc: 12.2000\n",
      " |~~ train@35180  Loss: 0.018782 Acc: 13.8000\n",
      " |~~ train@35185  Loss: 0.021317 Acc: 13.6000\n",
      " |~~ train@35190  Loss: 0.041662 Acc: 13.2000\n",
      " |~~ train@35195  Loss: 0.043132 Acc: 13.0000\n",
      " |~~ train@35200  Loss: 0.026270 Acc: 13.6000\n",
      " |~~ train@35205  Loss: 0.030748 Acc: 13.4000\n",
      " |~~ train@35210  Loss: 0.029067 Acc: 13.4000\n",
      " |~~ train@35215  Loss: 0.027068 Acc: 13.6000\n",
      " |~~ train@35220  Loss: 0.070496 Acc: 12.2000\n",
      " |~~ train@35225  Loss: 0.025538 Acc: 13.6000\n",
      " |~~ train@35230  Loss: 0.039456 Acc: 13.2000\n",
      " |~~ train@35235  Loss: 0.027410 Acc: 13.4000\n",
      " |~~ train@35240  Loss: 0.028883 Acc: 13.4000\n",
      " |~~ train@35245  Loss: 0.050084 Acc: 13.0000\n",
      " |~~ train@35250  Loss: 0.011126 Acc: 14.0000\n",
      " |~~ train@35255  Loss: 0.046188 Acc: 13.0000\n",
      " |~~ train@35260  Loss: 0.052286 Acc: 13.0000\n",
      " |~~ train@35265  Loss: 0.050613 Acc: 13.0000\n",
      " |~~ train@35270  Loss: 0.025148 Acc: 13.4000\n",
      " |~~ train@35275  Loss: 0.038073 Acc: 13.2000\n",
      " |~~ train@35280  Loss: 0.034805 Acc: 13.2000\n",
      " |~~ train@35285  Loss: 0.029520 Acc: 13.6000\n",
      " |~~ train@35290  Loss: 0.033128 Acc: 13.4000\n",
      " |~~ train@35295  Loss: 0.038305 Acc: 13.0000\n",
      " |~~ train@35300  Loss: 0.010684 Acc: 14.0000\n",
      " |~~ train@35305  Loss: 0.100385 Acc: 12.0000\n",
      " |~~ train@35310  Loss: 0.039353 Acc: 13.0000\n",
      " |~~ train@35315  Loss: 0.021921 Acc: 13.6000\n",
      " |~~ train@35320  Loss: 0.030312 Acc: 13.4000\n",
      " |~~ train@35325  Loss: 0.036483 Acc: 13.2000\n",
      " |~~ train@35330  Loss: 0.034882 Acc: 13.4000\n",
      " |~~ train@35335  Loss: 0.029780 Acc: 13.2000\n",
      " |~~ train@35340  Loss: 0.023687 Acc: 13.4000\n",
      " |~~ train@35345  Loss: 0.026278 Acc: 13.4000\n",
      " |~~ train@35350  Loss: 0.026658 Acc: 13.2000\n",
      " |~~ train@35355  Loss: 0.064981 Acc: 12.4000\n",
      " |~~ train@35360  Loss: 0.030307 Acc: 13.4000\n",
      " |~~ train@35365  Loss: 0.066182 Acc: 12.8000\n",
      " |~~ train@35370  Loss: 0.022838 Acc: 13.6000\n",
      " |~~ train@35375  Loss: 0.025407 Acc: 13.4000\n",
      " |~~ train@35380  Loss: 0.030434 Acc: 13.4000\n",
      " |~~ train@35385  Loss: 0.052648 Acc: 12.8000\n",
      " |~~ train@35390  Loss: 0.059569 Acc: 12.8000\n",
      " |~~ train@35395  Loss: 0.065894 Acc: 12.8000\n",
      " |~~ train@35400  Loss: 0.040427 Acc: 13.0000\n",
      " |~~ train@35405  Loss: 0.047849 Acc: 12.8000\n",
      " |~~ train@35410  Loss: 0.039503 Acc: 13.6000\n",
      " |~~ train@35415  Loss: 0.038124 Acc: 13.0000\n",
      " |~~ train@35420  Loss: 0.037375 Acc: 13.2000\n",
      " |~~ train@35425  Loss: 0.056888 Acc: 12.8000\n",
      " |~~ train@35430  Loss: 0.030603 Acc: 13.0000\n",
      " |~~ train@35435  Loss: 0.048322 Acc: 13.0000\n",
      " |~~ train@35440  Loss: 0.037835 Acc: 13.4000\n",
      " |~~ train@35445  Loss: 0.027369 Acc: 13.4000\n",
      " |~~ train@35450  Loss: 0.062835 Acc: 12.8000\n",
      " |~~ train@35455  Loss: 0.062542 Acc: 12.6000\n",
      " |~~ train@35460  Loss: 0.036698 Acc: 13.0000\n",
      " |~~ train@35465  Loss: 0.029675 Acc: 13.4000\n",
      " |~~ train@35470  Loss: 0.024827 Acc: 13.6000\n",
      " |~~ train@35475  Loss: 0.021075 Acc: 13.6000\n",
      " |~~ train@35480  Loss: 0.018769 Acc: 13.6000\n",
      " |~~ train@35485  Loss: 0.031311 Acc: 13.2000\n",
      " |~~ train@35490  Loss: 0.032264 Acc: 13.4000\n",
      " |~~ train@35495  Loss: 0.024986 Acc: 13.6000\n",
      " |~~ train@35500  Loss: 0.017517 Acc: 13.8000\n",
      " |~~ train@35505  Loss: 0.019086 Acc: 13.6000\n",
      " |~~ train@35510  Loss: 0.045667 Acc: 13.2000\n",
      " |~~ train@35515  Loss: 0.012441 Acc: 14.0000\n",
      " |~~ train@35520  Loss: 0.024853 Acc: 13.8000\n",
      " |~~ train@35525  Loss: 0.029901 Acc: 13.6000\n",
      " |~~ train@35530  Loss: 0.041582 Acc: 13.4000\n",
      " |~~ train@35535  Loss: 0.041296 Acc: 13.0000\n",
      " |~~ train@35540  Loss: 0.015576 Acc: 13.8000\n",
      " |~~ train@35545  Loss: 0.057103 Acc: 13.0000\n",
      " |~~ train@35550  Loss: 0.049905 Acc: 12.8000\n",
      " |~~ train@35555  Loss: 0.029605 Acc: 13.6000\n",
      " |~~ train@35560  Loss: 0.024931 Acc: 13.6000\n",
      " |~~ train@35565  Loss: 0.051804 Acc: 12.8000\n",
      " |~~ train@35570  Loss: 0.013330 Acc: 13.8000\n",
      " |~~ train@35575  Loss: 0.025524 Acc: 13.4000\n",
      " |~~ train@35580  Loss: 0.015461 Acc: 13.8000\n",
      " |~~ train@35585  Loss: 0.011754 Acc: 14.0000\n",
      " |~~ train@35590  Loss: 0.040837 Acc: 13.0000\n",
      " |~~ train@35595  Loss: 0.018188 Acc: 13.6000\n",
      " |~~ train@35600  Loss: 0.029927 Acc: 13.4000\n",
      " |~~ train@35605  Loss: 0.070535 Acc: 12.6000\n",
      " |~~ train@35610  Loss: 0.025177 Acc: 13.6000\n",
      " |~~ train@35615  Loss: 0.035381 Acc: 13.2000\n",
      " |~~ train@35620  Loss: 0.036204 Acc: 13.6000\n",
      " |~~ train@35625  Loss: 0.021291 Acc: 13.4000\n",
      " |~~ train@35630  Loss: 0.084852 Acc: 12.2000\n",
      " |~~ train@35635  Loss: 0.049635 Acc: 13.0000\n",
      " |~~ train@35640  Loss: 0.078362 Acc: 12.2000\n",
      " |~~ train@35645  Loss: 0.040522 Acc: 12.8000\n",
      " |~~ train@35650  Loss: 0.035596 Acc: 13.4000\n",
      " |~~ train@35655  Loss: 0.036785 Acc: 13.2000\n",
      " |~~ train@35660  Loss: 0.036404 Acc: 13.2000\n",
      " |~~ train@35665  Loss: 0.010876 Acc: 14.0000\n",
      " |~~ train@35670  Loss: 0.028726 Acc: 13.2000\n",
      " |~~ train@35675  Loss: 0.031456 Acc: 13.4000\n",
      " |~~ train@35680  Loss: 0.026806 Acc: 13.6000\n",
      " |~~ train@35685  Loss: 0.031604 Acc: 13.4000\n",
      " |~~ train@35690  Loss: 0.015521 Acc: 13.8000\n",
      " |~~ train@35695  Loss: 0.040725 Acc: 13.2000\n",
      " |~~ train@35700  Loss: 0.019530 Acc: 13.6000\n",
      " |~~ train@35705  Loss: 0.036339 Acc: 13.2000\n",
      " |~~ train@35710  Loss: 0.022362 Acc: 13.6000\n",
      " |~~ train@35715  Loss: 0.035627 Acc: 13.2000\n",
      " |~~ train@35720  Loss: 0.031479 Acc: 13.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@35725  Loss: 0.021925 Acc: 13.6000\n",
      " |~~ train@35730  Loss: 0.064718 Acc: 12.4000\n",
      " |~~ train@35735  Loss: 0.039982 Acc: 13.2000\n",
      " |~~ train@35740  Loss: 0.022106 Acc: 13.6000\n",
      " |~~ train@35745  Loss: 0.036637 Acc: 13.0000\n",
      " |~~ train@35750  Loss: 0.034347 Acc: 13.2000\n",
      " |~~ train@35755  Loss: 0.038805 Acc: 13.0000\n",
      " |~~ train@35760  Loss: 0.054529 Acc: 12.8000\n",
      " |~~ train@35765  Loss: 0.041706 Acc: 13.2000\n",
      " |~~ train@35770  Loss: 0.018927 Acc: 13.6000\n",
      " |~~ train@35775  Loss: 0.034565 Acc: 13.2000\n",
      " |~~ train@35780  Loss: 0.020352 Acc: 13.6000\n",
      " |~~ train@35785  Loss: 0.011867 Acc: 14.0000\n",
      " |~~ train@35790  Loss: 0.049459 Acc: 13.0000\n",
      " |~~ train@35795  Loss: 0.053440 Acc: 12.6000\n",
      " |~~ train@35800  Loss: 0.040671 Acc: 13.2000\n",
      " |~~ train@35805  Loss: 0.016577 Acc: 13.8000\n",
      " |~~ train@35810  Loss: 0.014636 Acc: 13.8000\n",
      " |~~ train@35815  Loss: 0.037486 Acc: 13.2000\n",
      " |~~ train@35820  Loss: 0.021282 Acc: 13.6000\n",
      " |~~ train@35825  Loss: 0.022359 Acc: 13.6000\n",
      " |~~ train@35830  Loss: 0.056864 Acc: 12.8000\n",
      " |~~ train@35835  Loss: 0.037580 Acc: 13.4000\n",
      " |~~ train@35840  Loss: 0.020271 Acc: 13.6000\n",
      " |~~ train@35845  Loss: 0.011357 Acc: 14.0000\n",
      " |~~ train@35850  Loss: 0.024771 Acc: 13.6000\n",
      " |~~ train@35855  Loss: 0.048056 Acc: 13.0000\n",
      " |~~ train@35860  Loss: 0.040173 Acc: 13.2000\n",
      " |~~ train@35865  Loss: 0.024230 Acc: 13.4000\n",
      " |~~ train@35870  Loss: 0.030807 Acc: 13.4000\n",
      " |~~ train@35875  Loss: 0.051248 Acc: 13.2000\n",
      " |~~ train@35880  Loss: 0.018718 Acc: 13.8000\n",
      " |~~ train@35885  Loss: 0.039975 Acc: 13.4000\n",
      " |~~ train@35890  Loss: 0.027174 Acc: 13.4000\n",
      " |~~ train@35895  Loss: 0.018726 Acc: 13.8000\n",
      " |~~ train@35900  Loss: 0.056188 Acc: 13.0000\n",
      " |~~ train@35905  Loss: 0.051590 Acc: 13.0000\n",
      " |~~ train@35910  Loss: 0.024812 Acc: 13.2000\n",
      " |~~ train@35915  Loss: 0.079207 Acc: 12.4000\n",
      " |~~ train@35920  Loss: 0.009677 Acc: 14.0000\n",
      " |~~ train@35925  Loss: 0.022980 Acc: 13.4000\n",
      " |~~ train@35930  Loss: 0.033367 Acc: 13.4000\n",
      " |~~ train@35935  Loss: 0.045618 Acc: 13.0000\n",
      " |~~ train@35940  Loss: 0.045098 Acc: 13.0000\n",
      " |~~ train@35945  Loss: 0.058791 Acc: 12.8000\n",
      " |~~ train@35950  Loss: 0.041393 Acc: 13.4000\n",
      " |~~ train@35955  Loss: 0.009666 Acc: 14.0000\n",
      " |~~ train@35960  Loss: 0.016359 Acc: 13.8000\n",
      " |~~ train@35965  Loss: 0.018843 Acc: 13.8000\n",
      " |~~ train@35970  Loss: 0.037979 Acc: 13.2000\n",
      " |~~ train@35975  Loss: 0.026492 Acc: 13.4000\n",
      " |~~ train@35980  Loss: 0.015478 Acc: 13.8000\n",
      " |~~ train@35985  Loss: 0.025355 Acc: 13.4000\n",
      " |~~ train@35990  Loss: 0.041966 Acc: 13.2000\n",
      " |~~ train@35995  Loss: 0.047885 Acc: 13.0000\n",
      " |~~ train@36000  Loss: 0.012326 Acc: 13.8000\n",
      " |~~ train@36005  Loss: 0.026876 Acc: 13.4000\n",
      " |~~ train@36010  Loss: 0.036661 Acc: 13.4000\n",
      " |~~ train@36015  Loss: 0.043588 Acc: 13.0000\n",
      " |~~ train@36020  Loss: 0.057853 Acc: 12.6000\n",
      " |~~ train@36025  Loss: 0.037244 Acc: 13.2000\n",
      " |~~ train@36030  Loss: 0.026879 Acc: 13.4000\n",
      " |~~ train@36035  Loss: 0.036264 Acc: 13.2000\n",
      " |~~ train@36040  Loss: 0.030447 Acc: 13.2000\n",
      " |~~ train@36045  Loss: 0.023674 Acc: 13.6000\n",
      " |~~ train@36050  Loss: 0.018031 Acc: 13.8000\n",
      " |~~ train@36055  Loss: 0.015171 Acc: 13.8000\n",
      " |~~ train@36060  Loss: 0.050589 Acc: 13.0000\n",
      " |~~ train@36065  Loss: 0.019888 Acc: 13.6000\n",
      " |~~ train@36070  Loss: 0.015557 Acc: 13.8000\n",
      " |~~ train@36075  Loss: 0.034168 Acc: 13.4000\n",
      " |~~ train@36080  Loss: 0.017257 Acc: 13.8000\n",
      " |~~ train@36085  Loss: 0.036345 Acc: 13.2000\n",
      " |~~ train@36090  Loss: 0.037128 Acc: 13.2000\n",
      " |~~ train@36095  Loss: 0.041237 Acc: 13.2000\n",
      " |~~ train@36100  Loss: 0.038906 Acc: 13.0000\n",
      " |~~ train@36105  Loss: 0.059526 Acc: 12.6000\n",
      " |~~ train@36110  Loss: 0.044103 Acc: 13.0000\n",
      " |~~ train@36115  Loss: 0.050095 Acc: 12.6000\n",
      " |~~ train@36120  Loss: 0.010231 Acc: 14.0000\n",
      " |~~ train@36125  Loss: 0.057351 Acc: 12.6000\n",
      " |~~ train@36130  Loss: 0.017985 Acc: 13.6000\n",
      " |~~ train@36135  Loss: 0.033961 Acc: 13.6000\n",
      " |~~ train@36140  Loss: 0.039995 Acc: 13.0000\n",
      " |~~ train@36145  Loss: 0.027280 Acc: 13.6000\n",
      " |~~ train@36150  Loss: 0.047987 Acc: 13.0000\n",
      " |~~ train@36155  Loss: 0.052479 Acc: 12.8000\n",
      " |~~ train@36160  Loss: 0.035225 Acc: 13.2000\n",
      " |~~ train@36165  Loss: 0.050028 Acc: 13.2000\n",
      " |~~ train@36170  Loss: 0.018132 Acc: 13.8000\n",
      " |~~ train@36175  Loss: 0.037210 Acc: 13.2000\n",
      " |~~ train@36180  Loss: 0.030009 Acc: 13.6000\n",
      " |~~ train@36185  Loss: 0.030209 Acc: 13.4000\n",
      " |~~ train@36190  Loss: 0.053661 Acc: 12.8000\n",
      " |~~ train@36195  Loss: 0.018262 Acc: 13.8000\n",
      " |~~ train@36200  Loss: 0.034986 Acc: 13.2000\n",
      " |~~ train@36205  Loss: 0.053497 Acc: 12.8000\n",
      " |~~ train@36210  Loss: 0.041611 Acc: 13.0000\n",
      " |~~ train@36215  Loss: 0.038045 Acc: 13.2000\n",
      " |~~ train@36220  Loss: 0.039385 Acc: 13.2000\n",
      " |~~ train@36225  Loss: 0.039037 Acc: 13.4000\n",
      " |~~ train@36230  Loss: 0.026075 Acc: 13.6000\n",
      " |~~ train@36235  Loss: 0.023746 Acc: 13.6000\n",
      " |~~ train@36240  Loss: 0.029329 Acc: 13.6000\n",
      " |~~ train@36245  Loss: 0.020752 Acc: 13.8000\n",
      " |~~ train@36250  Loss: 0.026012 Acc: 13.4000\n",
      " |~~ train@36255  Loss: 0.062880 Acc: 12.6000\n",
      " |~~ train@36260  Loss: 0.010619 Acc: 14.0000\n",
      " |~~ train@36265  Loss: 0.052844 Acc: 12.8000\n",
      " |~~ train@36270  Loss: 0.017541 Acc: 13.8000\n",
      " |~~ train@36275  Loss: 0.030219 Acc: 13.4000\n",
      " |~~ train@36280  Loss: 0.022995 Acc: 13.6000\n",
      " |~~ train@36285  Loss: 0.037564 Acc: 13.2000\n",
      " |~~ train@36290  Loss: 0.013847 Acc: 13.8000\n",
      " |~~ train@36295  Loss: 0.048605 Acc: 13.0000\n",
      " |~~ train@36300  Loss: 0.032548 Acc: 13.6000\n",
      " |~~ train@36305  Loss: 0.015929 Acc: 13.8000\n",
      " |~~ train@36310  Loss: 0.061851 Acc: 12.6000\n",
      " |~~ train@36315  Loss: 0.028238 Acc: 13.4000\n",
      " |~~ train@36320  Loss: 0.048322 Acc: 12.8000\n",
      " |~~ train@36325  Loss: 0.041002 Acc: 13.0000\n",
      " |~~ train@36330  Loss: 0.011262 Acc: 14.0000\n",
      " |~~ train@36335  Loss: 0.028217 Acc: 13.4000\n",
      " |~~ train@36340  Loss: 0.028797 Acc: 13.6000\n",
      " |~~ train@36345  Loss: 0.044946 Acc: 13.0000\n",
      " |~~ train@36350  Loss: 0.028591 Acc: 13.6000\n",
      " |~~ train@36355  Loss: 0.051458 Acc: 13.0000\n",
      " |~~ train@36360  Loss: 0.055237 Acc: 13.2000\n",
      " |~~ train@36365  Loss: 0.026698 Acc: 13.6000\n",
      " |~~ train@36370  Loss: 0.018904 Acc: 13.6000\n",
      " |~~ train@36375  Loss: 0.020430 Acc: 13.6000\n",
      " |~~ train@36380  Loss: 0.019837 Acc: 13.6000\n",
      " |~~ train@36385  Loss: 0.048073 Acc: 13.0000\n",
      " |~~ train@36390  Loss: 0.015467 Acc: 13.6000\n",
      " |~~ train@36395  Loss: 0.053060 Acc: 12.6000\n",
      " |~~ train@36400  Loss: 0.021648 Acc: 13.6000\n",
      " |~~ train@36405  Loss: 0.074915 Acc: 12.6000\n",
      " |~~ train@36410  Loss: 0.041989 Acc: 13.0000\n",
      " |~~ train@36415  Loss: 0.029001 Acc: 13.4000\n",
      " |~~ train@36420  Loss: 0.028783 Acc: 13.4000\n",
      " |~~ train@36425  Loss: 0.053647 Acc: 13.0000\n",
      " |~~ train@36430  Loss: 0.035872 Acc: 13.4000\n",
      " |~~ train@36435  Loss: 0.054425 Acc: 13.0000\n",
      " |~~ train@36440  Loss: 0.056854 Acc: 12.8000\n",
      " |~~ train@36445  Loss: 0.018515 Acc: 13.8000\n",
      " |~~ train@36450  Loss: 0.038499 Acc: 13.0000\n",
      " |~~ train@36455  Loss: 0.015032 Acc: 13.8000\n",
      " |~~ train@36460  Loss: 0.018362 Acc: 13.6000\n",
      " |~~ train@36465  Loss: 0.024801 Acc: 13.4000\n",
      " |~~ train@36470  Loss: 0.049343 Acc: 13.0000\n",
      " |~~ train@36475  Loss: 0.013105 Acc: 13.8000\n",
      " |~~ train@36480  Loss: 0.030814 Acc: 13.4000\n",
      " |~~ train@36485  Loss: 0.036462 Acc: 13.2000\n",
      " |~~ train@36490  Loss: 0.072748 Acc: 12.4000\n",
      " |~~ train@36495  Loss: 0.020636 Acc: 13.6000\n",
      " |~~ train@36500  Loss: 0.039775 Acc: 13.2000\n",
      " |~~ train@36505  Loss: 0.079175 Acc: 11.8000\n",
      " |~~ train@36510  Loss: 0.020201 Acc: 13.6000\n",
      " |~~ train@36515  Loss: 0.037092 Acc: 13.0000\n",
      " |~~ train@36520  Loss: 0.020790 Acc: 13.8000\n",
      " |~~ train@36525  Loss: 0.030600 Acc: 13.2000\n",
      " |~~ train@36530  Loss: 0.018165 Acc: 13.8000\n",
      " |~~ train@36535  Loss: 0.054318 Acc: 12.8000\n",
      " |~~ train@36540  Loss: 0.027103 Acc: 13.6000\n",
      " |~~ train@36545  Loss: 0.035532 Acc: 13.2000\n",
      " |~~ train@36550  Loss: 0.028006 Acc: 13.6000\n",
      " |~~ train@36555  Loss: 0.024949 Acc: 13.4000\n",
      " |~~ train@36560  Loss: 0.028043 Acc: 13.6000\n",
      " |~~ train@36565  Loss: 0.021379 Acc: 13.8000\n",
      " |~~ train@36570  Loss: 0.022887 Acc: 13.6000\n",
      " |~~ train@36575  Loss: 0.051516 Acc: 12.8000\n",
      " |~~ train@36580  Loss: 0.015144 Acc: 13.8000\n",
      " |~~ train@36585  Loss: 0.037589 Acc: 13.2000\n",
      " |~~ train@36590  Loss: 0.066461 Acc: 12.2000\n",
      " |~~ train@36595  Loss: 0.029984 Acc: 13.6000\n",
      " |~~ train@36600  Loss: 0.070168 Acc: 12.4000\n",
      " |~~ train@36605  Loss: 0.019028 Acc: 13.6000\n",
      " |~~ train@36610  Loss: 0.031828 Acc: 13.4000\n",
      " |~~ train@36615  Loss: 0.071151 Acc: 12.4000\n",
      " |~~ train@36620  Loss: 0.032734 Acc: 13.0000\n",
      " |~~ train@36625  Loss: 0.017428 Acc: 13.6000\n",
      " |~~ train@36630  Loss: 0.024508 Acc: 13.4000\n",
      " |~~ train@36635  Loss: 0.010724 Acc: 14.0000\n",
      " |~~ train@36640  Loss: 0.031552 Acc: 13.2000\n",
      " |~~ train@36645  Loss: 0.032538 Acc: 13.0000\n",
      " |~~ train@36650  Loss: 0.014862 Acc: 13.8000\n",
      " |~~ train@36655  Loss: 0.029688 Acc: 13.4000\n",
      " |~~ train@36660  Loss: 0.062040 Acc: 12.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@36665  Loss: 0.039034 Acc: 13.4000\n",
      " |~~ train@36670  Loss: 0.038779 Acc: 13.4000\n",
      " |~~ train@36675  Loss: 0.024839 Acc: 13.4000\n",
      " |~~ train@36680  Loss: 0.057202 Acc: 12.8000\n",
      " |~~ train@36685  Loss: 0.037849 Acc: 13.2000\n",
      " |~~ train@36690  Loss: 0.051892 Acc: 13.2000\n",
      " |~~ train@36695  Loss: 0.014610 Acc: 13.8000\n",
      " |~~ train@36700  Loss: 0.012461 Acc: 13.8000\n",
      " |~~ train@36705  Loss: 0.021765 Acc: 13.6000\n",
      " |~~ train@36710  Loss: 0.048927 Acc: 12.6000\n",
      " |~~ train@36715  Loss: 0.054524 Acc: 13.2000\n",
      " |~~ train@36720  Loss: 0.026868 Acc: 13.4000\n",
      " |~~ train@36725  Loss: 0.045738 Acc: 13.2000\n",
      " |~~ train@36730  Loss: 0.025833 Acc: 13.6000\n",
      " |~~ train@36735  Loss: 0.011076 Acc: 14.0000\n",
      " |~~ train@36740  Loss: 0.035727 Acc: 13.4000\n",
      " |~~ train@36745  Loss: 0.056893 Acc: 12.6000\n",
      " |~~ train@36750  Loss: 0.023955 Acc: 13.6000\n",
      " |~~ train@36755  Loss: 0.074555 Acc: 12.2000\n",
      " |~~ train@36760  Loss: 0.047706 Acc: 13.0000\n",
      " |~~ train@36765  Loss: 0.025031 Acc: 13.6000\n",
      " |~~ train@36770  Loss: 0.030983 Acc: 13.2000\n",
      " |~~ train@36775  Loss: 0.017930 Acc: 13.8000\n",
      " |~~ train@36780  Loss: 0.010953 Acc: 14.0000\n",
      " |~~ train@36785  Loss: 0.021908 Acc: 13.8000\n",
      " |~~ train@36790  Loss: 0.029849 Acc: 13.4000\n",
      " |~~ train@36795  Loss: 0.046216 Acc: 13.0000\n",
      " |~~ train@36800  Loss: 0.060887 Acc: 12.8000\n",
      " |~~ train@36805  Loss: 0.038818 Acc: 13.4000\n",
      " |~~ train@36810  Loss: 0.010083 Acc: 14.0000\n",
      " |~~ train@36815  Loss: 0.010025 Acc: 14.0000\n",
      " |~~ train@36820  Loss: 0.027484 Acc: 13.4000\n",
      " |~~ train@36825  Loss: 0.033661 Acc: 13.4000\n",
      " |~~ train@36830  Loss: 0.010694 Acc: 14.0000\n",
      " |~~ train@36835  Loss: 0.018179 Acc: 13.8000\n",
      " |~~ train@36840  Loss: 0.048952 Acc: 12.8000\n",
      " |~~ train@36845  Loss: 0.030463 Acc: 13.4000\n",
      " |~~ train@36850  Loss: 0.042726 Acc: 13.0000\n",
      " |~~ train@36855  Loss: 0.025742 Acc: 13.4000\n",
      " |~~ train@36860  Loss: 0.029596 Acc: 13.4000\n",
      " |~~ train@36865  Loss: 0.043745 Acc: 13.0000\n",
      " |~~ train@36870  Loss: 0.054217 Acc: 13.0000\n",
      " |~~ train@36875  Loss: 0.061253 Acc: 12.6000\n",
      " |~~ train@36880  Loss: 0.016061 Acc: 13.6000\n",
      " |~~ train@36885  Loss: 0.018014 Acc: 13.8000\n",
      " |~~ train@36890  Loss: 0.080877 Acc: 12.2000\n",
      " |~~ train@36895  Loss: 0.015859 Acc: 13.8000\n",
      " |~~ train@36900  Loss: 0.053259 Acc: 12.6000\n",
      " |~~ train@36905  Loss: 0.032355 Acc: 13.2000\n",
      " |~~ train@36910  Loss: 0.036730 Acc: 13.2000\n",
      " |~~ train@36915  Loss: 0.013366 Acc: 13.8000\n",
      " |~~ train@36920  Loss: 0.028217 Acc: 13.6000\n",
      " |~~ train@36925  Loss: 0.035870 Acc: 13.0000\n",
      " |~~ train@36930  Loss: 0.027801 Acc: 13.4000\n",
      " |~~ train@36935  Loss: 0.017391 Acc: 13.8000\n",
      " |~~ train@36940  Loss: 0.047256 Acc: 13.0000\n",
      " |~~ train@36945  Loss: 0.050084 Acc: 12.8000\n",
      " |~~ train@36950  Loss: 0.067151 Acc: 12.8000\n",
      " |~~ train@36955  Loss: 0.036888 Acc: 13.4000\n",
      " |~~ train@36960  Loss: 0.042939 Acc: 13.4000\n",
      " |~~ train@36965  Loss: 0.010739 Acc: 14.0000\n",
      " |~~ train@36970  Loss: 0.015559 Acc: 13.8000\n",
      " |~~ train@36975  Loss: 0.036773 Acc: 13.4000\n",
      " |~~ train@36980  Loss: 0.020476 Acc: 13.8000\n",
      " |~~ train@36985  Loss: 0.022425 Acc: 13.6000\n",
      " |~~ train@36990  Loss: 0.062037 Acc: 12.4000\n",
      " |~~ train@36995  Loss: 0.062262 Acc: 12.6000\n",
      " |~~ train@37000  Loss: 0.014852 Acc: 13.8000\n",
      " |~~ train@37005  Loss: 0.020188 Acc: 13.6000\n",
      " |~~ train@37010  Loss: 0.024356 Acc: 13.6000\n",
      " |~~ train@37015  Loss: 0.047773 Acc: 13.2000\n",
      " |~~ train@37020  Loss: 0.045252 Acc: 13.2000\n",
      " |~~ train@37025  Loss: 0.019032 Acc: 13.8000\n",
      " |~~ train@37030  Loss: 0.042470 Acc: 13.0000\n",
      " |~~ train@37035  Loss: 0.055598 Acc: 12.6000\n",
      " |~~ train@37040  Loss: 0.034715 Acc: 13.4000\n",
      " |~~ train@37045  Loss: 0.020785 Acc: 13.8000\n",
      " |~~ train@37050  Loss: 0.027161 Acc: 13.4000\n",
      " |~~ train@37055  Loss: 0.037597 Acc: 13.4000\n",
      " |~~ train@37060  Loss: 0.035406 Acc: 13.4000\n",
      " |~~ train@37065  Loss: 0.047558 Acc: 13.2000\n",
      " |~~ train@37070  Loss: 0.038868 Acc: 13.2000\n",
      " |~~ train@37075  Loss: 0.014688 Acc: 13.8000\n",
      " |~~ train@37080  Loss: 0.018007 Acc: 13.8000\n",
      " |~~ train@37085  Loss: 0.067198 Acc: 12.4000\n",
      " |~~ train@37090  Loss: 0.009909 Acc: 14.0000\n",
      " |~~ train@37095  Loss: 0.040666 Acc: 13.0000\n",
      " |~~ train@37100  Loss: 0.025861 Acc: 13.4000\n",
      " |~~ train@37105  Loss: 0.032139 Acc: 13.4000\n",
      " |~~ train@37110  Loss: 0.058051 Acc: 12.8000\n",
      " |~~ train@37115  Loss: 0.047247 Acc: 13.0000\n",
      " |~~ train@37120  Loss: 0.034385 Acc: 13.4000\n",
      " |~~ train@37125  Loss: 0.042740 Acc: 13.2000\n",
      " |~~ train@37130  Loss: 0.026774 Acc: 13.6000\n",
      " |~~ train@37135  Loss: 0.038420 Acc: 13.2000\n",
      " |~~ train@37140  Loss: 0.043373 Acc: 13.2000\n",
      " |~~ train@37145  Loss: 0.022615 Acc: 13.6000\n",
      " |~~ train@37150  Loss: 0.037014 Acc: 13.4000\n",
      " |~~ train@37155  Loss: 0.028893 Acc: 13.4000\n",
      " |~~ train@37160  Loss: 0.031558 Acc: 13.4000\n",
      " |~~ train@37165  Loss: 0.041304 Acc: 13.0000\n",
      " |~~ train@37170  Loss: 0.042102 Acc: 13.2000\n",
      " |~~ train@37175  Loss: 0.029693 Acc: 13.4000\n",
      " |~~ train@37180  Loss: 0.044193 Acc: 13.0000\n",
      " |~~ train@37185  Loss: 0.054527 Acc: 12.8000\n",
      " |~~ train@37190  Loss: 0.021208 Acc: 13.8000\n",
      " |~~ train@37195  Loss: 0.027692 Acc: 13.6000\n",
      " |~~ train@37200  Loss: 0.083981 Acc: 11.8000\n",
      " |~~ train@37205  Loss: 0.037691 Acc: 13.0000\n",
      " |~~ train@37210  Loss: 0.021740 Acc: 13.6000\n",
      " |~~ train@37215  Loss: 0.020077 Acc: 13.8000\n",
      " |~~ train@37220  Loss: 0.009883 Acc: 14.0000\n",
      " |~~ train@37225  Loss: 0.019374 Acc: 13.6000\n",
      " |~~ train@37230  Loss: 0.053476 Acc: 13.0000\n",
      " |~~ train@37235  Loss: 0.049503 Acc: 13.0000\n",
      " |~~ train@37240  Loss: 0.019775 Acc: 13.8000\n",
      " |~~ train@37245  Loss: 0.019618 Acc: 13.6000\n",
      " |~~ train@37250  Loss: 0.046718 Acc: 13.0000\n",
      " |~~ train@37255  Loss: 0.039500 Acc: 13.0000\n",
      " |~~ train@37260  Loss: 0.073571 Acc: 12.6000\n",
      " |~~ train@37265  Loss: 0.024160 Acc: 13.6000\n",
      " |~~ train@37270  Loss: 0.023365 Acc: 13.4000\n",
      " |~~ train@37275  Loss: 0.077599 Acc: 12.4000\n",
      " |~~ train@37280  Loss: 0.034033 Acc: 13.4000\n",
      " |~~ train@37285  Loss: 0.077666 Acc: 12.2000\n",
      " |~~ train@37290  Loss: 0.021811 Acc: 13.8000\n",
      " |~~ train@37295  Loss: 0.051736 Acc: 13.0000\n",
      " |~~ train@37300  Loss: 0.023037 Acc: 13.6000\n",
      " |~~ train@37305  Loss: 0.031642 Acc: 13.2000\n",
      " |~~ train@37310  Loss: 0.036986 Acc: 13.4000\n",
      " |~~ train@37315  Loss: 0.027338 Acc: 13.4000\n",
      " |~~ train@37320  Loss: 0.016294 Acc: 13.8000\n",
      " |~~ train@37325  Loss: 0.032246 Acc: 13.2000\n",
      " |~~ train@37330  Loss: 0.042513 Acc: 13.0000\n",
      " |~~ train@37335  Loss: 0.061640 Acc: 12.8000\n",
      " |~~ train@37340  Loss: 0.014654 Acc: 13.6000\n",
      " |~~ train@37345  Loss: 0.033130 Acc: 13.2000\n",
      " |~~ train@37350  Loss: 0.031695 Acc: 13.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-29:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-25:\n",
      "Process Process-23:\n",
      "Process Process-21:\n",
      "Traceback (most recent call last):\n",
      "Process Process-26:\n",
      "Traceback (most recent call last):\n",
      "Process Process-28:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-3-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-24:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |~~ train@37355  Loss: 0.020940 Acc: 13.8000\n",
      " |~~ train@37360  Loss: 0.046885 Acc: 13.0000\n",
      " |~~ train@37365  Loss: 0.024683 Acc: 13.6000\n",
      " |~~ train@37370  Loss: 0.015186 Acc: 13.8000\n",
      " |~~ train@37375  Loss: 0.037839 Acc: 13.2000\n",
      " |~~ train@37380  Loss: 0.045156 Acc: 13.0000\n",
      " |~~ train@37385  Loss: 0.030542 Acc: 13.4000\n",
      " |~~ train@37390  Loss: 0.022626 Acc: 13.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "Process Process-30:\n",
      "  File \"<ipython-input-3-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"<ipython-input-3-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 42, in __getitem__\n",
      "    target = self.get_one_hot_labels(fname)\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 45, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 234, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 75, in get_one_hot_labels\n",
      "    labels = self.get_labels(fname)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 212, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 234, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 57, in get_labels\n",
      "    return self.image_details[self.image_details['Image Index'] == fname]['Finding Labels'].values[0]\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 608, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 42, in __getitem__\n",
      "    target = self.get_one_hot_labels(fname)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms/transforms.py\", line 147, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\", line 879, in wrapper\n",
      "    res = na_op(values, other)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms/functional.py\", line 197, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 75, in get_one_hot_labels\n",
      "    labels = self.get_labels(fname)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\", line 783, in na_op\n",
      "    result = _comp_method_OBJECT_ARRAY(op, x, y)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 1712, in resize\n",
      "    return self._new(self.im.resize(size, resample))\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 57, in get_labels\n",
      "    return self.image_details[self.image_details['Image Index'] == fname]['Finding Labels'].values[0]\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\", line 763, in _comp_method_OBJECT_ARRAY\n",
      "    result = lib.scalar_compare(x, y, op)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 45, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms/transforms.py\", line 147, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms/functional.py\", line 197, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 1712, in resize\n",
      "    return self._new(self.im.resize(size, resample))\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 2133, in __getitem__\n",
      "    return self._getitem_array(key)\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 42, in __getitem__\n",
      "    target = self.get_one_hot_labels(fname)\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _pin_memory_loop\n",
      "    r = in_queue.get()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-0f9efe16d4ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             num_epochs=10)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-e3e23468b1d7>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs, outfolder)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-22:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 2175, in _getitem_array\n",
      "    return self._take(indexer, axis=0, convert=False)\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 75, in get_one_hot_labels\n",
      "    labels = self.get_labels(fname)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\", line 2150, in _take\n",
      "    verify=True)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 4259, in take\n",
      "    axis=axis, allow_dups=True)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 4145, in reindex_indexer\n",
      "    for blk in self.blocks]\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 4145, in <listcomp>\n",
      "    for blk in self.blocks]\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 57, in get_labels\n",
      "    return self.image_details[self.image_details['Image Index'] == fname]['Finding Labels'].values[0]\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 1236, in take_nd\n",
      "    return self.make_block_same_class(new_values, new_mgr_locs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\", line 879, in wrapper\n",
      "    res = na_op(values, other)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 224, in make_block_same_class\n",
      "    fastpath=fastpath, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 2952, in make_block\n",
      "    return klass(values, ndim=ndim, fastpath=fastpath, placement=placement)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\", line 783, in na_op\n",
      "    result = _comp_method_OBJECT_ARRAY(op, x, y)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 2077, in __init__\n",
      "    placement=placement, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\", line 763, in _comp_method_OBJECT_ARRAY\n",
      "    result = lib.scalar_compare(x, y, op)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 114, in __init__\n",
      "    self.mgr_locs = placement\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\", line 226, in mgr_locs\n",
      "    @mgr_locs.setter\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"<ipython-input-3-4cc34eea5387>\", line 68, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 860, in convert\n",
      "    self.load()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 212, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 608, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "Process Process-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-4-21cc0ac35a56>\", line 43, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"<ipython-input-3-4cc34eea5387>\", line 67, in pil_loader\n",
      "    with Image.open(f) as img:\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 2486, in open\n",
      "    prefix = fp.read(16)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "train_model(model_ft,\n",
    "            criterion,\n",
    "            optimizer_ft,\n",
    "            exp_lr_scheduler,\n",
    "            num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model results to S3\n",
    "\n",
    "aws s3 cp ResNet18PlusFlexibleFC_Epoch9.tar s3://bdh-xrayproj-modelparameters/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.list_buckets()\n",
    "\n",
    "S3 Commands: http://docs.aws.amazon.com/cli/latest/userguide/using-s3-commands.html\n",
    "\n",
    "Boto3 QuickStart: http://boto3.readthedocs.io/en/latest/guide/quickstart.html\n",
    "\n",
    "Key Management: https://aws.amazon.com/blogs/security/a-safer-way-to-distribute-aws-credentials-to-ec2/\n",
    "\n",
    "AWS IAM Rules: http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model results back from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_lr_scheduler.last_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ed2ea89b-99da-4fde-a3ac-91d4d4e3865a"
    }
   },
   "source": [
    "# Analysis of Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "nbpresent": {
     "id": "9235665b-a758-4c35-a922-55466a19bd44"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING ITERATION...\n",
      "PROCESSING FIRST 750 OBSERVATIONS\n",
      "STARTING ITERATION...\n",
      "PROCESSING FIRST 406 OBSERVATIONS\n"
     ]
    }
   ],
   "source": [
    "out_model_30.train(mode=False)\n",
    "\n",
    "obs_counter = 0\n",
    "total_pred = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "total_act = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "\n",
    "conf_a = {}\n",
    "conf_b = {}\n",
    "conf_c = {}\n",
    "conf_d = {}\n",
    "for i in range(1,10):\n",
    "    conf_a[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_b[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_c[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "    conf_d[i] = Variable(torch.FloatTensor(torch.zeros(14)))\n",
    "\n",
    "for data in dataloaders['val']:\n",
    "    print(\"STARTING ITERATION...\")\n",
    "    inputs, labels = data\n",
    "    print(\"PROCESSING FIRST {} OBSERVATIONS\".format(len(inputs)))\n",
    "\n",
    "    inputs = Variable(inputs.cuda())\n",
    "    labels = Variable(labels.cuda())\n",
    "\n",
    "    outputs = out_model_30(inputs).sigmoid()\n",
    "    \n",
    "    total_act += labels.sum(0).cpu()\n",
    "    total_pred += outputs.sum(0).cpu()\n",
    "\n",
    "    # Store statistics (convert from autograd.Variable to float/int)\n",
    "    for i in range(1,10):\n",
    "        t = i/10\n",
    "        conf_a[i] += ((outputs.sigmoid()>t) == (labels>0.5)).sum(0).cpu().float()\n",
    "        conf_b[i] += ((outputs.sigmoid()<t) == (labels>0.5)).sum(0).cpu().float()\n",
    "        conf_c[i] += ((outputs.sigmoid()>t) == (labels<0.5)).sum(0).cpu().float()\n",
    "        conf_d[i] += ((outputs.sigmoid()<t) == (labels<0.5)).sum(0).cpu().float()\n",
    "\n",
    "    obs_counter += len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "nbpresent": {
     "id": "82758b84-e7ce-48d3-a3e1-f012ab124eea"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00 -2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00 -2.1475e+09  0.0000e+00 -2.1475e+09  0.0000e+00\n",
      " 6.2634e+06 -1.0000e+00 -2.1475e+09  0.0000e+00 -2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "Columns 6 to 11 \n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00 -6.5460e+04  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "-2.1475e+09  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "-2.1475e+09  0.0000e+00 -2.1475e+09 -2.1475e+09 -2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "Columns 12 to 13 \n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      "-2.1475e+09  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00\n",
      "[torch.IntTensor of size 9x14]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comparison = Variable(torch.FloatTensor(9, 14))\n",
    "for i in range(9):\n",
    "    comparison[0] = conf_a[1] / obs_counter\n",
    "print(comparison.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "nbpresent": {
     "id": "b5bbfb54-d465-4c52-90ea-fff045789b9b"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.3183\n",
       " 0.1462\n",
       " 0.3356\n",
       " 0.2171\n",
       " 0.3166\n",
       " 0.3183\n",
       " 0.2803\n",
       " 0.2898\n",
       " 0.2232\n",
       " 0.3279\n",
       " 0.2846\n",
       " 0.3045\n",
       " 0.3002\n",
       " 0.3192\n",
       "[torch.FloatTensor of size 14]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_d[9] / obs_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "nbpresent": {
     "id": "2b02d75e-a8b2-4d29-a9c3-27903e05d160"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fibrosis',\n",
       " 'Infiltration',\n",
       " 'Hernia',\n",
       " 'Effusion',\n",
       " 'Emphysema',\n",
       " 'Edema',\n",
       " 'Cardiomegaly',\n",
       " 'Mass',\n",
       " 'Nodule',\n",
       " 'Atelectasis',\n",
       " 'Pneumothorax',\n",
       " 'Pleural_Thickening',\n",
       " 'Consolidation',\n",
       " 'Pneumonia']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data_train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "nbpresent": {
     "id": "4feafc69-38b0-41e8-b670-92c3aa26bfff"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'state': model.state_dict(),\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "            'val_error': val_error\n",
    "        }, model_out_path)\n",
    "'''\n",
    "test_load = torch.load('/user/xrayproj/output/20171120-01h41m56s_model_9.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'state', 'optimizer', 'scheduler', 'val_error'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_load.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_opt = test_load['optimizer']\n",
    "load_sched = test_load['scheduler']\n",
    "load_state = test_load['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.resnet18(pretrained=True)\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace FC layer\n",
    "model2.fc = nn.Linear(model2.fc.in_features, len(img_data_train.labels))\n",
    "\n",
    "model2_c = DataParallel(model2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_c.load_state_dict(load_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.7873  0.5093  0.2980  0.6386  0.4665  0.3371  0.1614  0.1846  0.1925  0.6630\n",
       "\n",
       "Columns 10 to 13 \n",
       " 0.0288  0.4468  0.3684  0.2549\n",
       "[torch.cuda.FloatTensor of size 1x14 (GPU 0)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_c.forward(Variable(img_data_train[0][0].unsqueeze(0).cuda())).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
